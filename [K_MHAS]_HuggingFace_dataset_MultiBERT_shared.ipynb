{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9moVKInibnca",
        "dryCfxh4btMS",
        "wqqbD-tBcehO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "593d3b82c197440f9bd091bfed9aa536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38373b0b07fc4c048870dd5eb81981fe",
              "IPY_MODEL_aaf21922bf804e66baf07e85e5ff248d",
              "IPY_MODEL_1126b608f8504b61a8b93a556c01adaf"
            ],
            "layout": "IPY_MODEL_edb4e52323664c1b99fa0665caa9f299"
          }
        },
        "38373b0b07fc4c048870dd5eb81981fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f9ce4e5b8a432da0655dec1b66c3a9",
            "placeholder": "​",
            "style": "IPY_MODEL_8a1e088dac59469dab3198479729d102",
            "value": "README.md: 100%"
          }
        },
        "aaf21922bf804e66baf07e85e5ff248d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ca43a688154985b7ba5bdc2324c589",
            "max": 10565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f891162dc284da8b746bcfc6e8c4442",
            "value": 10565
          }
        },
        "1126b608f8504b61a8b93a556c01adaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a697e4e84bce42568aa9fd9bf1016393",
            "placeholder": "​",
            "style": "IPY_MODEL_606188878960479c9816819dafbc1b71",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 435kB/s]"
          }
        },
        "edb4e52323664c1b99fa0665caa9f299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f9ce4e5b8a432da0655dec1b66c3a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1e088dac59469dab3198479729d102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99ca43a688154985b7ba5bdc2324c589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f891162dc284da8b746bcfc6e8c4442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a697e4e84bce42568aa9fd9bf1016393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606188878960479c9816819dafbc1b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b56dfff0167a4182b134b9b1f52d34db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef084cc6ead6454ca9eaafb714292592",
              "IPY_MODEL_3fd7dcb1927649a493911f488e7344f6",
              "IPY_MODEL_5e67f60390794cd890b7e3754c8390fb"
            ],
            "layout": "IPY_MODEL_5b25af586cff4435a0b5b5eb4186da0b"
          }
        },
        "ef084cc6ead6454ca9eaafb714292592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71dc8f9d05946419ef24a7b8de76914",
            "placeholder": "​",
            "style": "IPY_MODEL_b298a08ec31547f683640e08071a67d9",
            "value": "kmhas_korean_hate_speech.py: 100%"
          }
        },
        "3fd7dcb1927649a493911f488e7344f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2586af70790842629e7db16060135c98",
            "max": 4730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3bf5a28218a4810bc1e2a1db1331726",
            "value": 4730
          }
        },
        "5e67f60390794cd890b7e3754c8390fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7bc77b126d54e50ac468bae77235d80",
            "placeholder": "​",
            "style": "IPY_MODEL_f87e655dbf384220a0f1503d77c0a215",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "5b25af586cff4435a0b5b5eb4186da0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71dc8f9d05946419ef24a7b8de76914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b298a08ec31547f683640e08071a67d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2586af70790842629e7db16060135c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bf5a28218a4810bc1e2a1db1331726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7bc77b126d54e50ac468bae77235d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87e655dbf384220a0f1503d77c0a215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be34973176f4531af33b201a379192f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8244091c31c492ca6801a27b78a26e1",
              "IPY_MODEL_e1a71da04fea4c049a54454003eacf5e",
              "IPY_MODEL_53340d771a8745f2b0eee0763eeec1d7"
            ],
            "layout": "IPY_MODEL_63a146898ce0431192eebe7ed8b5a03b"
          }
        },
        "c8244091c31c492ca6801a27b78a26e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73269139a9874c84bf150f37c89bac8e",
            "placeholder": "​",
            "style": "IPY_MODEL_c2db2b2fd9a74a3a947b9eaba2a88e68",
            "value": "0000.parquet: 100%"
          }
        },
        "e1a71da04fea4c049a54454003eacf5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67346806bbc4d70b9c2861d3dd4fc9e",
            "max": 5244851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46e38b8eac244fc082ee917e1cc348b8",
            "value": 5244851
          }
        },
        "53340d771a8745f2b0eee0763eeec1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c8e4a8e4854415f933c4a47f0f8a00f",
            "placeholder": "​",
            "style": "IPY_MODEL_1ebbe92a20be41a8971d6e178b67565b",
            "value": " 5.24M/5.24M [00:00&lt;00:00, 45.8MB/s]"
          }
        },
        "63a146898ce0431192eebe7ed8b5a03b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73269139a9874c84bf150f37c89bac8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2db2b2fd9a74a3a947b9eaba2a88e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67346806bbc4d70b9c2861d3dd4fc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e38b8eac244fc082ee917e1cc348b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c8e4a8e4854415f933c4a47f0f8a00f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebbe92a20be41a8971d6e178b67565b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d603197d549f484d81dfb03696e7c779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_437f49ab1cdc4f06bc28f57e42ad4f57",
              "IPY_MODEL_08dd1140a6284cc3b7f3e3ad55df929a",
              "IPY_MODEL_cbbc82d24c17453c859bc6afb4ea6b41"
            ],
            "layout": "IPY_MODEL_17c83819197a429b9a3908366e3c6edb"
          }
        },
        "437f49ab1cdc4f06bc28f57e42ad4f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e57d7364b0254693927c87c4aec78a46",
            "placeholder": "​",
            "style": "IPY_MODEL_e435d53e89014ec2bee3ddb92baf0471",
            "value": "default/validation/0000.parquet: 100%"
          }
        },
        "08dd1140a6284cc3b7f3e3ad55df929a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c1da93a45f4b9b8fba7d89ee6632c7",
            "max": 578860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b535652765924580929a4e2eed3da622",
            "value": 578860
          }
        },
        "cbbc82d24c17453c859bc6afb4ea6b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7a8fddc60e4698bdbed336fc1cd614",
            "placeholder": "​",
            "style": "IPY_MODEL_c8b77fe049524c4387d07e984fdc5a9d",
            "value": " 579k/579k [00:00&lt;00:00, 1.36MB/s]"
          }
        },
        "17c83819197a429b9a3908366e3c6edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57d7364b0254693927c87c4aec78a46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e435d53e89014ec2bee3ddb92baf0471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c1da93a45f4b9b8fba7d89ee6632c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b535652765924580929a4e2eed3da622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc7a8fddc60e4698bdbed336fc1cd614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b77fe049524c4387d07e984fdc5a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6552578bb91f4993b319bf9f3b09b7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5df793210b3c409b9a231b91c0e525bf",
              "IPY_MODEL_6802ec43a4fb4202b618ee25a5d5062f",
              "IPY_MODEL_b56e376ab756440a802c17bd2ce35404"
            ],
            "layout": "IPY_MODEL_853e8444e86b461ca1ff05196b1ec9a3"
          }
        },
        "5df793210b3c409b9a231b91c0e525bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_648c5893dccb4d11b604378cd1bea92c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a7fb273d56a447eb32ce3a6b44f99fc",
            "value": "0000.parquet: 100%"
          }
        },
        "6802ec43a4fb4202b618ee25a5d5062f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99add81ce6f6418b93fd881abe25250c",
            "max": 1458266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0bc56f7828f43ed9d27130f4a9a7d6b",
            "value": 1458266
          }
        },
        "b56e376ab756440a802c17bd2ce35404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01487b7677844bfa812804e16a17d373",
            "placeholder": "​",
            "style": "IPY_MODEL_d674894e63ea4a3f83d1d8cf3a5912dd",
            "value": " 1.46M/1.46M [00:00&lt;00:00, 34.7MB/s]"
          }
        },
        "853e8444e86b461ca1ff05196b1ec9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "648c5893dccb4d11b604378cd1bea92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a7fb273d56a447eb32ce3a6b44f99fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99add81ce6f6418b93fd881abe25250c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bc56f7828f43ed9d27130f4a9a7d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01487b7677844bfa812804e16a17d373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d674894e63ea4a3f83d1d8cf3a5912dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3fa8701e6a40ee91755444afffc19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_908fd0ea7c384532a7bf431af7e3a43d",
              "IPY_MODEL_08ba9e7fb6d04d1488f5bdd75abc8416",
              "IPY_MODEL_f957d47248b248a79274982f5eadad22"
            ],
            "layout": "IPY_MODEL_f4f6180353644abda9be0823b67d9369"
          }
        },
        "908fd0ea7c384532a7bf431af7e3a43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c36a4b4a3f4122ad27de760cef850d",
            "placeholder": "​",
            "style": "IPY_MODEL_7db8673c44c142e682af19e0f8462edb",
            "value": "Generating train split: 100%"
          }
        },
        "08ba9e7fb6d04d1488f5bdd75abc8416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1701e029335443399c1a80c508511e1f",
            "max": 78977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8c1fa1dae614b68883d149da9c5ca67",
            "value": 78977
          }
        },
        "f957d47248b248a79274982f5eadad22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a846b859a2a4f17b77b5ca2ae4278a6",
            "placeholder": "​",
            "style": "IPY_MODEL_ee9429c02c1b459ea0d88790659061f5",
            "value": " 78977/78977 [00:00&lt;00:00, 356109.09 examples/s]"
          }
        },
        "f4f6180353644abda9be0823b67d9369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c36a4b4a3f4122ad27de760cef850d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db8673c44c142e682af19e0f8462edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1701e029335443399c1a80c508511e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c1fa1dae614b68883d149da9c5ca67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a846b859a2a4f17b77b5ca2ae4278a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9429c02c1b459ea0d88790659061f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d0da4bee014863a4e9cea8c767d743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28ec946383484670b2fc3d3d84567e75",
              "IPY_MODEL_65dc86b07ad54622987563e02ad995ac",
              "IPY_MODEL_be8518b65621477a90605e8504c651a1"
            ],
            "layout": "IPY_MODEL_20784e9158da47938bd52c15d29108ed"
          }
        },
        "28ec946383484670b2fc3d3d84567e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_951b94e4bd724527b51a8e56b37489eb",
            "placeholder": "​",
            "style": "IPY_MODEL_75ffd262623a42a8989c29f242dcd513",
            "value": "Generating validation split: 100%"
          }
        },
        "65dc86b07ad54622987563e02ad995ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0050f0a58a94eb8af4c123a5ccf2777",
            "max": 8776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2550facf1dab436692ec0c2d53e2492f",
            "value": 8776
          }
        },
        "be8518b65621477a90605e8504c651a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc60bf627e154966a45b87db02373450",
            "placeholder": "​",
            "style": "IPY_MODEL_2066d183ab704a64bccc56ec2572696b",
            "value": " 8776/8776 [00:00&lt;00:00, 183921.91 examples/s]"
          }
        },
        "20784e9158da47938bd52c15d29108ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951b94e4bd724527b51a8e56b37489eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ffd262623a42a8989c29f242dcd513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0050f0a58a94eb8af4c123a5ccf2777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2550facf1dab436692ec0c2d53e2492f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc60bf627e154966a45b87db02373450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2066d183ab704a64bccc56ec2572696b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db7dee2a6040474da1b723274daad13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d598857903754806b78ceec6ce01a70b",
              "IPY_MODEL_f172ea5a90c846f2a4fa74064dc233e2",
              "IPY_MODEL_9cc52890d6334cf1855641f21765f3cf"
            ],
            "layout": "IPY_MODEL_e3a77d00f792445b9fe3fcd3e6fabff6"
          }
        },
        "d598857903754806b78ceec6ce01a70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe0baaa0bb14d03a90cee948544ad48",
            "placeholder": "​",
            "style": "IPY_MODEL_11cbdb5e8726404884274ae70321fc4a",
            "value": "Generating test split: 100%"
          }
        },
        "f172ea5a90c846f2a4fa74064dc233e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dce504c21064dabbbe041c1eab4372e",
            "max": 21939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5099197c19bc4869a1c134584c995540",
            "value": 21939
          }
        },
        "9cc52890d6334cf1855641f21765f3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a25b54d31a949018a0daf44bd4108aa",
            "placeholder": "​",
            "style": "IPY_MODEL_85e868703809409fb1e417267059c074",
            "value": " 21939/21939 [00:00&lt;00:00, 231906.98 examples/s]"
          }
        },
        "e3a77d00f792445b9fe3fcd3e6fabff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe0baaa0bb14d03a90cee948544ad48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cbdb5e8726404884274ae70321fc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dce504c21064dabbbe041c1eab4372e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5099197c19bc4869a1c134584c995540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a25b54d31a949018a0daf44bd4108aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e868703809409fb1e417267059c074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386a558ef1fd482086ddba1b129d7ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f3964d51ef2475cba5b7682abfe2a76",
              "IPY_MODEL_55dbf20cc55442b5bbae2e09dea2be96",
              "IPY_MODEL_102fa433bce842c58116627095682845"
            ],
            "layout": "IPY_MODEL_2d0fc787aa6c45d2847a9449cad480ac"
          }
        },
        "0f3964d51ef2475cba5b7682abfe2a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881e08c6e75d479eb09fddf517f186fe",
            "placeholder": "​",
            "style": "IPY_MODEL_0df5c7b39cfe42d2b76be6d7b02d39ef",
            "value": "model.safetensors: 100%"
          }
        },
        "55dbf20cc55442b5bbae2e09dea2be96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3294b8e11efb4682a7a4a63673d16161",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a955f594a284836a88241e4a4c83891",
            "value": 445000316
          }
        },
        "102fa433bce842c58116627095682845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f8cdbed6b14448b6e781cb6befb22c",
            "placeholder": "​",
            "style": "IPY_MODEL_ca997dec68154adda399990227209840",
            "value": " 445M/445M [00:02&lt;00:00, 195MB/s]"
          }
        },
        "2d0fc787aa6c45d2847a9449cad480ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881e08c6e75d479eb09fddf517f186fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df5c7b39cfe42d2b76be6d7b02d39ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3294b8e11efb4682a7a4a63673d16161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a955f594a284836a88241e4a4c83891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50f8cdbed6b14448b6e781cb6befb22c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca997dec68154adda399990227209840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/%5BK_MHAS%5D_HuggingFace_dataset_MultiBERT_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the K-MHaS dataset from [HuggingFace](https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech) and checking meta information (published @COLING2022)\n"
      ],
      "metadata": {
        "id": "4Lyor-OIrwd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets fsspec -y\n",
        "!pip install datasets==3.2.0 fsspec[http]==2024.9.0\n"
      ],
      "metadata": {
        "id": "WMoJHDlhbklf",
        "outputId": "77c235e2-bbca-4358-b352-9859eb47cf44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.10.0\n",
            "Uninstalling fsspec-2024.10.0:\n",
            "  Successfully uninstalled fsspec-2024.10.0\n",
            "Collecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec==2024.9.0 (from fsspec[http]==2024.9.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "outputId": "903fcbd9-7d23-40e5-d2f8-c5fbc6bd7d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "outputId": "0b6b94e8-dea6-4852-9327-1bf8197ab25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "593d3b82c197440f9bd091bfed9aa536",
            "38373b0b07fc4c048870dd5eb81981fe",
            "aaf21922bf804e66baf07e85e5ff248d",
            "1126b608f8504b61a8b93a556c01adaf",
            "edb4e52323664c1b99fa0665caa9f299",
            "36f9ce4e5b8a432da0655dec1b66c3a9",
            "8a1e088dac59469dab3198479729d102",
            "99ca43a688154985b7ba5bdc2324c589",
            "2f891162dc284da8b746bcfc6e8c4442",
            "a697e4e84bce42568aa9fd9bf1016393",
            "606188878960479c9816819dafbc1b71",
            "b56dfff0167a4182b134b9b1f52d34db",
            "ef084cc6ead6454ca9eaafb714292592",
            "3fd7dcb1927649a493911f488e7344f6",
            "5e67f60390794cd890b7e3754c8390fb",
            "5b25af586cff4435a0b5b5eb4186da0b",
            "c71dc8f9d05946419ef24a7b8de76914",
            "b298a08ec31547f683640e08071a67d9",
            "2586af70790842629e7db16060135c98",
            "e3bf5a28218a4810bc1e2a1db1331726",
            "a7bc77b126d54e50ac468bae77235d80",
            "f87e655dbf384220a0f1503d77c0a215",
            "8be34973176f4531af33b201a379192f",
            "c8244091c31c492ca6801a27b78a26e1",
            "e1a71da04fea4c049a54454003eacf5e",
            "53340d771a8745f2b0eee0763eeec1d7",
            "63a146898ce0431192eebe7ed8b5a03b",
            "73269139a9874c84bf150f37c89bac8e",
            "c2db2b2fd9a74a3a947b9eaba2a88e68",
            "a67346806bbc4d70b9c2861d3dd4fc9e",
            "46e38b8eac244fc082ee917e1cc348b8",
            "4c8e4a8e4854415f933c4a47f0f8a00f",
            "1ebbe92a20be41a8971d6e178b67565b",
            "d603197d549f484d81dfb03696e7c779",
            "437f49ab1cdc4f06bc28f57e42ad4f57",
            "08dd1140a6284cc3b7f3e3ad55df929a",
            "cbbc82d24c17453c859bc6afb4ea6b41",
            "17c83819197a429b9a3908366e3c6edb",
            "e57d7364b0254693927c87c4aec78a46",
            "e435d53e89014ec2bee3ddb92baf0471",
            "16c1da93a45f4b9b8fba7d89ee6632c7",
            "b535652765924580929a4e2eed3da622",
            "fc7a8fddc60e4698bdbed336fc1cd614",
            "c8b77fe049524c4387d07e984fdc5a9d",
            "6552578bb91f4993b319bf9f3b09b7a7",
            "5df793210b3c409b9a231b91c0e525bf",
            "6802ec43a4fb4202b618ee25a5d5062f",
            "b56e376ab756440a802c17bd2ce35404",
            "853e8444e86b461ca1ff05196b1ec9a3",
            "648c5893dccb4d11b604378cd1bea92c",
            "2a7fb273d56a447eb32ce3a6b44f99fc",
            "99add81ce6f6418b93fd881abe25250c",
            "d0bc56f7828f43ed9d27130f4a9a7d6b",
            "01487b7677844bfa812804e16a17d373",
            "d674894e63ea4a3f83d1d8cf3a5912dd",
            "ff3fa8701e6a40ee91755444afffc19e",
            "908fd0ea7c384532a7bf431af7e3a43d",
            "08ba9e7fb6d04d1488f5bdd75abc8416",
            "f957d47248b248a79274982f5eadad22",
            "f4f6180353644abda9be0823b67d9369",
            "d7c36a4b4a3f4122ad27de760cef850d",
            "7db8673c44c142e682af19e0f8462edb",
            "1701e029335443399c1a80c508511e1f",
            "a8c1fa1dae614b68883d149da9c5ca67",
            "6a846b859a2a4f17b77b5ca2ae4278a6",
            "ee9429c02c1b459ea0d88790659061f5",
            "99d0da4bee014863a4e9cea8c767d743",
            "28ec946383484670b2fc3d3d84567e75",
            "65dc86b07ad54622987563e02ad995ac",
            "be8518b65621477a90605e8504c651a1",
            "20784e9158da47938bd52c15d29108ed",
            "951b94e4bd724527b51a8e56b37489eb",
            "75ffd262623a42a8989c29f242dcd513",
            "f0050f0a58a94eb8af4c123a5ccf2777",
            "2550facf1dab436692ec0c2d53e2492f",
            "fc60bf627e154966a45b87db02373450",
            "2066d183ab704a64bccc56ec2572696b",
            "db7dee2a6040474da1b723274daad13d",
            "d598857903754806b78ceec6ce01a70b",
            "f172ea5a90c846f2a4fa74064dc233e2",
            "9cc52890d6334cf1855641f21765f3cf",
            "e3a77d00f792445b9fe3fcd3e6fabff6",
            "fbe0baaa0bb14d03a90cee948544ad48",
            "11cbdb5e8726404884274ae70321fc4a",
            "4dce504c21064dabbbe041c1eab4372e",
            "5099197c19bc4869a1c134584c995540",
            "9a25b54d31a949018a0daf44bd4108aa",
            "85e868703809409fb1e417267059c074"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "593d3b82c197440f9bd091bfed9aa536"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "kmhas_korean_hate_speech.py:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b56dfff0167a4182b134b9b1f52d34db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8be34973176f4531af33b201a379192f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "default/validation/0000.parquet:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d603197d549f484d81dfb03696e7c779"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6552578bb91f4993b319bf9f3b09b7a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff3fa8701e6a40ee91755444afffc19e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99d0da4bee014863a4e9cea8c767d743"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db7dee2a6040474da1b723274daad13d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "52e222ee-2e6d-47b5-f4d2-3bd24de2a223"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "96eac38f-f744-438f-f192-a2fcd2ba8611"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "8ae41e5f-f9fa-46f2-9630-77f0cc5ffb6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meta information\n",
        "\n",
        "print(dataset.info.description)\n",
        "print(dataset.info.homepage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AveWSDOj88",
        "outputId": "99f82862-05a4-4f7d-8ef9-9ba14952f28f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\n",
            "The fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.\n",
            "\n",
            "https://github.com/adlnlp/K-MHaS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bsDpBwOxPx",
        "outputId": "be318ad7-9495-4718-93f5-511a0fc41178"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@inproceedings{lee-etal-2022-k,\n",
            "    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n",
            "    author = \"Lee, Jean  and\n",
            "      Lim, Taejun  and\n",
            "      Lee, Heejun  and\n",
            "      Jo, Bogeun  and\n",
            "      Kim, Yangsok  and\n",
            "      Yoon, Heegeun  and\n",
            "      Han, Soyeon Caren\",\n",
            "    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n",
            "    month = oct,\n",
            "    year = \"2022\",\n",
            "    address = \"Gyeongju, Republic of Korea\",\n",
            "    publisher = \"International Committee on Computational Linguistics\",\n",
            "    url = \"https://aclanthology.org/2022.coling-1.311\",\n",
            "    pages = \"3530--3538\",\n",
            "    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare data from train, validation, and test dataset\n",
        "- Multi-label is converted to multi-label one hot encodding\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin\n",
        "          1: physical\n",
        "          2: politics\n",
        "          3: profanity\n",
        "          4: age\n",
        "          5: gender\n",
        "          6: race\n",
        "          7: religion\n",
        "          8: not_hate_speech"
      ],
      "metadata": {
        "id": "qqO0w2cKsjN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fykcu8FKZiOI",
        "outputId": "424c0434-321c-48b0-bb86-bba087f7b1ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "-IczFOCZZfvx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "id": "A5Jq_uiYcIWM",
        "outputId": "5c07dcde-128a-455c-ff36-fb9076d69d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, validation, and test dataset from HuggingFace\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding masking (able to remove this step depending on the model)\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multi-label to multi-label binary (one hot encoding)\n",
        "# [8] -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-xu24pnaxek",
        "outputId": "4def14f5-0aa0-4ea1-8991-d703b78006a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그만큼 길예르모가 잘했다고 보면되겠지 기대되네 셰이프 오브 워터 [SEP]',\n",
              " '[CLS] \"1. 8넘의 문재앙\" [SEP]',\n",
              " '[CLS] \"문재인 정권의 내로남불은 타의 추종을 불허하네. 자한당 욕할거리도 없음.\" [SEP]',\n",
              " '[CLS] \"짱개들 지나간 곳은 폐허된다 ㅋㅋ\" [SEP]',\n",
              " '[CLS] 곱창은 자갈치~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "438598cd-3039-4947-9dfe-91550255f169"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for Pytorch"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing : bert-base-multilingual-cased\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)"
      ],
      "metadata": {
        "id": "VKYP2VNkR-Gz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks\n"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('testset size:', len(test_labels))\n",
        "print('trainset size:', len(train_labels))\n",
        "print('validset size:', len(validation_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "ade13d48-cb21-4d04-bf0a-7bc8d843ba00"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset size: 21939\n",
            "trainset size: 78977\n",
            "validset size: 8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-BERT model"
      ],
      "metadata": {
        "id": "pXGKAsSXut0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setting"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfq1f2Y3Yhck",
        "outputId": "d0a25443-a391-4336-b943-d2746eb6209c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "2839be67-03de-4500-b50b-3951a71a4b47"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setting"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936,
          "referenced_widgets": [
            "386a558ef1fd482086ddba1b129d7ec8",
            "0f3964d51ef2475cba5b7682abfe2a76",
            "55dbf20cc55442b5bbae2e09dea2be96",
            "102fa433bce842c58116627095682845",
            "2d0fc787aa6c45d2847a9449cad480ac",
            "881e08c6e75d479eb09fddf517f186fe",
            "0df5c7b39cfe42d2b76be6d7b02d39ef",
            "3294b8e11efb4682a7a4a63673d16161",
            "2a955f594a284836a88241e4a4c83891",
            "50f8cdbed6b14448b6e781cb6befb22c",
            "ca997dec68154adda399990227209840"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "b71ff012-94a6-4225-fc0f-e604c4c1ba84"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:  24%|##3       | 105M/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "386a558ef1fd482086ddba1b129d7ec8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "# change epochs for improving results (our paper : epochs = 4)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "yO_GNYxCSYfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3291fd-51bd-412d-cf55-fdfe00f56def"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming_loss': hamming}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFH3QM6ctmP",
        "outputId": "31525220-5836-44cc-fe3f-53885b326162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:36,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:37.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [15:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:15:59.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:21,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.1362\n",
            "  Training epcoh took: 0:26:23\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0863\n",
            "  Training epcoh took: 0:26:33\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0641\n",
            "  Training epcoh took: 0:26:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:44.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:06,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:29.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0499\n",
            "  Training epcoh took: 0:26:31\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "PXTAMK1sc0Sq",
        "outputId": "ed123a8b-6629-4cf9-9602-6214ec84620a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n",
            "Hamming Loss: 0.0360\n",
            "Validation took: 0:00:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "\n",
        "# torch.save(model.state_dict(), path+\"BERT_model.pt\")"
      ],
      "metadata": {
        "id": "sdghDBnXdYlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "path = '/content/model/'\n",
        "#torch.save(model.state_dict(), path+\"BERT_multilabel_model.pt\")\n",
        "model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "874649f8-15db-49db-b414-9cb555436f38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-d28ce5f3d4a8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "sgx14gm68ElU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "for batch in validation_dataloader:\n",
        " batch = tuple(t.to(device) for t in batch)\n",
        " b_input_ids, b_input_mask, b_labels = batch\n",
        " with torch.no_grad():\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " logits = outputs[0]\n",
        " logits = logits.detach().cpu().numpy()\n",
        " label_ids = b_labels.to('cpu').numpy()\n",
        " for b in logits:\n",
        "  accum_logits.append(list(b))\n",
        " for b in label_ids:\n",
        "  accum_label_ids.append(list(b))\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))"
      ],
      "metadata": {
        "id": "1jqF9y4E7YjT",
        "outputId": "d40d2ba3-a15c-4936-adcc-37a55259b621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "accum_results = []\n",
        "accum_results.append(list(results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "1a9cbbda-d8f0-4675-98e6-de22a6bf39b7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [00:21,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    686.    Elapsed: 0:00:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [00:43,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    686.    Elapsed: 0:00:43.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [01:03,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    686.    Elapsed: 0:01:04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "400it [01:25,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    686.    Elapsed: 0:01:25.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [01:46,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    686.    Elapsed: 0:01:46.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "600it [02:07,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    686.    Elapsed: 0:02:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "686it [02:25,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down evaluation"
      ],
      "metadata": {
        "id": "lInDyL-9hjhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_labels):\n",
        "    ith_label_ids, ith_logits = [], []\n",
        "\n",
        "    for j, labels in enumerate(accum_label_ids):\n",
        "        if len(np.where(labels)[0]) == i+1:\n",
        "            ith_label_ids.append(accum_label_ids[j].tolist())\n",
        "            ith_logits.append(accum_logits[j].tolist())\n",
        "\n",
        "    ith_label_ids = np.array(ith_label_ids)\n",
        "    ith_logits = np.array(ith_logits)\n",
        "\n",
        "    if len(ith_label_ids) == 0 and len(ith_logits) == 0:\n",
        "        continue\n",
        "\n",
        "    results = multi_label_metrics(ith_logits, ith_label_ids)\n",
        "    accum_results.append(list(results.values()))\n",
        "\n",
        "    print('# of labels:', i+1)\n",
        "    print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "    print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "    print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "    print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "    print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "    print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uVtTwWhnHy",
        "outputId": "b46aba4e-871d-464b-d83e-253931bc1707"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer,\n",
        "device=0, max_length=10,\n",
        " return_all_scores=True, function_to_apply='sigmoid')\n",
        "result = pipe('틀니들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)\n",
        "label_dict = {'LABEL_0' : '출신차별', 'LABEL_1' : '외모차별', 'LABEL_2' : '정치성향차별', 'LABEL_3': '혐오욕설', 'LABEL_4': '연령차별', 'LABEL_5': '성차별', 'LABEL_6' : '인종차별', 'LABEL_7': '종교차별', 'LABEL_8': '해당사항없음'}\n",
        "def prediction(text):\n",
        " result = pipe(text)\n",
        " return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]\n",
        "prediction('틀니들은 왜 그렇게 민폐를 끼치냐?')"
      ],
      "metadata": {
        "id": "798meQSe6c-Y",
        "outputId": "dc7de4f4-de1b-476f-a14c-48b2804c59e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "def predict_labels(text, model, tokenizer, label_names, threshold=0.1):\n",
        "    # 텍스트를 모델의 입력 형식으로 인코딩\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 10,\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 모델을 사용하여 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    # 예측 결과에서 확률 추출\n",
        "    logits = outputs.logits\n",
        "    #print(logits)\n",
        "    probs = sigmoid(logits)\n",
        "    #print(probs)\n",
        "\n",
        "    # CPU로 이동 후 numpy 배열로 변환\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    #print(probs)\n",
        "\n",
        "    # 예측된 레이블 결정\n",
        "    predicted_labels = [label_names[i] for i in range(len(label_names)) if probs[0][i] >= threshold]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "2FStXOPPcqnO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"늙은 천주교 신자들은 다 속물이다\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "t18ZXNVec82c",
        "outputId": "2cc29389-6a13-47a6-979b-608076650095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 늙은 천주교 신자들은 다 속물이다 & Predicted labels: ['연령차별', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1\n",
        "text = \"못생긴 경상도 여자들은 나가라\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} -> Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "Q4wfueAfdARU",
        "outputId": "977dadfa-2dbb-4125-e5b8-ebe884057a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 못생긴 경상도 여자들은 나가라 -> Predicted labels: ['출신차별', '외모차별', '성차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LV_-RJXdR5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VSCode 쪽 코드 (receive_data.py)\n",
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "xCHlbhrqdDuu",
        "outputId": "0b48eefd-6111-45f7-fc5c-18a59f549f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1b184333c58d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/./content/model/attention_scores.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutputs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('문재앙')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f-0wLH1NexAK",
        "outputId": "4bc1f358-3e95-47f5-b570-58b7f2e8da7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.007721984758973122}, {'label': 'LABEL_1', 'score': 0.0032311684917658567}, {'label': 'LABEL_2', 'score': 0.985312283039093}, {'label': 'LABEL_3', 'score': 0.005993321072310209}, {'label': 'LABEL_4', 'score': 0.0053891874849796295}, {'label': 'LABEL_5', 'score': 0.002821417059749365}, {'label': 'LABEL_6', 'score': 0.0012292619794607162}, {'label': 'LABEL_7', 'score': 0.002137931529432535}, {'label': 'LABEL_8', 'score': 0.007046678103506565}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = \"cpu\"\n",
        "\n",
        "# 모델을 CPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, max_length=10, return_all_scores=True)\n",
        "\n",
        "result = pipe('깜둥이들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PmW6CiNigW55",
        "outputId": "5988fdae-233a-4f08-f2fe-2622ef5eb1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.14709047973155975}, {'label': 'LABEL_1', 'score': 0.26493778824806213}, {'label': 'LABEL_2', 'score': 0.026825927197933197}, {'label': 'LABEL_3', 'score': 0.03060534968972206}, {'label': 'LABEL_4', 'score': 0.08758819103240967}, {'label': 'LABEL_5', 'score': 0.09902970492839813}, {'label': 'LABEL_6', 'score': 0.8641231060028076}, {'label': 'LABEL_7', 'score': 0.14547504484653473}, {'label': 'LABEL_8', 'score': 0.11148741096258163}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "lEvK_zHWgiKj",
        "outputId": "503456ac-9f33-4bd9-fa0f-5a5a8935b0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ㅅ발 천주교도들은 너무 말이 많아 & Predicted labels: ['혐오욕설', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = '/home/jyhan/HW-output-files/example.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "NH4-k_-Zgp5L",
        "outputId": "c1b01126-cd3a-4219-f8a8-9c5e9307d3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file /home/jyhan/HW-output-files/example.txt does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def pickle_to_text(pickle_file_path, text_file_path):\n",
        "    # 피클 파일 불러오기\n",
        "    with open(pickle_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 텍스트 파일로 저장하기\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        for sublist in data:\n",
        "            # 각 서브리스트를 반복하고 숫자를 문자열로 변환하여 저장\n",
        "            for number in sublist:\n",
        "                f.write(f\"{number} \")\n",
        "            f.write(\"\\n\\n\\n\")  # 각 서브리스트 끝에 줄바꿈 추가"
      ],
      "metadata": {
        "id": "OpUp0tFHhvQQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def tanh_new(x) :\n",
        "    result = (F.tanh(x) + 1) /2\n",
        "    return result"
      ],
      "metadata": {
        "id": "_c7Qzz8DhxOh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number(num):\n",
        "    \"\"\"숫자를 7비트 2의 보수 형식으로 인코딩하는 함수, 음수 소수 부분을 고려\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = abs(num - int_num)\n",
        "\n",
        "    # Round integer part towards zero if num is negative and has a fractional part\n",
        "    if num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num = int_num - 1  # Round integer part one more negative\n",
        "            frac_num = 1 - frac_num  # Subtract fractional part from 1 to make it positive\n",
        "\n",
        "    # Clamp the values to fit within the 7-bit range\n",
        "    if int_num < -64:\n",
        "        int_num = -64\n",
        "    elif int_num > 63:\n",
        "        int_num = 63\n",
        "\n",
        "    # Apply 2's complement if the number is negative\n",
        "    if int_num < 0:\n",
        "        int_num = (1 << 7) + int_num  # 1 << 7 is 128, representing the range of 7-bit integers\n",
        "\n",
        "    # Format the number into 7-bit binary\n",
        "    int_part_bin = format(int_num & 0b1111111, '07b')  # Only the last 7 bits are used\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = int_part_bin + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "4RMAodqch2WA"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_input(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number(num) for num in numbers]"
      ],
      "metadata": {
        "id": "_sD86m8Zh5dr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools"
      ],
      "metadata": {
        "id": "6TPxkyv6h-nI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number_output(num):\n",
        "    \"\"\"숫자를 3비트 정수와 13비트 소수 형식으로 인코딩하는 함수, 값은 0부터 1 사이의 양수\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Clamp the values to fit within the 0 to 1 range\n",
        "    if num < 0:\n",
        "        num = 0\n",
        "    elif num > 1:\n",
        "        num = 1\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = num - int_num\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = '000' + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jYW_te9oh_oY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_output(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number_output(num) for num in numbers]"
      ],
      "metadata": {
        "id": "5a7CeXJmh_p6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [-3.0061, -4.5561, -3.7781, -4.6988, -1.8251, -4.0483, -4.8075,  4.6085, -5.1693]\n",
        "encoded_numbers = encode_numbers_input(probs)\n",
        "print(encoded_numbers)\n",
        "\n",
        "probs = [0.0472, 0.0104, 0.0224, 0.0090, 0.1388, 0.0172, 0.0081, 0.9901, 0.0057]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "W-j1Du8UiEQp",
        "outputId": "6649aeb2-9260-4f6c-8eaf-b88e9f124832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'encode_number' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-92e674e1e471>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3.0061\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.5561\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3.7781\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.6988\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.8251\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.0483\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.8075\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m4.6085\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5.1693\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_numbers_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0472\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0090\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1388\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0172\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0081\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9901\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0057\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-f174970f0a30>\u001b[0m in \u001b[0;36mencode_numbers_input\u001b[0;34m(numbers)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_numbers_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-f174970f0a30>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_numbers_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encode_number' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.0301, 0.0112, 0.0040, 0.7632, 0.0040, 0.0072, 0.0068, 0.8885, 0.0117]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "FFeQcYAWiMA8",
        "outputId": "f47ed1bf-e680-4342-a5b7-8c0d6374e084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000_0000011110110', '000_0000001011011', '000_0000000100000', '000_1100001101100', '000_0000000100000', '000_0000000111010', '000_0000000110111', '000_1110001101110', '000_0000001011111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin, decimal_part_bin = encoded.split('.')\n",
        "\n",
        "    # Integer part processing\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # Negative number (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # Positive number\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # Fractional part processing\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # Adjust for negative numbers\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the function with provided values\n",
        "encoded_values = [\n",
        "    \"0000000.0101010000101\",\n",
        "    \"0000000.0010111100000\",\n",
        "    \"0000000.0010110110000\",\n",
        "    \"0000000.0010001111011\",\n",
        "    \"0000000.0010001101110\",\n",
        "    \"0000000.0001110010000\",\n",
        "    \"0000000.0001100000110\",\n",
        "    \"0000000.0000000000010\",\n",
        "    \"1111111.1101100010111\",\n",
        "    \"1111111.1101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "kzwvRVHhiM6-",
        "outputId": "b6e59177-d34b-4af1-f964-835fe66b8fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3287353515625,\n",
              " 0.18359375,\n",
              " 0.177734375,\n",
              " 0.1400146484375,\n",
              " 0.138427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " -0.1534423828125,\n",
              " -0.1597900390625]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    # 입력 문자열을 반으로 나누어 정수 부분과 소수 부분으로 분리\n",
        "    mid_index = len(encoded) // 2\n",
        "    int_part_bin = encoded[:mid_index]\n",
        "    decimal_part_bin = encoded[mid_index:]\n",
        "\n",
        "    # 정수 부분 처리\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"00000000101010000101\",\n",
        "    \"00000000010111100000\",\n",
        "    \"00000000010110110000\",\n",
        "    \"00000000010001111011\",\n",
        "    \"00000000010001101110\",\n",
        "    \"00000000001110010000\",\n",
        "    \"00000000001100000110\",\n",
        "    \"00000000000000000010\",\n",
        "    \"11111111101100010111\",\n",
        "    \"11111111101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "Fy0SQbOSiad-",
        "outputId": "85b5efc4-5afd-4230-b2e0-0d5e9fd3ffcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0787353515625,\n",
              " 1.05859375,\n",
              " 1.052734375,\n",
              " 1.0150146484375,\n",
              " 1.013427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " 894.0965576171875,\n",
              " 894.0902099609375]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    if int(int_part_bin, 2) & (1 << 2):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 3)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0001000101001100\",\n",
        "    \"0000011001010100\",\n",
        "    \"0000000111011100\",\n",
        "    \"0000000111010100\",\n",
        "    \"0000000110110100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000011010100\",\n",
        "    \"0000000001100100\",\n",
        "    \"0000000001010100\",\n",
        "    \"0000000001000100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for encoded, decoded in zip(encoded_values, decoded_values):\n",
        "    print(f\"Encoded: {encoded} -> Decoded: {decoded}\")"
      ],
      "metadata": {
        "id": "i6y3VbyOiiIq",
        "outputId": "6344b7e1-6ee7-423f-e71c-165136bae36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: 0001000101001100 -> Decoded: 0.54052734375\n",
            "Encoded: 0000011001010100 -> Decoded: 0.19775390625\n",
            "Encoded: 0000000111011100 -> Decoded: 0.05810546875\n",
            "Encoded: 0000000111010100 -> Decoded: 0.05712890625\n",
            "Encoded: 0000000110110100 -> Decoded: 0.05322265625\n",
            "Encoded: 0000000100000100 -> Decoded: 0.03173828125\n",
            "Encoded: 0000000011010100 -> Decoded: 0.02587890625\n",
            "Encoded: 0000000001100100 -> Decoded: 0.01220703125\n",
            "Encoded: 0000000001010100 -> Decoded: 0.01025390625\n",
            "Encoded: 0000000001000100 -> Decoded: 0.00830078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "\n",
        "    # 리스트를 문자열 형식으로 변환\n",
        "    formatted_hex_list = \"[\" + \", \".join(f'\"{hex_value}\"' for hex_value in hex_list) + \"]\"\n",
        "\n",
        "    return formatted_hex_list\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"06dc 05c4 0494 03c4 039c 02e4 017c 0144 00e4 00ac\"\n",
        "formatted_hex_list = format_hex_input(hex_input)\n",
        "\n",
        "print(formatted_hex_list)"
      ],
      "metadata": {
        "id": "KiL0Vi9sikfX",
        "outputId": "075469cb-0bc3-4b65-a26f-7b5c83d6aa8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n",
        "\n",
        "float_values = hexa_to_float(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, float_value in zip(hex_strings, float_values):\n",
        "    print(f\"{float_value}\")"
      ],
      "metadata": {
        "id": "6FquW2OFiogU",
        "outputId": "fe893a3f-6eb3-46b5-fe45-28e32866bb30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21435546875\n",
            "0.18017578125\n",
            "0.14306640625\n",
            "0.11767578125\n",
            "0.11279296875\n",
            "0.09033203125\n",
            "0.04638671875\n",
            "0.03955078125\n",
            "0.02783203125\n",
            "0.02099609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "    return hex_list\n",
        "\n",
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "def convert_hex_input_to_float(hex_input):\n",
        "    hex_strings = format_hex_input(hex_input)\n",
        "    float_values = hexa_to_float(hex_strings)\n",
        "    return float_values\n",
        "\n",
        "def chunk_floats(float_values, chunk_size=10):\n",
        "    # float 값을 chunk_size 크기로 분할하고 각 chunk 사이에 두 개의 엔터를 추가\n",
        "    chunked_result = \"\"\n",
        "    for i in range(0, len(float_values), chunk_size):\n",
        "        chunk = float_values[i:i + chunk_size]\n",
        "        chunked_result += \"\\n\".join(map(str, chunk)) + \"\\n\\n\"\n",
        "    return chunked_result.strip()\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"\"\"\n",
        "1404\n",
        "026c\n",
        "0234\n",
        "0214\n",
        "0184\n",
        "017c\n",
        "015c\n",
        "001c\n",
        "001c\n",
        "0004\n",
        "\"\"\"\n",
        "\n",
        "float_values = convert_hex_input_to_float(hex_input)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "chunked_result = chunk_floats(float_values)\n",
        "\n",
        "print(chunked_result)"
      ],
      "metadata": {
        "id": "w7Z4vjWsiwnS",
        "outputId": "547caa23-6df2-4bab-9fa4-7f33a910a137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62548828125\n",
            "0.07568359375\n",
            "0.06884765625\n",
            "0.06494140625\n",
            "0.04736328125\n",
            "0.04638671875\n",
            "0.04248046875\n",
            "0.00341796875\n",
            "0.00341796875\n",
            "0.00048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0000110101000100\",\n",
        "    \"0000100000100100\",\n",
        "    \"0000001101111100\",\n",
        "    \"0000001011111100\",\n",
        "    \"0000000111000100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000001110100\",\n",
        "    \"0000000001000100\",\n",
        "    \"0000000000111100\",\n",
        "    \"0000000000110100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for decoded in decoded_values:\n",
        "    print(decoded)\n"
      ],
      "metadata": {
        "id": "8BR8NGmgi0Ny",
        "outputId": "b1865f5f-8d03-40d6-ff3b-6ba89cec5472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41455078125\n",
            "0.25439453125\n",
            "0.10888671875\n",
            "0.09326171875\n",
            "0.05517578125\n",
            "0.03173828125\n",
            "0.01416015625\n",
            "0.00830078125\n",
            "0.00732421875\n",
            "0.00634765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "new_hex_strings = [\"0d44\", \"0824\", \"037c\", \"02fc\", \"01c4\", \"0104\", \"0074\", \"0044\", \"003c\", \"0034\"]\n",
        "new_binary_strings = hexa_to_binary(new_hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(new_hex_strings, new_binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "1W-StNJci3XU",
        "outputId": "b8709404-48ce-48df-97ad-2cb91bda72e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000110101000100\n",
            "0000100000100100\n",
            "0000001101111100\n",
            "0000001011111100\n",
            "0000000111000100\n",
            "0000000100000100\n",
            "0000000001110100\n",
            "0000000001000100\n",
            "0000000000111100\n",
            "0000000000110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"069c\", \"046c\", \"045c\", \"0434\", \"02fc\", \"02a4\", \"026c\", \"01d4\", \"00e4\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")"
      ],
      "metadata": {
        "id": "xyNYFw6ki5gk",
        "outputId": "cb6cdb62-1a5a-4820-d2dc-ed8eaf3b5e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000011010011100\n",
            "0000010001101100\n",
            "0000010001011100\n",
            "0000010000110100\n",
            "0000001011111100\n",
            "0000001010100100\n",
            "0000001001101100\n",
            "0000000111010100\n",
            "0000000011100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "hex_strings = [\"045c\", \"0404\", \"03b4\", \"039c\", \"0374\", \"034c\", \"031c\", \"027c\", \"022c\", \"01bc\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "LCmwYD9Qi79m",
        "outputId": "10b486f1-bf62-4d3a-ff04-c920264e4931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000010001011100\n",
            "0000010000000100\n",
            "0000001110110100\n",
            "0000001110011100\n",
            "0000001101110100\n",
            "0000001101001100\n",
            "0000001100011100\n",
            "0000001001111100\n",
            "0000001000101100\n",
            "0000000110111100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error_rates(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    list of float: 각 데이터에 대한 오차율 (백분율) 리스트\n",
        "    \"\"\"\n",
        "    if len(actual_values) != len(predicted_values):\n",
        "        raise ValueError(\"실제 값 리스트와 예측 값 리스트의 길이는 같아야 합니다.\")\n",
        "\n",
        "    error_rates = []\n",
        "    for actual, predicted in zip(actual_values, predicted_values):\n",
        "        if actual == 0:\n",
        "            error_rate = 0\n",
        "        else:\n",
        "            error = actual - predicted\n",
        "            error_rate = abs((error / actual) * 100)\n",
        "        error_rates.append(error_rate)\n",
        "\n",
        "    return error_rates\n",
        "\n",
        "def calculate_average_error_rate(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 평균 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    float: 평균 오차율 (백분율)\n",
        "    \"\"\"\n",
        "    error_rates = calculate_error_rates(actual_values, predicted_values)\n",
        "    average_error_rate = sum(error_rates) / len(error_rates)\n",
        "    return average_error_rate"
      ],
      "metadata": {
        "id": "D2-wjc8yi_Ij"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용\n",
        "actual_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "predicted_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "average_error_rate = calculate_average_error_rate(actual_values, predicted_values)\n",
        "\n",
        "print(f\"최종 오차율: {average_error_rate}%\")"
      ],
      "metadata": {
        "id": "clf_RoSfjBeq",
        "outputId": "dac97dc8-f977-4f2e-f7c5-6f0e70c9fcf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 오차율: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정\n",
        "start_time = time.time()\n",
        "softmax_values = softmax(values)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Softmax output: {softmax_values}\")\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "i7BTwvyNjE92",
        "outputId": "27873bec-06cf-45c3-9f27-6bde985910f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output: [0.09222514 0.07933714 0.13408144 0.07743605 0.13117615 0.1283651\n",
            " 0.09086202 0.08387534 0.0808663  0.10177532]\n",
            "Execution time: 0.0003597736358642578 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정 (timeit 모듈 사용)\n",
        "execution_time = timeit.timeit(lambda: softmax(values), number=100000)\n",
        "print(f\"Average execution time over 1000 runs: {execution_time / 100000} seconds\")\n"
      ],
      "metadata": {
        "id": "I7TbeCl0jFAe",
        "outputId": "78ca5867-67eb-452b-d1ad-5524d94c4a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time over 1000 runs: 7.871906190000572e-06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "start_time = time.time()\n",
        "my_function()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "_Y3J9uF8jFCp",
        "outputId": "b449521a-fca4-4c3a-806d-b19cd663133e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.000333786010742 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "execution_time = timeit.timeit(my_function, number=1)\n",
        "print(f\"Execution time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "id": "9a5zh7itjK_1",
        "outputId": "0abc850a-2626-4209-ba14-eb2d8d2c7971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.000072781000199 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "id": "XarrC_jbjPME",
        "outputId": "2fb19cbe-1c2a-4121-8ec8-76971e13526d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0000922679901123 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import socket\n",
        "\n",
        "# HW -> SW connect\n",
        "# This should be fixed later when connecting with hardware.\n",
        "def receive_from_hardware(host: str, port: int, buffer_size: int = 1024) -> bytes:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.connect((host, port))\n",
        "        attention_probs_hw = s.recv(buffer_size)\n",
        "    return attention_probs_hw\n",
        "\n",
        "# HW 2진수 -> SW Decode\n",
        "def decode_values(encoded_values_list: list) -> list:\n",
        "    encoded_values = tuple(encoded_values_list)\n",
        "    decoded_values = []\n",
        "\n",
        "    for encoded_value in encoded_values:\n",
        "        special_value_bit = encoded_value[0]\n",
        "        if special_value_bit == '1':\n",
        "            decoded_values.append(0.0)\n",
        "        else:\n",
        "            sign_bit = encoded_value[1]\n",
        "            sign = -1 if sign_bit == '1' else 1\n",
        "\n",
        "            integer_part = int(encoded_value[2:5], 2)\n",
        "            fractional_part = int(encoded_value[5:], 2) / (1 << 13)\n",
        "\n",
        "            decoded_value = sign * (integer_part + fractional_part)\n",
        "            decoded_values.append(round(decoded_value, 7))\n",
        "\n",
        "    return decoded_values\n",
        "\n",
        "# 1D -> 4D 변환 코드\n",
        "def convert_to_4d(input_list):\n",
        "    # Step 1: Divide the list into sublists of 10 elements each\n",
        "    sublists = [input_list[i:i + 10] for i in range(0, len(input_list), 10)]\n",
        "\n",
        "    # Step 2: Group every 10 sublists into a larger list to form a [12, 10, 10] shape\n",
        "    grouped_sublists = [sublists[i:i + 10] for i in range(0, len(sublists), 10)]\n",
        "\n",
        "    # Step 3: Convert the final list to a tensor and add an extra dimension to form [1, 12, 10, 10]\n",
        "    attention_probs_4d = torch.tensor(grouped_sublists).unsqueeze(0)\n",
        "    return attention_probs_4d"
      ],
      "metadata": {
        "id": "vh30Ck9JjWVj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "03UOsodCJaEg",
        "outputId": "b306508c-dd05-4bef-d1ba-37a7b5e9843a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_raw_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "GEln6Bi7whyh",
        "outputId": "3cc846f0-0e85-4761-eab0-fa6a748bc692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "05VQ55mWooaT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import math\n",
        "attention_scores = layer_1_attention\n",
        "attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        " #Pickle 파일 저장\n",
        "if attention_mask is not None:\n",
        " # Apply the attention mask is (precomputed for all layers in BertModel\n",
        " attention_scores = attention_scores + attention_mask\n",
        " # attention_scores를 피클 파일로 저장합니다.\n",
        "attention_scores_list = attention_scores.tolist()  # torch.Tensor를 Python 리스트로 변환\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"wb\") as f:\n",
        " pickle.dump(attention_scores_list, f)\n",
        " #저장된 Pickle 파일 불러와서 plot\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        " outputs = pickle.load(f)\n",
        "out_chain3 = list(itertools.chain(*outputs))\n",
        "out_chain2 = list(itertools.chain(*out_chain3))\n",
        "out_chain1 = list(itertools.chain(*out_chain2))\n",
        "print(out_chain1)\n",
        "max_value = torch.max(attention_scores)\n",
        "min_value = torch.min(attention_scores)\n",
        "print(\"Max value in attention_scores:\", max_value.item())"
      ],
      "metadata": {
        "id": "YAV18-7XnknO",
        "outputId": "6677399f-036a-4de7-ea6f-d211165a955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b97d7302ca28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;31m#Pickle 파일 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "if2KlEtgI6bj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # Attention 값 활성화\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        # Attention Score (Softmax 이후 값)\n",
        "        attention_probs = outputs.attentions  # (batch, num_heads, seq_length, seq_length)\n",
        "\n",
        "        # Softmax 이전 값 = Scaled Dot-Product Attention Score (QK^T / sqrt(d_k))\n",
        "        raw_attentions = []\n",
        "        for layer in self.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.last_hidden_state)\n",
        "            K = layer.attention.self.key(outputs.last_hidden_state)\n",
        "            d_k = Q.shape[-1] ** 0.5  # sqrt(d_k)\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # QK^T / sqrt(d_k)\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, attention_probs  # Softmax 이전 값과 이후 값 반환\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# 입력 문장\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions = model(**inputs)\n",
        "\n",
        "# 첫 번째 레이어의 Softmax 이전 Attention Score 출력\n",
        "layer_1_raw_attention = raw_attentions[0].numpy()  # NumPy 변환\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "keaM8Y3PvqJ7",
        "outputId": "0ed0219a-8580-46d5-bf8a-6c4d8995cc0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 10, 10)):\n",
            "[[[-1.2585267e+00  2.6621759e-01 -8.7831020e-01 -5.4661173e-01\n",
            "   -2.8880724e-01  1.1142263e+00 -7.5586647e-01 -1.0404842e+00\n",
            "   -6.2354100e-01 -4.8658773e-01]\n",
            "  [-2.5612357e-01 -1.7154795e-01 -8.6090702e-01 -7.6754767e-01\n",
            "   -9.9591351e-01 -1.0064337e+00 -4.0744746e-01 -1.7507937e+00\n",
            "    1.7926955e-01  1.0923295e+00]\n",
            "  [-2.9597259e-01 -5.9717542e-01 -5.0122070e-01 -7.3208112e-01\n",
            "   -9.1411477e-01 -4.8521334e-01 -9.0301853e-01 -1.1684108e+00\n",
            "   -1.5857342e-01  1.2634809e+00]\n",
            "  [-1.3794887e-01 -2.0422029e-01  4.0585518e-01 -1.5016638e+00\n",
            "    5.4751128e-02  1.4497165e-01 -1.1364064e+00 -2.2216363e+00\n",
            "   -2.4729875e-01 -1.3346322e+00]\n",
            "  [ 1.0132506e+00  1.6417295e+00  6.2383556e-01  6.2764668e-01\n",
            "   -6.2279487e-01  9.1525161e-01  3.9802289e-01 -1.1625541e+00\n",
            "   -6.0396677e-01 -1.1437993e+00]\n",
            "  [ 1.1180567e+00  9.2262423e-01  1.6634616e+00  1.2863833e+00\n",
            "    3.0124974e-01 -3.3511552e-01  4.4247529e-01 -2.0134099e+00\n",
            "    1.5760978e-01 -7.0655382e-01]\n",
            "  [-2.5666538e-01  2.3752621e-01  8.9618230e-01  2.3380097e-02\n",
            "   -2.6171404e-01 -1.5986454e-01 -3.9145359e-01 -1.2563347e+00\n",
            "   -8.6368091e-02 -5.2962303e-01]\n",
            "  [-4.5617834e-01 -1.4080495e+00 -1.0176413e+00 -1.1380228e+00\n",
            "   -4.4654146e-01  1.3681081e-01 -9.1811270e-01 -1.7249386e+00\n",
            "    1.1240224e-01 -7.5502324e-01]\n",
            "  [-1.6819029e-01  6.5099800e-01 -4.0929699e-01  1.4927831e-01\n",
            "   -6.9800383e-01  1.3894488e+00  8.2726449e-02 -2.1458438e-01\n",
            "    8.2820904e-01  7.9360116e-01]\n",
            "  [-1.4812164e+00 -4.1874580e-02 -2.2205778e-03 -8.7177467e-01\n",
            "   -1.9289713e+00 -1.3873569e+00 -1.0950005e+00 -8.9245355e-01\n",
            "   -5.1268822e-01  1.1695848e+00]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 Head 수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        raw_attentions = []\n",
        "        for layer in self.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.last_hidden_state)  # (1, 10, 768)\n",
        "            K = layer.attention.self.key(outputs.last_hidden_state)  # (1, 10, 768)\n",
        "\n",
        "            # 🚀 **멀티헤드 형태로 변환 (12개 헤드 고려)**\n",
        "            Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, head_dim)\n",
        "            K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, head_dim)\n",
        "\n",
        "            # Softmax 이전 Attention Score (1, 12, 10, 10)\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, outputs.attentions  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# 입력 문장\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions = model(**inputs)\n",
        "\n",
        "#  Softmax 이전 값의 shape이 (1, 12, 10, 10)\n",
        "layer_1_raw_attention = raw_attentions[0].numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "6c_PDcdAuBHP",
        "outputId": "cc21fafc-d25a-4599-ad0c-35a6dc4ede2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[-0.16330126  0.74665904  0.5046175  ...  0.1053734  -0.3517992\n",
            "    -0.82628703]\n",
            "   [-0.85504246 -0.8495395   0.27420458 ... -0.7120759  -0.6404201\n",
            "    -0.7213575 ]\n",
            "   [-0.33850312 -0.49887422 -1.0850958  ... -0.41751945 -0.6837665\n",
            "     0.12196846]\n",
            "   ...\n",
            "   [ 0.04038128 -1.5239407  -0.4461439  ... -0.8514781  -0.62913764\n",
            "    -1.6456957 ]\n",
            "   [-0.48097274 -1.1991742  -0.16329284 ...  0.6281986  -0.76396775\n",
            "    -0.7268485 ]\n",
            "   [-0.87766147 -1.1943011  -0.7693224  ... -1.3699665  -1.3390534\n",
            "    -1.2797705 ]]\n",
            "\n",
            "  [[-1.5912344   0.20777252 -0.43285406 ... -0.1675356  -0.7102615\n",
            "    -1.2166344 ]\n",
            "   [-0.7868527  -1.6073718  -0.392333   ... -0.75894797 -0.4079647\n",
            "    -1.2190759 ]\n",
            "   [-0.8922362  -1.5154754  -0.5177639  ... -1.1458592   0.04225418\n",
            "    -0.81918186]\n",
            "   ...\n",
            "   [-0.91656446 -1.0473183  -1.0032847  ... -1.8697616  -0.1359748\n",
            "    -1.1439781 ]\n",
            "   [-1.0975006   0.37157917 -0.00895183 ... -0.17786475 -0.4199428\n",
            "    -0.6056418 ]\n",
            "   [-1.0515333  -1.0735983  -0.05120684 ...  0.6294587  -0.54036653\n",
            "    -1.3968381 ]]\n",
            "\n",
            "  [[-1.3334383   0.52438104 -0.77032316 ... -1.5920824  -0.6231944\n",
            "     0.6344059 ]\n",
            "   [ 0.60698706  0.8066657  -0.67015445 ... -1.5112193  -0.23542288\n",
            "     1.3105445 ]\n",
            "   [ 0.1526948   0.43083888 -0.17596313 ... -1.0903219   0.08325759\n",
            "     1.6672667 ]\n",
            "   ...\n",
            "   [-1.329351   -0.46315804 -0.77565247 ... -1.8013197  -0.62225544\n",
            "     0.04331292]\n",
            "   [-1.354799    0.23697038 -0.7694026  ... -1.0223584  -0.39240664\n",
            "     1.1857013 ]\n",
            "   [-0.77541286  1.3453577   0.29122424 ... -0.58102393  0.17997822\n",
            "     2.177164  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.63773     0.58566344  0.02071998 ...  0.6568019  -0.00503088\n",
            "     0.5775351 ]\n",
            "   [ 0.78469926  0.7234775   0.37324268 ...  0.569415    1.1611848\n",
            "     0.6611439 ]\n",
            "   [ 0.3827159  -0.38354316 -0.5915842  ...  0.07002717  0.5606207\n",
            "     0.02549144]\n",
            "   ...\n",
            "   [ 1.7375914   0.74641496  1.1182951  ...  1.1461586   0.9258757\n",
            "     1.1023892 ]\n",
            "   [ 1.1071512   1.3260292   0.03723068 ...  0.7178233   0.57782423\n",
            "     1.2720349 ]\n",
            "   [ 0.3825344   0.2458191  -0.4766403  ... -0.06924211  0.1440097\n",
            "     0.67922354]]\n",
            "\n",
            "  [[-0.3283248  -0.4531534  -0.86989236 ... -1.0598785  -0.37491632\n",
            "     0.2130923 ]\n",
            "   [-0.4929133  -1.5774691  -1.8541327  ... -1.1291902  -0.08987184\n",
            "     0.23253548]\n",
            "   [-0.4946392  -1.7031145  -2.267106   ... -1.085547   -0.52221733\n",
            "     0.45331928]\n",
            "   ...\n",
            "   [-0.7060982  -0.8856094  -0.4371871  ... -1.617462   -0.37426627\n",
            "     0.09161048]\n",
            "   [-0.5336012  -0.49941093  0.12769873 ... -0.99562484 -0.21031216\n",
            "     0.80872864]\n",
            "   [-1.1588708  -0.64251643 -1.3979228  ... -0.06940307 -1.1459157\n",
            "    -1.1483954 ]]\n",
            "\n",
            "  [[ 1.9371294   1.6769056   0.6644526  ...  1.3235898   0.4470895\n",
            "     0.93524164]\n",
            "   [ 1.2109681   4.041701    1.0350982  ...  0.7575122   0.9619884\n",
            "     2.167085  ]\n",
            "   [ 0.8685935   2.0647922   4.160913   ...  0.98664516  0.39813486\n",
            "     1.0062088 ]\n",
            "   ...\n",
            "   [ 1.6321392   1.4402163   1.1636865  ...  4.4765925   1.1307021\n",
            "     0.8986397 ]\n",
            "   [ 1.3424951   0.9187418   0.57245266 ...  1.02316     2.328365\n",
            "     1.0132259 ]\n",
            "   [ 0.4674242   1.5584285   0.5007494  ...  0.0055076   0.7250677\n",
            "     3.1158278 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#아무래도 진짜..코드 위에선  outputs.last_hidden_state 로 써서 12번째 레이어의 값으로 KQV 계산했을 수 있다.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        # BERT 모델의 기본 동작 수행\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # 어텐션 값 반환 활성화\n",
        "            output_hidden_states=True,  # 히든 스테이트 반환 활성화\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # 모델 설정값 가져오기\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 멀티헤드 개수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기 (64)\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        # === 첫 번째 Transformer 레이어에서 Query (Q), Key (K) 직접 가져오기 ===\n",
        "        first_layer = self.encoder.layer[0]  # 첫 번째 Transformer 레이어\n",
        "        input_tensor = outputs.hidden_states[0]  # 첫 번째 레이어 입력 (Embedding 후 결과)\n",
        "\n",
        "        # Query, Key 생성\n",
        "        Q = first_layer.attention.self.query(input_tensor)  # (1, 10, 768)\n",
        "        K = first_layer.attention.self.key(input_tensor)  # (1, 10, 768)\n",
        "\n",
        "        # === Multi-Head 형태로 변환 ===\n",
        "        # Query, Key의 shape을 (batch_size, num_heads, sequence_length, head_dim)로 변환\n",
        "        Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "        K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 계산 ===\n",
        "        raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # (1, 12, 10, 10)\n",
        "\n",
        "        return raw_attention, outputs.attentions[0]  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === 첫 번째 레이어의 Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "_beDp4MY8Ib_",
        "outputId": "0b00c82f-aae4-45ed-f787-5c713cee6352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# 1. 토크나이저 로드\n",
        "model_name = \"klue/bert-base\"  # 모델 이름 (학습에 사용된 것과 동일해야 함)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 2. 사전 학습된 모델 로드\n",
        "num_labels = len(label_names)  # 멀티라벨 분류를 위한 레이블 수\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "# 저장된 가중치 로드\n",
        "checkpoint_path = \"/content/model/BERT_multilabel_model.pt\"  # 저장된 모델 경로\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# 3. Attention 추출을 위해 모델 설정 변경\n",
        "model.config.output_attentions = True  # Attention 점수 출력 활성화\n",
        "model.eval()  # 평가 모드\n",
        "\n",
        "# 4. 입력 텍스트\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 5. 모델 추론\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits  # 최종 예측 값 (softmax 이전)\n",
        "    attentions = outputs.attentions  # Attention 점수\n",
        "\n",
        "# 6. Softmax 이전의 값을 출력\n",
        "print(f\"Logits (Softmax 이전 값): {logits}\")\n",
        "\n",
        "# 7. Attention 점수를 출력 (각 Layer마다 Attention 점수가 포함됨)\n",
        "for i, attention_layer in enumerate(attentions):\n",
        "    print(f\"Layer {i + 1} Attention Scores: {attention_layer.shape}\")\n",
        "\n",
        "# 각 Attention Layer의 Shape\n",
        "for i, attention in enumerate(attentions):\n",
        "    print(f\"Layer {i + 1} Attention Shape: {attention.shape}\")\n",
        "\n",
        "# 첫 번째 레이어의 Attention 값을 numpy로 변환하여 확인\n",
        "layer_1_attention = attentions[0].numpy()\n",
        "print(f\"Layer 1 Attention Scores (Shape: {layer_1_attention.shape}):\")\n",
        "print(layer_1_attention)\n"
      ],
      "metadata": {
        "id": "u9YiENTjOKK7",
        "outputId": "1fb107ae-a0f8-49f5-8083-707a93ca9ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-76-ccee9f185cc6>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits (Softmax 이전 값): tensor([[-2.4690, -4.7337, -4.9942,  2.2562, -5.2708, -4.6522, -5.1170,  1.8131,\n",
            "         -4.5230]])\n",
            "Layer 1 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 2 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 3 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 4 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 5 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 6 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 7 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 8 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 9 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 10 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 11 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 12 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 1 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 2 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 3 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 4 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 5 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 6 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 7 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 8 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 9 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 10 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 11 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 12 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 1 Attention Scores (Shape: (1, 12, 10, 10)):\n",
            "[[[[0.50276214 0.01801627 0.02399363 ... 0.0342509  0.03105909\n",
            "    0.06140413]\n",
            "   [0.28548524 0.12932299 0.11471977 ... 0.03935906 0.03413377\n",
            "    0.0462996 ]\n",
            "   [0.02393627 0.23049009 0.119009   ... 0.03462357 0.03437519\n",
            "    0.03273839]\n",
            "   ...\n",
            "   [0.07680625 0.00734722 0.00598513 ... 0.06522951 0.3043518\n",
            "    0.23911789]\n",
            "   [0.03908146 0.0087873  0.02467276 ... 0.27252406 0.04178381\n",
            "    0.42806664]\n",
            "   [0.13904521 0.01395757 0.00765489 ... 0.12952536 0.06837368\n",
            "    0.13328184]]\n",
            "\n",
            "  [[0.07985371 0.11216996 0.10060646 ... 0.10826609 0.09725763\n",
            "    0.2325552 ]\n",
            "   [0.0540519  0.01976733 0.12369999 ... 0.05865423 0.0952526\n",
            "    0.3069954 ]\n",
            "   [0.06732248 0.07314759 0.01510452 ... 0.17405728 0.11080742\n",
            "    0.3473453 ]\n",
            "   ...\n",
            "   [0.09490318 0.07963616 0.09468538 ... 0.0643936  0.0823948\n",
            "    0.34108797]\n",
            "   [0.02915837 0.1307724  0.08730808 ... 0.11512087 0.08144001\n",
            "    0.15715772]\n",
            "   [0.04625707 0.14411137 0.08635145 ... 0.16749963 0.07595401\n",
            "    0.21095937]]\n",
            "\n",
            "  [[0.19249158 0.02968404 0.00476936 ... 0.02142655 0.03418698\n",
            "    0.16786152]\n",
            "   [0.18242025 0.13631509 0.03929277 ... 0.06477983 0.03665771\n",
            "    0.17155178]\n",
            "   [0.18842699 0.07288257 0.04646761 ... 0.05176065 0.0615009\n",
            "    0.1846192 ]\n",
            "   ...\n",
            "   [0.12221343 0.16754884 0.08269276 ... 0.25251973 0.06872934\n",
            "    0.15158708]\n",
            "   [0.05153883 0.2571161  0.07073224 ... 0.07998767 0.06833493\n",
            "    0.18693537]\n",
            "   [0.41005656 0.04520131 0.00977826 ... 0.02479132 0.035253\n",
            "    0.1137526 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10091401 0.15715222 0.10352629 ... 0.07797453 0.12888864\n",
            "    0.2592011 ]\n",
            "   [0.11257173 0.15267216 0.17494407 ... 0.04752741 0.02646148\n",
            "    0.33733252]\n",
            "   [0.02282469 0.13679282 0.3181143  ... 0.0866075  0.11079092\n",
            "    0.12702297]\n",
            "   ...\n",
            "   [0.0292747  0.07044251 0.26751333 ... 0.13342448 0.05688879\n",
            "    0.18797602]\n",
            "   [0.05979285 0.10998605 0.11743829 ... 0.15265188 0.08031254\n",
            "    0.15957834]\n",
            "   [0.06887838 0.0913663  0.20700881 ... 0.13372055 0.09142224\n",
            "    0.16873328]]\n",
            "\n",
            "  [[0.37489742 0.02933082 0.01872855 ... 0.00941682 0.02215154\n",
            "    0.05373281]\n",
            "   [0.0477233  0.07654192 0.10908442 ... 0.06884889 0.13898917\n",
            "    0.08864494]\n",
            "   [0.07779457 0.0570039  0.1138563  ... 0.05632794 0.06416035\n",
            "    0.27175546]\n",
            "   ...\n",
            "   [0.12312736 0.13339986 0.05075939 ... 0.05491564 0.07999808\n",
            "    0.20520656]\n",
            "   [0.05629834 0.1606151  0.03484033 ... 0.18163337 0.17536202\n",
            "    0.19427177]\n",
            "   [0.26320818 0.01499027 0.01506835 ... 0.02027144 0.0245714\n",
            "    0.03274287]]\n",
            "\n",
            "  [[0.18579273 0.04888129 0.05709388 ... 0.04365798 0.07530626\n",
            "    0.43601793]\n",
            "   [0.29635048 0.23618098 0.05854771 ... 0.04919232 0.04249952\n",
            "    0.07779395]\n",
            "   [0.39474365 0.00597612 0.36150783 ... 0.03503075 0.03659008\n",
            "    0.1024332 ]\n",
            "   ...\n",
            "   [0.34529865 0.01474646 0.02463462 ... 0.27073318 0.04451074\n",
            "    0.1501966 ]\n",
            "   [0.24132645 0.04245967 0.1469332  ... 0.04169809 0.2451356\n",
            "    0.16123603]\n",
            "   [0.51953447 0.02683437 0.04897838 ... 0.07776037 0.04533174\n",
            "    0.18517023]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=True, return_dict=True):\n",
        "        # ✅ output_hidden_states=True 추가!\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,  # ✅ 여기를 추가해야 hidden_states가 출력됨!\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # Softmax 이후의 Attention Score\n",
        "        attention_probs = outputs.attentions\n",
        "\n",
        "        # Softmax 이전 값 (QK^T / sqrt(d_k)) 추출\n",
        "        raw_attentions = []\n",
        "        for layer in self.bert.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.hidden_states[-1])  # ✅ 이제 None이 아님!\n",
        "            K = layer.attention.self.key(outputs.hidden_states[-1])\n",
        "            d_k = Q.shape[-1] ** 0.5  # sqrt(d_k)\n",
        "\n",
        "            # Softmax 이전의 Attention Score\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, attention_probs, outputs.logits\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name, num_labels=len(label_names))\n",
        "\n",
        "# 입력 문장\n",
        "texts = [\"ㅅ발 천주교도들은 너무 말이 많아\"]\n",
        "\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions, logits = model(**inputs)\n",
        "\n",
        "# Softmax 이전의 Attention Score 확인\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {raw_attentions[0].shape}):\")\n",
        "print(raw_attentions[0].numpy())\n",
        "\n",
        "# Softmax 이후의 Attention Score 확인\n",
        "print(f\"Layer 1 Softmax 이후 Attention Score (Shape: {softmax_attentions[0].shape}):\")\n",
        "print(softmax_attentions[0].numpy())\n",
        "\n",
        "# 최종 분류 logits 출력\n",
        "print(f\"Logits (분류 모델의 Softmax 이전 값): {logits}\")\n"
      ],
      "metadata": {
        "id": "BCV0QwgTxr1e",
        "outputId": "860bdb15-aebf-47cf-a375-0a4ce3dfdee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertWithRawAttention were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: torch.Size([1, 10, 10])):\n",
            "[[[-1.25852823e+00  2.66215712e-01 -8.78310561e-01 -5.46610832e-01\n",
            "   -2.88807482e-01  1.11422515e+00 -7.55868137e-01 -1.04048252e+00\n",
            "   -6.23540282e-01 -4.86584216e-01]\n",
            "  [-2.56121695e-01 -1.71548009e-01 -8.60907257e-01 -7.67546833e-01\n",
            "   -9.95912910e-01 -1.00643361e+00 -4.07447457e-01 -1.75079393e+00\n",
            "    1.79270849e-01  1.09233379e+00]\n",
            "  [-2.95971274e-01 -5.97175062e-01 -5.01220524e-01 -7.32082844e-01\n",
            "   -9.14117396e-01 -4.85211074e-01 -9.03017342e-01 -1.16841352e+00\n",
            "   -1.58572093e-01  1.26348448e+00]\n",
            "  [-1.37948975e-01 -2.04223856e-01  4.05856907e-01 -1.50166214e+00\n",
            "    5.47514558e-02  1.44970313e-01 -1.13640618e+00 -2.22163677e+00\n",
            "   -2.47296557e-01 -1.33462834e+00]\n",
            "  [ 1.01324928e+00  1.64172506e+00  6.23836458e-01  6.27645195e-01\n",
            "   -6.22797310e-01  9.15249646e-01  3.98019969e-01 -1.16255677e+00\n",
            "   -6.03965938e-01 -1.14379549e+00]\n",
            "  [ 1.11805654e+00  9.22619820e-01  1.66346371e+00  1.28638303e+00\n",
            "    3.01247567e-01 -3.35117072e-01  4.42473382e-01 -2.01341057e+00\n",
            "    1.57611266e-01 -7.06549704e-01]\n",
            "  [-2.56664723e-01  2.37522781e-01  8.96184087e-01  2.33783759e-02\n",
            "   -2.61715978e-01 -1.59865290e-01 -3.91456425e-01 -1.25633550e+00\n",
            "   -8.63685906e-02 -5.29619396e-01]\n",
            "  [-4.56178546e-01 -1.40805280e+00 -1.01764131e+00 -1.13802481e+00\n",
            "   -4.46542889e-01  1.36807829e-01 -9.18115318e-01 -1.72494113e+00\n",
            "    1.12401016e-01 -7.55020678e-01]\n",
            "  [-1.68190569e-01  6.50996327e-01 -4.09294933e-01  1.49280071e-01\n",
            "   -6.98003054e-01  1.38944983e+00  8.27238634e-02 -2.14583308e-01\n",
            "    8.28214407e-01  7.93602645e-01]\n",
            "  [-1.48121583e+00 -4.18758541e-02 -2.22063810e-03 -8.71774971e-01\n",
            "   -1.92896914e+00 -1.38735354e+00 -1.09499991e+00 -8.92453134e-01\n",
            "   -5.12685597e-01  1.16958547e+00]]]\n",
            "Layer 1 Softmax 이후 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[0.50193053 0.01646294 0.02458053 ... 0.03021928 0.03516091\n",
            "    0.06308161]\n",
            "   [0.22571197 0.12214692 0.13914467 ... 0.03955203 0.03931026\n",
            "    0.05574832]\n",
            "   [0.00731852 0.15145266 0.11674146 ... 0.02108586 0.02430418\n",
            "    0.02280195]\n",
            "   ...\n",
            "   [0.0678239  0.00700259 0.0069513  ... 0.04489433 0.3237514\n",
            "    0.22219692]\n",
            "   [0.03092064 0.00997889 0.03502037 ... 0.2269365  0.04496774\n",
            "    0.41050157]\n",
            "   [0.0741941  0.01003211 0.01068952 ... 0.09740562 0.08451286\n",
            "    0.13224411]]\n",
            "\n",
            "  [[0.04115042 0.08926985 0.07000751 ... 0.10584227 0.1085436\n",
            "    0.3201155 ]\n",
            "   [0.05052924 0.01660708 0.09794959 ... 0.07169245 0.12102537\n",
            "    0.27986318]\n",
            "   [0.05395626 0.05563773 0.01607826 ... 0.17889246 0.10790431\n",
            "    0.3581522 ]\n",
            "   ...\n",
            "   [0.07962454 0.07294574 0.09648975 ... 0.07228429 0.08998562\n",
            "    0.3496276 ]\n",
            "   [0.0255961  0.1254367  0.08391792 ... 0.12145846 0.07797515\n",
            "    0.16491632]\n",
            "   [0.05308816 0.11393113 0.08302062 ... 0.15818529 0.0855791\n",
            "    0.22085819]]\n",
            "\n",
            "  [[0.25516987 0.03431695 0.00428409 ... 0.01912345 0.03518634\n",
            "    0.15660179]\n",
            "   [0.13680004 0.11780471 0.03900155 ... 0.06704757 0.03970232\n",
            "    0.24825518]\n",
            "   [0.11689737 0.09255069 0.05735985 ... 0.0605448  0.06487989\n",
            "    0.19065589]\n",
            "   ...\n",
            "   [0.11428072 0.20210367 0.08333405 ... 0.22817586 0.0654134\n",
            "    0.14926815]\n",
            "   [0.04288723 0.3133893  0.0878645  ... 0.06443704 0.06182248\n",
            "    0.14729889]\n",
            "   [0.3005874  0.05435768 0.01160257 ... 0.02809226 0.04214298\n",
            "    0.11146384]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05317722 0.14274758 0.10946882 ... 0.07352181 0.10586049\n",
            "    0.3477556 ]\n",
            "   [0.11008223 0.24453689 0.18030298 ... 0.05199188 0.02249919\n",
            "    0.20538071]\n",
            "   [0.01644883 0.12896726 0.33732638 ... 0.08603207 0.10337761\n",
            "    0.09454589]\n",
            "   ...\n",
            "   [0.03143752 0.08671279 0.31751582 ... 0.10323577 0.04712138\n",
            "    0.14935142]\n",
            "   [0.04219531 0.10846445 0.13773629 ... 0.14145379 0.072102\n",
            "    0.1732167 ]\n",
            "   [0.0542199  0.09281379 0.23242326 ... 0.1167574  0.08671355\n",
            "    0.1751735 ]]\n",
            "\n",
            "  [[0.5720189  0.01799796 0.0087535  ... 0.00541417 0.01432684\n",
            "    0.03467807]\n",
            "   [0.03808249 0.07802656 0.11277841 ... 0.06981867 0.13535056\n",
            "    0.0923093 ]\n",
            "   [0.04817314 0.05937601 0.11599965 ... 0.06266043 0.06124886\n",
            "    0.29385027]\n",
            "   ...\n",
            "   [0.11173632 0.13069044 0.0493538  ... 0.0537655  0.07555193\n",
            "    0.1833624 ]\n",
            "   [0.05658199 0.16392574 0.03680176 ... 0.1664859  0.143547\n",
            "    0.19960178]\n",
            "   [0.21057622 0.00922463 0.01137071 ... 0.01278055 0.0171657\n",
            "    0.02579084]]\n",
            "\n",
            "  [[0.20086427 0.04173107 0.04344716 ... 0.03688852 0.07055343\n",
            "    0.471857  ]\n",
            "   [0.23607269 0.3755227  0.05690284 ... 0.04558486 0.02987671\n",
            "    0.06265713]\n",
            "   [0.22610003 0.00912194 0.5442027  ... 0.04248916 0.03555816\n",
            "    0.08360582]\n",
            "   ...\n",
            "   [0.3231144  0.01766624 0.0279856  ... 0.30637172 0.04468505\n",
            "    0.14027685]\n",
            "   [0.2573445  0.03987942 0.14915828 ... 0.04214596 0.23392743\n",
            "    0.16138762]\n",
            "   [0.47199497 0.03932175 0.06136924 ... 0.09315775 0.05202026\n",
            "    0.16953959]]]]\n",
            "Logits (분류 모델의 Softmax 이전 값): tensor([[-0.5414,  0.4313,  0.0370, -0.0976, -0.0870, -0.2223, -0.2459,  0.2729,\n",
            "         -0.4879]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './model/attention_scores_2.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "Q0nZ4Onl21iB",
        "outputId": "868878ad-3db2-48fc-e23a-7f06e58611eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    0.11714409  0.5856975   0.6307755  -0.30920362  2.1947367\n",
            "  -0.14835791  0.49772462  2.0617602   1.4053444 ]\n",
            " [ 1.6703308   3.3466518   5.793112    4.621073    3.812749    2.3419719\n",
            "   1.8878778   2.3886065   1.5484276   1.9099072 ]\n",
            " [ 3.3168168   4.502995    3.8073637   5.2124023   2.3082643   3.0351076\n",
            "   2.4797425   1.6874914   2.6028967   1.5656495 ]\n",
            " [ 2.5718498   4.652975    6.7969666   3.8015726   5.3321524   2.659658\n",
            "   2.719986    2.416732    2.1785326   3.108758  ]\n",
            " [ 0.62522817  4.6419153   3.3077164   5.064213    3.339889    2.7762215\n",
            "   1.873533    3.4980125   2.023627    2.5917144 ]\n",
            " [ 3.9795005   2.6142015   2.2757936   2.9215946   3.511932    3.220555\n",
            "   3.0432897   2.8711824   4.3125715   4.3036885 ]\n",
            " [ 1.7959094   2.6852992   1.6750463   1.3191165   4.1721644   3.331105\n",
            "   2.4741642   4.5505824   2.6400094   3.1753776 ]\n",
            " [ 1.6387088   1.7666457   2.1017816   2.1071794   3.422982    3.3852067\n",
            "   4.2240024   2.9609547   3.9101954   4.537689  ]\n",
            " [ 3.3072975   1.2618201   2.365435    1.1282016   2.2333503   2.9970148\n",
            "   3.822887    4.3632503   3.529175    5.7495446 ]\n",
            " [ 4.5703983   3.1162205   2.4864216   3.426703    2.1799157   5.7463045\n",
            "   3.174025    4.4660215   6.618206    5.1483626 ]] [[-1.0886638   0.02555725  0.311149   -0.1185468  -0.07704417 -1.6976843\n",
            "  -0.04857237 -0.46038562 -0.6803706   0.9627847 ]\n",
            " [-1.7430696  -0.5790163   0.7301598   0.43518707  0.06117958 -1.1784676\n",
            "  -0.22009215 -0.7375137  -0.6899191   0.97234195]\n",
            " [-0.43296996 -0.34776625 -0.61825126 -0.5565975  -0.20672473 -1.1309534\n",
            "   0.21543759 -0.0585902  -1.3146526   1.1253307 ]\n",
            " [-0.5908074  -0.25380707  0.00024927  0.01682144  0.45576128 -0.25012723\n",
            "   0.03673334  0.14773999 -0.3354175   1.2667636 ]\n",
            " [-1.7260594  -0.03702255  0.32314226  0.09670944 -0.25472367 -1.5367095\n",
            "   0.7070519   0.6523646  -1.2064693   0.59022087]\n",
            " [-1.209122    0.15285142  0.38227442  0.2848917   0.37704596 -0.8517933\n",
            "   0.01839954  0.43778053 -0.49263728  0.7998164 ]\n",
            " [-0.2891728   0.10043441 -0.09115115  0.03625927  0.10675713 -0.83618826\n",
            "   0.2000978   0.5833909  -0.17491554  0.60655284]\n",
            " [-0.35978922  0.09165996  0.42240837  0.1125567  -0.06464243 -1.3896195\n",
            "   0.38931042 -0.33630806 -0.56914496  0.99600965]\n",
            " [-0.96181583  0.22939461  0.1490941   0.16794282  0.17030033 -0.5399121\n",
            "   0.03469593  0.6880506  -0.33433583  0.4417293 ]\n",
            " [-0.60645354 -0.3579516   0.47387433  0.27014586  0.25771543 -0.9096098\n",
            "   0.17429377 -0.10441241 -0.4639737   0.81911325]] [[ 2.8996303   0.02200214 -0.74852276  0.631462   -1.1275623   3.0894957\n",
            "   0.9280114  -0.14752409  4.0928345   2.411408  ]\n",
            " [ 0.5878507   3.011582    3.9065943   3.235908    0.50435984  0.34831482\n",
            "   0.17555894  2.1310635  -0.09421223  0.98545116]\n",
            " [ 0.6049058   2.2343197   2.6323042   2.430443    0.4869851   0.8571075\n",
            "   1.0000788   1.5101197   0.56835276  1.3811649 ]\n",
            " [ 1.430701    2.0099015   4.087019    3.0947237   0.56819826  0.75650877\n",
            "   0.33274144  1.465734   -0.30525357  0.9727164 ]\n",
            " [-0.3164355   1.5521222   3.0174787   1.4834703   2.2269187  -1.30088\n",
            "   1.1328936   3.5774622  -1.429762   -0.17385992]\n",
            " [ 3.4188118   0.62846535  0.07279523  0.71736014 -0.32747287  2.2898376\n",
            "   1.0576711   0.22138332  3.0749917   2.4532826 ]\n",
            " [ 1.9065028   0.88415587  1.2080953   0.14300826  0.593324    0.49050444\n",
            "   0.5708541   1.5033801   0.42657304  0.6549574 ]\n",
            " [ 2.1231966   0.84968215  1.4300145   1.3541062   1.0749373   1.852924\n",
            "   0.76707125  1.5934157   1.0071483   2.0823565 ]\n",
            " [ 3.2195091   0.0096926   0.56950235  0.23191671 -0.32239503  2.1220663\n",
            "   1.1799686   0.2573312   1.7817802   2.0053072 ]\n",
            " [ 3.912785    0.8497595   0.3867088   0.8289084   0.23973835  3.5320184\n",
            "   1.3169683   0.9062026   4.1586957   2.9207473 ]] [[-0.91819704 -0.73714244 -1.2835796  -1.3152801  -1.7907189  -2.3600693\n",
            "  -1.71575    -2.0585341  -0.88458973 -1.0391645 ]\n",
            " [ 0.76816994  2.8525796   0.98103195  1.0893993   1.291576   -0.3590138\n",
            "  -0.05392636  1.1377413  -1.1812421   0.5328254 ]\n",
            " [ 0.44077566  1.889281    1.394224    1.2403969   0.93400806 -0.6091448\n",
            "   0.37211862  1.1208864  -0.48069543  0.9152784 ]\n",
            " [-0.4079485   1.9117765   0.61145085  1.4986356   1.2874416  -0.2541298\n",
            "   0.17829615  0.8347929  -0.5898164   1.7898803 ]\n",
            " [ 0.5058691   1.6893194   0.8303908   0.35562584  1.9394354  -0.32631215\n",
            "  -0.15927449  1.2605628  -1.4803319   0.92400664]\n",
            " [ 0.47246826  1.049527    0.68996495  0.5756347   0.2827701   1.6729834\n",
            "   1.2482777   1.4437281   1.0102694   0.7912869 ]\n",
            " [ 1.2386009   1.133507    0.64457095  0.43742573  1.0146374  -0.527435\n",
            "   1.1386023   1.2811688  -0.267912   -0.3252511 ]\n",
            " [-0.6168757   0.9414549   0.6545312   0.44207764  1.0313237   0.28013933\n",
            "   0.6557309   1.4528047   0.10742482  2.0227776 ]\n",
            " [ 0.6610696   1.1441543   0.83005744  0.6699963   0.68824714  0.8841506\n",
            "   1.2305831   1.0789971   0.96978915  0.1847023 ]\n",
            " [ 0.48081017  0.5815153   0.65710616  0.34215644 -0.4203801  -1.0223608\n",
            "  -0.1397903   0.8336154   0.45186663 -0.02691434]] [[-0.4206367  -0.26431718 -0.8189321   0.5453431  -0.81877565  3.265758\n",
            "   1.123025   -0.45972508  3.0087957   4.069817  ]\n",
            " [ 1.711552    4.0104914   6.097168    4.062114    3.3517642   0.6797678\n",
            "   2.4742503   2.5503993   1.0404894   2.6415534 ]\n",
            " [ 1.6555488   2.8842583   3.6345613   2.4311733   2.4532597   1.8469099\n",
            "   1.1871887   2.1401596   2.593385    2.5239465 ]\n",
            " [ 2.897587    4.3002462   6.664719    2.8146844   4.007442    0.92588633\n",
            "   0.9355154   1.9416659   1.1508867   2.0899508 ]\n",
            " [ 1.4384526   4.5608745   3.7128031   3.3055158   2.5344577   0.3143406\n",
            "   2.7502472   3.773708    1.4212635   1.7340083 ]\n",
            " [-1.8715912   2.1050293   2.2834506   2.1121552   1.4853789   2.427682\n",
            "   3.0749145   1.8919368   3.9486756   4.785963  ]\n",
            " [ 0.63691103  1.810391    0.84790796  1.1583683   2.2992978   1.9338874\n",
            "   2.1868212   3.2546113   2.360936    3.5164182 ]\n",
            " [ 0.39985502  1.6061538   1.7325523   0.35841948  2.477663    1.037012\n",
            "   2.7054691   2.465773    1.360221    2.7568579 ]\n",
            " [-1.5197104   0.47858107  1.2087647   0.85278237  1.0399474   2.266237\n",
            "   3.0739172   2.0501065   2.4958704   4.687452  ]\n",
            " [ 3.000189   -0.7293791  -0.74419117  1.7917078   0.4763999   2.9361863\n",
            "   2.2864735   2.0922556   2.3336442   3.609223  ]] [[ 2.3518488  -2.4012413  -2.5848315  -2.5842254  -1.4390004  -1.3970611\n",
            "  -1.486853   -1.3146498  -1.5213429  -0.10409442]\n",
            " [-0.08029907  0.95492965  3.0861502   1.0803758   2.8016753   1.3075106\n",
            "   2.5004106   3.4115536   1.5283737   2.4000955 ]\n",
            " [-0.98470867  1.4555954   1.5423824   0.30919918  3.159526    1.3234267\n",
            "   2.0309644   3.8802829   0.77620506  2.2096994 ]\n",
            " [-1.3650285   1.9985721   3.1277943   0.9758086   3.153818    2.5558827\n",
            "   2.7993655   3.6075718   2.483896    3.5096714 ]\n",
            " [-0.53188324  2.7865634   2.933026    1.9947041   2.6538177   0.17108425\n",
            "   1.41041     3.5341537   0.09414454  2.1139412 ]\n",
            " [-0.05147918  2.960376    2.8401773   2.9880128   2.2146826   3.026591\n",
            "   2.6003537   2.4387147   3.1415412   3.8921413 ]\n",
            " [-0.9958864   2.6857972   2.583294    2.6029804   2.5345263   1.2893649\n",
            "   1.4581535   2.6380162   2.0204773   2.2150342 ]\n",
            " [ 0.04527869  2.9330308   3.2778075   2.720913    3.2038531   1.2107869\n",
            "   1.9810863   2.4970698   1.1165935   1.571423  ]\n",
            " [-0.23130603  2.2237506   2.6563025   2.6123178   2.1577914   2.2081223\n",
            "   2.521809    2.3261166   1.9723585   2.7725258 ]\n",
            " [ 0.2493442   3.188392    3.1076705   3.369534    2.6593766   3.4948716\n",
            "   2.873453    2.958899    3.7007978   5.390417  ]] [[ 1.8577769  -0.1782641  -0.8391258  -0.20157872  0.03677352  1.8336577\n",
            "  -0.5154236  -0.9360012  -0.36019903  2.0303364 ]\n",
            " [ 0.07594603  1.6416981   2.4703162   1.7014173   1.7434708   0.00997017\n",
            "   1.3008279   1.896263    1.5449183   1.616728  ]\n",
            " [ 0.6953787   2.1692429   2.1441464   1.7379965   2.1794832   0.00943146\n",
            "   1.3819319   2.406196    1.5149322   1.8323896 ]\n",
            " [ 1.5004507   2.191609    2.7665334   0.9322765   2.0782743  -0.32668146\n",
            "   1.5269834   2.6152775   1.2686868   2.566569  ]\n",
            " [-0.5223735   2.492464    1.484075    1.3629732   1.5521193  -0.75108665\n",
            "   1.1117117   2.8975577   1.2339579   0.7913337 ]\n",
            " [ 4.608461    2.6140327   1.6747181   1.5631702   1.1256423   2.156302\n",
            "   1.8067638   1.0583446   1.9421829   4.2106786 ]\n",
            " [ 2.443831    2.08211     1.7901441   1.5581807   2.1890495   1.9666604\n",
            "   1.4040198   2.1084352   1.0204064   2.4160697 ]\n",
            " [ 1.6170082   2.1157253   1.7847257   1.1339206   2.4702833   1.1112541\n",
            "   1.9466188   2.2814734   1.4104946   2.5419347 ]\n",
            " [ 2.5761323   1.8463246   1.4472572   1.2411208   1.1666892   1.2266266\n",
            "   2.137839    1.720331    1.3243217   2.4792182 ]\n",
            " [ 5.4560094   2.8533223   1.9060035   2.8041744   2.1872957   4.541738\n",
            "   2.3418133   2.6403146   3.3154905   5.353278  ]] [[-0.20872909 -0.04676584 -0.06920808  0.22612049 -0.5273356  -0.03878088\n",
            "  -0.35037673 -0.24101785 -0.03800961 -0.4477717 ]\n",
            " [ 0.39312774 -0.72015625 -0.11039566 -0.47187504 -0.6243619  -0.5550632\n",
            "  -0.06305974  0.23725607 -0.29921988  0.67517275]\n",
            " [ 0.9336121  -0.30668795 -1.2280265  -0.23901877  0.21531588 -0.02921304\n",
            "   0.18740971  0.49287453 -0.32362545  0.5395098 ]\n",
            " [ 0.44989973 -0.07840493 -0.70561624 -0.6797175  -0.32464612 -0.00245793\n",
            "   0.24341476 -0.38152987 -0.6197981   0.69756246]\n",
            " [ 0.07505149 -0.34050646 -0.20628366 -0.03507853 -2.1298897  -0.46191064\n",
            "   0.10249646 -0.23292464 -0.44878232 -0.04885465]\n",
            " [ 0.2423661   0.24130446 -0.13099633  0.29947233  0.00284321  0.18978542\n",
            "   0.3024567   0.02645526  0.03272907  0.096457  ]\n",
            " [ 0.52392596 -0.43888092  0.6062699  -0.16046394 -0.4598454  -0.40288302\n",
            "  -0.34419575 -0.3142506  -0.00332226 -0.19334584]\n",
            " [-0.56612873 -0.188554   -0.02999487 -1.3156276  -0.39713255 -0.16519366\n",
            "  -0.31032342 -2.612752   -0.6005166   0.04201785]\n",
            " [ 0.2327159   0.3471023  -0.03875374  0.0647919  -0.1906524   0.13848405\n",
            "   0.0672462  -0.08677322  0.1582894  -0.00930041]\n",
            " [ 0.2202284  -0.15427314 -0.08931216 -0.03995595  0.00104465 -0.02846966\n",
            "  -0.06644918 -0.06230865  0.05504296 -0.25045082]] [[ 0.7274816   0.11507649  0.284214   -0.4026169  -0.22948742  0.5726925\n",
            "   0.7000268   0.13661313  2.2500303   2.2188106 ]\n",
            " [ 1.4019722   3.4689038   2.3157012   2.951157    1.1965826   1.1602786\n",
            "  -0.1770497   0.6572411   0.2278574   1.8796558 ]\n",
            " [ 1.2921461   0.8905095   3.709777    2.3455753   1.0153087   1.4283334\n",
            "   0.5606777   0.47134808  1.6395503   1.9080584 ]\n",
            " [ 1.8637079   3.003888    3.8354084   4.1362057   1.2275932   2.323182\n",
            "  -0.19235559  1.0532311   1.3310231   2.590262  ]\n",
            " [ 0.54005456  0.6143206   1.7547503   1.8359743   3.094353    0.6746429\n",
            "   0.2596902   1.5248697   0.47067168  1.3008693 ]\n",
            " [-0.9338605   0.5036669   0.87460697  0.45084783  0.901352   -0.10966269\n",
            "   1.9916923   1.3448064   2.0936713   0.80160993]\n",
            " [ 0.5728401  -0.04004947  0.45082232 -0.43184328  0.9820602   0.0408671\n",
            "   1.4810711   0.40630463  0.07374337  0.5373771 ]\n",
            " [ 2.0956993   0.6018912   0.6745899   0.5275235   1.8832694   0.7081071\n",
            "   1.0816227   3.1449246   0.19390348  2.3962045 ]\n",
            " [-0.3780636   0.18745206  1.7450609   0.46006605  0.8310921   0.57361317\n",
            "   2.0125527   1.6686664   1.5488706   1.1293051 ]\n",
            " [ 0.6197194   0.2847378   0.8111273   0.29930606  0.12218147  0.633571\n",
            "   1.7020148   1.1978279   2.0720472   1.3618188 ]] [[-0.7641907  -0.04179777 -0.03871024 -0.01029287  0.10982683 -3.409261\n",
            "  -0.8519444  -0.1011171  -0.61037153  1.11368   ]\n",
            " [ 0.6315195   1.5662173   1.0136852   0.79115003  0.5027024  -0.84586865\n",
            "  -0.60011023  1.0755258   0.36316153  1.5360875 ]\n",
            " [-0.19636366  1.3796113   0.9972024   0.42479315  0.7522633  -1.2828168\n",
            "  -0.24372143  0.53102773  0.60126495  1.431718  ]\n",
            " [-0.01733678  1.2261399   0.60732824 -0.3713482   1.0066447  -1.0930486\n",
            "  -0.34242573  1.2536769  -0.01925345  0.05428234]\n",
            " [-0.6089171   0.812452    0.73339826  0.27320436  1.0981218  -0.69458455\n",
            "   0.300511    1.9441388  -0.5859628   1.1883222 ]\n",
            " [-0.3862846   0.9120517   0.6206465   0.7143033   0.49330038 -1.0343239\n",
            "  -0.31964967  0.45504218  0.87512237  1.6519731 ]\n",
            " [-0.11572167  1.118077    1.1451776   0.45498532  0.7921902  -0.8244491\n",
            "   0.13255627  1.3740886   1.5412023   1.585442  ]\n",
            " [-0.42347932  0.7645048   1.1695968   0.8649328   1.0572455  -1.3920376\n",
            "   0.06315615  1.8586993   1.3764335   1.3430959 ]\n",
            " [-0.04602024  1.0310172   1.1641402   0.830472    0.55506825 -1.4279099\n",
            "  -0.305408    0.95073116  1.0027801   1.6112568 ]\n",
            " [-0.1204833   0.88820004  0.8350356   0.46982872  0.30827308 -1.1874206\n",
            "   0.06021432  0.6750055   0.5101989   1.052246  ]] [[ 3.5113144   0.23125732  0.14855024  0.31988123 -0.34488022  1.1630836\n",
            "  -0.23730999 -0.6694767   0.04084282  0.70824903]\n",
            " [ 1.7904973   2.2246804   2.806927    2.5454693   2.600652    2.0405247\n",
            "   2.0883412   2.6324604   1.0418186   2.819541  ]\n",
            " [ 2.5830665   2.5436692   2.6789215   2.552863    1.8923868   2.387744\n",
            "   2.497571    1.4598      1.4553257   3.0531595 ]\n",
            " [ 2.0304976   3.0259213   3.0475783   2.566625    2.3083878   2.8534472\n",
            "   2.431889    3.5424695   1.5133282   3.2522182 ]\n",
            " [ 0.85365546  2.1300118   2.9776423   2.764315    1.9021384   2.261848\n",
            "   0.78977865  2.7873087   1.51449     3.4065237 ]\n",
            " [ 4.7410984   2.2832878   2.5947425   2.7378526   1.9672732   3.6375775\n",
            "   2.2509813   3.3431032   1.4767879   2.352169  ]\n",
            " [ 1.3938805   2.63342     2.7286584   1.8677042   2.9486048   1.323737\n",
            "   0.75743663  3.4104338   1.7034984   2.298728  ]\n",
            " [ 1.5281339   3.5719974   3.1684306   2.4641638   3.45946     2.1354446\n",
            "   2.2208533   3.3282526   1.6605146   4.188968  ]\n",
            " [ 3.7193854   2.3510675   2.3213775   2.3511674   2.4487157   3.718595\n",
            "   2.4170146   3.097043    1.2444317   2.0928166 ]\n",
            " [ 5.245867    2.9236443   2.6110198   2.8997252   2.7353942   4.847442\n",
            "   2.6822622   3.372125    2.8552227   3.146039  ]] [[ 1.7404832   0.20622298  0.17036484  0.14028859 -0.0875273  -0.28903437\n",
            "  -0.05346468 -0.21828583  0.24408357  2.5945306 ]\n",
            " [ 2.5038111   3.8067138  -0.9152964  -1.0867347  -0.66055036 -0.3236773\n",
            "  -0.31045496 -1.4174232   0.43165812  1.9661093 ]\n",
            " [ 2.3395207  -1.5124058   1.7736304  -0.67819226 -1.0566123   0.19052632\n",
            "  -0.78984517 -1.3535223   0.9409393   0.73563135]\n",
            " [ 1.2547673   0.34710675 -0.44897196  2.7757225  -0.33859655 -0.15644921\n",
            "  -0.6115687  -0.48662195  0.41058114  0.87479126]\n",
            " [ 0.6738987   0.4476631  -1.602245   -0.6992324   3.0947883  -0.30546984\n",
            "  -0.6876085  -0.13776019  0.14923412  0.28215185]\n",
            " [ 1.546602   -0.46327224 -1.2862829  -1.491924   -1.288245   -1.6702429\n",
            "  -0.73712903 -1.5902119  -0.9095844   1.7985494 ]\n",
            " [ 1.4186683   0.2906626  -0.9079117  -1.503863   -0.35724834 -0.79060125\n",
            "   1.2171147  -1.3592548  -0.53071135  0.48501337]\n",
            " [ 1.5222133  -0.8623995  -0.37342417 -0.85203713 -1.0658941  -0.4834577\n",
            "   0.21761012  3.1788638   0.40442356  0.29755515]\n",
            " [ 1.7944585   0.43165296 -0.3501598  -0.7924533   0.07014562 -0.5650798\n",
            "  -0.51980543 -1.6325725  -1.2602837   0.9605556 ]\n",
            " [ 1.9798651  -0.5624908  -0.7449863  -1.232003   -0.63779896 -0.6748462\n",
            "  -0.8677051  -0.9195779  -0.8235787   0.9559839 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 각 최소 단위(10x10 행렬의 10개 값) 내림차순 정렬\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 최소 단위(10개) 값을 내림차순으로 정렬\n",
        "            sorted_attention_scores[i, j, k] = np.sort(attention_scores[i, j, k])[::-1]\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gTTz4HV13uLB",
        "outputId": "5818db24-998a-4401-bb51-ee5fa898edca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEeT1XRCxsN",
        "outputId": "80ffdd09-527c-451a-b066-cf19e57879ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/sorted_attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "-vdLamvD6Vcc",
        "outputId": "ebb7c8f2-0e95-4d80-fab9-5fec8ed982d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.50276214 0.18352194 0.07385454 ... 0.02399363 0.01801627\n",
            "    0.00693945]\n",
            "   [0.28548524 0.15781423 0.12932299 ... 0.0462996  0.03935906\n",
            "    0.03413377]\n",
            "   [0.42965856 0.23049009 0.119009   ... 0.03273839 0.02393627\n",
            "    0.01153364]\n",
            "   ...\n",
            "   [0.3043518  0.23911789 0.14382176 ... 0.02023179 0.00734722\n",
            "    0.00598513]\n",
            "   [0.42806664 0.27252406 0.0660226  ... 0.03525357 0.02467276\n",
            "    0.0087873 ]\n",
            "   [0.35068387 0.13904521 0.13328184 ... 0.01395757 0.00985229\n",
            "    0.00765489]]\n",
            "\n",
            "  [[0.2325552  0.13501358 0.11216996 ... 0.06796568 0.04669739\n",
            "    0.01961427]\n",
            "   [0.3069954  0.1544281  0.12369999 ... 0.0540519  0.03094326\n",
            "    0.01976733]\n",
            "   [0.3473453  0.17405728 0.11080742 ... 0.02729124 0.0272199\n",
            "    0.01510452]\n",
            "   ...\n",
            "   [0.34108797 0.14767179 0.09490318 ... 0.05895856 0.02201105\n",
            "    0.01425752]\n",
            "   [0.16335478 0.15715772 0.1307724  ... 0.07702713 0.06241015\n",
            "    0.02915837]\n",
            "   [0.21095937 0.16749963 0.14411137 ... 0.04625707 0.04081224\n",
            "    0.03196875]]\n",
            "\n",
            "  [[0.20825657 0.19249158 0.18383561 ... 0.02142655 0.01533512\n",
            "    0.00476936]\n",
            "   [0.24235135 0.18242025 0.17155178 ... 0.03665771 0.03388991\n",
            "    0.03156955]\n",
            "   [0.18842699 0.1846192  0.15932496 ... 0.0527045  0.05176065\n",
            "    0.04646761]\n",
            "   ...\n",
            "   [0.25251973 0.16754884 0.15158708 ... 0.03404357 0.03329607\n",
            "    0.02462847]\n",
            "   [0.2571161  0.21102408 0.18693537 ... 0.02713428 0.02467851\n",
            "    0.02251801]\n",
            "   [0.41005656 0.19873372 0.1137526  ... 0.02479132 0.01154065\n",
            "    0.00977826]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2592011  0.15715222 0.12888864 ... 0.05018471 0.01325505\n",
            "    0.0045917 ]\n",
            "   [0.33733252 0.17494407 0.15267216 ... 0.02646148 0.01087068\n",
            "    0.00389986]\n",
            "   [0.3181143  0.13679282 0.12702297 ... 0.02282469 0.02214158\n",
            "    0.01064354]\n",
            "   ...\n",
            "   [0.26751333 0.18797602 0.13342448 ... 0.04374462 0.0292747\n",
            "    0.00853144]\n",
            "   [0.18074659 0.15957834 0.15265188 ... 0.05979285 0.03502361\n",
            "    0.01639437]\n",
            "   [0.20700881 0.16873328 0.13372055 ... 0.06887838 0.02255044\n",
            "    0.00934925]]\n",
            "\n",
            "  [[0.37489742 0.2901547  0.11512411 ... 0.02215154 0.01872855\n",
            "    0.00941682]\n",
            "   [0.18999724 0.13898917 0.12236455 ... 0.07654192 0.06884889\n",
            "    0.0477233 ]\n",
            "   [0.27175546 0.12120829 0.1138563  ... 0.0570039  0.05632794\n",
            "    0.05246266]\n",
            "   ...\n",
            "   [0.20520656 0.13339986 0.12312736 ... 0.05491564 0.05075939\n",
            "    0.03485935]\n",
            "   [0.19427177 0.18163337 0.17536202 ... 0.03484033 0.02603423\n",
            "    0.0250867 ]\n",
            "   [0.2918996  0.27665862 0.26320818 ... 0.02027144 0.01506835\n",
            "    0.01499027]]\n",
            "\n",
            "  [[0.43601793 0.18579273 0.07530626 ... 0.03807148 0.03671275\n",
            "    0.03654618]\n",
            "   [0.29635048 0.23618098 0.07779395 ... 0.05147965 0.04919232\n",
            "    0.04249952]\n",
            "   [0.39474365 0.36150783 0.1024332  ... 0.01188225 0.00715878\n",
            "    0.00597612]\n",
            "   ...\n",
            "   [0.34529865 0.27073318 0.1501966  ... 0.03340842 0.02463462\n",
            "    0.01474646]\n",
            "   [0.2451356  0.24132645 0.16123603 ... 0.02899556 0.02688335\n",
            "    0.02529364]\n",
            "   [0.51953447 0.18517023 0.07776037 ... 0.02618033 0.01927708\n",
            "    0.01510626]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "3IpQeei26iui"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = \"/./content/model/sorted_attention_scores_2.txt\"  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "dhImdkUJ62U5",
        "outputId": "b9822e92-3cce-4324-899d-46943b500006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    2.1947362   2.06176     1.4053445   0.6307752   0.58569705\n",
            "   0.49772385  0.1171443  -0.14835815 -0.30920365]\n",
            " [ 5.7931113   4.6210723   3.8127494   3.3466516   2.388606    2.3419714\n",
            "   1.9099065   1.8878773   1.6703308   1.5484267 ]\n",
            " [ 5.212402    4.502995    3.8073645   3.3168163   3.035107    2.6028965\n",
            "   2.4797413   2.3082643   1.6874913   1.5656486 ]\n",
            " [ 6.7969666   5.332153    4.652974    3.8015728   3.1087575   2.7199864\n",
            "   2.6596584   2.57185     2.4167328   2.178532  ]\n",
            " [ 5.0642123   4.6419163   3.4980135   3.33989     3.3077157   2.776222\n",
            "   2.591714    2.023627    1.8735324   0.62522924]\n",
            " [ 4.312572    4.3036885   3.9794996   3.5119328   3.2205546   3.0432897\n",
            "   2.9215946   2.8711832   2.6142018   2.2757945 ]\n",
            " [ 4.5505824   4.1721644   3.3311045   3.1753774   2.6852996   2.6400094\n",
            "   2.474163    1.7959092   1.6750463   1.319116  ]\n",
            " [ 4.5376897   4.2240024   3.9101956   3.422982    3.3852065   2.9609554\n",
            "   2.1071799   2.1017816   1.7666456   1.6387084 ]\n",
            " [ 5.749544    4.363251    3.822886    3.5291743   3.3072975   2.9970138\n",
            "   2.3654344   2.2333505   1.26182     1.1282014 ]\n",
            " [ 6.6182046   5.7463036   5.148362    4.5703974   4.4660215   3.4267032\n",
            "   3.1740246   3.1162214   2.4864209   2.179915  ]] [[ 9.62784529e-01  3.11149150e-01  2.55574640e-02 -4.85723391e-02\n",
            "  -7.70441294e-02 -1.18546724e-01 -4.60385650e-01 -6.80370450e-01\n",
            "  -1.08866346e+00 -1.69768381e+00]\n",
            " [ 9.72342312e-01  7.30159998e-01  4.35187191e-01  6.11795522e-02\n",
            "  -2.20091984e-01 -5.79016626e-01 -6.89918935e-01 -7.37513602e-01\n",
            "  -1.17846775e+00 -1.74306989e+00]\n",
            " [ 1.12533069e+00  2.15437546e-01 -5.85901067e-02 -2.06724599e-01\n",
            "  -3.47766310e-01 -4.32970107e-01 -5.56597531e-01 -6.18251145e-01\n",
            "  -1.13095355e+00 -1.31465292e+00]\n",
            " [ 1.26676357e+00  4.55761015e-01  1.47740409e-01  3.67335863e-02\n",
            "   1.68215800e-02  2.49130127e-04 -2.50126958e-01 -2.53806859e-01\n",
            "  -3.35417181e-01 -5.90807140e-01]\n",
            " [ 7.07051992e-01  6.52364492e-01  5.90220928e-01  3.23142320e-01\n",
            "   9.67092812e-02 -3.70225869e-02 -2.54723728e-01 -1.20646906e+00\n",
            "  -1.53670979e+00 -1.72605956e+00]\n",
            " [ 7.99816489e-01  4.37780261e-01  3.82274300e-01  3.77045691e-01\n",
            "   2.84891605e-01  1.52851313e-01  1.83995999e-02 -4.92637485e-01\n",
            "  -8.51793349e-01 -1.20912230e+00]\n",
            " [ 6.06553137e-01  5.83390892e-01  2.00097620e-01  1.06757261e-01\n",
            "   1.00434326e-01  3.62592638e-02 -9.11512226e-02 -1.74915552e-01\n",
            "  -2.89172739e-01 -8.36188257e-01]\n",
            " [ 9.96009588e-01  4.22408402e-01  3.89310181e-01  1.12556770e-01\n",
            "   9.16600302e-02 -6.46427050e-02 -3.36308211e-01 -3.59789193e-01\n",
            "  -5.69145083e-01 -1.38962007e+00]\n",
            " [ 6.88050687e-01  4.41729665e-01  2.29394421e-01  1.70300364e-01\n",
            "   1.67942837e-01  1.49093851e-01  3.46958674e-02 -3.34335864e-01\n",
            "  -5.39912164e-01 -9.61816132e-01]\n",
            " [ 8.19113076e-01  4.73874301e-01  2.70145953e-01  2.57715315e-01\n",
            "   1.74293727e-01 -1.04412325e-01 -3.57951760e-01 -4.63973701e-01\n",
            "  -6.06453776e-01 -9.09609616e-01]] [[ 4.092835    3.089495    2.8996305   2.4114072   0.9280116   0.6314621\n",
            "   0.02200188 -0.14752427 -0.74852276 -1.1275623 ]\n",
            " [ 3.9065936   3.2359092   3.0115817   2.1310635   0.9854513   0.5878505\n",
            "   0.50435996  0.34831503  0.175559   -0.09421209]\n",
            " [ 2.6323042   2.4304433   2.234319    1.5101193   1.3811644   1.0000788\n",
            "   0.85710794  0.60490626  0.5683531   0.48698413]\n",
            " [ 4.0870185   3.0947244   2.0099018   1.4657339   1.4307015   0.97271603\n",
            "   0.7565092   0.5681987   0.3327423  -0.30525312]\n",
            " [ 3.5774617   3.0174778   2.2269177   1.5521219   1.4834702   1.1328934\n",
            "  -0.17385964 -0.31643584 -1.3008794  -1.4297612 ]\n",
            " [ 3.4188123   3.074992    2.453283    2.2898376   1.0576713   0.7173609\n",
            "   0.6284648   0.2213835   0.07279554 -0.32747284]\n",
            " [ 1.9065027   1.5033797   1.2080951   0.8841557   0.65495795  0.59332407\n",
            "   0.5708546   0.4905048   0.42657357  0.14300847]\n",
            " [ 2.1231968   2.0823562   1.852924    1.5934154   1.4300145   1.3541068\n",
            "   1.0749373   1.0071484   0.8496826   0.76707166]\n",
            " [ 3.2195091   2.122066    2.0053062   1.7817798   1.1799685   0.5695026\n",
            "   0.257331    0.231917    0.00969239 -0.3223953 ]\n",
            " [ 4.1586957   3.9127853   3.5320184   2.920747    1.3169682   0.90620166\n",
            "   0.84975827  0.82890856  0.38670912  0.23973802]] [[-0.7371427  -0.8845895  -0.91819656 -1.0391641  -1.2835793  -1.3152798\n",
            "  -1.7157488  -1.7907189  -2.0585341  -2.360069  ]\n",
            " [ 2.85258     1.2915757   1.1377412   1.0893992   0.9810324   0.7681697\n",
            "   0.5328255  -0.05392626 -0.3590129  -1.1812415 ]\n",
            " [ 1.8892814   1.3942242   1.2403971   1.1208861   0.93400806  0.9152787\n",
            "   0.4407753   0.37211823 -0.4806948  -0.6091446 ]\n",
            " [ 1.9117774   1.7898803   1.4986356   1.287442    0.83479303  0.61145127\n",
            "   0.17829587 -0.2541294  -0.40794897 -0.5898161 ]\n",
            " [ 1.9394357   1.6893197   1.2605628   0.9240067   0.8303909   0.5058692\n",
            "   0.3556258  -0.15927449 -0.32631204 -1.4803323 ]\n",
            " [ 1.672984    1.4437281   1.2482772   1.0495272   1.0102698   0.7912871\n",
            "   0.6899649   0.57563496  0.47246793  0.28276998]\n",
            " [ 1.281169    1.2386005   1.1386018   1.1335067   1.0146376   0.6445712\n",
            "   0.4374258  -0.2679118  -0.3252513  -0.52743465]\n",
            " [ 2.0227785   1.4528052   1.0313249   0.9414555   0.6557309   0.65453154\n",
            "   0.442078    0.2801403   0.10742534 -0.616876  ]\n",
            " [ 1.2305831   1.1441543   1.0789975   0.96978927  0.8841511   0.83005774\n",
            "   0.6882472   0.66999644  0.6610695   0.18470252]\n",
            " [ 0.8336157   0.65710616  0.5815149   0.48081034  0.45186692  0.34215623\n",
            "  -0.02691453 -0.13979028 -0.42038023 -1.0223606 ]] [[ 4.0698175   3.265758    3.0087962   1.1230251   0.5453435  -0.26431745\n",
            "  -0.42063725 -0.45972463 -0.8187756  -0.81893194]\n",
            " [ 6.097168    4.062113    4.0104914   3.3517637   2.641553    2.5503986\n",
            "   2.4742506   1.7115523   1.0404898   0.6797684 ]\n",
            " [ 3.6345613   2.8842587   2.5933852   2.5239463   2.4532604   2.4311736\n",
            "   2.1401598   1.8469099   1.6555493   1.1871887 ]\n",
            " [ 6.66472     4.3002467   4.007442    2.8975873   2.8146842   2.08995\n",
            "   1.9416658   1.1508873   0.9355155   0.925887  ]\n",
            " [ 4.5608754   3.7737079   3.7128038   3.305515    2.750248    2.5344577\n",
            "   1.7340081   1.4384531   1.4212637   0.31434077]\n",
            " [ 4.785963    3.9486759   3.0749137   2.4276817   2.2834513   2.1121554\n",
            "   2.1050296   1.8919371   1.4853793  -1.8715913 ]\n",
            " [ 3.5164182   3.2546115   2.3609362   2.299298    2.186821    1.9338875\n",
            "   1.8103911   1.1583686   0.847908    0.63691074]\n",
            " [ 2.7568579   2.7054698   2.4776633   2.4657736   1.7325536   1.6061542\n",
            "   1.3602213   1.0370121   0.399855    0.3584192 ]\n",
            " [ 4.6874523   3.0739164   2.495871    2.2662377   2.0501072   1.2087655\n",
            "   1.0399477   0.8527832   0.47858194 -1.5197108 ]\n",
            " [ 3.6092231   3.000189    2.9361858   2.3336432   2.2864738   2.092256\n",
            "   1.7917082   0.47639987 -0.72937936 -0.7441914 ]] [[ 2.3518493  -0.10409462 -1.3146498  -1.3970613  -1.4390007  -1.4868536\n",
            "  -1.5213429  -2.4012418  -2.5842257  -2.584832  ]\n",
            " [ 3.4115534   3.0861497   2.8016756   2.5004098   2.4000952   1.5283731\n",
            "   1.3075103   1.0803764   0.9549299  -0.08029935]\n",
            " [ 3.880282    3.1595256   2.2096982   2.0309634   1.542382    1.4555956\n",
            "   1.3234261   0.77620447  0.30919868 -0.9847092 ]\n",
            " [ 3.6075714   3.50967     3.153817    3.1277936   2.7993653   2.555882\n",
            "   2.4838946   1.9985723   0.9758085  -1.3650291 ]\n",
            " [ 3.534153    2.933026    2.786563    2.6538172   2.113941    1.9947034\n",
            "   1.4104099   0.17108409  0.09414434 -0.5318833 ]\n",
            " [ 3.8921409   3.1415412   3.0265913   2.9880128   2.960376    2.8401778\n",
            "   2.600354    2.4387147   2.2146823  -0.05147942]\n",
            " [ 2.685798    2.6380167   2.602979    2.5832932   2.5345256   2.2150333\n",
            "   2.0204775   1.4581529   1.2893647  -0.99588656]\n",
            " [ 3.2778072   3.2038534   2.9330308   2.7209134   2.4970696   1.9810863\n",
            "   1.5714234   1.2107861   1.1165932   0.0452789 ]\n",
            " [ 2.7725263   2.6563027   2.612318    2.521809    2.326117    2.2237513\n",
            "   2.2081223   2.1577919   1.9723593  -0.23130631]\n",
            " [ 5.3904166   3.7007978   3.4948714   3.3695335   3.1883922   3.1076703\n",
            "   2.9588985   2.8734522   2.6593766   0.24934432]] [[ 2.0303361   1.8577769   1.8336579   0.0367736  -0.17826423 -0.20157892\n",
            "  -0.36019862 -0.5154236  -0.83912545 -0.93600136]\n",
            " [ 2.4703157   1.8962625   1.743471    1.7014172   1.641698    1.6167275\n",
            "   1.544918    1.3008276   0.07594567  0.00997039]\n",
            " [ 2.4061959   2.1794827   2.169243    2.144146    1.832389    1.737996\n",
            "   1.5149316   1.3819318   0.6953784   0.00943107]\n",
            " [ 2.766533    2.615278    2.5665693   2.1916087   2.0782745   1.5269836\n",
            "   1.5004503   1.2686867   0.9322767  -0.32668108]\n",
            " [ 2.8975577   2.4924638   1.5521188   1.4840742   1.3629726   1.233958\n",
            "   1.1117119   0.7913333  -0.52237356 -0.75108665]\n",
            " [ 4.60846     4.210678    2.6140327   2.1563017   1.9421828   1.8067644\n",
            "   1.6747178   1.5631707   1.125642    1.0583442 ]\n",
            " [ 2.4438307   2.4160705   2.1890492   2.1084352   2.0821106   1.9666612\n",
            "   1.7901438   1.5581809   1.4040205   1.0204066 ]\n",
            " [ 2.5419347   2.4702833   2.2814732   2.115725    1.9466189   1.7847253\n",
            "   1.6170077   1.4104942   1.1339206   1.1112543 ]\n",
            " [ 2.5761325   2.4792182   2.1378393   1.8463252   1.7203313   1.4472574\n",
            "   1.3243221   1.2411209   1.2266269   1.166689  ]\n",
            " [ 5.456008    5.353278    4.5417376   3.3154898   2.8533227   2.804174\n",
            "   2.6403143   2.3418136   2.1872947   1.9060031 ]] [[ 2.2612034e-01 -3.8009651e-02 -3.8780950e-02 -4.6765979e-02\n",
            "  -6.9208048e-02 -2.0872875e-01 -2.4101795e-01 -3.5037675e-01\n",
            "  -4.4777170e-01 -5.2733576e-01]\n",
            " [ 6.7517233e-01  3.9312798e-01  2.3725607e-01 -6.3059896e-02\n",
            "  -1.1039569e-01 -2.9921985e-01 -4.7187513e-01 -5.5506325e-01\n",
            "  -6.2436157e-01 -7.2015613e-01]\n",
            " [ 9.3361211e-01  5.3950959e-01  4.9287438e-01  2.1531588e-01\n",
            "   1.8740979e-01 -2.9213024e-02 -2.3901868e-01 -3.0668780e-01\n",
            "  -3.2362556e-01 -1.2280266e+00]\n",
            " [ 6.9756258e-01  4.4989941e-01  2.4341451e-01 -2.4578855e-03\n",
            "  -7.8404859e-02 -3.2464623e-01 -3.8152993e-01 -6.1979800e-01\n",
            "  -6.7971754e-01 -7.0561594e-01]\n",
            " [ 1.0249646e-01  7.5051822e-02 -3.5078790e-02 -4.8854902e-02\n",
            "  -2.0628342e-01 -2.3292458e-01 -3.4050685e-01 -4.4878232e-01\n",
            "  -4.6191064e-01 -2.1298900e+00]\n",
            " [ 3.0245677e-01  2.9947233e-01  2.4236581e-01  2.4130450e-01\n",
            "   1.8978548e-01  9.6457012e-02  3.2729045e-02  2.6455250e-02\n",
            "   2.8431341e-03 -1.3099650e-01]\n",
            " [ 6.0627002e-01  5.2392596e-01 -3.3222097e-03 -1.6046396e-01\n",
            "  -1.9334581e-01 -3.1425053e-01 -3.4419578e-01 -4.0288299e-01\n",
            "  -4.3888095e-01 -4.5984560e-01]\n",
            " [ 4.2017981e-02 -2.9994713e-02 -1.6519363e-01 -1.8855403e-01\n",
            "  -3.1032318e-01 -3.9713272e-01 -5.6612849e-01 -6.0051662e-01\n",
            "  -1.3156273e+00 -2.6127512e+00]\n",
            " [ 3.4710228e-01  2.3271610e-01  1.5828943e-01  1.3848387e-01\n",
            "   6.7246109e-02  6.4791873e-02 -9.3004573e-03 -3.8753737e-02\n",
            "  -8.6773187e-02 -1.9065250e-01]\n",
            " [ 2.2022833e-01  5.5042971e-02  1.0446694e-03 -2.8469658e-02\n",
            "  -3.9955843e-02 -6.2308665e-02 -6.6449121e-02 -8.9312114e-02\n",
            "  -1.5427311e-01 -2.5045073e-01]] [[ 2.2500303   2.2188098   0.72748154  0.70002675  0.5726927   0.28421435\n",
            "   0.13661331  0.11507626 -0.22948778 -0.4026166 ]\n",
            " [ 3.4689047   2.9511573   2.3157015   1.8796562   1.401972    1.1965823\n",
            "   1.1602788   0.65724105  0.22785755 -0.17705007]\n",
            " [ 3.7097776   2.345575    1.9080586   1.6395502   1.4283338   1.2921458\n",
            "   1.0153087   0.89050937  0.5606781   0.47134796]\n",
            " [ 4.136206    3.8354082   3.0038881   2.590262    2.3231823   1.8637075\n",
            "   1.3310229   1.2275928   1.0532314  -0.19235544]\n",
            " [ 3.0943522   1.8359745   1.754751    1.5248697   1.300869    0.67464274\n",
            "   0.6143207   0.54005444  0.47067186  0.25969043]\n",
            " [ 2.093671    1.9916925   1.3448062   0.90135145  0.8746066   0.80161005\n",
            "   0.50366724  0.45084774 -0.10966281 -0.9338603 ]\n",
            " [ 1.481071    0.9820601   0.57283986  0.53737706  0.45082265  0.40630487\n",
            "   0.07374301  0.04086676 -0.04004949 -0.43184328]\n",
            " [ 3.1449246   2.3962047   2.0956986   1.8832694   1.0816227   0.7081071\n",
            "   0.6745899   0.60189104  0.52752346  0.19390377]\n",
            " [ 2.0125532   1.7450607   1.6686661   1.5488707   1.1293052   0.83109194\n",
            "   0.57361335  0.4600661   0.18745239 -0.3780639 ]\n",
            " [ 2.0720465   1.702015    1.3618184   1.1978276   0.81112695  0.63357085\n",
            "   0.6197195   0.29930586  0.2847378   0.12218094]] [[ 1.1136796   0.10982673 -0.01029239 -0.03871066 -0.04179818 -0.10111786\n",
            "  -0.6103709  -0.7641902  -0.8519441  -3.40926   ]\n",
            " [ 1.5662171   1.536088    1.0755256   1.0136856   0.79114985  0.63152\n",
            "   0.50270194  0.36316216 -0.6001095  -0.8458676 ]\n",
            " [ 1.4317175   1.3796111   0.99720216  0.75226283  0.60126483  0.5310282\n",
            "   0.42479292 -0.19636309 -0.24372135 -1.2828171 ]\n",
            " [ 1.2536767   1.22614     1.006644    0.6073282   0.05428209 -0.01733707\n",
            "  -0.01925353 -0.3424256  -0.3713482  -1.0930481 ]\n",
            " [ 1.944138    1.1883224   1.0981214   0.8124516   0.73339844  0.300511\n",
            "   0.27320418 -0.58596283 -0.6089169  -0.6945842 ]\n",
            " [ 1.6519732   0.9120511   0.87512183  0.71430326  0.6206471   0.49330038\n",
            "   0.45504287 -0.31964955 -0.3862843  -1.0343244 ]\n",
            " [ 1.585442    1.5412025   1.374089    1.1451781   1.1180769   0.79219013\n",
            "   0.45498502  0.13255624 -0.11572145 -0.8244491 ]\n",
            " [ 1.8586994   1.3764336   1.343096    1.1695964   1.0572457   0.86493284\n",
            "   0.76450497  0.06315581 -0.42347953 -1.3920381 ]\n",
            " [ 1.6112568   1.1641405   1.031017    1.0027806   0.95073164  0.8304718\n",
            "   0.5550675  -0.04601977 -0.3054078  -1.4279094 ]\n",
            " [ 1.0522461   0.88819987  0.83503574  0.675006    0.5101987   0.46982837\n",
            "   0.30827302  0.06021419 -0.12048295 -1.1874208 ]] [[ 3.5113134   1.1630836   0.70824885  0.31988132  0.23125714  0.1485499\n",
            "   0.04084336 -0.23731011 -0.34487998 -0.6694763 ]\n",
            " [ 2.8195403   2.8069272   2.6324606   2.6006522   2.5454693   2.2246802\n",
            "   2.088341    2.040524    1.7904971   1.0418183 ]\n",
            " [ 3.0531595   2.678921    2.583067    2.552863    2.5436697   2.497571\n",
            "   2.387744    1.892387    1.4597999   1.4553257 ]\n",
            " [ 3.5424693   3.2522175   3.0475783   3.025921    2.853447    2.5666246\n",
            "   2.4318888   2.3083885   2.030497    1.513328  ]\n",
            " [ 3.4065228   2.9776425   2.7873082   2.764315    2.2618475   2.1300116\n",
            "   1.9021385   1.5144892   0.85365564  0.7897786 ]\n",
            " [ 4.741098    3.6375775   3.3431034   2.7378519   2.5947423   2.3521683\n",
            "   2.2832873   2.2509809   1.967273    1.476788  ]\n",
            " [ 3.410435    2.9486058   2.728659    2.6334202   2.2987282   1.8677039\n",
            "   1.7034986   1.3938805   1.3237374   0.75743735]\n",
            " [ 4.1889677   3.5719972   3.4594595   3.3282528   3.1684306   2.464163\n",
            "   2.2208538   2.135445    1.6605139   1.5281328 ]\n",
            " [ 3.7193847   3.7185946   3.097043    2.4487157   2.4170141   2.351166\n",
            "   2.3510675   2.3213775   2.0928159   1.2444314 ]\n",
            " [ 5.245867    4.8474417   3.3721251   3.1460385   2.9236445   2.8997252\n",
            "   2.8552227   2.7353945   2.6822624   2.6110198 ]] [[ 2.59453     1.7404835   0.24408364  0.20622326  0.17036499  0.1402885\n",
            "  -0.05346457 -0.08752683 -0.21828592 -0.28903428]\n",
            " [ 3.8067126   2.5038111   1.9661092   0.4316581  -0.31045505 -0.32367745\n",
            "  -0.6605502  -0.9152964  -1.0867348  -1.4174232 ]\n",
            " [ 2.3395202   1.7736301   0.9409391   0.73563105  0.19052647 -0.67819226\n",
            "  -0.7898449  -1.056612   -1.3535221  -1.5124058 ]\n",
            " [ 2.775722    1.2547672   0.87479174  0.41058138  0.34710664 -0.15644918\n",
            "  -0.3385963  -0.44897178 -0.48662114 -0.6115686 ]\n",
            " [ 3.0947886   0.6738989   0.44766283  0.28215155  0.14923406 -0.13775949\n",
            "  -0.30547026 -0.6876078  -0.69923306 -1.6022447 ]\n",
            " [ 1.7985495   1.5466021  -0.46327183 -0.737129   -0.9095841  -1.2862828\n",
            "  -1.2882448  -1.4919236  -1.5902117  -1.6702434 ]\n",
            " [ 1.418668    1.217115    0.48501307  0.29066268 -0.3572482  -0.53071123\n",
            "  -0.7906014  -0.90791166 -1.3592551  -1.5038626 ]\n",
            " [ 3.1788635   1.5222138   0.40442383  0.2975553   0.21761003 -0.373424\n",
            "  -0.48345798 -0.8520371  -0.8623995  -1.0658942 ]\n",
            " [ 1.7944591   0.9605552   0.43165278  0.07014513 -0.35015965 -0.51980525\n",
            "  -0.5650798  -0.7924535  -1.2602834  -1.6325724 ]\n",
            " [ 1.9798659   0.95598394 -0.5624909  -0.6377991  -0.6748466  -0.7449865\n",
            "  -0.82357836 -0.8677052  -0.919578   -1.2320035 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path = \"./model/softmax_attention_scores.pkl\"\n",
        "with open(softmax_file_path, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax attention_scores가 {softmax_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "WUVvB7pr7RBf",
        "outputId": "b5f65e1b-76b3-429b-cd41-c8f2f15e29a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792055 0.09109741 0.09164357 ... 0.09258842 0.09229336\n",
            "    0.09513694]\n",
            "   [0.12004586 0.10268968 0.10120098 ... 0.09385469 0.09336554\n",
            "    0.09450836]\n",
            "   [0.09188308 0.11296417 0.10104739 ... 0.09287033 0.09284727\n",
            "    0.09269542]\n",
            "   ...\n",
            "   [0.09724706 0.09072162 0.09059814 ... 0.09612775 0.12209511\n",
            "    0.1143846 ]\n",
            "   [0.09323013 0.09044815 0.09189644 ... 0.11774409 0.09348241\n",
            "    0.13755944]\n",
            "   [0.10347308 0.09130668 0.09073301 ... 0.10249271 0.0964129\n",
            "    0.10287845]]\n",
            "\n",
            "  [[0.09785708 0.1010711  0.09990909 ... 0.1006773  0.09957507\n",
            "    0.11400125]\n",
            "   [0.09519613 0.09198768 0.10206269 ... 0.09563526 0.09920019\n",
            "    0.12259457]\n",
            "   [0.0963392  0.09690202 0.09143765 ... 0.10719077 0.10062093\n",
            "    0.12747219]\n",
            "   ...\n",
            "   [0.09908457 0.09758333 0.09906299 ... 0.0961072  0.0978529\n",
            "    0.12674263]\n",
            "   [0.09308667 0.10304288 0.09866013 ... 0.10144265 0.09808288\n",
            "    0.10579788]\n",
            "   [0.09461471 0.1043413  0.0984853  ... 0.10681042 0.09746661\n",
            "    0.11155472]]\n",
            "\n",
            "  [[0.10933199 0.09290536 0.09061925 ... 0.09214136 0.09332465\n",
            "    0.10667202]\n",
            "   [0.10829917 0.10341936 0.09385677 ... 0.09627965 0.09360978\n",
            "    0.10712849]\n",
            "   [0.10907564 0.09717342 0.0946402  ... 0.09514245 0.09607369\n",
            "    0.1086611 ]\n",
            "   ...\n",
            "   [0.10199555 0.10672598 0.09804323 ... 0.11619101 0.09668372\n",
            "    0.10503597]\n",
            "   [0.0949479  0.11661825 0.09678788 ... 0.09768786 0.09655614\n",
            "    0.10871448]\n",
            "   [0.1353592  0.0939795  0.09070874 ... 0.09208083 0.09304921\n",
            "    0.10064787]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09984183 0.10561763 0.10010299 ... 0.09757758 0.1026743\n",
            "    0.11696494]\n",
            "   [0.10077073 0.1048938  0.1072562  ... 0.09442478 0.09245645\n",
            "    0.1261673 ]\n",
            "   [0.09222058 0.10335313 0.12389978 ... 0.09829431 0.10070038\n",
            "    0.1023483 ]\n",
            "   ...\n",
            "   [0.09290123 0.09680557 0.11789276 ... 0.10309868 0.09550235\n",
            "    0.1088791 ]\n",
            "   [0.09593145 0.10086945 0.10162396 ... 0.10526626 0.09792026\n",
            "    0.10599791]\n",
            "   [0.09677328 0.09897416 0.11110785 ... 0.10325618 0.0989797\n",
            "    0.10693549]]\n",
            "\n",
            "  [[0.13062458 0.09245858 0.0914835  ... 0.09063558 0.09179717\n",
            "    0.09474251]\n",
            "   [0.09483223 0.09760492 0.10083348 ... 0.09685693 0.10389443\n",
            "    0.09879342]\n",
            "   [0.09761009 0.09560166 0.10119431 ... 0.09553706 0.09628828\n",
            "    0.11850341]\n",
            "   ...\n",
            "   [0.10222587 0.10328139 0.09508933 ... 0.09548536 0.09791066\n",
            "    0.11097045]\n",
            "   [0.09551324 0.10601512 0.09348555 ... 0.10826695 0.1075901\n",
            "    0.10964395]\n",
            "   [0.11690799 0.09121044 0.09121756 ... 0.0916934  0.09208853\n",
            "    0.09284412]]\n",
            "\n",
            "  [[0.10810776 0.0942751  0.09505253 ... 0.09378396 0.09679952\n",
            "    0.13884439]\n",
            "   [0.12123886 0.11415911 0.09557965 ... 0.09468964 0.09405801\n",
            "    0.09743701]\n",
            "   [0.132849   0.09005725 0.12850621 ... 0.0927122  0.09285689\n",
            "    0.09917664]\n",
            "   ...\n",
            "   [0.12697606 0.0912357  0.09214232 ... 0.1178524  0.09399209\n",
            "    0.10446963]\n",
            "   [0.11475074 0.09405647 0.10441453 ... 0.09398486 0.11518867\n",
            "    0.1059187 ]\n",
            "   [0.15028572 0.09182073 0.0938767  ... 0.09661791 0.09353498\n",
            "    0.10757346]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 1.0\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 1.0\n",
            "Sum of softmax values in [0, 9, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax attention_scores가 ./model/softmax_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "\n",
        "# 파일에서 데이터 로드\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(f\"Shape of attention_scores: {np.array(attention_scores).shape}\")\n"
      ],
      "metadata": {
        "id": "EvyTkAln9iH7",
        "outputId": "83609b4b-dd62-4e02-854d-d3e2d785f8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_scores: (1, 12, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"./model/attention_scores.pkl\"  # 기존 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 정렬 및 인덱스 저장\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)\n",
        "original_indices = np.zeros_like(attention_scores, dtype=int)\n",
        "\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 인덱스와 정렬된 배열 저장\n",
        "            sorted_indices = np.argsort(attention_scores[i, j, k])[::-1]  # 내림차순 인덱스\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][sorted_indices]\n",
        "            original_indices[i, j, k] = sorted_indices  # 원래의 순서 저장\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "# 4. 원래 인덱스 데이터를 새로운 파일로 저장\n",
        "indices_file_path = \"./model/original_indices.pkl\"\n",
        "with open(indices_file_path, \"wb\") as f:\n",
        "    pickle.dump(original_indices, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores와 원래 인덱스가 각각 {sorted_file_path}, {indices_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "eOuBuIM67wL7",
        "outputId": "979679d1-1b75-4729-b2e0-de81d1e48f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores와 원래 인덱스가 각각 ./model/sorted_attention_scores.pkl, ./model/original_indices.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path2 = \"./model/softmax_sorted_attention_scores.pkl\"\n",
        "with open(softmax_file_path2, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax sorted_attention_scores가 {softmax_file_path2}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "jM9BFbZ2-5sn",
        "outputId": "93d522d9-116a-41f5-8954-da77848dbf56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792053 0.107494   0.09632882 ... 0.09164356 0.0910974\n",
            "    0.0900939 ]\n",
            "   [0.12004589 0.10565753 0.10268968 ... 0.09450835 0.0938547\n",
            "    0.09336554]\n",
            "   [0.13786004 0.11296419 0.1010474  ... 0.09269542 0.09188308\n",
            "    0.09075053]\n",
            "   ...\n",
            "   [0.12209511 0.1143846  0.10398747 ... 0.0918981  0.09072163\n",
            "    0.09059815]\n",
            "   [0.13755941 0.11774407 0.095776   ... 0.09287394 0.09189644\n",
            "    0.09044816]\n",
            "   [0.12786184 0.10347308 0.10287845 ... 0.09130669 0.09093262\n",
            "    0.09073301]]\n",
            "\n",
            "  [[0.11400125 0.1034065  0.1010711  ... 0.09670064 0.09466569\n",
            "    0.09213626]\n",
            "   [0.12259459 0.10524758 0.10206271 ... 0.09519614 0.0930215\n",
            "    0.09198768]\n",
            "   [0.1274722  0.10719078 0.10062095 ... 0.0925588  0.09255221\n",
            "    0.09143765]\n",
            "   ...\n",
            "   [0.12674265 0.10445354 0.09908457 ... 0.09558626 0.09211903\n",
            "    0.09140754]\n",
            "   [0.10645555 0.10579788 0.10304288 ... 0.097651   0.09623402\n",
            "    0.09308667]\n",
            "   [0.11155473 0.10681042 0.10434131 ... 0.09461471 0.09410095\n",
            "    0.09327244]]\n",
            "\n",
            "  [[0.11106926 0.109332   0.1083897  ... 0.09214137 0.0915818\n",
            "    0.09061925]\n",
            "   [0.1149881  0.10829916 0.10712849 ... 0.09360979 0.09335104\n",
            "    0.09313469]\n",
            "   [0.10907564 0.10866109 0.10594706 ... 0.09523229 0.09514245\n",
            "    0.09464018]\n",
            "   ...\n",
            "   [0.116191   0.10672597 0.10503596 ... 0.09338766 0.09331789\n",
            "    0.09251253]\n",
            "   [0.11661825 0.11136506 0.10871448 ... 0.0926588  0.09243153\n",
            "    0.09223205]\n",
            "   [0.13535924 0.10957497 0.10064787 ... 0.09208082 0.09086874\n",
            "    0.09070873]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.11696494 0.10561763 0.10267429 ... 0.09490323 0.09146242\n",
            "    0.09067346]\n",
            "   [0.12616728 0.10725617 0.10489379 ... 0.09245644 0.09102614\n",
            "    0.09039383]\n",
            "   [0.12389981 0.10335314 0.1023483  ... 0.0922206  0.09215762\n",
            "    0.09110405]\n",
            "   ...\n",
            "   [0.11789278 0.10887911 0.1030987  ... 0.09425528 0.09290123\n",
            "    0.09099401]\n",
            "   [0.10826562 0.10599791 0.10526625 ... 0.09593145 0.09358449\n",
            "    0.09185722]\n",
            "   [0.11110785 0.10693549 0.10325618 ... 0.09677328 0.09239224\n",
            "    0.09118057]]\n",
            "\n",
            "  [[0.13062458 0.12001117 0.10074113 ... 0.09179718 0.0914835\n",
            "    0.09063558]\n",
            "   [0.10933136 0.10389442 0.10218148 ... 0.09760492 0.09685693\n",
            "    0.09483223]\n",
            "   [0.11850338 0.10194105 0.10119432 ... 0.09560166 0.09553707\n",
            "    0.0951685 ]\n",
            "   ...\n",
            "   [0.11097045 0.10328139 0.10222587 ... 0.09548537 0.09508932\n",
            "    0.09358936]\n",
            "   [0.10964393 0.10826696 0.1075901  ... 0.09348555 0.09266592\n",
            "    0.09257817]\n",
            "   [0.12031083 0.11849108 0.11690794 ... 0.09169339 0.09121755\n",
            "    0.09121043]]\n",
            "\n",
            "  [[0.13884437 0.10810775 0.09679953 ... 0.0932615  0.09313486\n",
            "    0.09311935]\n",
            "   [0.12123887 0.11415908 0.09743702 ... 0.09490645 0.09468964\n",
            "    0.09405801]\n",
            "   [0.13284895 0.12850621 0.09917663 ... 0.09059069 0.0901638\n",
            "    0.09005724]\n",
            "   ...\n",
            "   [0.12697604 0.11785242 0.10446963 ... 0.09295433 0.09214234\n",
            "    0.0912357 ]\n",
            "   [0.11518867 0.11475074 0.1059187  ... 0.09279858 0.09260277\n",
            "    0.09245569]\n",
            "   [0.1502857  0.10757348 0.09661792 ... 0.0917607  0.09112945\n",
            "    0.09075015]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0\n",
            "Sum of softmax values in [0, 0, 1]: 1.0\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0\n",
            "Sum of softmax values in [0, 0, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 7]: 1.0\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 1.0\n",
            "Sum of softmax values in [0, 1, 5]: 1.0\n",
            "Sum of softmax values in [0, 1, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 8]: 1.0\n",
            "Sum of softmax values in [0, 2, 9]: 1.0\n",
            "Sum of softmax values in [0, 3, 0]: 1.0\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 2]: 1.0\n",
            "Sum of softmax values in [0, 4, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 4]: 1.0\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 1.0\n",
            "Sum of softmax values in [0, 4, 8]: 1.0\n",
            "Sum of softmax values in [0, 4, 9]: 1.0\n",
            "Sum of softmax values in [0, 5, 0]: 1.0\n",
            "Sum of softmax values in [0, 5, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 5, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 3]: 1.0\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 1.0\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 6, 2]: 1.0\n",
            "Sum of softmax values in [0, 6, 3]: 1.0\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 1.0\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 1.0\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 1.0\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 6]: 1.0\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 3]: 1.0\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 0.9999999403953552\n",
            "Softmax sorted_attention_scores가 ./model/softmax_sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1Pr9O46V_Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "hhRL4CRO_QSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/restored_softmax.pkl\"\n",
        "text_file_path = \"/./content/model/restored_softmax_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "V-oYzGDQCZvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/softmax_sorted_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "THbCGtMz_twq",
        "outputId": "112c2397-825f-4837-ce06-6a4df446ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.10749399 0.09632882 0.0954031  0.09513693 0.09258841\n",
            "  0.09229334 0.09164356 0.0910974  0.0900939 ]\n",
            " [0.12004588 0.10565753 0.10268969 0.10120098 0.09709173 0.0958351\n",
            "  0.09575053 0.09450836 0.0938547  0.09336555]\n",
            " [0.13786007 0.11296417 0.10104739 0.09357624 0.09350549 0.09287033\n",
            "  0.09284727 0.09269542 0.09188308 0.09075052]\n",
            " [0.11074849 0.10814226 0.10393477 0.10047178 0.10030901 0.09913348\n",
            "  0.09670201 0.09443171 0.09372903 0.09239744]\n",
            " [0.1193184  0.10324923 0.10189565 0.09932904 0.09908514 0.09784093\n",
            "  0.09755905 0.0950703  0.09426644 0.09238588]\n",
            " [0.1328674  0.10326969 0.09898279 0.09854479 0.09625035 0.09615592\n",
            "  0.0958468  0.09484941 0.09185758 0.0913753 ]\n",
            " [0.11864013 0.1089671  0.10785589 0.10248473 0.09685351 0.09558748\n",
            "  0.09497281 0.09192704 0.0917357  0.0909756 ]\n",
            " [0.12209511 0.1143846  0.10398746 0.09853819 0.09724706 0.09612775\n",
            "  0.09440193 0.09189809 0.09072162 0.09059814]\n",
            " [0.13755944 0.11774409 0.09577599 0.0939422  0.09348241 0.09323013\n",
            "  0.09304722 0.09287393 0.09189644 0.09044815]\n",
            " [0.12786184 0.10347308 0.10287845 0.10249271 0.09869479 0.0964129\n",
            "  0.0952139  0.09130668 0.09093261 0.09073301]] [[0.11400125 0.1034065  0.1010711  0.1006773  0.09990909 0.09957507\n",
            "  0.09785708 0.09670063 0.09466569 0.09213626]\n",
            " [0.12259456 0.10524756 0.10206269 0.09920018 0.09916254 0.09589188\n",
            "  0.09563524 0.09519612 0.09302149 0.09198767]\n",
            " [0.12747219 0.10719077 0.10062093 0.09860631 0.09690202 0.0963392\n",
            "  0.09631989 0.09255879 0.0925522  0.09143765]\n",
            " [0.10658482 0.10630877 0.10104766 0.1003748  0.10008461 0.09871509\n",
            "  0.0979219  0.09733845 0.09657256 0.09505137]\n",
            " [0.11034425 0.10167924 0.10102019 0.10027704 0.10000083 0.09928491\n",
            "  0.09772887 0.09770507 0.09617376 0.0957859 ]\n",
            " [0.10516495 0.10368128 0.10063306 0.1006038  0.10018845 0.09995812\n",
            "  0.09989405 0.09896458 0.09562299 0.09528879]\n",
            " [0.11380466 0.10230775 0.1017336  0.10014401 0.09873901 0.09837577\n",
            "  0.09824028 0.09637209 0.09522659 0.0950562 ]\n",
            " [0.12674263 0.10445353 0.09908456 0.09906299 0.0978529  0.09758332\n",
            "  0.09610719 0.09558626 0.09211903 0.09140754]\n",
            " [0.10645555 0.10579788 0.10304288 0.10144265 0.09954634 0.09866013\n",
            "  0.09808288 0.097651   0.09623402 0.09308667]\n",
            " [0.11155472 0.10681042 0.1043413  0.10225179 0.0984853  0.09746661\n",
            "  0.09710175 0.09461471 0.09410094 0.09327243]] [[0.11106927 0.109332   0.10838971 0.10667203 0.10396456 0.09332467\n",
            "  0.09290537 0.09214137 0.09158181 0.09061927]\n",
            " [0.11498808 0.10829917 0.10712849 0.10341936 0.09627965 0.0959329\n",
            "  0.09385677 0.09360978 0.09335104 0.09313468]\n",
            " [0.10907564 0.1086611  0.10594706 0.10251999 0.09717342 0.09607369\n",
            "  0.09553417 0.09523229 0.09514245 0.0946402 ]\n",
            " [0.12777801 0.11388236 0.09597065 0.09547208 0.09541373 0.09527735\n",
            "  0.09474532 0.09463353 0.09392282 0.09290416]\n",
            " [0.11447315 0.10678963 0.10269815 0.10112287 0.10047487 0.09732886\n",
            "  0.0970234  0.09365991 0.09344386 0.09298529]\n",
            " [0.11844434 0.10639787 0.10390373 0.10112502 0.09893835 0.09716936\n",
            "  0.0958861  0.09353664 0.0925469  0.09205168]\n",
            " [0.11324795 0.10864487 0.10467929 0.10341784 0.10152826 0.09656344\n",
            "  0.09464015 0.0934985  0.09244199 0.09133781]\n",
            " [0.11619101 0.10672598 0.10503597 0.10199555 0.09804323 0.09668372\n",
            "  0.09610645 0.09338766 0.0933179  0.09251253]\n",
            " [0.11661826 0.11136508 0.10871449 0.09768787 0.09678789 0.09655615\n",
            "  0.09494792 0.09265881 0.09243154 0.09223206]\n",
            " [0.13535918 0.10957498 0.10064787 0.09704289 0.09668809 0.0939795\n",
            "  0.0930492  0.09208082 0.09086873 0.09070873]] [[0.1255899  0.10366833 0.10065787 0.09996307 0.09845075 0.09556752\n",
            "  0.09483397 0.09431619 0.09430879 0.09264354]\n",
            " [0.13242505 0.1023296  0.1009952  0.09722893 0.0965215  0.09473015\n",
            "  0.09469819 0.09453561 0.09363452 0.09290122]\n",
            " [0.10879505 0.10861369 0.10704175 0.0996678  0.09955349 0.0962432\n",
            "  0.09612511 0.09592903 0.09408776 0.09394309]\n",
            " [0.12335853 0.109509   0.10271551 0.09744254 0.09695764 0.09671901\n",
            "  0.09527482 0.09343539 0.09332724 0.09126032]\n",
            " [0.1051129  0.1042406  0.1015951  0.10096215 0.10058594 0.09961344\n",
            "  0.09938804 0.09867377 0.09613637 0.09369161]\n",
            " [0.11151089 0.10542171 0.10479862 0.10213321 0.0991762  0.09746461\n",
            "  0.09690585 0.09604911 0.09489696 0.09164282]\n",
            " [0.10953204 0.10539693 0.10379548 0.10073565 0.100105   0.09728067\n",
            "  0.09637927 0.09632144 0.09549578 0.09495777]\n",
            " [0.11535057 0.11265247 0.10442845 0.10190308 0.0975237  0.09578036\n",
            "  0.094757   0.0945795  0.09181842 0.09120651]\n",
            " [0.11083733 0.10423398 0.10382918 0.10361786 0.09832249 0.09829199\n",
            "  0.0961586  0.09549905 0.0948538  0.09435575]\n",
            " [0.12480727 0.10181123 0.1017132  0.09872679 0.09662166 0.09624251\n",
            "  0.09611325 0.09551828 0.094544   0.0939018 ]] [[0.13122697 0.11838867 0.09999187 0.09693875 0.09442222 0.0934737\n",
            "  0.09302619 0.09113406 0.09096654 0.090431  ]\n",
            " [0.11642858 0.11028487 0.10202178 0.09834425 0.09758889 0.09684826\n",
            "  0.09614606 0.0955855  0.09482107 0.09193079]\n",
            " [0.13121082 0.11401134 0.10236181 0.09529249 0.09509484 0.09347839\n",
            "  0.09292267 0.09219655 0.09185337 0.09157771]\n",
            " [0.11182034 0.11131455 0.10122852 0.09885452 0.09775028 0.09756619\n",
            "  0.0970481  0.09618475 0.09485637 0.09337639]\n",
            " [0.1190371  0.11268517 0.10337377 0.09892204 0.09817803 0.09598743\n",
            "  0.09449787 0.0939927  0.09308489 0.09024091]\n",
            " [0.1231669  0.11651503 0.10195184 0.09985358 0.09462189 0.09450209\n",
            "  0.0933025  0.09328135 0.09239239 0.09041242]\n",
            " [0.13613823 0.11589173 0.09990533 0.09561177 0.09451851 0.09313484\n",
            "  0.09205063 0.09152158 0.09145974 0.08976758]\n",
            " [0.1390204  0.11394679 0.10029403 0.09454747 0.09414111 0.09320738\n",
            "  0.09201896 0.09160782 0.0911697  0.09004641]\n",
            " [0.12268637 0.11812288 0.09949172 0.09598787 0.09570937 0.09495543\n",
            "  0.09386134 0.09341761 0.09317895 0.0925884 ]\n",
            " [0.11522201 0.10869771 0.10425299 0.10174679 0.09862161 0.09762945\n",
            "  0.09581748 0.09348565 0.0927586  0.09176765]] [[0.19221878 0.09784383 0.08963636 0.08957554 0.08923525 0.08854745\n",
            "  0.08842815 0.08823875 0.08822448 0.08805135]\n",
            " [0.11539409 0.10904791 0.10234714 0.10070689 0.09962562 0.09711855\n",
            "  0.09595603 0.09456613 0.09366652 0.09157109]\n",
            " [0.11589902 0.11491495 0.10738936 0.10107232 0.09720412 0.09633563\n",
            "  0.09241604 0.09182198 0.09179646 0.09115013]\n",
            " [0.11951818 0.10833368 0.10711588 0.09994849 0.09823545 0.09602655\n",
            "  0.09344209 0.09324856 0.09276845 0.09136264]\n",
            " [0.11600425 0.10421543 0.10398513 0.09926617 0.09877275 0.09778262\n",
            "  0.09739378 0.09617388 0.09505376 0.09135223]\n",
            " [0.11857469 0.10661126 0.1019878  0.09983031 0.09922573 0.09874775\n",
            "  0.09660321 0.09393042 0.09363413 0.09085469]\n",
            " [0.13629879 0.09932628 0.09855013 0.09824003 0.09734751 0.0959255\n",
            "  0.09526379 0.09510257 0.09359585 0.09034953]\n",
            " [0.1166717  0.10794695 0.10213608 0.10188431 0.10099822 0.09603059\n",
            "  0.09559518 0.09504844 0.09319708 0.09049152]\n",
            " [0.10728315 0.1037925  0.10343576 0.10218531 0.10196406 0.10056645\n",
            "  0.09859848 0.09630246 0.0945216  0.09135017]\n",
            " [0.18254873 0.09307522 0.09207456 0.09193303 0.09161045 0.09072111\n",
            "  0.0906655  0.08960212 0.08930827 0.08846102]] [[0.11651556 0.11437199 0.11160105 0.09936865 0.09705305 0.09333326\n",
            "  0.09255443 0.09213877 0.09158062 0.09148257]\n",
            " [0.11088444 0.10870033 0.10675944 0.10344209 0.10087191 0.09622392\n",
            "  0.09453411 0.09344795 0.09310738 0.09202842]\n",
            " [0.10944903 0.10575333 0.10088027 0.10072865 0.09912886 0.09830763\n",
            "  0.0975268  0.09695422 0.09693255 0.09433866]\n",
            " [0.10834975 0.10484561 0.10161021 0.10110388 0.10089392 0.0985859\n",
            "  0.09677326 0.09623311 0.09595081 0.0956535 ]\n",
            " [0.11836878 0.10995642 0.10637329 0.10316958 0.10050903 0.09407511\n",
            "  0.09224288 0.09195571 0.09188712 0.09146208]\n",
            " [0.11637533 0.107494   0.10246739 0.10176704 0.10082836 0.09627321\n",
            "  0.0941247  0.09410713 0.09370921 0.0928537 ]\n",
            " [0.17207588 0.10849798 0.09107385 0.09054288 0.09051681 0.08970771\n",
            "  0.08961482 0.0895204  0.08928338 0.08916631]\n",
            " [0.11313932 0.10984481 0.10417305 0.1018426  0.10149228 0.09582976\n",
            "  0.09468491 0.09335858 0.09303081 0.09260397]\n",
            " [0.12644607 0.10036467 0.10026442 0.09970112 0.09940325 0.0972826\n",
            "  0.09482437 0.09429312 0.09427355 0.09314673]\n",
            " [0.1405463  0.1159537  0.10057663 0.09612732 0.09178676 0.09127815\n",
            "  0.09113301 0.09111058 0.0908433  0.09064425]] [[0.10564238 0.10292613 0.10179431 0.10042136 0.09872103 0.09872036\n",
            "  0.09871954 0.09819727 0.09806671 0.09679093]\n",
            " [0.12064464 0.10207136 0.10152597 0.10133596 0.09803465 0.09705557\n",
            "  0.09630508 0.09615217 0.09468193 0.09219266]\n",
            " [0.10665165 0.10452332 0.10275489 0.10125034 0.10006174 0.09947256\n",
            "  0.09891605 0.097019   0.09581892 0.0935316 ]\n",
            " [0.11108197 0.1069545  0.10360119 0.10301835 0.09847432 0.09757042\n",
            "  0.09722493 0.0958219  0.09537969 0.09087261]\n",
            " [0.10333292 0.10259257 0.10245122 0.10149055 0.1004594  0.09958882\n",
            "  0.09949169 0.09887893 0.09800059 0.09371338]\n",
            " [0.10969684 0.10169461 0.10050323 0.09977714 0.09924264 0.0991381\n",
            "  0.09875637 0.09777958 0.09685702 0.09655443]\n",
            " [0.10171361 0.10146581 0.10124384 0.10099129 0.09960892 0.09923731\n",
            "  0.09916671 0.09902416 0.09887232 0.098676  ]\n",
            " [0.10602034 0.10511005 0.10080007 0.10076638 0.09995149 0.09937529\n",
            "  0.09768594 0.09724063 0.09691003 0.09613974]\n",
            " [0.10654233 0.10577352 0.10148946 0.10047438 0.10002071 0.0985586\n",
            "  0.09784236 0.09719845 0.0961601  0.09594019]\n",
            " [0.10370079 0.10097425 0.10082368 0.10058665 0.10050481 0.09954733\n",
            "  0.09918906 0.09886386 0.09817427 0.0976353 ]] [[0.13101614 0.10155541 0.09949803 0.09879939 0.09736524 0.09523892\n",
            "  0.09497467 0.09472965 0.0946505  0.09217209]\n",
            " [0.16043125 0.09743757 0.09690606 0.09600316 0.09286897 0.09224714\n",
            "  0.09165689 0.09157068 0.09061959 0.09025875]\n",
            " [0.12229677 0.10795741 0.09818567 0.09794795 0.09757593 0.09644455\n",
            "  0.0955545  0.09544124 0.09520435 0.09339152]\n",
            " [0.14856924 0.10204253 0.10037015 0.09949326 0.09272838 0.09220155\n",
            "  0.09164988 0.09154554 0.09090395 0.0904955 ]\n",
            " [0.13742623 0.10216511 0.10204151 0.09627024 0.0957383  0.09423456\n",
            "  0.09366982 0.09324936 0.09266366 0.09254126]\n",
            " [0.10827874 0.10729821 0.10317886 0.10045856 0.09872456 0.09777663\n",
            "  0.09749199 0.09618194 0.09610833 0.09450217]\n",
            " [0.13456634 0.10423085 0.10157086 0.09865664 0.09621219 0.09613518\n",
            "  0.09293942 0.09284518 0.09169888 0.0911445 ]\n",
            " [0.15805185 0.09799827 0.09751602 0.09492274 0.09333222 0.09234674\n",
            "  0.0920763  0.0920596  0.09175216 0.0899441 ]\n",
            " [0.15166666 0.10440575 0.09550705 0.09392787 0.0938193  0.09349321\n",
            "  0.09203372 0.0918356  0.09167873 0.09163215]\n",
            " [0.10974686 0.10353356 0.10199118 0.10157139 0.10014214 0.09902046\n",
            "  0.09866758 0.09735171 0.09568052 0.09229465]] [[0.11696494 0.10561763 0.1026743  0.10018165 0.10010299 0.09984183\n",
            "  0.09757758 0.09490325 0.09146243 0.09067347]\n",
            " [0.12616728 0.10725618 0.10489378 0.10077072 0.09898864 0.09442478\n",
            "  0.09362216 0.09245644 0.09102614 0.09039382]\n",
            " [0.12389978 0.10335313 0.1023483  0.10156903 0.10070038 0.09829431\n",
            "  0.09435275 0.09222058 0.09215761 0.09110405]\n",
            " [0.13135895 0.11509195 0.09834989 0.09702215 0.09552077 0.09462588\n",
            "  0.09443802 0.09247658 0.09081339 0.09030242]\n",
            " [0.11786105 0.10425267 0.10283441 0.10009396 0.0991247  0.098704\n",
            "  0.09789151 0.09510923 0.09314692 0.09098157]\n",
            " [0.11120586 0.11066937 0.10239101 0.1016436  0.09920651 0.09874985\n",
            "  0.09706905 0.09613745 0.0918766  0.09105068]\n",
            " [0.11243922 0.11034236 0.1020238  0.10166942 0.09871032 0.09781794\n",
            "  0.0956016  0.09512395 0.09494527 0.09132624]\n",
            " [0.11789278 0.10887911 0.1030987  0.10161806 0.09805292 0.09680559\n",
            "  0.09550236 0.09425528 0.09290124 0.09099401]\n",
            " [0.10826562 0.10599791 0.10526626 0.10162396 0.10086945 0.09868338\n",
            "  0.09792026 0.09593145 0.09358449 0.09185722]\n",
            " [0.11110785 0.10693549 0.10325618 0.10216829 0.0989797  0.09897416\n",
            "  0.09823224 0.09677328 0.09239224 0.09118057]] [[0.13062459 0.12001117 0.10074113 0.09474252 0.09386603 0.09363971\n",
            "  0.09245858 0.09179718 0.0914835  0.09063558]\n",
            " [0.10933135 0.10389441 0.10218149 0.10083347 0.0987934  0.09805172\n",
            "  0.09762    0.09760492 0.09685692 0.09483222]\n",
            " [0.11850341 0.10194103 0.10119431 0.09937377 0.09878195 0.09761009\n",
            "  0.09628828 0.09560166 0.09553706 0.09516849]\n",
            " [0.1064885  0.10433034 0.10290188 0.10156679 0.1006103  0.09858835\n",
            "  0.09808301 0.09728806 0.09667599 0.09346682]\n",
            " [0.11237273 0.10942037 0.10832172 0.0995042  0.09650969 0.0957105\n",
            "  0.09499046 0.09493661 0.09430388 0.09392986]\n",
            " [0.10560665 0.10434524 0.10314914 0.10254232 0.1011281  0.09828933\n",
            "  0.09727395 0.09697267 0.09606361 0.094629  ]\n",
            " [0.12966645 0.11357925 0.11246008 0.09314593 0.09302556 0.09259983\n",
            "  0.09171455 0.09159797 0.091246   0.09096438]\n",
            " [0.11097045 0.10328139 0.10222587 0.10110361 0.10058366 0.09976029\n",
            "  0.09791066 0.09548536 0.09508933 0.09358936]\n",
            " [0.10964395 0.10826695 0.1075901  0.10601512 0.09815793 0.0960831\n",
            "  0.09551324 0.09348555 0.09266593 0.09257816]\n",
            " [0.12031083 0.11849108 0.11690799 0.09304062 0.09284412 0.09219547\n",
            "  0.09208853 0.0916934  0.09121756 0.09121044]] [[0.13884439 0.10810776 0.09679952 0.09505253 0.0942751  0.09378396\n",
            "  0.09362106 0.0932615  0.09313487 0.09311935]\n",
            " [0.12123885 0.11415909 0.097437   0.09722511 0.09567007 0.09557963\n",
            "  0.09503611 0.09490646 0.09468962 0.09405799]\n",
            " [0.132849   0.12850621 0.09917664 0.09285689 0.0927122  0.0919118\n",
            "  0.09117553 0.0905907  0.09016381 0.09005725]\n",
            " [0.1297989  0.12024375 0.1006963  0.09401721 0.09367883 0.09252627\n",
            "  0.09244621 0.09233411 0.09221454 0.09204385]\n",
            " [0.12638246 0.12465423 0.099479   0.09614468 0.09545842 0.09220749\n",
            "  0.09193899 0.09154938 0.0913196  0.09086577]\n",
            " [0.13141826 0.12846188 0.09653927 0.09354375 0.09281931 0.09193935\n",
            "  0.09180678 0.09180298 0.09110983 0.09055864]\n",
            " [0.1273724  0.11926056 0.09824953 0.09632255 0.09553046 0.09303466\n",
            "  0.09287931 0.09279443 0.09237044 0.09218565]\n",
            " [0.12697604 0.1178524  0.10446963 0.09399208 0.09357508 0.09352376\n",
            "  0.09327863 0.09295432 0.09214232 0.0912357 ]\n",
            " [0.11518867 0.11475074 0.1059187  0.10441453 0.09405647 0.09398486\n",
            "  0.09382902 0.09279858 0.09260277 0.09245568]\n",
            " [0.15028572 0.10757346 0.09661791 0.0938767  0.09353498 0.09265015\n",
            "  0.09182073 0.09176069 0.09112944 0.09075014]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open( \"/./content/model/softmax_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "xhGzU2ZG_t3b",
        "outputId": "54c8137e-eff2-4565-b7b1-e1c1542b0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792055 0.09109741 0.09164357 0.09009392 0.09632883 0.09540311\n",
            "  0.107494   0.09258842 0.09229336 0.09513694]\n",
            " [0.12004586 0.10268968 0.10120098 0.09575053 0.09583508 0.09709172\n",
            "  0.10565752 0.09385469 0.09336554 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185757 0.09137529 0.09854478 0.09584679 0.0948494\n",
            "  0.09615591 0.13286738 0.09898278 0.10326968]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519613 0.09198768 0.10206269 0.10524758 0.0930215  0.09916256\n",
            "  0.09589189 0.09563526 0.09920019 0.12259457]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.09578589 0.0992849  0.10167923 0.10000082 0.09617375 0.10027704\n",
            "  0.09772886 0.09770505 0.10102018 0.11034424]\n",
            " [0.09562298 0.09995811 0.10516494 0.10018844 0.09989404 0.10063305\n",
            "  0.10060379 0.09528878 0.10368127 0.09896457]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908457 0.09758333 0.09906299 0.10445354 0.09140754 0.09558626\n",
            "  0.09211904 0.0961072  0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.10933199 0.09290536 0.09061925 0.0915818  0.1083897  0.10396454\n",
            "  0.11106926 0.09214136 0.09332465 0.10667202]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639788 0.09716938 0.10112503 0.09205169 0.09254691\n",
            "  0.09353665 0.11844435 0.09588612 0.09893835]\n",
            " [0.11324794 0.09464014 0.0913378  0.09244198 0.10467927 0.10152824\n",
            "  0.10341783 0.09349848 0.09656344 0.10864485]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.0949479  0.11661825 0.09678788 0.11136506 0.0926588  0.09223205\n",
            "  0.09243153 0.09768786 0.09655614 0.10871448]\n",
            " [0.1353592  0.0939795  0.09070874 0.09086874 0.0966881  0.0970429\n",
            "  0.10957499 0.09208083 0.09304921 0.10064787]] [[0.09431619 0.09845076 0.10366833 0.09264354 0.10065788 0.09556752\n",
            "  0.0943088  0.09483398 0.09996308 0.12558992]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113407 0.09302621 0.09096655 0.09999189 0.09347371\n",
            "  0.11838868 0.09693877 0.09442223 0.13122699]\n",
            " [0.11642858 0.09614605 0.11028486 0.09684824 0.09834424 0.09758888\n",
            "  0.10202176 0.09558548 0.09193078 0.09482107]\n",
            " [0.09292267 0.1023618  0.13121082 0.11401133 0.0915777  0.09347839\n",
            "  0.09219654 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024093 0.0939927  0.09598744 0.09817804 0.09449788 0.09892205\n",
            "  0.10337377 0.11268519 0.0930849  0.11903711]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152159 0.09205063 0.09145974 0.09561178 0.09990533\n",
            "  0.09451851 0.11589174 0.09313484 0.13613825]\n",
            " [0.09160781 0.09116969 0.09004641 0.09201896 0.09454746 0.0941411\n",
            "  0.10029402 0.11394678 0.09320737 0.13902038]\n",
            " [0.09258841 0.09495544 0.09341762 0.09949172 0.09386135 0.09570938\n",
            "  0.09598789 0.11812289 0.09317896 0.12268639]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.0904915  0.10794695 0.10099821 0.09559517 0.1166717  0.10213607\n",
            "  0.1018843  0.09319707 0.09603058 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912887 0.10944904 0.09433867 0.10088028 0.09830764 0.0975268\n",
            "  0.10072865 0.09693256 0.09695423 0.10575334]\n",
            " [0.10161023 0.09677327 0.10834976 0.10484561 0.10110389 0.09623312\n",
            "  0.0985859  0.0956535  0.09595082 0.10089393]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246737 0.10176703 0.09412469 0.10082835 0.0937092  0.09410712\n",
            "  0.0928537  0.11637531 0.0962732  0.10749398]\n",
            " [0.17207587 0.08952039 0.08916631 0.0897077  0.09107384 0.08961482\n",
            "  0.0905168  0.09054288 0.08928337 0.10849796]\n",
            " [0.1098448  0.10417304 0.0930308  0.0946849  0.09335857 0.09582975\n",
            "  0.09260397 0.10184258 0.10149226 0.11313931]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.14054629 0.09064424 0.09111057 0.0908433  0.09612731 0.09127814\n",
            "  0.10057662 0.09178675 0.091133   0.11595369]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665164 0.10275488 0.09353159 0.10125034 0.09947255 0.10006173\n",
            "  0.09701899 0.09581891 0.09891603 0.10452331]\n",
            " [0.11108198 0.09722494 0.09757043 0.09087262 0.09847433 0.10360121\n",
            "  0.09582192 0.10695451 0.0953797  0.10301836]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654232 0.1000207  0.09855858 0.09616009 0.10047437 0.09784234\n",
            "  0.09719844 0.10148945 0.09594018 0.1057735 ]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743756 0.16043124 0.09025874 0.09600315 0.09286896 0.09061958\n",
            "  0.09224714 0.09157067 0.09165689 0.09690605]\n",
            " [0.12229678 0.09520435 0.10795742 0.09818569 0.09339153 0.09644455\n",
            "  0.09794796 0.09544125 0.09757594 0.09555452]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872455 0.09450217 0.09777661 0.10317885 0.09749197 0.09618193\n",
            "  0.09610832 0.10827873 0.10045855 0.1072982 ]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.08994411 0.09333223 0.09175216 0.09207631\n",
            "  0.09234674 0.15805186 0.09799828 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077073 0.1048938  0.1072562  0.09898866 0.09102615 0.09362218\n",
            "  0.09039383 0.09442478 0.09245645 0.1261673 ]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135894 0.09834988 0.09081338 0.09247658\n",
            "  0.09030242 0.09443802 0.09552076 0.11509194]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290123 0.09680557 0.11789276 0.10161805 0.09425527 0.0980529\n",
            "  0.090994   0.10309868 0.09550235 0.1088791 ]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062458 0.09245858 0.0914835  0.09386603 0.10074112 0.09363971\n",
            "  0.12001116 0.09063558 0.09179717 0.09474251]\n",
            " [0.09483223 0.09760492 0.10083348 0.10933136 0.1021815  0.09805173\n",
            "  0.09762    0.09685693 0.10389443 0.09879342]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123886 0.11415911 0.09557965 0.09490647 0.09503613 0.09567008\n",
            "  0.09722512 0.09468964 0.09405801 0.09743701]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024376 0.09221455 0.09204386 0.12979892 0.09252628 0.09244622\n",
            "  0.09233411 0.09401721 0.09367883 0.10069631]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.0928193  0.09193934 0.09055864 0.09180677 0.09110983\n",
            "  0.09180297 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697606 0.0912357  0.09214232 0.09352377 0.09357508 0.09295433\n",
            "  0.09327864 0.1178524  0.09399209 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 정렬된 데이터와 원래 인덱스 로드\n",
        "sorted_file_path3 = \"./model/sorted_attention_scores.pkl\"\n",
        "indices_file_path3 = \"./model/original_indices.pkl\"\n",
        "restored_file_path3 = \"./model/restored_softmax.pkl\"\n",
        "\n",
        "with open(sorted_file_path3, \"rb\") as f:\n",
        "    sorted_attention_scores = pickle.load(f)\n",
        "\n",
        "with open(indices_file_path3, \"rb\") as f:\n",
        "    original_indices = pickle.load(f)\n",
        "\n",
        "# 2. 원래 순서로 복원\n",
        "restored_attention_scores = np.zeros_like(sorted_attention_scores)\n",
        "for i in range(sorted_attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(sorted_attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(sorted_attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 순서로 복원\n",
        "            inverse_indices = np.argsort(original_indices[i, j, k])  # 원래 순서 찾기\n",
        "            restored_attention_scores[i, j, k] = sorted_attention_scores[i, j, k][inverse_indices]\n",
        "\n",
        "# 3. 복원된 결과를 새로운 파일에 저장\n",
        "with open(restored_file_path3, \"wb\") as f:\n",
        "    pickle.dump(restored_attention_scores, f)\n",
        "\n",
        "print(f\"복원된 softmax attention_scores가 {restored_file_path3}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "MIofHJFRCG0b",
        "outputId": "ea3b115a-5c7c-49f1-89e6-6715fa22bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복원된 softmax attention_scores가 ./model/restored_softmax.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/restored_softmax_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "BIQ4u34qCk1E",
        "outputId": "b31e641a-a68a-4c58-f0ea-68cecc2a221f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.0910974  0.09164356 0.0900939  0.09632882 0.0954031\n",
            "  0.10749399 0.09258841 0.09229334 0.09513693]\n",
            " [0.12004588 0.10268969 0.10120098 0.09575053 0.0958351  0.09709173\n",
            "  0.10565753 0.0938547  0.09336555 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185758 0.0913753  0.09854479 0.0958468  0.09484941\n",
            "  0.09615592 0.1328674  0.09898279 0.10326969]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519612 0.09198767 0.10206269 0.10524756 0.09302149 0.09916254\n",
            "  0.09589188 0.09563524 0.09920018 0.12259456]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.0957859  0.09928491 0.10167924 0.10000083 0.09617376 0.10027704\n",
            "  0.09772887 0.09770507 0.10102019 0.11034425]\n",
            " [0.09562299 0.09995812 0.10516495 0.10018845 0.09989405 0.10063306\n",
            "  0.1006038  0.09528879 0.10368128 0.09896458]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908456 0.09758332 0.09906299 0.10445353 0.09140754 0.09558626\n",
            "  0.09211903 0.09610719 0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.109332   0.09290537 0.09061927 0.09158181 0.10838971 0.10396456\n",
            "  0.11106927 0.09214137 0.09332467 0.10667203]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639787 0.09716936 0.10112502 0.09205168 0.0925469\n",
            "  0.09353664 0.11844434 0.0958861  0.09893835]\n",
            " [0.11324795 0.09464015 0.09133781 0.09244199 0.10467929 0.10152826\n",
            "  0.10341784 0.0934985  0.09656344 0.10864487]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.09494792 0.11661826 0.09678789 0.11136508 0.09265881 0.09223206\n",
            "  0.09243154 0.09768787 0.09655615 0.10871449]\n",
            " [0.13535918 0.0939795  0.09070873 0.09086873 0.09668809 0.09704289\n",
            "  0.10957498 0.09208082 0.0930492  0.10064787]] [[0.09431619 0.09845075 0.10366833 0.09264354 0.10065787 0.09556752\n",
            "  0.09430879 0.09483397 0.09996307 0.1255899 ]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113406 0.09302619 0.09096654 0.09999187 0.0934737\n",
            "  0.11838867 0.09693875 0.09442222 0.13122697]\n",
            " [0.11642858 0.09614606 0.11028487 0.09684826 0.09834425 0.09758889\n",
            "  0.10202178 0.0955855  0.09193079 0.09482107]\n",
            " [0.09292267 0.10236181 0.13121082 0.11401134 0.09157771 0.09347839\n",
            "  0.09219655 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024091 0.0939927  0.09598743 0.09817803 0.09449787 0.09892204\n",
            "  0.10337377 0.11268517 0.09308489 0.1190371 ]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152158 0.09205063 0.09145974 0.09561177 0.09990533\n",
            "  0.09451851 0.11589173 0.09313484 0.13613823]\n",
            " [0.09160782 0.0911697  0.09004641 0.09201896 0.09454747 0.09414111\n",
            "  0.10029403 0.11394679 0.09320738 0.1390204 ]\n",
            " [0.0925884  0.09495543 0.09341761 0.09949172 0.09386134 0.09570937\n",
            "  0.09598787 0.11812288 0.09317895 0.12268637]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.09049152 0.10794695 0.10099822 0.09559518 0.1166717  0.10213608\n",
            "  0.10188431 0.09319708 0.09603059 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912886 0.10944903 0.09433866 0.10088027 0.09830763 0.0975268\n",
            "  0.10072865 0.09693255 0.09695422 0.10575333]\n",
            " [0.10161021 0.09677326 0.10834975 0.10484561 0.10110388 0.09623311\n",
            "  0.0985859  0.0956535  0.09595081 0.10089392]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246739 0.10176704 0.0941247  0.10082836 0.09370921 0.09410713\n",
            "  0.0928537  0.11637533 0.09627321 0.107494  ]\n",
            " [0.17207588 0.0895204  0.08916631 0.08970771 0.09107385 0.08961482\n",
            "  0.09051681 0.09054288 0.08928338 0.10849798]\n",
            " [0.10984481 0.10417305 0.09303081 0.09468491 0.09335858 0.09582976\n",
            "  0.09260397 0.1018426  0.10149228 0.11313932]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.1405463  0.09064425 0.09111058 0.0908433  0.09612732 0.09127815\n",
            "  0.10057663 0.09178676 0.09113301 0.1159537 ]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665165 0.10275489 0.0935316  0.10125034 0.09947256 0.10006174\n",
            "  0.097019   0.09581892 0.09891605 0.10452332]\n",
            " [0.11108197 0.09722493 0.09757042 0.09087261 0.09847432 0.10360119\n",
            "  0.0958219  0.1069545  0.09537969 0.10301835]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654233 0.10002071 0.0985586  0.0961601  0.10047438 0.09784236\n",
            "  0.09719845 0.10148946 0.09594019 0.10577352]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743757 0.16043125 0.09025875 0.09600316 0.09286897 0.09061959\n",
            "  0.09224714 0.09157068 0.09165689 0.09690606]\n",
            " [0.12229677 0.09520435 0.10795741 0.09818567 0.09339152 0.09644455\n",
            "  0.09794795 0.09544124 0.09757593 0.0955545 ]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872456 0.09450217 0.09777663 0.10317886 0.09749199 0.09618194\n",
            "  0.09610833 0.10827874 0.10045856 0.10729821]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.0899441  0.09333222 0.09175216 0.0920763\n",
            "  0.09234674 0.15805185 0.09799827 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077072 0.10489378 0.10725618 0.09898864 0.09102614 0.09362216\n",
            "  0.09039382 0.09442478 0.09245644 0.12616728]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135895 0.09834989 0.09081339 0.09247658\n",
            "  0.09030242 0.09443802 0.09552077 0.11509195]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290124 0.09680559 0.11789278 0.10161806 0.09425528 0.09805292\n",
            "  0.09099401 0.1030987  0.09550236 0.10887911]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062459 0.09245858 0.0914835  0.09386603 0.10074113 0.09363971\n",
            "  0.12001117 0.09063558 0.09179718 0.09474252]\n",
            " [0.09483222 0.09760492 0.10083347 0.10933135 0.10218149 0.09805172\n",
            "  0.09762    0.09685692 0.10389441 0.0987934 ]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123885 0.11415909 0.09557963 0.09490646 0.09503611 0.09567007\n",
            "  0.09722511 0.09468962 0.09405799 0.097437  ]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024375 0.09221454 0.09204385 0.1297989  0.09252627 0.09244621\n",
            "  0.09233411 0.09401721 0.09367883 0.1006963 ]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.09281931 0.09193935 0.09055864 0.09180678 0.09110983\n",
            "  0.09180298 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697604 0.0912357  0.09214232 0.09352376 0.09357508 0.09295432\n",
            "  0.09327863 0.1178524  0.09399208 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_text_file(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    # 데이터 전처리: 불필요한 문자 제거 및 정리\n",
        "    data = data.replace(\"\\n\", \" \")  # 줄바꿈 제거\n",
        "    data = data.replace(\"[\", \"\").replace(\"]\", \"\")  # 대괄호 제거\n",
        "    data = data.split()  # 공백 기준으로 나눔\n",
        "\n",
        "    # 문자열을 float으로 변환\n",
        "    try:\n",
        "        data_list = [float(value) for value in data]\n",
        "        return np.array(data_list)  # numpy 배열로 변환\n",
        "    except ValueError as e:\n",
        "        print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "        raise\n",
        "\n",
        "# 두 파일의 데이터 읽기\n",
        "try:\n",
        "    restored_data = parse_text_file('./model/restored_softmax_2.txt')\n",
        "    original_data = parse_text_file('./model/attention_scores_2.txt')\n",
        "\n",
        "    # 데이터 형태 확인\n",
        "    print(f\"Restored data shape: {restored_data.shape}\")\n",
        "    print(f\"Original data shape: {original_data.shape}\")\n",
        "\n",
        "    # 데이터 값 하나하나 비교\n",
        "    if np.array_equal(restored_data, original_data):\n",
        "        print(\"두 데이터는 형태와 값이 모두 동일합니다.\")\n",
        "    else:\n",
        "        print(\"데이터에 차이가 있습니다.\")\n",
        "\n",
        "        # 값이 다를 경우, 차이를 확인\n",
        "        differences = np.where(restored_data != original_data)\n",
        "        print(f\"값이 다른 위치: {differences}\")\n",
        "        print(f\"Restored data at differences: {restored_data[differences]}\")\n",
        "        print(f\"Original data at differences: {original_data[differences]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"파일 처리 중 오류 발생: {e}\")\n"
      ],
      "metadata": {
        "id": "NqnBhDHgkSWH",
        "outputId": "5b70cbcc-752c-49ec-fba2-149541753efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored data shape: (1200,)\n",
            "Original data shape: (1200,)\n",
            "두 데이터는 형태와 값이 모두 동일합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 10진수 소수를 32비트 fixed-point binary로 변환하는 함수\n",
        "def float_to_fixed_point(value, frac_bits=13):\n",
        "    \"\"\"\n",
        "    소수점 값을 32비트 fixed-point binary로 변환.\n",
        "    - 31~13 비트: 0\n",
        "    - 12~0 비트: 소수점 값\n",
        "    \"\"\"\n",
        "    max_value = 2**frac_bits - 1  # 13비트 최대 값\n",
        "    fixed_point = int(value * max_value)  # 소수점 값을 frac 부분으로 변환\n",
        "    fixed_binary = format(fixed_point, f'032b')  # 32비트 binary 표현\n",
        "    return fixed_binary\n",
        "\n",
        "# txt 파일 처리 함수\n",
        "def process_txt_file(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 데이터를 읽어옵니다\n",
        "        data = f.readlines()\n",
        "\n",
        "    # 변환된 데이터를 저장할 리스트\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        # [[ 및 ]] 제거 (데이터 전처리)\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        # 각 줄에서 숫자 데이터 추출\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))\n",
        "        except ValueError:\n",
        "            print(f\"라인 변환 중 오류 발생: {line}\")\n",
        "            continue\n",
        "        # 32비트 fixed-point 형식으로 변환\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        # 변환된 줄을 다시 저장\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# 입력 파일과 출력 파일 경로\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# txt 파일 변환 수행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"파일이 성공적으로 변환되어 {output_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "L0_EwJhUCIzu",
        "outputId": "a73f9050-4f26-4861-9862-81f6543023a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    음수의 경우 정수부를 내림하여 변환하고, 남은 값을 소수부로 변환.\n",
        "    \"\"\"\n",
        "    max_int_value = 2**(int_bits - 1) - 1  # 7비트 최대값 (63)\n",
        "    min_int_value = -2**(int_bits - 1)     # 7비트 최소값 (-64)\n",
        "    max_frac_value = 2**frac_bits           # 13비트 정밀도 (8192)\n",
        "\n",
        "    # ✅ 정수부 조정 (floor 적용하여 내림)\n",
        "    int_part = int(np.floor(value))\n",
        "    frac_part = abs(value - int_part)\n",
        "\n",
        "    # ✅ 정수부 범위 확인\n",
        "    if int_part < min_int_value or int_part > max_int_value:\n",
        "        raise ValueError(f\"정수부 {int_part}가 {min_int_value} ~ {max_int_value} 범위를 벗어남!\")\n",
        "\n",
        "    # ✅ 2의 보수 변환 (정수부 7비트)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 앞 12비트는 항상 0 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트, 항상 양수)\n",
        "    frac_binary = format(int(round(frac_part * max_frac_value)), f'0{frac_bits}b')\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "id": "gNlyfcx-D_Mi",
        "outputId": "b8518686-a8ed-42f1-9cf9-d367777b8fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/output.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "y9gvMWCUC7wz",
        "outputId": "3a16bf05-17e6-4d04-a637-1e1a3ecbff30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000000000000001000000010110 00000000000000000000010111011111 00000000000000000000001001011100 00000000000000000000001000001101 00000000000000000000000111110110 00000000000000000000000100011000\n",
            "00000000000000000000000011111110 00000000000000000000000011000100 00000000000000000000000010010011 00000000000000000000000000111000\n",
            "00000000000000000000100100100010 00000000000000000000010100001100 00000000000000000000010000100011 00000000000000000000001110101011 00000000000000000000001001011000 00000000000000000000000111101101\n",
            "00000000000000000000000111100110 00000000000000000000000101111011 00000000000000000000000101000010 00000000000000000000000100010111\n",
            "00000000000000000000110110111111 00000000000000000000011101011111 00000000000000000000001111001110 00000000000000000000000101011001 00000000000000000000000101010011 00000000000000000000000100011011\n",
            "00000000000000000000000100011001 00000000000000000000000100001100 00000000000000000000000011000100 00000000000000000000000001011110\n",
            "00000000000000000000011010000100 00000000000000000000010111000001 00000000000000000000010001111100 00000000000000000000001101100111 00000000000000000000001101011001 00000000000000000000001011111001\n",
            "00000000000000000000001000101110 00000000000000000000000101101011 00000000000000000000000100101110 00000000000000000000000010111001\n",
            "00000000000000000000100011101101 00000000000000000000010001001100 00000000000000000000001111100000 00000000000000000000001100001111 00000000000000000000001011111011 00000000000000000000001010010011\n",
            "00000000000000000000001001111100 00000000000000000000000110101000 00000000000000000000000101100011 00000000000000000000000010111101\n",
            "00000000000000000000110001111001 00000000000000000000010001101000 00000000000000000000001100001101 00000000000000000000001011101001 00000000000000000000001000101000 00000000000000000000001000100000\n",
            "00000000000000000000001000000101 00000000000000000000000110110000 00000000000000000000000010101001 00000000000000000000000001111110\n",
            "00000000000000000000100011001001 00000000000000000000011000010000 00000000000000000000010110111100 00000000000000000000010000011010 00000000000000000000001001001011 00000000000000000000000111011111\n",
            "00000000000000000000000110101010 00000000000000000000000010011111 00000000000000000000000010001110 00000000000000000000000001001010\n",
            "00000000000000000000100110111100 00000000000000000000011110100110 00000000000000000000010010011010 00000000000000000000001011100001 00000000000000000000001001110101 00000000000000000000001000010110\n",
            "00000000000000000000000110000001 00000000000000000000000010100101 00000000000000000000000000111100 00000000000000000000000000110001\n",
            "00000000000000000000110110110010 00000000000000000000100010111000 00000000000000000000001000011100 00000000000000000000000101111110 00000000000000000000000101010110 00000000000000000000000101000000\n",
            "00000000000000000000000100110000 00000000000000000000000100100000 00000000000000000000000011001010 00000000000000000000000001000111\n",
            "00000000000000000000101100111000 00000000000000000000010001110010 00000000000000000000010001000011 00000000000000000000010000100100 00000000000000000000001011101111 00000000000000000000001000110000\n",
            "00000000000000000000000111001001 00000000000000000000000001110010 00000000000000000000000001010000 00000000000000000000000000111110 00000000000000000000011101110000 00000000000000000000010001010001 00000000000000000000001110010110 00000000000000000000001101110110 00000000000000000000001100111000 00000000000000000000001100011100\n",
            "00000000000000000000001010001110 00000000000000000000001000101100 00000000000000000000000101111110 00000000000000000000000010100000\n",
            "00000000000000000000100111010010 00000000000000000000010011110000 00000000000000000000001111110101 00000000000000000000001100001100 00000000000000000000001100001001 00000000000000000000000111110110\n",
            "00000000000000000000000111100000 00000000000000000000000110111010 00000000000000000000000011111101 00000000000000000000000010100001\n",
            "00000000000000000000101100011101 00000000000000000000010110010001 00000000000000000000001110001011 00000000000000000000001011100101 00000000000000000000001001010111 00000000000000000000001000100111\n",
            "00000000000000000000001000100101 00000000000000000000000011011111 00000000000000000000000011011110 00000000000000000000000001111011\n",
            "00000000000000000000010101000010 00000000000000000000010100101101 00000000000000000000001110001101 00000000000000000000001101010111 00000000000000000000001100111111 00000000000000000000001011001110\n",
            "00000000000000000000001010001100 00000000000000000000001001011011 00000000000000000000001000011010 00000000000000000000000110011000\n",
            "00000000000000000000011001011111 00000000000000000000001111000001 00000000000000000000001110001100 00000000000000000000001101001111 00000000000000000000001100111001 00000000000000000000001011111110\n",
            "00000000000000000000001001111101 00000000000000000000001001111011 00000000000000000000000111111001 00000000000000000000000111011000\n",
            "00000000000000000000010011010011 00000000000000000000010001011110 00000000000000000000001101101010 00000000000000000000001101100111 00000000000000000000001101000101 00000000000000000000001100110011\n",
            "00000000000000000000001100101101 00000000000000000000001011100001 00000000000000000000000111000111 00000000000000000000000110101011\n",
            "00000000000000000000011101100000 00000000000000000000001111111000 00000000000000000000001111001010 00000000000000000000001101001001 00000000000000000000001011010101 00000000000000000000001010110111\n",
            "00000000000000000000001010101100 00000000000000000000001000001110 00000000000000000000000110101100 00000000000000000000000110011110\n",
            "00000000000000000000101011101001 00000000000000000000010010111001 00000000000000000000001100001001 00000000000000000000001100000111 00000000000000000000001010100010 00000000000000000000001010001100\n",
            "00000000000000000000001000001111 00000000000000000000000111100010 00000000000000000000000010110100 00000000000000000000000001110100\n",
            "00000000000000000000010100111010 00000000000000000000010100000111 00000000000000000000010000101111 00000000000000000000001110101110 00000000000000000000001100010100 00000000000000000000001011001011\n",
            "00000000000000000000001010011011 00000000000000000000001001110110 00000000000000000000000111111111 00000000000000000000000011101110\n",
            "00000000000000000000011010111111 00000000000000000000010101011011 00000000000000000000010010011100 00000000000000000000001111110110 00000000000000000000001011000011 00000000000000000000001001101110\n",
            "00000000000000000000001001001111 00000000000000000000000101111010 00000000000000000000000101001110 00000000000000000000000100000101 00000000000000000000011010101001 00000000000000000000011000101000 00000000000000000000010111100001 00000000000000000000010101011110 00000000000000000000010010001100 00000000000000000000000100011000\n",
            "00000000000000000000000011110011 00000000000000000000000010101111 00000000000000000000000001111101 00000000000000000000000000100111\n",
            "00000000000000000000011111000001 00000000000000000000010111010110 00000000000000000000010101111101 00000000000000000000010001011100 00000000000000000000001000010010 00000000000000000000000111110101\n",
            "00000000000000000000000101000001 00000000000000000000000100101100 00000000000000000000000100010101 00000000000000000000000100000010\n",
            "00000000000000000000011000000111 00000000000000000000010111101000 00000000000000000000010100011001 00000000000000000000010000001011 00000000000000000000001001010100 00000000000000000000000111110111\n",
            "00000000000000000000000111001001 00000000000000000000000110101111 00000000000000000000000110100111 00000000000000000000000101111100\n",
            "00000000000000000000101100110110 00000000000000000000011110000111 00000000000000000000001000001101 00000000000000000000000111100011 00000000000000000000000111011110 00000000000000000000000111010010\n",
            "00000000000000000000000110100100 00000000000000000000000110011010 00000000000000000000000101011101 00000000000000000000000100000011\n",
            "00000000000000000000011110010110 00000000000000000000010101011101 00000000000000000000010000011101 00000000000000000000001110011110 00000000000000000000001101101010 00000000000000000000001001100101\n",
            "00000000000000000000001001001011 00000000000000000000000100101010 00000000000000000000000100011000 00000000000000000000000011101111\n",
            "00000000000000000000100010110100 00000000000000000000010101000101 00000000000000000000010010000011 00000000000000000000001110100101 00000000000000000000001011110010 00000000000000000000001001011110\n",
            "00000000000000000000000111110001 00000000000000000000000100100110 00000000000000000000000011001111 00000000000000000000000010100011\n",
            "00000000000000000000011101000010 00000000000000000000010111101110 00000000000000000000010010111101 00000000000000000000010001011010 00000000000000000000001111000011 00000000000000000000001000101000\n",
            "00000000000000000000000110000100 00000000000000000000000100100000 00000000000000000000000011000011 00000000000000000000000001100001\n",
            "00000000000000000000100000010100 00000000000000000000010101011100 00000000000000000000010011011001 00000000000000000000001111101001 00000000000000000000001010100101 00000000000000000000001000110010\n",
            "00000000000000000000001000000001 00000000000000000000000100010110 00000000000000000000000100010000 00000000000000000000000011001001\n",
            "00000000000000000000100000111010 00000000000000000000011011000000 00000000000000000000010111111011 00000000000000000000001010001111 00000000000000000000001001000011 00000000000000000000001000101111\n",
            "00000000000000000000000110100110 00000000000000000000000011011110 00000000000000000000000011001010 00000000000000000000000010111000\n",
            "00000000000000000000110100011110 00000000000000000000011001011011 00000000000000000000001110100011 00000000000000000000001001111000 00000000000000000000001001011010 00000000000000000000000101110010\n",
            "00000000000000000000000100100000 00000000000000000000000011001011 00000000000000000000000001011110 00000000000000000000000001010000 00000000000000000000101010011100 00000000000000000000010001111000 00000000000000000000001110000111 00000000000000000000001101001110 00000000000000000000001011010001 00000000000000000000000111011110\n",
            "00000000000000000000000110011111 00000000000000000000000101110010 00000000000000000000000101110001 00000000000000000000000011011111\n",
            "00000000000000000000110001011011 00000000000000000000010000011011 00000000000000000000001110110000 00000000000000000000001001111001 00000000000000000000001000111101 00000000000000000000000110100011\n",
            "00000000000000000000000110100001 00000000000000000000000110010010 00000000000000000000000101000100 00000000000000000000000100000100\n",
            "00000000000000000000010111110010 00000000000000000000010111100100 00000000000000000000010101101101 00000000000000000000001100100100 00000000000000000000001100011011 00000000000000000000001000000110\n",
            "00000000000000000000000111111100 00000000000000000000000111101011 00000000000000000000000101001100 00000000000000000000000101000000\n",
            "00000000000000000000101000001010 00000000000000000000011000111011 00000000000000000000010000101110 00000000000000000000001001111111 00000000000000000000001001010110 00000000000000000000001001000010\n",
            "00000000000000000000000111000110 00000000000000000000000100100111 00000000000000000000000100011101 00000000000000000000000001100110\n",
            "00000000000000000000010011001111 00000000000000000000010010001011 00000000000000000000001110111001 00000000000000000000001110000101 00000000000000000000001101100111 00000000000000000000001100010111\n",
            "00000000000000000000001100000101 00000000000000000000001011001010 00000000000000000000000111110100 00000000000000000000000100100001\n",
            "00000000000000000000011010111100 00000000000000000000010011110000 00000000000000000000010010111111 00000000000000000000001111101100 00000000000000000000001011111100 00000000000000000000001001101101\n",
            "00000000000000000000001000111110 00000000000000000000000111110101 00000000000000000000000110010010 00000000000000000000000001110101\n",
            "00000000000000000000011000100101 00000000000000000000010011101010 00000000000000000000010001101100 00000000000000000000001101110111 00000000000000000000001101000100 00000000000000000000001001011001\n",
            "00000000000000000000001000001101 00000000000000000000001000001000 00000000000000000000000111000010 00000000000000000000000110010011\n",
            "00000000000000000000011111011110 00000000000000000000011100011100 00000000000000000000010010101111 00000000000000000000001111100110 00000000000000000000001001111111 00000000000000000000000111101011\n",
            "00000000000000000000000110010011 00000000000000000000000110000100 00000000000000000000000010010001 00000000000000000000000001011010\n",
            "00000000000000000000011010001000 00000000000000000000010010010001 00000000000000000000010001110001 00000000000000000000010001100000 00000000000000000000001010110011 00000000000000000000001010110000\n",
            "00000000000000000000000111111100 00000000000000000000000111000100 00000000000000000000000110001100 00000000000000000000000101100001\n",
            "00000000000000000000101001100101 00000000000000000000001111100001 00000000000000000000001111011001 00000000000000000000001011100101 00000000000000000000001000110101 00000000000000000000001000010100\n",
            "00000000000000000000001000001001 00000000000000000000000111010110 00000000000000000000000110000010 00000000000000000000000101001011 00000000000000000000110000100011 00000000000000000000100011010111 00000000000000000000001101110000 00000000000000000000001001110010 00000000000000000000000110011011 00000000000000000000000101001000\n",
            "00000000000000000000000100100001 00000000000000000000000001111000 00000000000000000000000001101001 00000000000000000000000000111001\n",
            "00000000000000000000100000100101 00000000000000000000011001101001 00000000000000000000001111101011 00000000000000000000001010111110 00000000000000000000001001111111 00000000000000000000001001000001\n",
            "00000000000000000000001000000101 00000000000000000000000111010101 00000000000000000000000110010011 00000000000000000000000010010110\n",
            "00000000000000000000110000011011 00000000000000000000011110011100 00000000000000000000010000101001 00000000000000000000000111011111 00000000000000000000000111001110 00000000000000000000000101000001\n",
            "00000000000000000000000100010001 00000000000000000000000011010000 00000000000000000000000010110010 00000000000000000000000010011001\n",
            "00000000000000000000011011010100 00000000000000000000011010101111 00000000000000000000001110100101 00000000000000000000001011100011 00000000000000000000001010000111 00000000000000000000001001111000\n",
            "00000000000000000000001001001100 00000000000000000000001000000011 00000000000000000000000110010001 00000000000000000000000100010000\n",
            "00000000000000000000100011100100 00000000000000000000011100100010 00000000000000000000010001100000 00000000000000000000001011110111 00000000000000000000001010111010 00000000000000000000001000000001\n",
            "00000000000000000000000110000001 00000000000000000000000101010101 00000000000000000000000100000101 00000000000000000000000000000111\n",
            "00000000000000000000101000001000 00000000000000000000100001000001 00000000000000000000001111111011 00000000000000000000001101010001 00000000000000000000000110011000 00000000000000000000000110001110\n",
            "00000000000000000000000100100101 00000000000000000000000100100011 00000000000000000000000011010101 00000000000000000000000000100011\n",
            "00000000000000000000110101011000 00000000000000000000100000110001 00000000000000000000001101110001 00000000000000000000001000001001 00000000000000000000000110101011 00000000000000000000000100110010\n",
            "00000000000000000000000011010011 00000000000000000000000010100011 00000000000000000000000010011110 00000000000000000000000000000101\n",
            "00000000000000000000111000001000 00000000000000000000011110101011 00000000000000000000001110010110 00000000000000000000000110110011 00000000000000000000000110001111 00000000000000000000000100111110\n",
            "00000000000000000000000011010101 00000000000000000000000010110000 00000000000000000000000010001001 00000000000000000000000000100011\n",
            "00000000000000000000100111100110 00000000000000000000100010110000 00000000000000000000001100110010 00000000000000000000001000001100 00000000000000000000000111110100 00000000000000000000000110110011\n",
            "00000000000000000000000101010100 00000000000000000000000100101110 00000000000000000000000100011001 00000000000000000000000011100101\n",
            "00000000000000000000011111010000 00000000000000000000010111110010 00000000000000000000010010011100 00000000000000000000001111010101 00000000000000000000001011010101 00000000000000000000001010000011\n",
            "00000000000000000000000111101001 00000000000000000000000100011111 00000000000000000000000011011111 00000000000000000000000010000111 00000000000000000001100100100101 00000000000000000000001110001001 00000000000000000000000010111100 00000000000000000000000010110110 00000000000000000000000010010111 00000000000000000000000001011000\n",
            "00000000000000000000000001001101 00000000000000000000000000111011 00000000000000000000000000111010 00000000000000000000000000101010\n",
            "00000000000000000000011111011011 00000000000000000000011000001011 00000000000000000000010000000100 00000000000000000000001110000000 00000000000000000000001100100111 00000000000000000000001001010110\n",
            "00000000000000000000000111110100 00000000000000000000000101111100 00000000000000000000000100101110 00000000000000000000000001110101\n",
            "00000000000000000000100000001100 00000000000000000000011111000110 00000000000000000000010110011011 00000000000000000000001110101010 00000000000000000000001001101011 00000000000000000000001000100001\n",
            "00000000000000000000000011001101 00000000000000000000000010011000 00000000000000000000000010010110 00000000000000000000000001011100\n",
            "00000000000000000000100100000100 00000000000000000000010111011111 00000000000000000000010110000010 00000000000000000000001101001011 00000000000000000000001010111101 00000000000000000000001000000011\n",
            "00000000000000000000000100100100 00000000000000000000000100010011 00000000000000000000000011101000 00000000000000000000000001101011\n",
            "00000000000000000000100000000011 00000000000000000000010010010101 00000000000000000000010010000011 00000000000000000000001100000111 00000000000000000000001011011110 00000000000000000000001010001011\n",
            "00000000000000000000001001101011 00000000000000000000001000000011 00000000000000000000000110100011 00000000000000000000000001011110\n",
            "00000000000000000000100010111100 00000000000000000000010101010101 00000000000000000000001111101010 00000000000000000000001100111011 00000000000000000000001100001001 00000000000000000000001011100001\n",
            "00000000000000000000001000101110 00000000000000000000000101001000 00000000000000000000000100101110 00000000000000000000000000110111\n",
            "00000000000000000000110101010000 00000000000000000000001100110000 00000000000000000000001011110000 00000000000000000000001011010110 00000000000000000000001010001011 00000000000000000000001000010011\n",
            "00000000000000000000000111011010 00000000000000000000000111001100 00000000000000000000000101001001 00000000000000000000000000101000\n",
            "00000000000000000000100000110111 00000000000000000000010110111011 00000000000000000000001111110101 00000000000000000000001111100001 00000000000000000000001110011010 00000000000000000000000111111100\n",
            "00000000000000000000000111010111 00000000000000000000000110101000 00000000000000000000000100000111 00000000000000000000000000010110\n",
            "00000000000000000000010101111011 00000000000000000000010001101100 00000000000000000000010001010000 00000000000000000000001111101100 00000000000000000000001111011011 00000000000000000000001101101010\n",
            "00000000000000000000001011001000 00000000000000000000001000000111 00000000000000000000000101101110 00000000000000000000000001010110\n",
            "00000000000000000001011101001101 00000000000000000000000111000000 00000000000000000000000101100111 00000000000000000000000101011011 00000000000000000000000100111110 00000000000000000000000011101110\n",
            "00000000000000000000000011101001 00000000000000000000000010001000 00000000000000000000000001101110 00000000000000000000000000011111 00000000000000000000100000111011 00000000000000000000011110100011 00000000000000000000011011011010 00000000000000000000001100100011 00000000000000000000001001100010 00000000000000000000000100100010\n",
            "00000000000000000000000011011101 00000000000000000000000010111000 00000000000000000000000010000111 00000000000000000000000001111110\n",
            "00000000000000000000011010010011 00000000000000000000010111110000 00000000000000000000010101011101 00000000000000000000010001011010 00000000000000000000001110001100 00000000000000000000001000001010\n",
            "00000000000000000000000101111000 00000000000000000000000100011010 00000000000000000000000011111100 00000000000000000000000010011100\n",
            "00000000000000000000011000011110 00000000000000000000010100000100 00000000000000000000001110000010 00000000000000000000001101110101 00000000000000000000001011110010 00000000000000000000001010101110\n",
            "00000000000000000000001001101101 00000000000000000000001000111101 00000000000000000000001000111011 00000000000000000000000101011101\n",
            "00000000000000000000010111001010 00000000000000000000010010111101 00000000000000000000001110111100 00000000000000000000001110010011 00000000000000000000001110000010 00000000000000000000001011000100\n",
            "00000000000000000000001000101100 00000000000000000000000111111111 00000000000000000000000111100110 00000000000000000000000111001101\n",
            "00000000000000000000100010110111 00000000000000000000011001011011 00000000000000000000010101001100 00000000000000000000010001010001 00000000000000000000001101111011 00000000000000000000000101011101\n",
            "00000000000000000000000010111100 00000000000000000000000010100011 00000000000000000000000010011101 00000000000000000000000001110111\n",
            "00000000000000000000100000100001 00000000000000000000010110010110 00000000000000000000010000001110 00000000000000000000001111010110 00000000000000000000001110001010 00000000000000000000001000001111\n",
            "00000000000000000000000101010111 00000000000000000000000101010101 00000000000000000000000100110010 00000000000000000000000011100111\n",
            "00000000000000000001010101001001 00000000000000000000011010000111 00000000000000000000000011101101 00000000000000000000000010111101 00000000000000000000000010111011 00000000000000000000000001110001\n",
            "00000000000000000000000001101001 00000000000000000000000001100000 00000000000000000000000001001011 00000000000000000000000001000000\n",
            "00000000000000000000011100111001 00000000000000000000011001000111 00000000000000000000010010010101 00000000000000000000001111011100 00000000000000000000001110111111 00000000000000000000000111101001\n",
            "00000000000000000000000110000111 00000000000000000000000100010011 00000000000000000000000011110110 00000000000000000000000011010001\n",
            "00000000000000000000101011010011 00000000000000000000001101101111 00000000000000000000001101100111 00000000000000000000001100111001 00000000000000000000001100100000 00000000000000000000001001110000\n",
            "00000000000000000000000110011110 00000000000000000000000101110000 00000000000000000000000101101110 00000000000000000000000100001100\n",
            "00000000000000000000111001101011 00000000000000000000100001000011 00000000000000000000001110110110 00000000000000000000001001000011 00000000000000000000000011001001 00000000000000000000000010011011\n",
            "00000000000000000000000010001110 00000000000000000000000010001100 00000000000000000000000001110100 00000000000000000000000001100010 00000000000000000000010011110111 00000000000000000000010000100010 00000000000000000000001111000111 00000000000000000000001101011000 00000000000000000000001011001100 00000000000000000000001011001100\n",
            "00000000000000000000001011001100 00000000000000000000001010100000 00000000000000000000001010010101 00000000000000000000001000101010\n",
            "00000000000000000000100101001001 00000000000000000000001111110000 00000000000000000000001111000100 00000000000000000000001110110101 00000000000000000000001010100101 00000000000000000000001001010011\n",
            "00000000000000000000001000010011 00000000000000000000001000000110 00000000000000000000000110001000 00000000000000000000000010101110\n",
            "00000000000000000000010101001000 00000000000000000000010010100011 00000000000000000000010000010111 00000000000000000000001110011110 00000000000000000000001100111110 00000000000000000000001100001101\n",
            "00000000000000000000001011011111 00000000000000000000001001000001 00000000000000000000000111011011 00000000000000000000000100010101\n",
            "00000000000000000000011010011101 00000000000000000000010101100111 00000000000000000000010001100010 00000000000000000000010000110100 00000000000000000000001011000010 00000000000000000000001001110111\n",
            "00000000000000000000001001011001 00000000000000000000000111100010 00000000000000000000000110111101 00000000000000000000000000110000\n",
            "00000000000000000000010001000010 00000000000000000000010000000111 00000000000000000000001111111100 00000000000000000000001110101111 00000000000000000000001101011011 00000000000000000000001100010100\n",
            "00000000000000000000001100001100 00000000000000000000001011011001 00000000000000000000001010010000 00000000000000000000000100100010\n",
            "00000000000000000000011000101110 00000000000000000000001111000001 00000000000000000000001101100001 00000000000000000000001100100101 00000000000000000000001011111001 00000000000000000000001011110001\n",
            "00000000000000000000001011010001 00000000000000000000001010000000 00000000000000000000001000110010 00000000000000000000001000011000\n",
            "00000000000000000000001110111110 00000000000000000000001110101010 00000000000000000000001110011000 00000000000000000000001110000100 00000000000000000000001100010011 00000000000000000000001011110100\n",
            "00000000000000000000001011101111 00000000000000000000001011100011 00000000000000000000001011010110 00000000000000000000001011000110\n",
            "00000000000000000000010100010110 00000000000000000000010011001111 00000000000000000000001101111000 00000000000000000000001101110101 00000000000000000000001100110011 00000000000000000000001100000011\n",
            "00000000000000000000001001110111 00000000000000000000001001010001 00000000000000000000001000110110 00000000000000000000000111110100\n",
            "00000000000000000000010100111111 00000000000000000000010100000011 00000000000000000000001110110001 00000000000000000000001101011110 00000000000000000000001100111001 00000000000000000000001011000001\n",
            "00000000000000000000001010000101 00000000000000000000001001001111 00000000000000000000000111110111 00000000000000000000000111100100\n",
            "00000000000000000000010001011101 00000000000000000000001110000011 00000000000000000000001101110111 00000000000000000000001101100100 00000000000000000000001101011101 00000000000000000000001100001111\n",
            "00000000000000000000001011110001 00000000000000000000001011010110 00000000000000000000001010011101 00000000000000000000001001110000 00000000000000000000110000000000 00000000000000000000001111011001 00000000000000000000001100110010 00000000000000000000001011111000 00000000000000000000001010000000 00000000000000000000000111001011\n",
            "00000000000000000000000110110101 00000000000000000000000110011111 00000000000000000000000110011001 00000000000000000000000010111111\n",
            "00000000000000000001001011010010 00000000000000000000001011011110 00000000000000000000001010110001 00000000000000000000001001100101 00000000000000000000000101010101 00000000000000000000000100011110\n",
            "00000000000000000000000011101001 00000000000000000000000011100001 00000000000000000000000010001100 00000000000000000000000001101011\n",
            "00000000000000000000100110111101 00000000000000000000010111000000 00000000000000000000001010110110 00000000000000000000001010100011 00000000000000000000001010000011 00000000000000000000001000100100\n",
            "00000000000000000000000111011000 00000000000000000000000111001110 00000000000000000000000110111010 00000000000000000000000100011100\n",
            "00000000000000000001000000111010 00000000000000000000010000110101 00000000000000000000001110101101 00000000000000000000001101100101 00000000000000000000000100100101 00000000000000000000000011110110\n",
            "00000000000000000000000011000101 00000000000000000000000010111011 00000000000000000000000010000010 00000000000000000000000001011101\n",
            "00000000000000000000110110011000 00000000000000000000010000011100 00000000000000000000010000010010 00000000000000000000001000110101 00000000000000000000001000001000 00000000000000000000000110000110\n",
            "00000000000000000000000101010101 00000000000000000000000100110000 00000000000000000000000011111100 00000000000000000000000011110001\n",
            "00000000000000000000010111000110 00000000000000000000010101111100 00000000000000000000010000111011 00000000000000000000001101100000 00000000000000000000001011010010 00000000000000000000001010000011\n",
            "00000000000000000000001001101011 00000000000000000000000111111100 00000000000000000000000111110110 00000000000000000000000101101100\n",
            "00000000000000000000110011100111 00000000000000000000010010111011 00000000000000000000001111100111 00000000000000000000001011111001 00000000000000000000001000101011 00000000000000000000001000100101\n",
            "00000000000000000000000100010000 00000000000000000000000100000111 00000000000000000000000010100010 00000000000000000000000001110000\n",
            "00000000000000000001001001001111 00000000000000000000001100000100 00000000000000000000001011011100 00000000000000000000000111111111 00000000000000000000000101110101 00000000000000000000000100011110\n",
            "00000000000000000000000100000110 00000000000000000000000100000100 00000000000000000000000011101001 00000000000000000000000001000110\n",
            "00000000000000000001000011101011 00000000000000000000010011111000 00000000000000000000001000011110 00000000000000000000000110010110 00000000000000000000000110001100 00000000000000000000000101110000\n",
            "00000000000000000000000011101111 00000000000000000000000011011101 00000000000000000000000011001111 00000000000000000000000011001011\n",
            "00000000000000000000011000110101 00000000000000000000010001010111 00000000000000000000001111011100 00000000000000000000001110111010 00000000000000000000001101000110 00000000000000000000001011101010\n",
            "00000000000000000000001011001101 00000000000000000000001001011111 00000000000000000000000111010001 00000000000000000000000010101010 00000000000000000000100001001011 00000000000000000000010100000111 00000000000000000000010000011111 00000000000000000000001101010110 00000000000000000000001101001111 00000000000000000000001100111010\n",
            "00000000000000000000001001111110 00000000000000000000000110011011 00000000000000000000000001101100 00000000000000000000000000100101\n",
            "00000000000000000000101011001011 00000000000000000000010110011000 00000000000000000000010011100010 00000000000000000000001110011010 00000000000000000000001100000111 00000000000000000000000110000101\n",
            "00000000000000000000000100111111 00000000000000000000000011011000 00000000000000000000000001011001 00000000000000000000000000011111\n",
            "00000000000000000000101000101101 00000000000000000000010001100000 00000000000000000000010000010000 00000000000000000000001111010001 00000000000000000000001110001011 00000000000000000000001011000101\n",
            "00000000000000000000000101110110 00000000000000000000000010111010 00000000000000000000000010110101 00000000000000000000000001010111\n",
            "00000000000000000000110000100101 00000000000000000000011111101010 00000000000000000000001011100010 00000000000000000000001001110011 00000000000000000000000111110011 00000000000000000000000110100110\n",
            "00000000000000000000000110010110 00000000000000000000000011101010 00000000000000000000000001010101 00000000000000000000000000100111\n",
            "00000000000000000000100010001000 00000000000000000000010010011011 00000000000000000000010000101011 00000000000000000000001101001110 00000000000000000000001011111110 00000000000000000000001011011011\n",
            "00000000000000000000001010011000 00000000000000000000000110101011 00000000000000000000000100000001 00000000000000000000000001000000\n",
            "00000000000000000000011010101001 00000000000000000000011010000010 00000000000000000000010000000101 00000000000000000000001111001001 00000000000000000000001100000010 00000000000000000000001011011100\n",
            "00000000000000000000001001010000 00000000000000000000001000000001 00000000000000000000000010001110 00000000000000000000000001000100\n",
            "00000000000000000000011100000100 00000000000000000000011001101001 00000000000000000000001111100111 00000000000000000000001111001011 00000000000000000000001011011001 00000000000000000000001010001111\n",
            "00000000000000000000000111010011 00000000000000000000000110101010 00000000000000000000000110011010 00000000000000000000000001011100\n",
            "00000000000000000000100010001111 00000000000000000000011000000011 00000000000000000000010001000100 00000000000000000000001111001110 00000000000000000000001010101001 00000000000000000000001001000000\n",
            "00000000000000000000000111010001 00000000000000000000000101100110 00000000000000000000000011101111 00000000000000000000000001000101\n",
            "00000000000000000000010111001000 00000000000000000000010100011011 00000000000000000000010011100010 00000000000000000000001111000001 00000000000000000000001110000100 00000000000000000000001011010001\n",
            "00000000000000000000001010010001 00000000000000000000000111101001 00000000000000000000000100011110 00000000000000000000000010000110\n",
            "00000000000000000000011010011111 00000000000000000000010101100110 00000000000000000000010001000111 00000000000000000000001111110000 00000000000000000000001011101100 00000000000000000000001011101100\n",
            "00000000000000000000001010101110 00000000000000000000001000110100 00000000000000000000000010111000 00000000000000000000000001001100 00000000000000000000101111111110 00000000000000000000100101001000 00000000000000000000001110101110 00000000000000000000000110111000 00000000000000000000000101101011 00000000000000000000000101011000\n",
            "00000000000000000000000011110000 00000000000000000000000010110101 00000000000000000000000010011001 00000000000000000000000001001101\n",
            "00000000000000000000011000010100 00000000000000000000010001110010 00000000000000000000001111101010 00000000000000000000001101111101 00000000000000000000001011010110 00000000000000000000001010011000\n",
            "00000000000000000000001001110100 00000000000000000000001001110010 00000000000000000000001000110011 00000000000000000000000110000110\n",
            "00000000000000000000100010110001 00000000000000000000001111100000 00000000000000000000001110100100 00000000000000000000001100001111 00000000000000000000001011011110 00000000000000000000001001111101\n",
            "00000000000000000000001000001101 00000000000000000000000111010010 00000000000000000000000111001101 00000000000000000000000110101101\n",
            "00000000000000000000010100111011 00000000000000000000010010010100 00000000000000000000010000100011 00000000000000000000001110111000 00000000000000000000001101101010 00000000000000000000001011000100\n",
            "00000000000000000000001010011010 00000000000000000000001001010111 00000000000000000000001000100011 00000000000000000000000100001111\n",
            "00000000000000000000011100000000 00000000000000000000011000100110 00000000000000000000010111010100 00000000000000000000001100011100 00000000000000000000001000100010 00000000000000000000000111011110\n",
            "00000000000000000000000110100000 00000000000000000000000110011011 00000000000000000000000101100101 00000000000000000000000101000100\n",
            "00000000000000000000010011110111 00000000000000000000010010010100 00000000000000000000010000110110 00000000000000000000010000000110 00000000000000000000001110010100 00000000000000000000001010101011\n",
            "00000000000000000000001001010110 00000000000000000000001000111100 00000000000000000000000111101111 00000000000000000000000101110100\n",
            "00000000000000000000101111000001 00000000000000000000011110000100 00000000000000000000011100110011 00000000000000000000000100101011 00000000000000000000000100100001 00000000000000000000000011111011\n",
            "00000000000000000000000010101101 00000000000000000000000010100010 00000000000000000000000010000011 00000000000000000000000001101001\n",
            "00000000000000000000011010010000 00000000000000000000010001000100 00000000000000000000001111110000 00000000000000000000001110010110 00000000000000000000001101101011 00000000000000000000001100101000\n",
            "00000000000000000000001010001111 00000000000000000000000111000001 00000000000000000000000110011111 00000000000000000000000100011101\n",
            "00000000000000000000011000110111 00000000000000000000010111001111 00000000000000000000010110011100 00000000000000000000010100100011 00000000000000000000001010101100 00000000000000000000000111111101\n",
            "00000000000000000000000111001101 00000000000000000000000100011101 00000000000000000000000011010101 00000000000000000000000011001101\n",
            "00000000000000000000100101010110 00000000000000000000100011011010 00000000000000000000100001101011 00000000000000000000000100011101 00000000000000000000000100001100 00000000000000000000000011010010\n",
            "00000000000000000000000011001001 00000000000000000000000010100110 00000000000000000000000001111011 00000000000000000000000001111010 00000000000000000000110111110011 00000000000000000000010111110001 00000000000000000000001001101000 00000000000000000000000111010011 00000000000000000000000110010000 00000000000000000000000101100101\n",
            "00000000000000000000000101010111 00000000000000000000000100110111 00000000000000000000000100101100 00000000000000000000000100101011\n",
            "00000000000000000000100101111011 00000000000000000000011110001110 00000000000000000000001001111101 00000000000000000000001001101011 00000000000000000000000111100111 00000000000000000000000111011111\n",
            "00000000000000000000000110110000 00000000000000000000000110100101 00000000000000000000000110010010 00000000000000000000000101011100\n",
            "00000000000000000000110010100001 00000000000000000000101110010001 00000000000000000000001101000111 00000000000000000000000100101011 00000000000000000000000100011110 00000000000000000000000011010111\n",
            "00000000000000000000000010010110 00000000000000000000000001100001 00000000000000000000000000111010 00000000000000000000000000110000\n",
            "00000000000000000000101111001000 00000000000000000000100101010110 00000000000000000000001110101001 00000000000000000000000101110111 00000000000000000000000101011001 00000000000000000000000011110100\n",
            "00000000000000000000000011101101 00000000000000000000000011100011 00000000000000000000000011011000 00000000000000000000000011001001\n",
            "00000000000000000000101011101111 00000000000000000000101001111110 00000000000000000000001101000111 00000000000000000000001000101111 00000000000000000000000111110101 00000000000000000000000011011001\n",
            "00000000000000000000000011000001 00000000000000000000000010011110 00000000000000000000000010001010 00000000000000000000000001100001\n",
            "00000000000000000000110001000011 00000000000000000000101110001000 00000000000000000000001001100100 00000000000000000000000101100010 00000000000000000000000100100010 00000000000000000000000011010100\n",
            "00000000000000000000000011001000 00000000000000000000000011001000 00000000000000000000000010001010 00000000000000000000000001011000\n",
            "00000000000000000000101100100101 00000000000000000000100100001010 00000000000000000000001011010111 00000000000000000000001000110100 00000000000000000000000111110001 00000000000000000000000100011000\n",
            "00000000000000000000000100001010 00000000000000000000000100000011 00000000000000000000000011011101 00000000000000000000000011001101\n",
            "00000000000000000000101100001100 00000000000000000000100010101001 00000000000000000000010011001110 00000000000000000000000101101100 00000000000000000000000101001000 00000000000000000000000101000011\n",
            "00000000000000000000000100101110 00000000000000000000000100010001 00000000000000000000000011001001 00000000000000000000000001111000\n",
            "00000000000000000000011111010111 00000000000000000000011110111000 00000000000000000000010100101000 00000000000000000000010010110011 00000000000000000000000101011011 00000000000000000000000101010101\n",
            "00000000000000000000000101000111 00000000000000000000000011101101 00000000000000000000000011011100 00000000000000000000000011001111\n",
            "00000000000000000001000010011111 00000000000000000000010111101100 00000000000000000000001001111100 00000000000000000000000110010001 00000000000000000000000101110011 00000000000000000000000100100101\n",
            "00000000000000000000000011011011 00000000000000000000000011010110 00000000000000000000000010011101 00000000000000000000000001111011\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt(input_file, output_file):\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # txt 파일 읽기 및 값 분리\n",
        "    with open(input_file, 'r') as f:\n",
        "        content = f.read()  # 파일 전체 내용을 읽음\n",
        "        binary_values = content.split()  # 스페이스와 줄바꿈을 기준으로 값을 분리\n",
        "\n",
        "    # 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            # 줄 생성\n",
        "            line = template.format(index=i + 9, binary_value=binary_value)  # index는 9부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "# 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output.txt'  # 입력 파일 경로 (값들이 스페이스/줄바꿈으로 구별됨)\n",
        "output_code_file = './model/generated_code.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# 코드 생성 함수 호출\n",
        "generate_code_from_txt(input_txt_file, output_code_file)\n",
        "print(f\"코드가 성공적으로 생성되어 {output_code_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "bBrrgb7-GxN3",
        "outputId": "f0cb0f48-c37f-4104-a56c-058865602b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코드가 성공적으로 생성되어 ./model/generated_code.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hex_to_16bit_binary(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일 내용 읽기 및 분리 (스페이스 및 줄바꿈 기준)\n",
        "        hex_values = f.read().split()\n",
        "\n",
        "    # 16진수 -> 16비트 2진수 변환\n",
        "    binary_values = [format(int(hex_value, 16), '016b') for hex_value in hex_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for binary_value in binary_values:\n",
        "            f.write(binary_value + \"\\n\")  # 각 값을 줄바꿈으로 저장\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/cordic_result.txt'  # 16진수 값이 저장된 입력 파일\n",
        "output_txt_file = './model/binary_values.txt'  # 변환된 16비트 2진수를 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_hex_to_16bit_binary(input_txt_file, output_txt_file)\n",
        "print(f\"16진수 값이 16비트 2진수로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "cCw_Fb3iL9zA",
        "outputId": "b6fd9154-b56d-4a51-a997-010e7b1580ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16진수 값이 16비트 2진수로 변환되어 ./model/binary_values.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary_to_decimal(input_file, output_file):\n",
        "    def binary_to_decimal(binary_str):\n",
        "        # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "        int_part = int(binary_str[:3], 2)  # 정수부\n",
        "        frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "        return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 16비트 바이너리 값 읽기\n",
        "        binary_values = f.read().splitlines()\n",
        "\n",
        "    # 16비트 이진수를 10진수로 변환\n",
        "    decimal_values = [binary_to_decimal(binary) for binary in binary_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for decimal in decimal_values:\n",
        "            f.write(f\"{decimal:.10f}\\n\")  # 소수점 10자리까지 출력\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/binary_values.txt'  # 16비트 바이너리 입력 파일\n",
        "output_txt_file = './model/cordic_dec_val.txt'  # 변환된 10진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_binary_to_decimal(input_txt_file, output_txt_file)\n",
        "print(f\"16비트 바이너리 값이 10진수 소수점 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "6YmJ4ZPhM_Nb",
        "outputId": "512305c2-be40-4195-c07b-a12c42162280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16비트 바이너리 값이 10진수 소수점 값으로 변환되어 ./model/cordic_dec_val.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_fixed_point_hex(input_file, output_file):\n",
        "    def float_to_fixed_point(value):\n",
        "        \"\"\"\n",
        "        10진수 소수를 16비트 고정소수점 표현으로 변환:\n",
        "        - 앞 3비트: 정수부 (0~7)\n",
        "        - 뒤 13비트: 소수부\n",
        "        \"\"\"\n",
        "        # 정수부: value의 정수 부분 (0~7 사이 값)\n",
        "        int_part = int(value)\n",
        "        if int_part > 7:\n",
        "            raise ValueError(f\"정수부가 3비트를 초과했습니다: {value}\")\n",
        "\n",
        "        # 소수부: value의 소수 부분을 13비트로 표현\n",
        "        frac_part = value - int_part\n",
        "        frac_binary = int(round(frac_part * (2 ** 13)))  # 소수부를 2^13로 스케일링\n",
        "\n",
        "        # 16비트 바이너리 표현\n",
        "        binary_value = f\"{int_part:03b}{frac_binary:013b}\"\n",
        "        return binary_value\n",
        "\n",
        "    def binary_to_hex(binary_str):\n",
        "        \"\"\"\n",
        "        16비트 바이너리를 16진수(hex)로 변환.\n",
        "        \"\"\"\n",
        "        return f\"0x{int(binary_str, 2):04X}\"\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 10진수 소수점 값 읽기 (불필요한 문자 제거)\n",
        "        raw_data = f.read()\n",
        "        cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "        decimal_values = [float(value) for value in cleaned_data.split()]\n",
        "\n",
        "    # 10진수를 16비트 고정소수점 -> 16진수로 변환\n",
        "    hex_values = []\n",
        "    for value in decimal_values:\n",
        "        binary_value = float_to_fixed_point(value)  # 16비트 바이너리 변환\n",
        "        hex_value = binary_to_hex(binary_value)  # 16진수 변환\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for hex_value in hex_values:\n",
        "            f.write(f\"{hex_value}\\n\")\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/softmax_sorted_attention_scores_2.txt'  # 입력 파일\n",
        "output_txt_file = './model/converted_fixed_point_hex.txt'  # 변환된 16진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "decimal_to_fixed_point_hex(input_txt_file, output_txt_file)\n",
        "print(f\"소수점 값이 16비트 16진수 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jaDSmkz7Rmej",
        "outputId": "1be6d348-7a2d-4fe4-b519-52be78856cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소수점 값이 16비트 16진수 값으로 변환되어 ./model/converted_fixed_point_hex.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2, num_values=463):\n",
        "    \"\"\"\n",
        "    두 파일에서 첫 번째 파일의 num_values만큼 데이터를 비교하여 1대1 오차율 및 평균 오차율 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "    num_values: 비교할 데이터 개수 (기본값: 463)\n",
        "\n",
        "    Returns:\n",
        "    각 값의 오차율 리스트 및 전체 평균 오차율\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 제한\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (463개 값이 맞는지)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / 값1 * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    return error_rates, mean_error_rate\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출\n",
        "error_rates, mean_error_rate = calculate_error_metrics(file1_path, file2_path, num_values=463)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"각 값의 오차율 (퍼센트):\\n{error_rates}\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n"
      ],
      "metadata": {
        "id": "ubtP_IPwR_KR",
        "outputId": "be4fd042-4afa-4cdd-d5c3-8bb45e8d4805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "[ 8.60191699  8.56347219  8.9813711   9.01522718  8.2937444   9.16508751\n",
            "  9.51409798 10.29058539 10.95181509 12.18763845  9.41453822  9.52617972\n",
            "  9.83866032  9.52449838  9.13086224  9.54281761  9.63956941 10.04731984\n",
            "  9.77323863 10.34836172  9.44353868  9.35780286  8.72450078  9.05629591\n",
            "  9.13881228  9.8852359   9.91252753 10.09258192 11.06591246 12.45199472\n",
            " 10.663906    9.71874717 10.4020173  10.31936805  9.5248385   9.83845806\n",
            "  9.57066063 10.136645   10.96232    12.56145863 10.0816439  10.18922969\n",
            " 10.69458686 10.60539919  9.89207746 10.29142528 10.61010461 10.42404284\n",
            " 10.32972731 12.57555533  9.88104141  9.22177712 10.00571897  9.50366448\n",
            " 10.08483835  9.17734417  9.52944574  9.65163424 12.15988383 12.75186519\n",
            "  9.06472473  8.88823754  9.10464065  9.10543083  9.39927953  8.80494621\n",
            "  9.50913867 12.07512371 12.30888716 13.24722651  8.37798402  8.8535684\n",
            "  8.46784598  9.51097671  8.95653935  9.2093156   9.13690409 11.04775964\n",
            " 12.48781707 12.64113141  8.97280222  9.06533875  9.61041263  8.6314692\n",
            "  9.16574603  9.46115939  9.67632373  9.88096467 11.04976558 12.82792397\n",
            "  9.60011118  9.00706619  9.63711914  9.09691468  9.33721459  8.88633036\n",
            "  9.23184039 12.83657725 13.30075368 13.55001206 10.07623267 10.0216439\n",
            "  9.66521963 10.09417595  9.96323778 10.33211546 10.27322315  9.57221297\n",
            "  9.86441466 12.88053824  9.52958348  9.9527953  10.51339789  9.7646162\n",
            "  9.80628052  9.47794313  9.77171892 10.27807304 10.75648511 12.00124169\n",
            "  9.93512217  9.78162599  9.18529511  9.43533457  9.34449072  9.98328842\n",
            " 10.00534905 11.31015506 11.31808068 12.67496901 10.40577095 10.69244917\n",
            " 10.65710702 10.42597828  9.77039349 10.30403744 10.20023837  9.85750626\n",
            "  9.71753384 10.44604601 10.18430251  9.96975017  9.72048637  9.55974592\n",
            "  9.86238033  9.6709649  10.41786743 10.44480935 10.17249528  9.59909523\n",
            " 10.96778803 10.67196013 10.14258616 10.17460951 10.631359    9.90931122\n",
            "  9.9798048  10.02594949  9.78580444 10.17084885 10.26636268 10.24870433\n",
            " 10.87091069 10.68045288 10.27729341 10.68446698 10.83713088  9.94576459\n",
            " 10.24281012 10.44041078  9.79741721  9.85371468  9.89270963  9.91664879\n",
            " 10.27792245  9.58183612 10.24881929  9.82799076 11.84154219 12.71208458\n",
            " 10.53982737 10.30392934 10.40989072 10.22621666 10.36395833 10.36547266\n",
            " 10.01935934 10.50594075 10.10350726 11.72803388  9.86409433 10.17256668\n",
            "  9.97187384 10.30903006 10.56138098  9.71303081 10.12528898  9.92361146\n",
            " 10.52375794 11.50550602  9.46505919  9.41801687  8.56730962  8.48455579\n",
            "  8.49175878  9.3502962   9.84380363 10.75457333 11.43129006 12.61490379\n",
            "  9.13153726 10.46152731  9.84545866 10.00794164 10.05131427 10.44910682\n",
            " 10.81128737 11.10366362 11.41162027 11.67042721 10.57048925 10.99232375\n",
            " 10.1486146  10.02046411 10.04407769 10.28725055  9.88787446 10.23621169\n",
            " 10.34030425  9.89402831  9.67200681 10.19115886  9.38810953  9.95932822\n",
            " 10.02659659 10.18407712  9.77207761  9.90175068  9.69363438 10.89637299\n",
            "  9.62243921 10.19401528  9.82960141  9.6090872  10.31596432  9.86833073\n",
            " 10.21421923 11.04420899 11.30095246 11.84984872  9.2450101   9.68192293\n",
            " 10.43500921  9.60673515 10.05510785 10.04866431  9.48454244 10.14649744\n",
            " 11.3244677  11.92335936  9.94610305 10.11004681  9.61683699 10.00959042\n",
            " 10.13330498  9.72789619  9.89407476 10.19146386 11.45081899 12.79815704\n",
            "  8.84220275 10.2597439  10.17432144  9.62871047 10.06385265  9.59137716\n",
            " 10.24965671 10.32222437 10.40470782 11.36582666  8.44344157  9.17430584\n",
            " 10.0395331   9.46455665  9.47342715  8.72479865  9.53786887 11.19002599\n",
            " 11.46341925 11.70449296  9.30115949  9.17539489  9.15609163  9.18577466\n",
            "  9.58644664  8.58834235  9.67400171 10.82740271 12.30570733 12.50381435\n",
            " 10.02761511  9.74376765 10.1154165   9.9038687   9.60825107  9.84952712\n",
            "  9.66945203  9.23611715  9.24466527 11.20834092  9.51064863 10.22516339\n",
            "  9.74763533  9.98125126  9.77557456  9.78965641  9.82670968 10.01558693\n",
            " 10.03136856 10.8998586   9.95804147 10.14163609  9.93445007 10.22946348\n",
            " 10.35603192 10.09300522 10.22825482  9.43555752 10.53925208 10.70947975\n",
            "  9.6429296  10.13292862  9.81103905  9.74015435  9.28176498  9.55140174\n",
            " 10.1869799  10.265868   10.39363509 12.89389793 10.09367661 10.078121\n",
            " 10.06081513 10.75081721 10.19417207 10.28961674 10.53974019 10.35020529\n",
            " 10.21534431 11.00663784 10.78302222 10.69750977 10.42381485 10.43711326\n",
            "  9.79116746  9.71528215 10.34791271 10.31546275 10.62573315 13.48833024\n",
            " 11.00133915 10.723536   10.55018369 10.03040512 10.72358404  9.92275629\n",
            "  9.93757392 10.00355601  9.93205019 10.55490119  8.78860954  9.66041594\n",
            "  9.88011867  9.72819094  9.64882772  9.60543452  9.75854681  8.93200302\n",
            " 12.20771935 12.96051543 10.57519502 11.02201729 10.51430224 10.73968696\n",
            " 10.74447959 10.77883233 10.18986466  9.92828599 10.6760813  10.22529756\n",
            "  9.93511853  9.82716173  9.93305509 10.29094309  9.66176759 10.09378308\n",
            " 10.24184509  9.90615493 10.00583559  9.71816603  8.27792778  8.47150221\n",
            "  8.89557201  9.30307148  8.07920127  9.17592991  9.70112954 11.97874999\n",
            " 12.18496515 12.84933397  9.45886843 10.24362836  9.6005462   9.7269715\n",
            "  9.57559283  9.4052212  10.20424781  9.82888698  9.68438365 12.07056418\n",
            "  9.0355165   9.20994245  9.23647017  9.14177719  9.36861159  9.17045234\n",
            "  9.82334149 10.68829828 11.10183676 11.43625458 10.47646269 10.10114473\n",
            " 10.45936867 10.14843609 10.39367159 10.6019987  10.18617964 10.15990705\n",
            " 10.67307102 11.38135017  9.5213961   9.62855477  9.11177747 10.07326456\n",
            "  9.91272203  9.3689755  10.05950101  9.61206966 10.68106091 14.16920816\n",
            "  9.81351824  9.37766324  9.67572254 10.0243789   9.91528196 10.05462123\n",
            " 10.42291879 10.44795535 11.51063827 13.95264478  8.67569269  8.28062712\n",
            " 10.94487531]\n",
            "전체 평균 오차율 (퍼센트): 10.167753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def txt_to_pkl(input_txt_file, output_pkl_file):\n",
        "    # txt 파일 읽기\n",
        "    with open(input_txt_file, 'r') as f:\n",
        "        # 모든 줄에서 숫자 데이터를 추출\n",
        "        data = [float(value) for line in f for value in line.split()]\n",
        "\n",
        "    # pkl 파일로 저장\n",
        "    with open(output_pkl_file, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    print(f\"TXT 파일이 {output_pkl_file}로 변환되었습니다!\")\n",
        "\n",
        "# 입력 txt 파일 경로와 출력 pkl 파일 경로\n",
        "input_txt_file = './model/cordic_dec_val.txt'\n",
        "output_pkl_file = './model/cordic_dec_val.pkl'\n",
        "\n",
        "# 변환 함수 호출\n",
        "txt_to_pkl(input_txt_file, output_pkl_file)\n"
      ],
      "metadata": {
        "id": "OrQuhc19gboQ",
        "outputId": "968a1b9e-a704-4887-9694-0afa6e2149ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TXT 파일이 ./model/cordic_dec_val.pkl로 변환되었습니다!\n"
          ]
        }
      ]
    }
  ]
}