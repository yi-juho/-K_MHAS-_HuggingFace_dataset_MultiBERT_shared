{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9moVKInibnca",
        "dryCfxh4btMS",
        "wqqbD-tBcehO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbc9ca1c89fc4ff7976aae19531655c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_920a4c091b274fbea972bb6389e9f107",
              "IPY_MODEL_c2dcf1e9dced4dceb4043268b716c095",
              "IPY_MODEL_72cafa78f4f046088e253434d0d7c250"
            ],
            "layout": "IPY_MODEL_81f9a0b9f33b4edbb05a0f058d1e2a9a"
          }
        },
        "920a4c091b274fbea972bb6389e9f107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a84b48c7044315a055ace5453fe2e1",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2f9de00e8b4f2eb25010203bd3d536",
            "value": "README.md: 100%"
          }
        },
        "c2dcf1e9dced4dceb4043268b716c095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9163e63613f24374910a35936f236832",
            "max": 10565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ae6b53d666f4c8ebd68bfb1074751df",
            "value": 10565
          }
        },
        "72cafa78f4f046088e253434d0d7c250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4c5dfcdb3e4c9eb910d7a3d055468e",
            "placeholder": "​",
            "style": "IPY_MODEL_879d29e6e66444bfa89a74f8877cfa48",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 493kB/s]"
          }
        },
        "81f9a0b9f33b4edbb05a0f058d1e2a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a84b48c7044315a055ace5453fe2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2f9de00e8b4f2eb25010203bd3d536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9163e63613f24374910a35936f236832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae6b53d666f4c8ebd68bfb1074751df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4c5dfcdb3e4c9eb910d7a3d055468e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879d29e6e66444bfa89a74f8877cfa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1683d36dbc64a7ea420a57b87f242fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14fbfb8903de4269a05a20d2b0e3c762",
              "IPY_MODEL_0a6fb321c8444faaabcc45076d6fd040",
              "IPY_MODEL_38d54750cf194e50b8d2e8f41bb094b0"
            ],
            "layout": "IPY_MODEL_6539f842ef534068be4c7c051eb7366b"
          }
        },
        "14fbfb8903de4269a05a20d2b0e3c762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dde5ff71a354c1fabaad7ce9a855117",
            "placeholder": "​",
            "style": "IPY_MODEL_dc1c880a0f7b47d98540ffd424bea47f",
            "value": "kmhas_korean_hate_speech.py: 100%"
          }
        },
        "0a6fb321c8444faaabcc45076d6fd040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c443f12fa644489527b4a8967af799",
            "max": 4730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d237d77670494f77839b983d92e43e47",
            "value": 4730
          }
        },
        "38d54750cf194e50b8d2e8f41bb094b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e54488dcda9493a9bd509381991a4c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9a9d16792aa942978301250ad7e2f0db",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 437kB/s]"
          }
        },
        "6539f842ef534068be4c7c051eb7366b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dde5ff71a354c1fabaad7ce9a855117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1c880a0f7b47d98540ffd424bea47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c443f12fa644489527b4a8967af799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d237d77670494f77839b983d92e43e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e54488dcda9493a9bd509381991a4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9d16792aa942978301250ad7e2f0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "964943c1797b415e9120e8c04ff038a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93f8be103de54eab953255281b78e31b",
              "IPY_MODEL_d05d59fe6eee4368b5f7cd8cafd72d75",
              "IPY_MODEL_608a71e3f2264fe9af5f70cfa8ef9a4b"
            ],
            "layout": "IPY_MODEL_cec0ed6846cd416d88a4a9ac0b72894a"
          }
        },
        "93f8be103de54eab953255281b78e31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977fb9474d6742ad81bc6ddf687f02b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e037fcd4b82a4cd1892d3dd4e749a693",
            "value": "0000.parquet: 100%"
          }
        },
        "d05d59fe6eee4368b5f7cd8cafd72d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7446c9abec04a728a8c63c5ee419797",
            "max": 5244851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8552fb6096e44acf8a6b5148d829bf92",
            "value": 5244851
          }
        },
        "608a71e3f2264fe9af5f70cfa8ef9a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c264cde1bf4984b13e24e7641c7115",
            "placeholder": "​",
            "style": "IPY_MODEL_22f363868faa4d69acaba559bcb69c3c",
            "value": " 5.24M/5.24M [00:00&lt;00:00, 24.2MB/s]"
          }
        },
        "cec0ed6846cd416d88a4a9ac0b72894a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977fb9474d6742ad81bc6ddf687f02b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e037fcd4b82a4cd1892d3dd4e749a693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7446c9abec04a728a8c63c5ee419797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8552fb6096e44acf8a6b5148d829bf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86c264cde1bf4984b13e24e7641c7115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f363868faa4d69acaba559bcb69c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c03e0442b7e2458ea1a67942f3778bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27f82a790cb549c3843eaca879bb7b07",
              "IPY_MODEL_0304038c148b4c659f0736de4d0b0467",
              "IPY_MODEL_87ee99cd4f8e40258efd22f60bfb169c"
            ],
            "layout": "IPY_MODEL_449dbf375f6f46d6bba69691b4a8ed5d"
          }
        },
        "27f82a790cb549c3843eaca879bb7b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a489feb8de3e460191cbba0adfa3f45d",
            "placeholder": "​",
            "style": "IPY_MODEL_eb61bfe360164535920bc24cce2a820f",
            "value": "default/validation/0000.parquet: 100%"
          }
        },
        "0304038c148b4c659f0736de4d0b0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2778847e889049029123a13d94fcf2f3",
            "max": 578860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5da80f6bb8940ceb1d38f37bd9b1ac5",
            "value": 578860
          }
        },
        "87ee99cd4f8e40258efd22f60bfb169c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da51434bbb64bb08546866e88d8afd8",
            "placeholder": "​",
            "style": "IPY_MODEL_f52f422e3e684eb184e939c1cff46c91",
            "value": " 579k/579k [00:00&lt;00:00, 1.37MB/s]"
          }
        },
        "449dbf375f6f46d6bba69691b4a8ed5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a489feb8de3e460191cbba0adfa3f45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb61bfe360164535920bc24cce2a820f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2778847e889049029123a13d94fcf2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5da80f6bb8940ceb1d38f37bd9b1ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3da51434bbb64bb08546866e88d8afd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52f422e3e684eb184e939c1cff46c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8988f0ed6e604a698222ed36a40723b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a133afa115b480aac0e3dd6916500a1",
              "IPY_MODEL_ff3e5294383944bb8e69f6e6bc1ffc47",
              "IPY_MODEL_acff041d53c845d884729da8bdafde7a"
            ],
            "layout": "IPY_MODEL_24e57a15ebc7434f9733499d94884dc5"
          }
        },
        "5a133afa115b480aac0e3dd6916500a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99101716c6f044db9b0e2285734a2df9",
            "placeholder": "​",
            "style": "IPY_MODEL_da571b148e244631a0233adf3e75624f",
            "value": "0000.parquet: 100%"
          }
        },
        "ff3e5294383944bb8e69f6e6bc1ffc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d54cd571064dcdb4a92599447edfbf",
            "max": 1458266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c9b8322db824b46b4d2ca2632094cf6",
            "value": 1458266
          }
        },
        "acff041d53c845d884729da8bdafde7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d1e02498bd41839b4b1c0bc901285e",
            "placeholder": "​",
            "style": "IPY_MODEL_e759807a94b84202b0a1fff08aa01023",
            "value": " 1.46M/1.46M [00:00&lt;00:00, 64.4MB/s]"
          }
        },
        "24e57a15ebc7434f9733499d94884dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99101716c6f044db9b0e2285734a2df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da571b148e244631a0233adf3e75624f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88d54cd571064dcdb4a92599447edfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9b8322db824b46b4d2ca2632094cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3d1e02498bd41839b4b1c0bc901285e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e759807a94b84202b0a1fff08aa01023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d821363b7844bf79d892d0a45fba48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2f3070ac96347b9adaf1998bc13d4c0",
              "IPY_MODEL_16d14344da17438d90724fa96a75ff97",
              "IPY_MODEL_79e47fdc0c894255bc8f384d45a15f1f"
            ],
            "layout": "IPY_MODEL_35ec7436d9f540b5ba5f1282b2af014f"
          }
        },
        "b2f3070ac96347b9adaf1998bc13d4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3582e497b3db4eb48d04c8e98812ffe0",
            "placeholder": "​",
            "style": "IPY_MODEL_eaf39abd322e4f43b165ee3e34c55783",
            "value": "Generating train split: 100%"
          }
        },
        "16d14344da17438d90724fa96a75ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4ec03d95f64b0d854d91f3bd317f35",
            "max": 78977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ed4860a25cf4581991ffe4fed4bf2de",
            "value": 78977
          }
        },
        "79e47fdc0c894255bc8f384d45a15f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06d362d1eae4a4db026ee2f0412581f",
            "placeholder": "​",
            "style": "IPY_MODEL_2482fb8c6b60481c8fa3399a332f5cf7",
            "value": " 78977/78977 [00:00&lt;00:00, 745639.99 examples/s]"
          }
        },
        "35ec7436d9f540b5ba5f1282b2af014f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3582e497b3db4eb48d04c8e98812ffe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf39abd322e4f43b165ee3e34c55783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4ec03d95f64b0d854d91f3bd317f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed4860a25cf4581991ffe4fed4bf2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e06d362d1eae4a4db026ee2f0412581f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2482fb8c6b60481c8fa3399a332f5cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572827a2045f497cb1ceea0b18bc994b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149aacf311bd4d239a587e41e8e4fc61",
              "IPY_MODEL_482ab4e36d67430b879d930bf9ac2eae",
              "IPY_MODEL_eedac08ca1084056910f71fc6c78a274"
            ],
            "layout": "IPY_MODEL_f46ee324226840d9b0e910e29439fbf7"
          }
        },
        "149aacf311bd4d239a587e41e8e4fc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c11455e20f43daad06a3dc2573582a",
            "placeholder": "​",
            "style": "IPY_MODEL_5222d4a5d54b46e1ab5fd451e86db76d",
            "value": "Generating validation split: 100%"
          }
        },
        "482ab4e36d67430b879d930bf9ac2eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5884795388c438887e7666cd9054a85",
            "max": 8776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b071801c1314cb2acdf68400af1d1d2",
            "value": 8776
          }
        },
        "eedac08ca1084056910f71fc6c78a274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c73062ea5724f90aa415b326ca43e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_d63b4e7349a14a7ca7a3d45b87b18ea1",
            "value": " 8776/8776 [00:00&lt;00:00, 266449.59 examples/s]"
          }
        },
        "f46ee324226840d9b0e910e29439fbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c11455e20f43daad06a3dc2573582a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5222d4a5d54b46e1ab5fd451e86db76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5884795388c438887e7666cd9054a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b071801c1314cb2acdf68400af1d1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c73062ea5724f90aa415b326ca43e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63b4e7349a14a7ca7a3d45b87b18ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df558f6459e94efcb90677883b2ffcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbce1eeb83f34661b975d4f71e815447",
              "IPY_MODEL_6a255b83744b4a09ace3d7e8f5e754e4",
              "IPY_MODEL_eaa3e788ffd94aad8f9fb4c3ad83cb6b"
            ],
            "layout": "IPY_MODEL_4c7a0b5d91144071b7e46eeb686a2659"
          }
        },
        "fbce1eeb83f34661b975d4f71e815447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d92035c7f94b08a02ca8bf1ca4ba32",
            "placeholder": "​",
            "style": "IPY_MODEL_06757748368d4ea1965a4362429e91ca",
            "value": "Generating test split: 100%"
          }
        },
        "6a255b83744b4a09ace3d7e8f5e754e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa0e4f430f44fcda33fc615cd7989ad",
            "max": 21939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c342ea011943568317aec41a0eed2f",
            "value": 21939
          }
        },
        "eaa3e788ffd94aad8f9fb4c3ad83cb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a5478c2daf4850bd036c72e80a2942",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c641699800475ab7a638303044e20d",
            "value": " 21939/21939 [00:00&lt;00:00, 498701.12 examples/s]"
          }
        },
        "4c7a0b5d91144071b7e46eeb686a2659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d92035c7f94b08a02ca8bf1ca4ba32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06757748368d4ea1965a4362429e91ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aa0e4f430f44fcda33fc615cd7989ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c342ea011943568317aec41a0eed2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97a5478c2daf4850bd036c72e80a2942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c641699800475ab7a638303044e20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c85fefc0387404a9d3d2b638869de16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20f31647753b496e92356e2946788f84",
              "IPY_MODEL_ca67d6408f974a6296cc3de9a85c8b39",
              "IPY_MODEL_4cb556b7c1c942119a7f814f78697899"
            ],
            "layout": "IPY_MODEL_aa8f387696a543c4a07f519aaa4e3549"
          }
        },
        "20f31647753b496e92356e2946788f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879e324249b8444cbe08e42549eaf606",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7123357c124f46807eb5e333798166",
            "value": ""
          }
        },
        "ca67d6408f974a6296cc3de9a85c8b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99deef2c523146a2b81b5061be1af6c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1db05e87413949b8acd069857a395c15",
            "value": 0
          }
        },
        "4cb556b7c1c942119a7f814f78697899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f7b01b33f746e0a249f5fcfac3be45",
            "placeholder": "​",
            "style": "IPY_MODEL_b09cd4c4ac5946f4a2825ca95cec7860",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "aa8f387696a543c4a07f519aaa4e3549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879e324249b8444cbe08e42549eaf606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7123357c124f46807eb5e333798166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99deef2c523146a2b81b5061be1af6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1db05e87413949b8acd069857a395c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60f7b01b33f746e0a249f5fcfac3be45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09cd4c4ac5946f4a2825ca95cec7860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3155474e44aa4deca90de1f7e847e111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccdeb411067d4cd790e306c938b79783",
              "IPY_MODEL_44e1e262ebf74ca2a0d88e1049b471c0",
              "IPY_MODEL_6dcc3d95e83249479b01780a0c0278f9"
            ],
            "layout": "IPY_MODEL_f1967cef57464988963aa53729ca9002"
          }
        },
        "ccdeb411067d4cd790e306c938b79783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83fa3e5bf0844e37a975455608f4aa25",
            "placeholder": "​",
            "style": "IPY_MODEL_1694b1385754431a9873a7417de12eab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "44e1e262ebf74ca2a0d88e1049b471c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9dec8193c0463a949fac5a84395e5e",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cfcf7bbccdc40f5b64f6abb272b4bdd",
            "value": 289
          }
        },
        "6dcc3d95e83249479b01780a0c0278f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970262c304c247efbf5be781e82d94a9",
            "placeholder": "​",
            "style": "IPY_MODEL_30bafde4bfd14bd9877646c73d61e6af",
            "value": " 289/289 [00:00&lt;00:00, 13.0kB/s]"
          }
        },
        "f1967cef57464988963aa53729ca9002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fa3e5bf0844e37a975455608f4aa25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1694b1385754431a9873a7417de12eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9dec8193c0463a949fac5a84395e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cfcf7bbccdc40f5b64f6abb272b4bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "970262c304c247efbf5be781e82d94a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bafde4bfd14bd9877646c73d61e6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24b841d12bd34bfebfe0f9627a2c5cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c6f2d54b12147c09f101f8c8e9230cf",
              "IPY_MODEL_d8fb9fa49a2a479aa05c2b31afbe8ee3",
              "IPY_MODEL_29e71004a125406f837f461340031e05"
            ],
            "layout": "IPY_MODEL_17d5b34f21544bfeb8b76588c8ce60cc"
          }
        },
        "5c6f2d54b12147c09f101f8c8e9230cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244b8ae6f7bd4366a6259cf59b9aa15e",
            "placeholder": "​",
            "style": "IPY_MODEL_59ae442bfb224cf08eb70498852da889",
            "value": "vocab.txt: 100%"
          }
        },
        "d8fb9fa49a2a479aa05c2b31afbe8ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab744e8f06e489d8c952a7946b483f6",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e290e4769cc84437b212fb2253a2780a",
            "value": 248477
          }
        },
        "29e71004a125406f837f461340031e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c9ef84e15841fbb17b77a0d6b34b44",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff94128c03f4d36b83bb9d137f7de41",
            "value": " 248k/248k [00:00&lt;00:00, 14.5MB/s]"
          }
        },
        "17d5b34f21544bfeb8b76588c8ce60cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244b8ae6f7bd4366a6259cf59b9aa15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ae442bfb224cf08eb70498852da889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eab744e8f06e489d8c952a7946b483f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e290e4769cc84437b212fb2253a2780a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66c9ef84e15841fbb17b77a0d6b34b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff94128c03f4d36b83bb9d137f7de41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3bdfe503a984a26bf02000aa4efd4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5edc21c3169b445c9691987d70dd719a",
              "IPY_MODEL_77e8bafc033f4561b7817ab8f703043b",
              "IPY_MODEL_5d81bc31507e40db964fe2cefa0ec1b1"
            ],
            "layout": "IPY_MODEL_ad31bb6d9db24e0f97032aa22f60eaa4"
          }
        },
        "5edc21c3169b445c9691987d70dd719a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588247e5a2e24186bf0ab16af283f7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c5fa160c502044ea991bdd7fa71601ee",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "77e8bafc033f4561b7817ab8f703043b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e05738fb774e38adbc6347183427dc",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e9ec652a27347898cc62a3e1bdcb0a2",
            "value": 125
          }
        },
        "5d81bc31507e40db964fe2cefa0ec1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1ecac9619b47a5a0c3e948bf6301c2",
            "placeholder": "​",
            "style": "IPY_MODEL_bcaece7affb94c1cbef7e5cd5755c5d0",
            "value": " 125/125 [00:00&lt;00:00, 8.21kB/s]"
          }
        },
        "ad31bb6d9db24e0f97032aa22f60eaa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588247e5a2e24186bf0ab16af283f7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fa160c502044ea991bdd7fa71601ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10e05738fb774e38adbc6347183427dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9ec652a27347898cc62a3e1bdcb0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c1ecac9619b47a5a0c3e948bf6301c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcaece7affb94c1cbef7e5cd5755c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be2ab138d914e9eaf266cc7a5b215e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c450e71047494c9b9662e148d5858b59",
              "IPY_MODEL_020d38200d25449793ef8efdd1ea90aa",
              "IPY_MODEL_43dd39eaed724c478a60e0be65cd061c"
            ],
            "layout": "IPY_MODEL_f48d9030a9b94c64b6381b372bd712c7"
          }
        },
        "c450e71047494c9b9662e148d5858b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672c6bbcb65040c392a7aa7b564c62af",
            "placeholder": "​",
            "style": "IPY_MODEL_c94bddb7f5ec4b33967a5898d30fac80",
            "value": "tokenizer.json: 100%"
          }
        },
        "020d38200d25449793ef8efdd1ea90aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e082766ee24def9f1fb05a6a7f3dba",
            "max": 494860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_457fb60f90cb4433b86e031d30927ea9",
            "value": 494860
          }
        },
        "43dd39eaed724c478a60e0be65cd061c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4ee25a6fde4699b6c23d8e59c04cb8",
            "placeholder": "​",
            "style": "IPY_MODEL_87cf407f27ec4098b03ca61222ce20ed",
            "value": " 495k/495k [00:00&lt;00:00, 29.6MB/s]"
          }
        },
        "f48d9030a9b94c64b6381b372bd712c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672c6bbcb65040c392a7aa7b564c62af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94bddb7f5ec4b33967a5898d30fac80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e082766ee24def9f1fb05a6a7f3dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457fb60f90cb4433b86e031d30927ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e4ee25a6fde4699b6c23d8e59c04cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cf407f27ec4098b03ca61222ce20ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eefe6a34b3924a8b8e00f6b0b815bc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f04643a6a846569e9d247d76c76709",
              "IPY_MODEL_9c0e63695901421cb091a576a5f6e1a8",
              "IPY_MODEL_3e4ef2f1b0624d19bcde8997225d16ee"
            ],
            "layout": "IPY_MODEL_980037e5c43342fdbec3929c7f74d915"
          }
        },
        "89f04643a6a846569e9d247d76c76709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdde2723b5454f2ca016af3a0e38566c",
            "placeholder": "​",
            "style": "IPY_MODEL_670788c274ad4daba4dacd7c6890bb2d",
            "value": "config.json: 100%"
          }
        },
        "9c0e63695901421cb091a576a5f6e1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f46853d35824e918b3fc73b3a9de56b",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bca974e87c8f4c45980e1d3df527c388",
            "value": 425
          }
        },
        "3e4ef2f1b0624d19bcde8997225d16ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a773eae1a644d8b447b4a4695535f7",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdce5eead644dacbe5e141dfdd21ac9",
            "value": " 425/425 [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "980037e5c43342fdbec3929c7f74d915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdde2723b5454f2ca016af3a0e38566c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670788c274ad4daba4dacd7c6890bb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f46853d35824e918b3fc73b3a9de56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca974e87c8f4c45980e1d3df527c388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78a773eae1a644d8b447b4a4695535f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdce5eead644dacbe5e141dfdd21ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77d79972ac1b4812ac705fc40712492c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bcba738d2a54b4cb0e8f75f9351da65",
              "IPY_MODEL_08bfa423587e46e5804e7e37f1f2b989",
              "IPY_MODEL_d631698f5f7e4084907eee87ae0e07ae"
            ],
            "layout": "IPY_MODEL_0c00f2838ad34863a27716d22c571d28"
          }
        },
        "2bcba738d2a54b4cb0e8f75f9351da65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cdd98a5e3b4508940c478bdd522e35",
            "placeholder": "​",
            "style": "IPY_MODEL_23d9778c842e44bdb76a66be32ab97e4",
            "value": "model.safetensors: 100%"
          }
        },
        "08bfa423587e46e5804e7e37f1f2b989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf47e55edf4a4111b242b3ed6390f156",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0804b796d9834043a13d807aeb961d26",
            "value": 445000316
          }
        },
        "d631698f5f7e4084907eee87ae0e07ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0163dcf8bd5469fb0bef99cc5abc336",
            "placeholder": "​",
            "style": "IPY_MODEL_09a21be481c64a6a882170c93c7497bd",
            "value": " 445M/445M [00:02&lt;00:00, 119MB/s]"
          }
        },
        "0c00f2838ad34863a27716d22c571d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cdd98a5e3b4508940c478bdd522e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d9778c842e44bdb76a66be32ab97e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf47e55edf4a4111b242b3ed6390f156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0804b796d9834043a13d807aeb961d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0163dcf8bd5469fb0bef99cc5abc336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a21be481c64a6a882170c93c7497bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/%5BK_MHAS%5D_HuggingFace_dataset_MultiBERT_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the K-MHaS dataset from [HuggingFace](https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech) and checking meta information (published @COLING2022)\n"
      ],
      "metadata": {
        "id": "4Lyor-OIrwd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets fsspec -y\n",
        "!pip install datasets==3.2.0 fsspec[http]==2024.9.0\n"
      ],
      "metadata": {
        "id": "WMoJHDlhbklf",
        "outputId": "53b98920-a39e-422f-deba-0aaa978e5cb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.10.0\n",
            "Uninstalling fsspec-2024.10.0:\n",
            "  Successfully uninstalled fsspec-2024.10.0\n",
            "Collecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec==2024.9.0 (from fsspec[http]==2024.9.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "outputId": "4f1cf07b-c25b-4b05-f016-f90ce9c04799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "outputId": "49cf6e4e-ec1a-4379-adf3-4903def26373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "dbc9ca1c89fc4ff7976aae19531655c7",
            "920a4c091b274fbea972bb6389e9f107",
            "c2dcf1e9dced4dceb4043268b716c095",
            "72cafa78f4f046088e253434d0d7c250",
            "81f9a0b9f33b4edbb05a0f058d1e2a9a",
            "20a84b48c7044315a055ace5453fe2e1",
            "2c2f9de00e8b4f2eb25010203bd3d536",
            "9163e63613f24374910a35936f236832",
            "0ae6b53d666f4c8ebd68bfb1074751df",
            "8a4c5dfcdb3e4c9eb910d7a3d055468e",
            "879d29e6e66444bfa89a74f8877cfa48",
            "d1683d36dbc64a7ea420a57b87f242fc",
            "14fbfb8903de4269a05a20d2b0e3c762",
            "0a6fb321c8444faaabcc45076d6fd040",
            "38d54750cf194e50b8d2e8f41bb094b0",
            "6539f842ef534068be4c7c051eb7366b",
            "9dde5ff71a354c1fabaad7ce9a855117",
            "dc1c880a0f7b47d98540ffd424bea47f",
            "a5c443f12fa644489527b4a8967af799",
            "d237d77670494f77839b983d92e43e47",
            "4e54488dcda9493a9bd509381991a4c1",
            "9a9d16792aa942978301250ad7e2f0db",
            "964943c1797b415e9120e8c04ff038a6",
            "93f8be103de54eab953255281b78e31b",
            "d05d59fe6eee4368b5f7cd8cafd72d75",
            "608a71e3f2264fe9af5f70cfa8ef9a4b",
            "cec0ed6846cd416d88a4a9ac0b72894a",
            "977fb9474d6742ad81bc6ddf687f02b3",
            "e037fcd4b82a4cd1892d3dd4e749a693",
            "a7446c9abec04a728a8c63c5ee419797",
            "8552fb6096e44acf8a6b5148d829bf92",
            "86c264cde1bf4984b13e24e7641c7115",
            "22f363868faa4d69acaba559bcb69c3c",
            "c03e0442b7e2458ea1a67942f3778bfa",
            "27f82a790cb549c3843eaca879bb7b07",
            "0304038c148b4c659f0736de4d0b0467",
            "87ee99cd4f8e40258efd22f60bfb169c",
            "449dbf375f6f46d6bba69691b4a8ed5d",
            "a489feb8de3e460191cbba0adfa3f45d",
            "eb61bfe360164535920bc24cce2a820f",
            "2778847e889049029123a13d94fcf2f3",
            "f5da80f6bb8940ceb1d38f37bd9b1ac5",
            "3da51434bbb64bb08546866e88d8afd8",
            "f52f422e3e684eb184e939c1cff46c91",
            "8988f0ed6e604a698222ed36a40723b8",
            "5a133afa115b480aac0e3dd6916500a1",
            "ff3e5294383944bb8e69f6e6bc1ffc47",
            "acff041d53c845d884729da8bdafde7a",
            "24e57a15ebc7434f9733499d94884dc5",
            "99101716c6f044db9b0e2285734a2df9",
            "da571b148e244631a0233adf3e75624f",
            "88d54cd571064dcdb4a92599447edfbf",
            "7c9b8322db824b46b4d2ca2632094cf6",
            "a3d1e02498bd41839b4b1c0bc901285e",
            "e759807a94b84202b0a1fff08aa01023",
            "2d821363b7844bf79d892d0a45fba48e",
            "b2f3070ac96347b9adaf1998bc13d4c0",
            "16d14344da17438d90724fa96a75ff97",
            "79e47fdc0c894255bc8f384d45a15f1f",
            "35ec7436d9f540b5ba5f1282b2af014f",
            "3582e497b3db4eb48d04c8e98812ffe0",
            "eaf39abd322e4f43b165ee3e34c55783",
            "4a4ec03d95f64b0d854d91f3bd317f35",
            "6ed4860a25cf4581991ffe4fed4bf2de",
            "e06d362d1eae4a4db026ee2f0412581f",
            "2482fb8c6b60481c8fa3399a332f5cf7",
            "572827a2045f497cb1ceea0b18bc994b",
            "149aacf311bd4d239a587e41e8e4fc61",
            "482ab4e36d67430b879d930bf9ac2eae",
            "eedac08ca1084056910f71fc6c78a274",
            "f46ee324226840d9b0e910e29439fbf7",
            "f8c11455e20f43daad06a3dc2573582a",
            "5222d4a5d54b46e1ab5fd451e86db76d",
            "d5884795388c438887e7666cd9054a85",
            "5b071801c1314cb2acdf68400af1d1d2",
            "8c73062ea5724f90aa415b326ca43e9c",
            "d63b4e7349a14a7ca7a3d45b87b18ea1",
            "df558f6459e94efcb90677883b2ffcb8",
            "fbce1eeb83f34661b975d4f71e815447",
            "6a255b83744b4a09ace3d7e8f5e754e4",
            "eaa3e788ffd94aad8f9fb4c3ad83cb6b",
            "4c7a0b5d91144071b7e46eeb686a2659",
            "e8d92035c7f94b08a02ca8bf1ca4ba32",
            "06757748368d4ea1965a4362429e91ca",
            "2aa0e4f430f44fcda33fc615cd7989ad",
            "51c342ea011943568317aec41a0eed2f",
            "97a5478c2daf4850bd036c72e80a2942",
            "a0c641699800475ab7a638303044e20d"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbc9ca1c89fc4ff7976aae19531655c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "kmhas_korean_hate_speech.py:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1683d36dbc64a7ea420a57b87f242fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "964943c1797b415e9120e8c04ff038a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "default/validation/0000.parquet:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c03e0442b7e2458ea1a67942f3778bfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8988f0ed6e604a698222ed36a40723b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d821363b7844bf79d892d0a45fba48e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572827a2045f497cb1ceea0b18bc994b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df558f6459e94efcb90677883b2ffcb8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "be82a12f-31e1-472f-cff1-f30b24fb3685"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "049c3346-ae92-41e5-d53f-c5dd8af174a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "0075612e-aa93-4da0-95d6-6e20c101b2f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meta information\n",
        "\n",
        "print(dataset.info.description)\n",
        "print(dataset.info.homepage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AveWSDOj88",
        "outputId": "cc999361-9b39-44b7-ecd2-6f1d6ce7a9ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\n",
            "The fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.\n",
            "\n",
            "https://github.com/adlnlp/K-MHaS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bsDpBwOxPx",
        "outputId": "8df7f654-1f6f-4232-9827-85ee0a0b7853"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@inproceedings{lee-etal-2022-k,\n",
            "    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n",
            "    author = \"Lee, Jean  and\n",
            "      Lim, Taejun  and\n",
            "      Lee, Heejun  and\n",
            "      Jo, Bogeun  and\n",
            "      Kim, Yangsok  and\n",
            "      Yoon, Heegeun  and\n",
            "      Han, Soyeon Caren\",\n",
            "    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n",
            "    month = oct,\n",
            "    year = \"2022\",\n",
            "    address = \"Gyeongju, Republic of Korea\",\n",
            "    publisher = \"International Committee on Computational Linguistics\",\n",
            "    url = \"https://aclanthology.org/2022.coling-1.311\",\n",
            "    pages = \"3530--3538\",\n",
            "    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare data from train, validation, and test dataset\n",
        "- Multi-label is converted to multi-label one hot encodding\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin\n",
        "          1: physical\n",
        "          2: politics\n",
        "          3: profanity\n",
        "          4: age\n",
        "          5: gender\n",
        "          6: race\n",
        "          7: religion\n",
        "          8: not_hate_speech"
      ],
      "metadata": {
        "id": "qqO0w2cKsjN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fykcu8FKZiOI",
        "outputId": "333620c1-c23b-4cbf-9a3a-9ceb74088161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "-IczFOCZZfvx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "id": "A5Jq_uiYcIWM",
        "outputId": "1645835b-6bea-481f-866f-35f87a237059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "0c85fefc0387404a9d3d2b638869de16",
            "20f31647753b496e92356e2946788f84",
            "ca67d6408f974a6296cc3de9a85c8b39",
            "4cb556b7c1c942119a7f814f78697899",
            "aa8f387696a543c4a07f519aaa4e3549",
            "879e324249b8444cbe08e42549eaf606",
            "2b7123357c124f46807eb5e333798166",
            "99deef2c523146a2b81b5061be1af6c1",
            "1db05e87413949b8acd069857a395c15",
            "60f7b01b33f746e0a249f5fcfac3be45",
            "b09cd4c4ac5946f4a2825ca95cec7860"
          ]
        },
        "outputId": "42e2fac6-93bb-4fa8-e6f8-8d8a78e5df4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c85fefc0387404a9d3d2b638869de16"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, validation, and test dataset from HuggingFace\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding masking (able to remove this step depending on the model)\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multi-label to multi-label binary (one hot encoding)\n",
        "# [8] -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-xu24pnaxek",
        "outputId": "a0022d8d-d22b-46da-9731-db317fc27d6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그만큼 길예르모가 잘했다고 보면되겠지 기대되네 셰이프 오브 워터 [SEP]',\n",
              " '[CLS] \"1. 8넘의 문재앙\" [SEP]',\n",
              " '[CLS] \"문재인 정권의 내로남불은 타의 추종을 불허하네. 자한당 욕할거리도 없음.\" [SEP]',\n",
              " '[CLS] \"짱개들 지나간 곳은 폐허된다 ㅋㅋ\" [SEP]',\n",
              " '[CLS] 곱창은 자갈치~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "23eaf053-ebb3-406f-a3e6-d95dd480c09c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for Pytorch"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing : bert-base-multilingual-cased\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)"
      ],
      "metadata": {
        "id": "VKYP2VNkR-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3155474e44aa4deca90de1f7e847e111",
            "ccdeb411067d4cd790e306c938b79783",
            "44e1e262ebf74ca2a0d88e1049b471c0",
            "6dcc3d95e83249479b01780a0c0278f9",
            "f1967cef57464988963aa53729ca9002",
            "83fa3e5bf0844e37a975455608f4aa25",
            "1694b1385754431a9873a7417de12eab",
            "9f9dec8193c0463a949fac5a84395e5e",
            "1cfcf7bbccdc40f5b64f6abb272b4bdd",
            "970262c304c247efbf5be781e82d94a9",
            "30bafde4bfd14bd9877646c73d61e6af",
            "24b841d12bd34bfebfe0f9627a2c5cb2",
            "5c6f2d54b12147c09f101f8c8e9230cf",
            "d8fb9fa49a2a479aa05c2b31afbe8ee3",
            "29e71004a125406f837f461340031e05",
            "17d5b34f21544bfeb8b76588c8ce60cc",
            "244b8ae6f7bd4366a6259cf59b9aa15e",
            "59ae442bfb224cf08eb70498852da889",
            "eab744e8f06e489d8c952a7946b483f6",
            "e290e4769cc84437b212fb2253a2780a",
            "66c9ef84e15841fbb17b77a0d6b34b44",
            "9ff94128c03f4d36b83bb9d137f7de41",
            "e3bdfe503a984a26bf02000aa4efd4dd",
            "5edc21c3169b445c9691987d70dd719a",
            "77e8bafc033f4561b7817ab8f703043b",
            "5d81bc31507e40db964fe2cefa0ec1b1",
            "ad31bb6d9db24e0f97032aa22f60eaa4",
            "588247e5a2e24186bf0ab16af283f7ee",
            "c5fa160c502044ea991bdd7fa71601ee",
            "10e05738fb774e38adbc6347183427dc",
            "5e9ec652a27347898cc62a3e1bdcb0a2",
            "5c1ecac9619b47a5a0c3e948bf6301c2",
            "bcaece7affb94c1cbef7e5cd5755c5d0",
            "1be2ab138d914e9eaf266cc7a5b215e8",
            "c450e71047494c9b9662e148d5858b59",
            "020d38200d25449793ef8efdd1ea90aa",
            "43dd39eaed724c478a60e0be65cd061c",
            "f48d9030a9b94c64b6381b372bd712c7",
            "672c6bbcb65040c392a7aa7b564c62af",
            "c94bddb7f5ec4b33967a5898d30fac80",
            "d2e082766ee24def9f1fb05a6a7f3dba",
            "457fb60f90cb4433b86e031d30927ea9",
            "7e4ee25a6fde4699b6c23d8e59c04cb8",
            "87cf407f27ec4098b03ca61222ce20ed",
            "eefe6a34b3924a8b8e00f6b0b815bc77",
            "89f04643a6a846569e9d247d76c76709",
            "9c0e63695901421cb091a576a5f6e1a8",
            "3e4ef2f1b0624d19bcde8997225d16ee",
            "980037e5c43342fdbec3929c7f74d915",
            "cdde2723b5454f2ca016af3a0e38566c",
            "670788c274ad4daba4dacd7c6890bb2d",
            "9f46853d35824e918b3fc73b3a9de56b",
            "bca974e87c8f4c45980e1d3df527c388",
            "78a773eae1a644d8b447b4a4695535f7",
            "dbdce5eead644dacbe5e141dfdd21ac9"
          ]
        },
        "outputId": "fcc32a2b-fcff-4ffd-b58a-337e03f21b3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3155474e44aa4deca90de1f7e847e111"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24b841d12bd34bfebfe0f9627a2c5cb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bdfe503a984a26bf02000aa4efd4dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1be2ab138d914e9eaf266cc7a5b215e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eefe6a34b3924a8b8e00f6b0b815bc77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks\n"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('testset size:', len(test_labels))\n",
        "print('trainset size:', len(train_labels))\n",
        "print('validset size:', len(validation_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "ae6de24f-6ac4-4279-b8b6-cb5f87b49377"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset size: 21939\n",
            "trainset size: 78977\n",
            "validset size: 8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-BERT model"
      ],
      "metadata": {
        "id": "pXGKAsSXut0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setting"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfq1f2Y3Yhck",
        "outputId": "6457fb1a-bb2b-4d14-ae66-15b5c10781a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "f6e65466-dfc9-49bd-875c-f26e037b2806"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setting"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936,
          "referenced_widgets": [
            "77d79972ac1b4812ac705fc40712492c",
            "2bcba738d2a54b4cb0e8f75f9351da65",
            "08bfa423587e46e5804e7e37f1f2b989",
            "d631698f5f7e4084907eee87ae0e07ae",
            "0c00f2838ad34863a27716d22c571d28",
            "08cdd98a5e3b4508940c478bdd522e35",
            "23d9778c842e44bdb76a66be32ab97e4",
            "bf47e55edf4a4111b242b3ed6390f156",
            "0804b796d9834043a13d807aeb961d26",
            "a0163dcf8bd5469fb0bef99cc5abc336",
            "09a21be481c64a6a882170c93c7497bd"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "7bacc8c2-7e21-4f83-c25a-fc2c5ebab95f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77d79972ac1b4812ac705fc40712492c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "# change epochs for improving results (our paper : epochs = 4)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "yO_GNYxCSYfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b169d4c4-8072-416b-f564-0f5ae4147aa7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming_loss': hamming}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFH3QM6ctmP",
        "outputId": "31525220-5836-44cc-fe3f-53885b326162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:36,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:37.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [15:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:15:59.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:21,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.1362\n",
            "  Training epcoh took: 0:26:23\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0863\n",
            "  Training epcoh took: 0:26:33\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0641\n",
            "  Training epcoh took: 0:26:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:44.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:06,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:29.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0499\n",
            "  Training epcoh took: 0:26:31\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "PXTAMK1sc0Sq",
        "outputId": "ed123a8b-6629-4cf9-9602-6214ec84620a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n",
            "Hamming Loss: 0.0360\n",
            "Validation took: 0:00:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "\n",
        "# torch.save(model.state_dict(), path+\"BERT_model.pt\")"
      ],
      "metadata": {
        "id": "sdghDBnXdYlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "path = '/content/model/'\n",
        "#torch.save(model.state_dict(), path+\"BERT_multilabel_model.pt\")\n",
        "model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "ad416117-3eff-4b0c-a2d1-4898f04c756e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d28ce5f3d4a8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "sgx14gm68ElU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "for batch in validation_dataloader:\n",
        " batch = tuple(t.to(device) for t in batch)\n",
        " b_input_ids, b_input_mask, b_labels = batch\n",
        " with torch.no_grad():\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " logits = outputs[0]\n",
        " logits = logits.detach().cpu().numpy()\n",
        " label_ids = b_labels.to('cpu').numpy()\n",
        " for b in logits:\n",
        "  accum_logits.append(list(b))\n",
        " for b in label_ids:\n",
        "  accum_label_ids.append(list(b))\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))"
      ],
      "metadata": {
        "id": "1jqF9y4E7YjT",
        "outputId": "cf18cc10-509e-4cd9-c4de-851e02c4514b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "accum_results = []\n",
        "accum_results.append(list(results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "5226812c-3752-4d94-8503-350f86408c23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:20,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    686.    Elapsed: 0:00:20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "201it [00:40,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    686.    Elapsed: 0:00:41.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "301it [01:00,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    686.    Elapsed: 0:01:01.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "401it [01:21,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    686.    Elapsed: 0:01:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [01:41,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    686.    Elapsed: 0:01:42.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "601it [02:01,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    686.    Elapsed: 0:02:02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "686it [02:19,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down evaluation"
      ],
      "metadata": {
        "id": "lInDyL-9hjhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_labels):\n",
        "    ith_label_ids, ith_logits = [], []\n",
        "\n",
        "    for j, labels in enumerate(accum_label_ids):\n",
        "        if len(np.where(labels)[0]) == i+1:\n",
        "            ith_label_ids.append(accum_label_ids[j].tolist())\n",
        "            ith_logits.append(accum_logits[j].tolist())\n",
        "\n",
        "    ith_label_ids = np.array(ith_label_ids)\n",
        "    ith_logits = np.array(ith_logits)\n",
        "\n",
        "    if len(ith_label_ids) == 0 and len(ith_logits) == 0:\n",
        "        continue\n",
        "\n",
        "    results = multi_label_metrics(ith_logits, ith_label_ids)\n",
        "    accum_results.append(list(results.values()))\n",
        "\n",
        "    print('# of labels:', i+1)\n",
        "    print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "    print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "    print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "    print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "    print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "    print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uVtTwWhnHy",
        "outputId": "20dbc434-b41c-4d14-a69c-cb949ec53aa9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer,\n",
        "device=0, max_length=10,\n",
        " return_all_scores=True, function_to_apply='sigmoid')\n",
        "result = pipe('틀니들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)\n",
        "label_dict = {'LABEL_0' : '출신차별', 'LABEL_1' : '외모차별', 'LABEL_2' : '정치성향차별', 'LABEL_3': '혐오욕설', 'LABEL_4': '연령차별', 'LABEL_5': '성차별', 'LABEL_6' : '인종차별', 'LABEL_7': '종교차별', 'LABEL_8': '해당사항없음'}\n",
        "def prediction(text):\n",
        " result = pipe(text)\n",
        " return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]\n",
        "prediction('틀니들은 왜 그렇게 민폐를 끼치냐?')"
      ],
      "metadata": {
        "id": "798meQSe6c-Y",
        "outputId": "94f72f70-150e-4589-883b-d0b15c1cec4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "def predict_labels(text, model, tokenizer, label_names, threshold=0.1):\n",
        "    # 텍스트를 모델의 입력 형식으로 인코딩\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 10,\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 모델을 사용하여 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    # 예측 결과에서 확률 추출\n",
        "    logits = outputs.logits\n",
        "    #print(logits)\n",
        "    probs = sigmoid(logits)\n",
        "    #print(probs)\n",
        "\n",
        "    # CPU로 이동 후 numpy 배열로 변환\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    #print(probs)\n",
        "\n",
        "    # 예측된 레이블 결정\n",
        "    predicted_labels = [label_names[i] for i in range(len(label_names)) if probs[0][i] >= threshold]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "2FStXOPPcqnO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"늙은 천주교 신자들은 다 속물이다\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "t18ZXNVec82c",
        "outputId": "03c077fc-2d9e-46a5-ee29-1a3898bfbc64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 늙은 천주교 신자들은 다 속물이다 & Predicted labels: ['연령차별', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1\n",
        "text = \"못생긴 경상도 여자들은 나가라\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} -> Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "Q4wfueAfdARU",
        "outputId": "66b7787f-05ef-4aa0-f41f-d37cf583c769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 못생긴 경상도 여자들은 나가라 -> Predicted labels: ['출신차별', '외모차별', '성차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LV_-RJXdR5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VSCode 쪽 코드 (receive_data.py)\n",
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "xCHlbhrqdDuu",
        "outputId": "dfab927a-95c7-4912-c8ac-f2abdd2b3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1b184333c58d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/./content/model/attention_scores.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutputs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('문재앙')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f-0wLH1NexAK",
        "outputId": "04a688d7-36e6-4da8-d4bf-ce2445731148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.007721984758973122}, {'label': 'LABEL_1', 'score': 0.0032311684917658567}, {'label': 'LABEL_2', 'score': 0.985312283039093}, {'label': 'LABEL_3', 'score': 0.005993321072310209}, {'label': 'LABEL_4', 'score': 0.0053891874849796295}, {'label': 'LABEL_5', 'score': 0.002821417059749365}, {'label': 'LABEL_6', 'score': 0.0012292619794607162}, {'label': 'LABEL_7', 'score': 0.002137931529432535}, {'label': 'LABEL_8', 'score': 0.007046678103506565}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = \"cpu\"\n",
        "\n",
        "# 모델을 CPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, max_length=10, return_all_scores=True)\n",
        "\n",
        "result = pipe('깜둥이들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PmW6CiNigW55",
        "outputId": "58a9ebda-049b-4f56-a0a1-df64cdc26632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.14709047973155975}, {'label': 'LABEL_1', 'score': 0.26493778824806213}, {'label': 'LABEL_2', 'score': 0.026825927197933197}, {'label': 'LABEL_3', 'score': 0.03060534968972206}, {'label': 'LABEL_4', 'score': 0.08758819103240967}, {'label': 'LABEL_5', 'score': 0.09902970492839813}, {'label': 'LABEL_6', 'score': 0.8641231060028076}, {'label': 'LABEL_7', 'score': 0.14547504484653473}, {'label': 'LABEL_8', 'score': 0.11148741096258163}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "lEvK_zHWgiKj",
        "outputId": "40027b4f-3050-491a-a215-f6dd0a5aaefd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ㅅ발 천주교도들은 너무 말이 많아 & Predicted labels: ['혐오욕설', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = '/home/jyhan/HW-output-files/example.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "NH4-k_-Zgp5L",
        "outputId": "1675b92e-3162-4d6f-8956-2b22a852f997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file /home/jyhan/HW-output-files/example.txt does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def pickle_to_text(pickle_file_path, text_file_path):\n",
        "    # 피클 파일 불러오기\n",
        "    with open(pickle_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 텍스트 파일로 저장하기\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        for sublist in data:\n",
        "            # 각 서브리스트를 반복하고 숫자를 문자열로 변환하여 저장\n",
        "            for number in sublist:\n",
        "                f.write(f\"{number} \")\n",
        "            f.write(\"\\n\\n\\n\")  # 각 서브리스트 끝에 줄바꿈 추가"
      ],
      "metadata": {
        "id": "OpUp0tFHhvQQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def tanh_new(x) :\n",
        "    result = (F.tanh(x) + 1) /2\n",
        "    return result"
      ],
      "metadata": {
        "id": "_c7Qzz8DhxOh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number(num):\n",
        "    \"\"\"숫자를 7비트 2의 보수 형식으로 인코딩하는 함수, 음수 소수 부분을 고려\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = abs(num - int_num)\n",
        "\n",
        "    # Round integer part towards zero if num is negative and has a fractional part\n",
        "    if num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num = int_num - 1  # Round integer part one more negative\n",
        "            frac_num = 1 - frac_num  # Subtract fractional part from 1 to make it positive\n",
        "\n",
        "    # Clamp the values to fit within the 7-bit range\n",
        "    if int_num < -64:\n",
        "        int_num = -64\n",
        "    elif int_num > 63:\n",
        "        int_num = 63\n",
        "\n",
        "    # Apply 2's complement if the number is negative\n",
        "    if int_num < 0:\n",
        "        int_num = (1 << 7) + int_num  # 1 << 7 is 128, representing the range of 7-bit integers\n",
        "\n",
        "    # Format the number into 7-bit binary\n",
        "    int_part_bin = format(int_num & 0b1111111, '07b')  # Only the last 7 bits are used\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = int_part_bin + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "4RMAodqch2WA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_input(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number(num) for num in numbers]"
      ],
      "metadata": {
        "id": "_sD86m8Zh5dr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools"
      ],
      "metadata": {
        "id": "6TPxkyv6h-nI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number_output(num):\n",
        "    \"\"\"숫자를 3비트 정수와 13비트 소수 형식으로 인코딩하는 함수, 값은 0부터 1 사이의 양수\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Clamp the values to fit within the 0 to 1 range\n",
        "    if num < 0:\n",
        "        num = 0\n",
        "    elif num > 1:\n",
        "        num = 1\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = num - int_num\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = '000' + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jYW_te9oh_oY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_output(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number_output(num) for num in numbers]"
      ],
      "metadata": {
        "id": "5a7CeXJmh_p6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.0301, 0.0112, 0.0040, 0.7632, 0.0040, 0.0072, 0.0068, 0.8885, 0.0117]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "FFeQcYAWiMA8",
        "outputId": "4a9eecf1-be85-4ce2-eebf-24ba23e57a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000_0000011110110', '000_0000001011011', '000_0000000100000', '000_1100001101100', '000_0000000100000', '000_0000000111010', '000_0000000110111', '000_1110001101110', '000_0000001011111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [-3.0061, -4.5561, -3.7781, -4.6988, -1.8251, -4.0483, -4.8075,  4.6085, -5.1693]\n",
        "encoded_numbers = encode_numbers_input(probs)\n",
        "print(encoded_numbers)\n",
        "\n",
        "probs = [0.0472, 0.0104, 0.0224, 0.0090, 0.1388, 0.0172, 0.0081, 0.9901, 0.0057]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "W-j1Du8UiEQp",
        "outputId": "5ba2d29f-010b-4dc7-a083-5b4aa76dac6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1111100_1111111001110', '1111011_0111000110100', '1111100_0011100011001', '1111011_0100110100011', '1111110_0010110011000', '1111011_1111001110100', '1111011_0011000101000', '0000100_1001101111000', '1111010_1101010010101']\n",
            "['000_0000110000010', '000_0000001010101', '000_0000010110111', '000_0000001001001', '000_0010001110001', '000_0000010001100', '000_0000001000010', '000_1111110101110', '000_0000000101110']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin, decimal_part_bin = encoded.split('.')\n",
        "\n",
        "    # Integer part processing\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # Negative number (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # Positive number\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # Fractional part processing\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # Adjust for negative numbers\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the function with provided values\n",
        "encoded_values = [\n",
        "    \"0000000.0101010000101\",\n",
        "    \"0000000.0010111100000\",\n",
        "    \"0000000.0010110110000\",\n",
        "    \"0000000.0010001111011\",\n",
        "    \"0000000.0010001101110\",\n",
        "    \"0000000.0001110010000\",\n",
        "    \"0000000.0001100000110\",\n",
        "    \"0000000.0000000000010\",\n",
        "    \"1111111.1101100010111\",\n",
        "    \"1111111.1101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "kzwvRVHhiM6-",
        "outputId": "87f403af-2f96-487f-d532-346fc79d999f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3287353515625,\n",
              " 0.18359375,\n",
              " 0.177734375,\n",
              " 0.1400146484375,\n",
              " 0.138427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " -0.1534423828125,\n",
              " -0.1597900390625]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    # 입력 문자열을 반으로 나누어 정수 부분과 소수 부분으로 분리\n",
        "    mid_index = len(encoded) // 2\n",
        "    int_part_bin = encoded[:mid_index]\n",
        "    decimal_part_bin = encoded[mid_index:]\n",
        "\n",
        "    # 정수 부분 처리\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"00000000101010000101\",\n",
        "    \"00000000010111100000\",\n",
        "    \"00000000010110110000\",\n",
        "    \"00000000010001111011\",\n",
        "    \"00000000010001101110\",\n",
        "    \"00000000001110010000\",\n",
        "    \"00000000001100000110\",\n",
        "    \"00000000000000000010\",\n",
        "    \"11111111101100010111\",\n",
        "    \"11111111101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "Fy0SQbOSiad-",
        "outputId": "58c9d2d5-64d7-40f1-8e26-e8b720de1731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0787353515625,\n",
              " 1.05859375,\n",
              " 1.052734375,\n",
              " 1.0150146484375,\n",
              " 1.013427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " 894.0965576171875,\n",
              " 894.0902099609375]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    if int(int_part_bin, 2) & (1 << 2):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 3)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0001000101001100\",\n",
        "    \"0000011001010100\",\n",
        "    \"0000000111011100\",\n",
        "    \"0000000111010100\",\n",
        "    \"0000000110110100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000011010100\",\n",
        "    \"0000000001100100\",\n",
        "    \"0000000001010100\",\n",
        "    \"0000000001000100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for encoded, decoded in zip(encoded_values, decoded_values):\n",
        "    print(f\"Encoded: {encoded} -> Decoded: {decoded}\")"
      ],
      "metadata": {
        "id": "i6y3VbyOiiIq",
        "outputId": "d18ed430-6ee4-45cf-de99-3c19ce9fc963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: 0001000101001100 -> Decoded: 0.54052734375\n",
            "Encoded: 0000011001010100 -> Decoded: 0.19775390625\n",
            "Encoded: 0000000111011100 -> Decoded: 0.05810546875\n",
            "Encoded: 0000000111010100 -> Decoded: 0.05712890625\n",
            "Encoded: 0000000110110100 -> Decoded: 0.05322265625\n",
            "Encoded: 0000000100000100 -> Decoded: 0.03173828125\n",
            "Encoded: 0000000011010100 -> Decoded: 0.02587890625\n",
            "Encoded: 0000000001100100 -> Decoded: 0.01220703125\n",
            "Encoded: 0000000001010100 -> Decoded: 0.01025390625\n",
            "Encoded: 0000000001000100 -> Decoded: 0.00830078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "\n",
        "    # 리스트를 문자열 형식으로 변환\n",
        "    formatted_hex_list = \"[\" + \", \".join(f'\"{hex_value}\"' for hex_value in hex_list) + \"]\"\n",
        "\n",
        "    return formatted_hex_list\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"06dc 05c4 0494 03c4 039c 02e4 017c 0144 00e4 00ac\"\n",
        "formatted_hex_list = format_hex_input(hex_input)\n",
        "\n",
        "print(formatted_hex_list)"
      ],
      "metadata": {
        "id": "KiL0Vi9sikfX",
        "outputId": "11a20eaa-1053-4fff-9e76-a57406a3d9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n",
        "\n",
        "float_values = hexa_to_float(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, float_value in zip(hex_strings, float_values):\n",
        "    print(f\"{float_value}\")"
      ],
      "metadata": {
        "id": "6FquW2OFiogU",
        "outputId": "64437692-6e83-421a-acc9-3845b358764f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21435546875\n",
            "0.18017578125\n",
            "0.14306640625\n",
            "0.11767578125\n",
            "0.11279296875\n",
            "0.09033203125\n",
            "0.04638671875\n",
            "0.03955078125\n",
            "0.02783203125\n",
            "0.02099609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "    return hex_list\n",
        "\n",
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "def convert_hex_input_to_float(hex_input):\n",
        "    hex_strings = format_hex_input(hex_input)\n",
        "    float_values = hexa_to_float(hex_strings)\n",
        "    return float_values\n",
        "\n",
        "def chunk_floats(float_values, chunk_size=10):\n",
        "    # float 값을 chunk_size 크기로 분할하고 각 chunk 사이에 두 개의 엔터를 추가\n",
        "    chunked_result = \"\"\n",
        "    for i in range(0, len(float_values), chunk_size):\n",
        "        chunk = float_values[i:i + chunk_size]\n",
        "        chunked_result += \"\\n\".join(map(str, chunk)) + \"\\n\\n\"\n",
        "    return chunked_result.strip()\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"\"\"\n",
        "1404\n",
        "026c\n",
        "0234\n",
        "0214\n",
        "0184\n",
        "017c\n",
        "015c\n",
        "001c\n",
        "001c\n",
        "0004\n",
        "\"\"\"\n",
        "\n",
        "float_values = convert_hex_input_to_float(hex_input)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "chunked_result = chunk_floats(float_values)\n",
        "\n",
        "print(chunked_result)"
      ],
      "metadata": {
        "id": "w7Z4vjWsiwnS",
        "outputId": "3c58dfca-79d2-4391-b371-dae1ce3a8e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62548828125\n",
            "0.07568359375\n",
            "0.06884765625\n",
            "0.06494140625\n",
            "0.04736328125\n",
            "0.04638671875\n",
            "0.04248046875\n",
            "0.00341796875\n",
            "0.00341796875\n",
            "0.00048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0000110101000100\",\n",
        "    \"0000100000100100\",\n",
        "    \"0000001101111100\",\n",
        "    \"0000001011111100\",\n",
        "    \"0000000111000100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000001110100\",\n",
        "    \"0000000001000100\",\n",
        "    \"0000000000111100\",\n",
        "    \"0000000000110100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for decoded in decoded_values:\n",
        "    print(decoded)\n"
      ],
      "metadata": {
        "id": "8BR8NGmgi0Ny",
        "outputId": "5007fe73-fb15-4b6d-8e01-8f0754f04ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41455078125\n",
            "0.25439453125\n",
            "0.10888671875\n",
            "0.09326171875\n",
            "0.05517578125\n",
            "0.03173828125\n",
            "0.01416015625\n",
            "0.00830078125\n",
            "0.00732421875\n",
            "0.00634765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "new_hex_strings = [\"0d44\", \"0824\", \"037c\", \"02fc\", \"01c4\", \"0104\", \"0074\", \"0044\", \"003c\", \"0034\"]\n",
        "new_binary_strings = hexa_to_binary(new_hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(new_hex_strings, new_binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "1W-StNJci3XU",
        "outputId": "a05245c4-c9b1-4bb6-f50d-33781a626908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000110101000100\n",
            "0000100000100100\n",
            "0000001101111100\n",
            "0000001011111100\n",
            "0000000111000100\n",
            "0000000100000100\n",
            "0000000001110100\n",
            "0000000001000100\n",
            "0000000000111100\n",
            "0000000000110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"069c\", \"046c\", \"045c\", \"0434\", \"02fc\", \"02a4\", \"026c\", \"01d4\", \"00e4\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")"
      ],
      "metadata": {
        "id": "xyNYFw6ki5gk",
        "outputId": "5e7147bc-284e-4384-faf7-0830c1eb0b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000011010011100\n",
            "0000010001101100\n",
            "0000010001011100\n",
            "0000010000110100\n",
            "0000001011111100\n",
            "0000001010100100\n",
            "0000001001101100\n",
            "0000000111010100\n",
            "0000000011100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "hex_strings = [\"045c\", \"0404\", \"03b4\", \"039c\", \"0374\", \"034c\", \"031c\", \"027c\", \"022c\", \"01bc\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "LCmwYD9Qi79m",
        "outputId": "2e98ba7e-cba3-4bd9-a7bc-55602c0d475e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000010001011100\n",
            "0000010000000100\n",
            "0000001110110100\n",
            "0000001110011100\n",
            "0000001101110100\n",
            "0000001101001100\n",
            "0000001100011100\n",
            "0000001001111100\n",
            "0000001000101100\n",
            "0000000110111100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error_rates(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    list of float: 각 데이터에 대한 오차율 (백분율) 리스트\n",
        "    \"\"\"\n",
        "    if len(actual_values) != len(predicted_values):\n",
        "        raise ValueError(\"실제 값 리스트와 예측 값 리스트의 길이는 같아야 합니다.\")\n",
        "\n",
        "    error_rates = []\n",
        "    for actual, predicted in zip(actual_values, predicted_values):\n",
        "        if actual == 0:\n",
        "            error_rate = 0\n",
        "        else:\n",
        "            error = actual - predicted\n",
        "            error_rate = abs((error / actual) * 100)\n",
        "        error_rates.append(error_rate)\n",
        "\n",
        "    return error_rates\n",
        "\n",
        "def calculate_average_error_rate(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 평균 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    float: 평균 오차율 (백분율)\n",
        "    \"\"\"\n",
        "    error_rates = calculate_error_rates(actual_values, predicted_values)\n",
        "    average_error_rate = sum(error_rates) / len(error_rates)\n",
        "    return average_error_rate"
      ],
      "metadata": {
        "id": "D2-wjc8yi_Ij"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용\n",
        "actual_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "predicted_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "average_error_rate = calculate_average_error_rate(actual_values, predicted_values)\n",
        "\n",
        "print(f\"최종 오차율: {average_error_rate}%\")"
      ],
      "metadata": {
        "id": "clf_RoSfjBeq",
        "outputId": "a64c4b96-f498-4d5e-dba9-b4ef00611485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 오차율: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정\n",
        "start_time = time.time()\n",
        "softmax_values = softmax(values)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Softmax output: {softmax_values}\")\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "i7BTwvyNjE92",
        "outputId": "34aa7c73-366c-430c-c8cf-847d61cf3ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output: [0.07587164 0.0910116  0.07831849 0.06958124 0.12896939 0.12623521\n",
            " 0.12722802 0.1129899  0.10400488 0.08578965]\n",
            "Execution time: 0.0046842098236083984 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정 (timeit 모듈 사용)\n",
        "execution_time = timeit.timeit(lambda: softmax(values), number=100000)\n",
        "print(f\"Average execution time over 1000 runs: {execution_time / 100000} seconds\")\n"
      ],
      "metadata": {
        "id": "I7TbeCl0jFAe",
        "outputId": "d1c34d21-a55f-4579-bad9-144d183991ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time over 1000 runs: 8.994136329999946e-06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "start_time = time.time()\n",
        "my_function()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "_Y3J9uF8jFCp",
        "outputId": "d16b08d5-bee5-4ddb-866b-a78fc3168b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0002713203430176 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "execution_time = timeit.timeit(my_function, number=1)\n",
        "print(f\"Execution time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "id": "9a5zh7itjK_1",
        "outputId": "2ec4da21-f3b1-493d-e78f-5c5ee500a4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001646370000117 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "id": "XarrC_jbjPME",
        "outputId": "82c3ebea-96f1-4ac0-dab5-960e78901f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001087188720703 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import socket\n",
        "\n",
        "# HW -> SW connect\n",
        "# This should be fixed later when connecting with hardware.\n",
        "def receive_from_hardware(host: str, port: int, buffer_size: int = 1024) -> bytes:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.connect((host, port))\n",
        "        attention_probs_hw = s.recv(buffer_size)\n",
        "    return attention_probs_hw\n",
        "\n",
        "# HW 2진수 -> SW Decode\n",
        "def decode_values(encoded_values_list: list) -> list:\n",
        "    encoded_values = tuple(encoded_values_list)\n",
        "    decoded_values = []\n",
        "\n",
        "    for encoded_value in encoded_values:\n",
        "        special_value_bit = encoded_value[0]\n",
        "        if special_value_bit == '1':\n",
        "            decoded_values.append(0.0)\n",
        "        else:\n",
        "            sign_bit = encoded_value[1]\n",
        "            sign = -1 if sign_bit == '1' else 1\n",
        "\n",
        "            integer_part = int(encoded_value[2:5], 2)\n",
        "            fractional_part = int(encoded_value[5:], 2) / (1 << 13)\n",
        "\n",
        "            decoded_value = sign * (integer_part + fractional_part)\n",
        "            decoded_values.append(round(decoded_value, 7))\n",
        "\n",
        "    return decoded_values\n",
        "\n",
        "# 1D -> 4D 변환 코드\n",
        "def convert_to_4d(input_list):\n",
        "    # Step 1: Divide the list into sublists of 10 elements each\n",
        "    sublists = [input_list[i:i + 10] for i in range(0, len(input_list), 10)]\n",
        "\n",
        "    # Step 2: Group every 10 sublists into a larger list to form a [12, 10, 10] shape\n",
        "    grouped_sublists = [sublists[i:i + 10] for i in range(0, len(sublists), 10)]\n",
        "\n",
        "    # Step 3: Convert the final list to a tensor and add an extra dimension to form [1, 12, 10, 10]\n",
        "    attention_probs_4d = torch.tensor(grouped_sublists).unsqueeze(0)\n",
        "    return attention_probs_4d"
      ],
      "metadata": {
        "id": "vh30Ck9JjWVj"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_raw_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "GEln6Bi7whyh",
        "outputId": "bb945a28-f5cc-44a6-eb12-552898c49c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/softmax_bert_layer1.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_softmax_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "YgDd7AmYGVMO",
        "outputId": "26c7570d-67c1-45bb-bc49-cee2211d6bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/softmax_bert_layer1.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "05VQ55mWooaT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import math\n",
        "attention_scores = layer_1_attention\n",
        "attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        " #Pickle 파일 저장\n",
        "if attention_mask is not None:\n",
        " # Apply the attention mask is (precomputed for all layers in BertModel\n",
        " attention_scores = attention_scores + attention_mask\n",
        " # attention_scores를 피클 파일로 저장합니다.\n",
        "attention_scores_list = attention_scores.tolist()  # torch.Tensor를 Python 리스트로 변환\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"wb\") as f:\n",
        " pickle.dump(attention_scores_list, f)\n",
        " #저장된 Pickle 파일 불러와서 plot\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        " outputs = pickle.load(f)\n",
        "out_chain3 = list(itertools.chain(*outputs))\n",
        "out_chain2 = list(itertools.chain(*out_chain3))\n",
        "out_chain1 = list(itertools.chain(*out_chain2))\n",
        "print(out_chain1)\n",
        "max_value = torch.max(attention_scores)\n",
        "min_value = torch.min(attention_scores)\n",
        "print(\"Max value in attention_scores:\", max_value.item())"
      ],
      "metadata": {
        "id": "YAV18-7XnknO",
        "outputId": "6677399f-036a-4de7-ea6f-d211165a955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b97d7302ca28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;31m#Pickle 파일 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "if2KlEtgI6bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#아무래도 진짜..코드 위에선  outputs.last_hidden_state 로 써서 12번째 레이어의 값으로 KQV 계산했을 수 있다.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        # BERT 모델의 기본 동작 수행\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # 어텐션 값 반환 활성화\n",
        "            output_hidden_states=True,  # 히든 스테이트 반환 활성화\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # 모델 설정값 가져오기\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 멀티헤드 개수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기 (64)\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        # === 첫 번째 Transformer 레이어에서 Query (Q), Key (K) 직접 가져오기 ===\n",
        "        first_layer = self.encoder.layer[0]  # 첫 번째 Transformer 레이어\n",
        "        input_tensor = outputs.hidden_states[0]  # 첫 번째 레이어 입력 (Embedding 후 결과)\n",
        "\n",
        "        # Query, Key 생성\n",
        "        Q = first_layer.attention.self.query(input_tensor)  # (1, 10, 768)\n",
        "        K = first_layer.attention.self.key(input_tensor)  # (1, 10, 768)\n",
        "\n",
        "        # === Multi-Head 형태로 변환 ===\n",
        "        # Query, Key의 shape을 (batch_size, num_heads, sequence_length, head_dim)로 변환\n",
        "        Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "        K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 계산 ===\n",
        "        raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # (1, 12, 10, 10)\n",
        "\n",
        "        return raw_attention, outputs.attentions[0]  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === 첫 번째 레이어의 Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "_beDp4MY8Ib_",
        "outputId": "8ee17bfc-a22d-4111-bb48-935ea4541144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder\n",
        "\n",
        "# === Softmax 이전 Attention Score 추출을 위한 BertSelfAttention 수정 ===\n",
        "class BertSelfAttentionWithRawScores(BertSelfAttention):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.raw_attention_scores = None  # Softmax 이전 Attention Score 저장\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        # === Query, Key, Value 생성 ===\n",
        "        mixed_query_layer = self.query(hidden_states)  # (batch, seq_len, hidden_dim)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        # === Multi-Head Attention 변환 ===\n",
        "        batch_size, seq_length, hidden_dim = hidden_states.shape\n",
        "        num_heads = self.num_attention_heads\n",
        "        head_dim = self.attention_head_size  # hidden_dim // num_heads (768/12=64)\n",
        "\n",
        "        assert hidden_dim == num_heads * head_dim  # 차원 검증\n",
        "\n",
        "        # Query, Key, Value를 (batch, num_heads, seq_len, head_dim) 형태로 변환\n",
        "        query_layer = mixed_query_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        key_layer = mixed_key_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        value_layer = mixed_value_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 저장 ===\n",
        "        self.raw_attention_scores = torch.matmul(query_layer, key_layer.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "\n",
        "        # === Softmax 적용 ===\n",
        "        attention_probs = nn.functional.softmax(self.raw_attention_scores, dim=-1)\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.transpose(1, 2).contiguous()\n",
        "        context_layer = context_layer.view(batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Softmax 이전과 이후 값 반환 (BERT 내부 연산 유지)\n",
        "        if output_attentions:\n",
        "            return context_layer, attention_probs, self.raw_attention_scores  # Softmax 이후 값, Softmax 이전 값\n",
        "        return context_layer, attention_probs\n",
        "\n",
        "# === BERT Encoder에서 Custom BertSelfAttention 적용 ===\n",
        "class BertEncoderWithRawAttention(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # 기존 BERT의 레이어를 유지하면서, BertSelfAttention을 수정한 레이어로 교체\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionWithRawScores(config)\n",
        "\n",
        "# === 새로운 BERT 모델 정의 ===\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.encoder = BertEncoderWithRawAttention(config)  # 수정된 Encoder 적용\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, inputs_embeds=None,\n",
        "                output_attentions=True, output_hidden_states=True, return_dict=True):\n",
        "\n",
        "        # BERT의 기본 forward 호출\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        softmax_attention = outputs.attentions[0]\n",
        "\n",
        "        # === Softmax 이전 Attention Score ===\n",
        "        raw_attention = self.encoder.layer[0].attention.self.raw_attention_scores\n",
        "\n",
        "        return raw_attention, softmax_attention\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name)  # 모델 설정값 로드\n",
        "model = BertWithRawAttention.from_pretrained(model_name, config=config)  # 기존 가중치 로드\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Softmax 이전 Attention Score (Shape: {raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n",
        "\n",
        "# === Softmax 이후 Attention Score 확인 ===\n",
        "layer_1_softmax_attention = softmax_attention.numpy()\n",
        "print(f\"Softmax 이후 Attention Score (Shape: {softmax_attention.shape}):\")\n",
        "print(layer_1_softmax_attention)\n"
      ],
      "metadata": {
        "id": "PtMgJMl6-cXT",
        "outputId": "957f6a04-62ac-45d9-c3f7-f5a3f87bc920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 이전 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n",
            "Softmax 이후 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[0.5283773  0.01831239 0.02925736 ... 0.02679347 0.12802093\n",
            "    0.06640536]\n",
            "   [0.00969707 0.05183908 0.5986064  ... 0.01988765 0.00858417\n",
            "    0.01232217]\n",
            "   [0.06677455 0.2186561  0.10905681 ... 0.01309194 0.03270088\n",
            "    0.01159014]\n",
            "   ...\n",
            "   [0.01616001 0.01836555 0.02567743 ... 0.06062973 0.15665187\n",
            "    0.293395  ]\n",
            "   [0.04999034 0.00646467 0.01949128 ... 0.14370786 0.06240886\n",
            "    0.5748314 ]\n",
            "   [0.06373078 0.01488702 0.0079303  ... 0.05741416 0.49397027\n",
            "    0.11359414]]\n",
            "\n",
            "  [[0.03568741 0.10874645 0.1446925  ... 0.06689178 0.05368272\n",
            "    0.2776181 ]\n",
            "   [0.01723383 0.05519805 0.20440505 ... 0.0471074  0.04940367\n",
            "    0.2604174 ]\n",
            "   [0.07099048 0.07730429 0.05898389 ... 0.10322649 0.02939613\n",
            "    0.3372574 ]\n",
            "   ...\n",
            "   [0.06292941 0.09883609 0.13758078 ... 0.06442455 0.05104246\n",
            "    0.24415724]\n",
            "   [0.03459279 0.11384704 0.10506249 ... 0.18009992 0.06478832\n",
            "    0.1407789 ]\n",
            "   [0.05027521 0.06445801 0.14809294 ... 0.08305917 0.05797384\n",
            "    0.2091557 ]]\n",
            "\n",
            "  [[0.15359114 0.00864228 0.00399939 ... 0.00729464 0.50648683\n",
            "    0.0942614 ]\n",
            "   [0.01585225 0.17893858 0.43792823 ... 0.0741822  0.00801447\n",
            "    0.0235921 ]\n",
            "   [0.03428007 0.17485864 0.2603332  ... 0.08475611 0.03304965\n",
            "    0.07450179]\n",
            "   ...\n",
            "   [0.18211858 0.05096522 0.09105611 ... 0.1072194  0.05965689\n",
            "    0.17483066]\n",
            "   [0.44636625 0.01801714 0.0315361  ... 0.02307989 0.10599701\n",
            "    0.13254708]\n",
            "   [0.2774437  0.0129694  0.00816243 ... 0.01372248 0.35479093\n",
            "    0.10288175]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.04930858 0.10154388 0.10185789 ... 0.09569554 0.05750762\n",
            "    0.3224567 ]\n",
            "   [0.08078458 0.20571339 0.11838616 ... 0.12593833 0.06177064\n",
            "    0.19960773]\n",
            "   [0.0412325  0.19937783 0.13601877 ... 0.08533785 0.09154727\n",
            "    0.2100422 ]\n",
            "   ...\n",
            "   [0.02443384 0.08015428 0.12018657 ... 0.23940288 0.14780325\n",
            "    0.14295706]\n",
            "   [0.04283044 0.12574883 0.14365427 ... 0.1160476  0.12224771\n",
            "    0.22464608]\n",
            "   [0.05391058 0.14782219 0.14016856 ... 0.11944017 0.10129216\n",
            "    0.17417422]]\n",
            "\n",
            "  [[0.7349549  0.0276535  0.02545838 ... 0.01123482 0.02285883\n",
            "    0.04455587]\n",
            "   [0.0558468  0.08621079 0.15432207 ... 0.12961587 0.02641504\n",
            "    0.15628102]\n",
            "   [0.11732682 0.11279433 0.12912983 ... 0.03815653 0.03798619\n",
            "    0.18773969]\n",
            "   ...\n",
            "   [0.02055062 0.1586586  0.10597336 ... 0.12433876 0.02345941\n",
            "    0.29404283]\n",
            "   [0.24240194 0.06169973 0.05989478 ... 0.1300937  0.02040222\n",
            "    0.04765695]\n",
            "   [0.40604973 0.03981538 0.02912593 ... 0.06234814 0.03718225\n",
            "    0.04973197]]\n",
            "\n",
            "  [[0.20841888 0.04493827 0.04335542 ... 0.02939372 0.04667228\n",
            "    0.4896042 ]\n",
            "   [0.17757389 0.65346533 0.00581406 ... 0.00351891 0.02235911\n",
            "    0.10371897]\n",
            "   [0.43387496 0.00921498 0.24637778 ... 0.01080181 0.10714414\n",
            "    0.08725781]\n",
            "   ...\n",
            "   [0.13022482 0.01199692 0.0195627  ... 0.6826026  0.04258374\n",
            "    0.03826763]\n",
            "   [0.42847222 0.1096639  0.05017955 ... 0.01391817 0.02019598\n",
            "    0.18610723]\n",
            "   [0.5374471  0.04228677 0.03523285 ... 0.02958855 0.03256983\n",
            "    0.19304997]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './model/attention_scores_2.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "Q0nZ4Onl21iB",
        "outputId": "71229106-fba1-4c96-bac1-f0616740206b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    0.11714409  0.5856975   0.6307755  -0.30920362  2.1947367\n",
            "  -0.14835791  0.49772462  2.0617602   1.4053444 ]\n",
            " [ 1.6703308   3.3466518   5.793112    4.621073    3.812749    2.3419719\n",
            "   1.8878778   2.3886065   1.5484276   1.9099072 ]\n",
            " [ 3.3168168   4.502995    3.8073637   5.2124023   2.3082643   3.0351076\n",
            "   2.4797425   1.6874914   2.6028967   1.5656495 ]\n",
            " [ 2.5718498   4.652975    6.7969666   3.8015726   5.3321524   2.659658\n",
            "   2.719986    2.416732    2.1785326   3.108758  ]\n",
            " [ 0.62522817  4.6419153   3.3077164   5.064213    3.339889    2.7762215\n",
            "   1.873533    3.4980125   2.023627    2.5917144 ]\n",
            " [ 3.9795005   2.6142015   2.2757936   2.9215946   3.511932    3.220555\n",
            "   3.0432897   2.8711824   4.3125715   4.3036885 ]\n",
            " [ 1.7959094   2.6852992   1.6750463   1.3191165   4.1721644   3.331105\n",
            "   2.4741642   4.5505824   2.6400094   3.1753776 ]\n",
            " [ 1.6387088   1.7666457   2.1017816   2.1071794   3.422982    3.3852067\n",
            "   4.2240024   2.9609547   3.9101954   4.537689  ]\n",
            " [ 3.3072975   1.2618201   2.365435    1.1282016   2.2333503   2.9970148\n",
            "   3.822887    4.3632503   3.529175    5.7495446 ]\n",
            " [ 4.5703983   3.1162205   2.4864216   3.426703    2.1799157   5.7463045\n",
            "   3.174025    4.4660215   6.618206    5.1483626 ]] [[-1.0886638e+00  2.5557250e-02  3.1114900e-01 -1.1854680e-01\n",
            "  -7.7044167e-02 -1.6976843e+00 -4.8572365e-02 -4.6038562e-01\n",
            "  -6.8037063e-01  9.6278471e-01]\n",
            " [-1.7430696e+00 -5.7901633e-01  7.3015982e-01  4.3518707e-01\n",
            "   6.1179582e-02 -1.1784676e+00 -2.2009215e-01 -7.3751372e-01\n",
            "  -6.8991911e-01  9.7234195e-01]\n",
            " [-4.3296996e-01 -3.4776625e-01 -6.1825126e-01 -5.5659747e-01\n",
            "  -2.0672473e-01 -1.1309534e+00  2.1543759e-01 -5.8590204e-02\n",
            "  -1.3146526e+00  1.1253307e+00]\n",
            " [-5.9080738e-01 -2.5380707e-01  2.4927259e-04  1.6821440e-02\n",
            "   4.5576128e-01 -2.5012723e-01  3.6733337e-02  1.4773999e-01\n",
            "  -3.3541751e-01  1.2667636e+00]\n",
            " [-1.7260594e+00 -3.7022546e-02  3.2314226e-01  9.6709438e-02\n",
            "  -2.5472367e-01 -1.5367095e+00  7.0705187e-01  6.5236461e-01\n",
            "  -1.2064693e+00  5.9022087e-01]\n",
            " [-1.2091219e+00  1.5285142e-01  3.8227442e-01  2.8489169e-01\n",
            "   3.7704596e-01 -8.5179329e-01  1.8399542e-02  4.3778053e-01\n",
            "  -4.9263728e-01  7.9981643e-01]\n",
            " [-2.8917280e-01  1.0043441e-01 -9.1151148e-02  3.6259271e-02\n",
            "   1.0675713e-01 -8.3618826e-01  2.0009780e-01  5.8339089e-01\n",
            "  -1.7491554e-01  6.0655284e-01]\n",
            " [-3.5978922e-01  9.1659956e-02  4.2240837e-01  1.1255670e-01\n",
            "  -6.4642429e-02 -1.3896195e+00  3.8931042e-01 -3.3630806e-01\n",
            "  -5.6914496e-01  9.9600965e-01]\n",
            " [-9.6181583e-01  2.2939461e-01  1.4909410e-01  1.6794282e-01\n",
            "   1.7030033e-01 -5.3991210e-01  3.4695931e-02  6.8805063e-01\n",
            "  -3.3433583e-01  4.4172931e-01]\n",
            " [-6.0645354e-01 -3.5795161e-01  4.7387433e-01  2.7014586e-01\n",
            "   2.5771543e-01 -9.0960979e-01  1.7429377e-01 -1.0441241e-01\n",
            "  -4.6397370e-01  8.1911325e-01]] [[ 2.8996303   0.02200214 -0.74852276  0.631462   -1.1275623   3.0894957\n",
            "   0.9280114  -0.14752409  4.0928345   2.411408  ]\n",
            " [ 0.5878507   3.011582    3.9065943   3.235908    0.50435984  0.34831482\n",
            "   0.17555894  2.1310635  -0.09421223  0.98545116]\n",
            " [ 0.6049058   2.2343197   2.6323042   2.430443    0.4869851   0.8571075\n",
            "   1.0000788   1.5101197   0.56835276  1.3811649 ]\n",
            " [ 1.430701    2.0099015   4.087019    3.0947237   0.56819826  0.75650877\n",
            "   0.33274144  1.465734   -0.30525357  0.9727164 ]\n",
            " [-0.3164355   1.5521222   3.0174787   1.4834703   2.2269187  -1.30088\n",
            "   1.1328936   3.5774622  -1.429762   -0.17385992]\n",
            " [ 3.4188118   0.62846535  0.07279523  0.71736014 -0.32747287  2.2898376\n",
            "   1.0576711   0.22138332  3.0749917   2.4532826 ]\n",
            " [ 1.9065028   0.88415587  1.2080953   0.14300826  0.593324    0.49050444\n",
            "   0.5708541   1.5033801   0.42657304  0.6549574 ]\n",
            " [ 2.1231966   0.84968215  1.4300145   1.3541062   1.0749373   1.852924\n",
            "   0.76707125  1.5934157   1.0071483   2.0823565 ]\n",
            " [ 3.2195091   0.0096926   0.56950235  0.23191671 -0.32239503  2.1220663\n",
            "   1.1799686   0.2573312   1.7817802   2.0053072 ]\n",
            " [ 3.912785    0.8497595   0.3867088   0.8289084   0.23973835  3.5320184\n",
            "   1.3169683   0.9062026   4.1586957   2.9207473 ]] [[-0.91819704 -0.73714244 -1.2835796  -1.3152801  -1.7907189  -2.3600693\n",
            "  -1.71575    -2.0585341  -0.88458973 -1.0391645 ]\n",
            " [ 0.76816994  2.8525796   0.98103195  1.0893993   1.291576   -0.3590138\n",
            "  -0.05392636  1.1377413  -1.1812421   0.5328254 ]\n",
            " [ 0.44077566  1.889281    1.394224    1.2403969   0.93400806 -0.6091448\n",
            "   0.37211862  1.1208864  -0.48069543  0.9152784 ]\n",
            " [-0.4079485   1.9117765   0.61145085  1.4986356   1.2874416  -0.2541298\n",
            "   0.17829615  0.8347929  -0.5898164   1.7898803 ]\n",
            " [ 0.5058691   1.6893194   0.8303908   0.35562584  1.9394354  -0.32631215\n",
            "  -0.15927449  1.2605628  -1.4803319   0.92400664]\n",
            " [ 0.47246826  1.049527    0.68996495  0.5756347   0.2827701   1.6729834\n",
            "   1.2482777   1.4437281   1.0102694   0.7912869 ]\n",
            " [ 1.2386009   1.133507    0.64457095  0.43742573  1.0146374  -0.527435\n",
            "   1.1386023   1.2811688  -0.267912   -0.3252511 ]\n",
            " [-0.6168757   0.9414549   0.6545312   0.44207764  1.0313237   0.28013933\n",
            "   0.6557309   1.4528047   0.10742482  2.0227776 ]\n",
            " [ 0.6610696   1.1441543   0.83005744  0.6699963   0.68824714  0.8841506\n",
            "   1.2305831   1.0789971   0.96978915  0.1847023 ]\n",
            " [ 0.48081017  0.5815153   0.65710616  0.34215644 -0.4203801  -1.0223608\n",
            "  -0.1397903   0.8336154   0.45186663 -0.02691434]] [[-0.4206367  -0.26431718 -0.8189321   0.5453431  -0.81877565  3.265758\n",
            "   1.123025   -0.45972508  3.0087957   4.069817  ]\n",
            " [ 1.711552    4.0104914   6.097168    4.062114    3.3517642   0.6797678\n",
            "   2.4742503   2.5503993   1.0404894   2.6415534 ]\n",
            " [ 1.6555488   2.8842583   3.6345613   2.4311733   2.4532597   1.8469099\n",
            "   1.1871887   2.1401596   2.593385    2.5239465 ]\n",
            " [ 2.897587    4.3002462   6.664719    2.8146844   4.007442    0.92588633\n",
            "   0.9355154   1.9416659   1.1508867   2.0899508 ]\n",
            " [ 1.4384526   4.5608745   3.7128031   3.3055158   2.5344577   0.3143406\n",
            "   2.7502472   3.773708    1.4212635   1.7340083 ]\n",
            " [-1.8715912   2.1050293   2.2834506   2.1121552   1.4853789   2.427682\n",
            "   3.0749145   1.8919368   3.9486756   4.785963  ]\n",
            " [ 0.63691103  1.810391    0.84790796  1.1583683   2.2992978   1.9338874\n",
            "   2.1868212   3.2546113   2.360936    3.5164182 ]\n",
            " [ 0.39985502  1.6061538   1.7325523   0.35841948  2.477663    1.037012\n",
            "   2.7054691   2.465773    1.360221    2.7568579 ]\n",
            " [-1.5197104   0.47858107  1.2087647   0.85278237  1.0399474   2.266237\n",
            "   3.0739172   2.0501065   2.4958704   4.687452  ]\n",
            " [ 3.000189   -0.7293791  -0.74419117  1.7917078   0.4763999   2.9361863\n",
            "   2.2864735   2.0922556   2.3336442   3.609223  ]] [[ 2.3518488  -2.4012413  -2.5848315  -2.5842254  -1.4390004  -1.3970611\n",
            "  -1.486853   -1.3146498  -1.5213429  -0.10409442]\n",
            " [-0.08029907  0.95492965  3.0861502   1.0803758   2.8016753   1.3075106\n",
            "   2.5004106   3.4115536   1.5283737   2.4000955 ]\n",
            " [-0.98470867  1.4555954   1.5423824   0.30919918  3.159526    1.3234267\n",
            "   2.0309644   3.8802829   0.77620506  2.2096994 ]\n",
            " [-1.3650285   1.9985721   3.1277943   0.9758086   3.153818    2.5558827\n",
            "   2.7993655   3.6075718   2.483896    3.5096714 ]\n",
            " [-0.53188324  2.7865634   2.933026    1.9947041   2.6538177   0.17108425\n",
            "   1.41041     3.5341537   0.09414454  2.1139412 ]\n",
            " [-0.05147918  2.960376    2.8401773   2.9880128   2.2146826   3.026591\n",
            "   2.6003537   2.4387147   3.1415412   3.8921413 ]\n",
            " [-0.9958864   2.6857972   2.583294    2.6029804   2.5345263   1.2893649\n",
            "   1.4581535   2.6380162   2.0204773   2.2150342 ]\n",
            " [ 0.04527869  2.9330308   3.2778075   2.720913    3.2038531   1.2107869\n",
            "   1.9810863   2.4970698   1.1165935   1.571423  ]\n",
            " [-0.23130603  2.2237506   2.6563025   2.6123178   2.1577914   2.2081223\n",
            "   2.521809    2.3261166   1.9723585   2.7725258 ]\n",
            " [ 0.2493442   3.188392    3.1076705   3.369534    2.6593766   3.4948716\n",
            "   2.873453    2.958899    3.7007978   5.390417  ]] [[ 1.8577769  -0.1782641  -0.8391258  -0.20157872  0.03677352  1.8336577\n",
            "  -0.5154236  -0.9360012  -0.36019903  2.0303364 ]\n",
            " [ 0.07594603  1.6416981   2.4703162   1.7014173   1.7434708   0.00997017\n",
            "   1.3008279   1.896263    1.5449183   1.616728  ]\n",
            " [ 0.6953787   2.1692429   2.1441464   1.7379965   2.1794832   0.00943146\n",
            "   1.3819319   2.406196    1.5149322   1.8323896 ]\n",
            " [ 1.5004507   2.191609    2.7665334   0.9322765   2.0782743  -0.32668146\n",
            "   1.5269834   2.6152775   1.2686868   2.566569  ]\n",
            " [-0.5223735   2.492464    1.484075    1.3629732   1.5521193  -0.75108665\n",
            "   1.1117117   2.8975577   1.2339579   0.7913337 ]\n",
            " [ 4.608461    2.6140327   1.6747181   1.5631702   1.1256423   2.156302\n",
            "   1.8067638   1.0583446   1.9421829   4.2106786 ]\n",
            " [ 2.443831    2.08211     1.7901441   1.5581807   2.1890495   1.9666604\n",
            "   1.4040198   2.1084352   1.0204064   2.4160697 ]\n",
            " [ 1.6170082   2.1157253   1.7847257   1.1339206   2.4702833   1.1112541\n",
            "   1.9466188   2.2814734   1.4104946   2.5419347 ]\n",
            " [ 2.5761323   1.8463246   1.4472572   1.2411208   1.1666892   1.2266266\n",
            "   2.137839    1.720331    1.3243217   2.4792182 ]\n",
            " [ 5.4560094   2.8533223   1.9060035   2.8041744   2.1872957   4.541738\n",
            "   2.3418133   2.6403146   3.3154905   5.353278  ]] [[-2.0872909e-01 -4.6765838e-02 -6.9208078e-02  2.2612049e-01\n",
            "  -5.2733558e-01 -3.8780876e-02 -3.5037673e-01 -2.4101785e-01\n",
            "  -3.8009610e-02 -4.4777170e-01]\n",
            " [ 3.9312774e-01 -7.2015625e-01 -1.1039566e-01 -4.7187504e-01\n",
            "  -6.2436187e-01 -5.5506319e-01 -6.3059740e-02  2.3725607e-01\n",
            "  -2.9921988e-01  6.7517275e-01]\n",
            " [ 9.3361211e-01 -3.0668795e-01 -1.2280265e+00 -2.3901877e-01\n",
            "   2.1531588e-01 -2.9213035e-02  1.8740971e-01  4.9287453e-01\n",
            "  -3.2362545e-01  5.3950977e-01]\n",
            " [ 4.4989973e-01 -7.8404926e-02 -7.0561624e-01 -6.7971748e-01\n",
            "  -3.2464612e-01 -2.4579277e-03  2.4341476e-01 -3.8152987e-01\n",
            "  -6.1979812e-01  6.9756246e-01]\n",
            " [ 7.5051486e-02 -3.4050646e-01 -2.0628366e-01 -3.5078533e-02\n",
            "  -2.1298897e+00 -4.6191064e-01  1.0249646e-01 -2.3292464e-01\n",
            "  -4.4878232e-01 -4.8854653e-02]\n",
            " [ 2.4236611e-01  2.4130446e-01 -1.3099633e-01  2.9947233e-01\n",
            "   2.8432137e-03  1.8978542e-01  3.0245671e-01  2.6455259e-02\n",
            "   3.2729067e-02  9.6456997e-02]\n",
            " [ 5.2392596e-01 -4.3888092e-01  6.0626990e-01 -1.6046394e-01\n",
            "  -4.5984539e-01 -4.0288302e-01 -3.4419575e-01 -3.1425059e-01\n",
            "  -3.3222637e-03 -1.9334584e-01]\n",
            " [-5.6612873e-01 -1.8855400e-01 -2.9994866e-02 -1.3156276e+00\n",
            "  -3.9713255e-01 -1.6519366e-01 -3.1032342e-01 -2.6127520e+00\n",
            "  -6.0051662e-01  4.2017855e-02]\n",
            " [ 2.3271590e-01  3.4710231e-01 -3.8753740e-02  6.4791903e-02\n",
            "  -1.9065240e-01  1.3848405e-01  6.7246199e-02 -8.6773224e-02\n",
            "   1.5828940e-01 -9.3004052e-03]\n",
            " [ 2.2022840e-01 -1.5427314e-01 -8.9312159e-02 -3.9955951e-02\n",
            "   1.0446525e-03 -2.8469656e-02 -6.6449180e-02 -6.2308647e-02\n",
            "   5.5042960e-02 -2.5045082e-01]] [[ 0.7274816   0.11507649  0.284214   -0.4026169  -0.22948742  0.5726925\n",
            "   0.7000268   0.13661313  2.2500303   2.2188106 ]\n",
            " [ 1.4019722   3.4689038   2.3157012   2.951157    1.1965826   1.1602786\n",
            "  -0.1770497   0.6572411   0.2278574   1.8796558 ]\n",
            " [ 1.2921461   0.8905095   3.709777    2.3455753   1.0153087   1.4283334\n",
            "   0.5606777   0.47134808  1.6395503   1.9080584 ]\n",
            " [ 1.8637079   3.003888    3.8354084   4.1362057   1.2275932   2.323182\n",
            "  -0.19235559  1.0532311   1.3310231   2.590262  ]\n",
            " [ 0.54005456  0.6143206   1.7547503   1.8359743   3.094353    0.6746429\n",
            "   0.2596902   1.5248697   0.47067168  1.3008693 ]\n",
            " [-0.9338605   0.5036669   0.87460697  0.45084783  0.901352   -0.10966269\n",
            "   1.9916923   1.3448064   2.0936713   0.80160993]\n",
            " [ 0.5728401  -0.04004947  0.45082232 -0.43184328  0.9820602   0.0408671\n",
            "   1.4810711   0.40630463  0.07374337  0.5373771 ]\n",
            " [ 2.0956993   0.6018912   0.6745899   0.5275235   1.8832694   0.7081071\n",
            "   1.0816227   3.1449246   0.19390348  2.3962045 ]\n",
            " [-0.3780636   0.18745206  1.7450609   0.46006605  0.8310921   0.57361317\n",
            "   2.0125527   1.6686664   1.5488706   1.1293051 ]\n",
            " [ 0.6197194   0.2847378   0.8111273   0.29930606  0.12218147  0.633571\n",
            "   1.7020148   1.1978279   2.0720472   1.3618188 ]] [[-0.7641907  -0.04179777 -0.03871024 -0.01029287  0.10982683 -3.409261\n",
            "  -0.8519444  -0.1011171  -0.61037153  1.11368   ]\n",
            " [ 0.6315195   1.5662173   1.0136852   0.79115003  0.5027024  -0.84586865\n",
            "  -0.60011023  1.0755258   0.36316153  1.5360875 ]\n",
            " [-0.19636366  1.3796113   0.9972024   0.42479315  0.7522633  -1.2828168\n",
            "  -0.24372143  0.53102773  0.60126495  1.431718  ]\n",
            " [-0.01733678  1.2261399   0.60732824 -0.3713482   1.0066447  -1.0930486\n",
            "  -0.34242573  1.2536769  -0.01925345  0.05428234]\n",
            " [-0.6089171   0.812452    0.73339826  0.27320436  1.0981218  -0.69458455\n",
            "   0.300511    1.9441388  -0.5859628   1.1883222 ]\n",
            " [-0.3862846   0.9120517   0.6206465   0.7143033   0.49330038 -1.0343239\n",
            "  -0.31964967  0.45504218  0.87512237  1.6519731 ]\n",
            " [-0.11572167  1.118077    1.1451776   0.45498532  0.7921902  -0.8244491\n",
            "   0.13255627  1.3740886   1.5412023   1.585442  ]\n",
            " [-0.42347932  0.7645048   1.1695968   0.8649328   1.0572455  -1.3920376\n",
            "   0.06315615  1.8586993   1.3764335   1.3430959 ]\n",
            " [-0.04602024  1.0310172   1.1641402   0.830472    0.55506825 -1.4279099\n",
            "  -0.305408    0.95073116  1.0027801   1.6112568 ]\n",
            " [-0.1204833   0.88820004  0.8350356   0.46982872  0.30827308 -1.1874206\n",
            "   0.06021432  0.6750055   0.5101989   1.052246  ]] [[ 3.5113144   0.23125732  0.14855024  0.31988123 -0.34488022  1.1630836\n",
            "  -0.23730999 -0.6694767   0.04084282  0.70824903]\n",
            " [ 1.7904973   2.2246804   2.806927    2.5454693   2.600652    2.0405247\n",
            "   2.0883412   2.6324604   1.0418186   2.819541  ]\n",
            " [ 2.5830665   2.5436692   2.6789215   2.552863    1.8923868   2.387744\n",
            "   2.497571    1.4598      1.4553257   3.0531595 ]\n",
            " [ 2.0304976   3.0259213   3.0475783   2.566625    2.3083878   2.8534472\n",
            "   2.431889    3.5424695   1.5133282   3.2522182 ]\n",
            " [ 0.85365546  2.1300118   2.9776423   2.764315    1.9021384   2.261848\n",
            "   0.78977865  2.7873087   1.51449     3.4065237 ]\n",
            " [ 4.7410984   2.2832878   2.5947425   2.7378526   1.9672732   3.6375775\n",
            "   2.2509813   3.3431032   1.4767879   2.352169  ]\n",
            " [ 1.3938805   2.63342     2.7286584   1.8677042   2.9486048   1.323737\n",
            "   0.75743663  3.4104338   1.7034984   2.298728  ]\n",
            " [ 1.5281339   3.5719974   3.1684306   2.4641638   3.45946     2.1354446\n",
            "   2.2208533   3.3282526   1.6605146   4.188968  ]\n",
            " [ 3.7193854   2.3510675   2.3213775   2.3511674   2.4487157   3.718595\n",
            "   2.4170146   3.097043    1.2444317   2.0928166 ]\n",
            " [ 5.245867    2.9236443   2.6110198   2.8997252   2.7353942   4.847442\n",
            "   2.6822622   3.372125    2.8552227   3.146039  ]] [[ 1.7404832   0.20622298  0.17036484  0.14028859 -0.0875273  -0.28903437\n",
            "  -0.05346468 -0.21828583  0.24408357  2.5945306 ]\n",
            " [ 2.5038111   3.8067138  -0.9152964  -1.0867347  -0.66055036 -0.3236773\n",
            "  -0.31045496 -1.4174232   0.43165812  1.9661093 ]\n",
            " [ 2.3395207  -1.5124058   1.7736304  -0.67819226 -1.0566123   0.19052632\n",
            "  -0.78984517 -1.3535223   0.9409393   0.73563135]\n",
            " [ 1.2547673   0.34710675 -0.44897196  2.7757225  -0.33859655 -0.15644921\n",
            "  -0.6115687  -0.48662195  0.41058114  0.87479126]\n",
            " [ 0.6738987   0.4476631  -1.602245   -0.6992324   3.0947883  -0.30546984\n",
            "  -0.6876085  -0.13776019  0.14923412  0.28215185]\n",
            " [ 1.546602   -0.46327224 -1.2862829  -1.491924   -1.288245   -1.6702429\n",
            "  -0.73712903 -1.5902119  -0.9095844   1.7985494 ]\n",
            " [ 1.4186683   0.2906626  -0.9079117  -1.503863   -0.35724834 -0.79060125\n",
            "   1.2171147  -1.3592548  -0.53071135  0.48501337]\n",
            " [ 1.5222133  -0.8623995  -0.37342417 -0.85203713 -1.0658941  -0.4834577\n",
            "   0.21761012  3.1788638   0.40442356  0.29755515]\n",
            " [ 1.7944585   0.43165296 -0.3501598  -0.7924533   0.07014562 -0.5650798\n",
            "  -0.51980543 -1.6325725  -1.2602837   0.9605556 ]\n",
            " [ 1.9798651  -0.5624908  -0.7449863  -1.232003   -0.63779896 -0.6748462\n",
            "  -0.8677051  -0.9195779  -0.8235787   0.9559839 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEeT1XRCxsN",
        "outputId": "2280526b-746f-4618-f369-331b71dbc8fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/softmax_bert_layer1.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rL1fG-obHzeW",
        "outputId": "70b2e98b-de4c-40b7-b43f-390571802adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_SM_bert.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/sorted_attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "-vdLamvD6Vcc",
        "outputId": "ebb7c8f2-0e95-4d80-fab9-5fec8ed982d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.50276214 0.18352194 0.07385454 ... 0.02399363 0.01801627\n",
            "    0.00693945]\n",
            "   [0.28548524 0.15781423 0.12932299 ... 0.0462996  0.03935906\n",
            "    0.03413377]\n",
            "   [0.42965856 0.23049009 0.119009   ... 0.03273839 0.02393627\n",
            "    0.01153364]\n",
            "   ...\n",
            "   [0.3043518  0.23911789 0.14382176 ... 0.02023179 0.00734722\n",
            "    0.00598513]\n",
            "   [0.42806664 0.27252406 0.0660226  ... 0.03525357 0.02467276\n",
            "    0.0087873 ]\n",
            "   [0.35068387 0.13904521 0.13328184 ... 0.01395757 0.00985229\n",
            "    0.00765489]]\n",
            "\n",
            "  [[0.2325552  0.13501358 0.11216996 ... 0.06796568 0.04669739\n",
            "    0.01961427]\n",
            "   [0.3069954  0.1544281  0.12369999 ... 0.0540519  0.03094326\n",
            "    0.01976733]\n",
            "   [0.3473453  0.17405728 0.11080742 ... 0.02729124 0.0272199\n",
            "    0.01510452]\n",
            "   ...\n",
            "   [0.34108797 0.14767179 0.09490318 ... 0.05895856 0.02201105\n",
            "    0.01425752]\n",
            "   [0.16335478 0.15715772 0.1307724  ... 0.07702713 0.06241015\n",
            "    0.02915837]\n",
            "   [0.21095937 0.16749963 0.14411137 ... 0.04625707 0.04081224\n",
            "    0.03196875]]\n",
            "\n",
            "  [[0.20825657 0.19249158 0.18383561 ... 0.02142655 0.01533512\n",
            "    0.00476936]\n",
            "   [0.24235135 0.18242025 0.17155178 ... 0.03665771 0.03388991\n",
            "    0.03156955]\n",
            "   [0.18842699 0.1846192  0.15932496 ... 0.0527045  0.05176065\n",
            "    0.04646761]\n",
            "   ...\n",
            "   [0.25251973 0.16754884 0.15158708 ... 0.03404357 0.03329607\n",
            "    0.02462847]\n",
            "   [0.2571161  0.21102408 0.18693537 ... 0.02713428 0.02467851\n",
            "    0.02251801]\n",
            "   [0.41005656 0.19873372 0.1137526  ... 0.02479132 0.01154065\n",
            "    0.00977826]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2592011  0.15715222 0.12888864 ... 0.05018471 0.01325505\n",
            "    0.0045917 ]\n",
            "   [0.33733252 0.17494407 0.15267216 ... 0.02646148 0.01087068\n",
            "    0.00389986]\n",
            "   [0.3181143  0.13679282 0.12702297 ... 0.02282469 0.02214158\n",
            "    0.01064354]\n",
            "   ...\n",
            "   [0.26751333 0.18797602 0.13342448 ... 0.04374462 0.0292747\n",
            "    0.00853144]\n",
            "   [0.18074659 0.15957834 0.15265188 ... 0.05979285 0.03502361\n",
            "    0.01639437]\n",
            "   [0.20700881 0.16873328 0.13372055 ... 0.06887838 0.02255044\n",
            "    0.00934925]]\n",
            "\n",
            "  [[0.37489742 0.2901547  0.11512411 ... 0.02215154 0.01872855\n",
            "    0.00941682]\n",
            "   [0.18999724 0.13898917 0.12236455 ... 0.07654192 0.06884889\n",
            "    0.0477233 ]\n",
            "   [0.27175546 0.12120829 0.1138563  ... 0.0570039  0.05632794\n",
            "    0.05246266]\n",
            "   ...\n",
            "   [0.20520656 0.13339986 0.12312736 ... 0.05491564 0.05075939\n",
            "    0.03485935]\n",
            "   [0.19427177 0.18163337 0.17536202 ... 0.03484033 0.02603423\n",
            "    0.0250867 ]\n",
            "   [0.2918996  0.27665862 0.26320818 ... 0.02027144 0.01506835\n",
            "    0.01499027]]\n",
            "\n",
            "  [[0.43601793 0.18579273 0.07530626 ... 0.03807148 0.03671275\n",
            "    0.03654618]\n",
            "   [0.29635048 0.23618098 0.07779395 ... 0.05147965 0.04919232\n",
            "    0.04249952]\n",
            "   [0.39474365 0.36150783 0.1024332  ... 0.01188225 0.00715878\n",
            "    0.00597612]\n",
            "   ...\n",
            "   [0.34529865 0.27073318 0.1501966  ... 0.03340842 0.02463462\n",
            "    0.01474646]\n",
            "   [0.2451356  0.24132645 0.16123603 ... 0.02899556 0.02688335\n",
            "    0.02529364]\n",
            "   [0.51953447 0.18517023 0.07776037 ... 0.02618033 0.01927708\n",
            "    0.01510626]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "3IpQeei26iui"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = \"/./content/model/sorted_attention_scores_2.txt\"  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "dhImdkUJ62U5",
        "outputId": "dcc9a8e2-3659-477e-fc1a-dc245a6b6edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    2.1947367   2.0617602   1.4053444   0.6307755   0.5856975\n",
            "   0.49772462  0.11714409 -0.14835791 -0.30920362]\n",
            " [ 5.793112    4.621073    3.812749    3.3466518   2.3886065   2.3419719\n",
            "   1.9099072   1.8878778   1.6703308   1.5484276 ]\n",
            " [ 5.2124023   4.502995    3.8073637   3.3168168   3.0351076   2.6028967\n",
            "   2.4797425   2.3082643   1.6874914   1.5656495 ]\n",
            " [ 6.7969666   5.3321524   4.652975    3.8015726   3.108758    2.719986\n",
            "   2.659658    2.5718498   2.416732    2.1785326 ]\n",
            " [ 5.064213    4.6419153   3.4980125   3.339889    3.3077164   2.7762215\n",
            "   2.5917144   2.023627    1.873533    0.62522817]\n",
            " [ 4.3125715   4.3036885   3.9795005   3.511932    3.220555    3.0432897\n",
            "   2.9215946   2.8711824   2.6142015   2.2757936 ]\n",
            " [ 4.5505824   4.1721644   3.331105    3.1753776   2.6852992   2.6400094\n",
            "   2.4741642   1.7959094   1.6750463   1.3191165 ]\n",
            " [ 4.537689    4.2240024   3.9101954   3.422982    3.3852067   2.9609547\n",
            "   2.1071794   2.1017816   1.7666457   1.6387088 ]\n",
            " [ 5.7495446   4.3632503   3.822887    3.529175    3.3072975   2.9970148\n",
            "   2.365435    2.2333503   1.2618201   1.1282016 ]\n",
            " [ 6.618206    5.7463045   5.1483626   4.5703983   4.4660215   3.426703\n",
            "   3.174025    3.1162205   2.4864216   2.1799157 ]] [[ 0.9627847   0.311149    0.02555725 -0.04857237 -0.07704417 -0.1185468\n",
            "  -0.46038562 -0.6803706  -1.0886638  -1.6976843 ]\n",
            " [ 0.97234195  0.7301598   0.43518707  0.06117958 -0.22009215 -0.5790163\n",
            "  -0.6899191  -0.7375137  -1.1784676  -1.7430696 ]\n",
            " [ 1.1253307   0.21543759 -0.0585902  -0.20672473 -0.34776625 -0.43296996\n",
            "  -0.5565975  -0.61825126 -1.1309534  -1.3146526 ]\n",
            " [ 1.2667636   0.45576128  0.14773999  0.03673334  0.01682144  0.00024927\n",
            "  -0.25012723 -0.25380707 -0.3354175  -0.5908074 ]\n",
            " [ 0.7070519   0.6523646   0.59022087  0.32314226  0.09670944 -0.03702255\n",
            "  -0.25472367 -1.2064693  -1.5367095  -1.7260594 ]\n",
            " [ 0.7998164   0.43778053  0.38227442  0.37704596  0.2848917   0.15285142\n",
            "   0.01839954 -0.49263728 -0.8517933  -1.209122  ]\n",
            " [ 0.60655284  0.5833909   0.2000978   0.10675713  0.10043441  0.03625927\n",
            "  -0.09115115 -0.17491554 -0.2891728  -0.83618826]\n",
            " [ 0.99600965  0.42240837  0.38931042  0.1125567   0.09165996 -0.06464243\n",
            "  -0.33630806 -0.35978922 -0.56914496 -1.3896195 ]\n",
            " [ 0.6880506   0.4417293   0.22939461  0.17030033  0.16794282  0.1490941\n",
            "   0.03469593 -0.33433583 -0.5399121  -0.96181583]\n",
            " [ 0.81911325  0.47387433  0.27014586  0.25771543  0.17429377 -0.10441241\n",
            "  -0.3579516  -0.4639737  -0.60645354 -0.9096098 ]] [[ 4.0928345   3.0894957   2.8996303   2.411408    0.9280114   0.631462\n",
            "   0.02200214 -0.14752409 -0.74852276 -1.1275623 ]\n",
            " [ 3.9065943   3.235908    3.011582    2.1310635   0.98545116  0.5878507\n",
            "   0.50435984  0.34831482  0.17555894 -0.09421223]\n",
            " [ 2.6323042   2.430443    2.2343197   1.5101197   1.3811649   1.0000788\n",
            "   0.8571075   0.6049058   0.56835276  0.4869851 ]\n",
            " [ 4.087019    3.0947237   2.0099015   1.465734    1.430701    0.9727164\n",
            "   0.75650877  0.56819826  0.33274144 -0.30525357]\n",
            " [ 3.5774622   3.0174787   2.2269187   1.5521222   1.4834703   1.1328936\n",
            "  -0.17385992 -0.3164355  -1.30088    -1.429762  ]\n",
            " [ 3.4188118   3.0749917   2.4532826   2.2898376   1.0576711   0.71736014\n",
            "   0.62846535  0.22138332  0.07279523 -0.32747287]\n",
            " [ 1.9065028   1.5033801   1.2080953   0.88415587  0.6549574   0.593324\n",
            "   0.5708541   0.49050444  0.42657304  0.14300826]\n",
            " [ 2.1231966   2.0823565   1.852924    1.5934157   1.4300145   1.3541062\n",
            "   1.0749373   1.0071483   0.84968215  0.76707125]\n",
            " [ 3.2195091   2.1220663   2.0053072   1.7817802   1.1799686   0.56950235\n",
            "   0.2573312   0.23191671  0.0096926  -0.32239503]\n",
            " [ 4.1586957   3.912785    3.5320184   2.9207473   1.3169683   0.9062026\n",
            "   0.8497595   0.8289084   0.3867088   0.23973835]] [[-0.73714244 -0.88458973 -0.91819704 -1.0391645  -1.2835796  -1.3152801\n",
            "  -1.71575    -1.7907189  -2.0585341  -2.3600693 ]\n",
            " [ 2.8525796   1.291576    1.1377413   1.0893993   0.98103195  0.76816994\n",
            "   0.5328254  -0.05392636 -0.3590138  -1.1812421 ]\n",
            " [ 1.889281    1.394224    1.2403969   1.1208864   0.93400806  0.9152784\n",
            "   0.44077566  0.37211862 -0.48069543 -0.6091448 ]\n",
            " [ 1.9117765   1.7898803   1.4986356   1.2874416   0.8347929   0.61145085\n",
            "   0.17829615 -0.2541298  -0.4079485  -0.5898164 ]\n",
            " [ 1.9394354   1.6893194   1.2605628   0.92400664  0.8303908   0.5058691\n",
            "   0.35562584 -0.15927449 -0.32631215 -1.4803319 ]\n",
            " [ 1.6729834   1.4437281   1.2482777   1.049527    1.0102694   0.7912869\n",
            "   0.68996495  0.5756347   0.47246826  0.2827701 ]\n",
            " [ 1.2811688   1.2386009   1.1386023   1.133507    1.0146374   0.64457095\n",
            "   0.43742573 -0.267912   -0.3252511  -0.527435  ]\n",
            " [ 2.0227776   1.4528047   1.0313237   0.9414549   0.6557309   0.6545312\n",
            "   0.44207764  0.28013933  0.10742482 -0.6168757 ]\n",
            " [ 1.2305831   1.1441543   1.0789971   0.96978915  0.8841506   0.83005744\n",
            "   0.68824714  0.6699963   0.6610696   0.1847023 ]\n",
            " [ 0.8336154   0.65710616  0.5815153   0.48081017  0.45186663  0.34215644\n",
            "  -0.02691434 -0.1397903  -0.4203801  -1.0223608 ]] [[ 4.069817    3.265758    3.0087957   1.123025    0.5453431  -0.26431718\n",
            "  -0.4206367  -0.45972508 -0.81877565 -0.8189321 ]\n",
            " [ 6.097168    4.062114    4.0104914   3.3517642   2.6415534   2.5503993\n",
            "   2.4742503   1.711552    1.0404894   0.6797678 ]\n",
            " [ 3.6345613   2.8842583   2.593385    2.5239465   2.4532597   2.4311733\n",
            "   2.1401596   1.8469099   1.6555488   1.1871887 ]\n",
            " [ 6.664719    4.3002462   4.007442    2.897587    2.8146844   2.0899508\n",
            "   1.9416659   1.1508867   0.9355154   0.92588633]\n",
            " [ 4.5608745   3.773708    3.7128031   3.3055158   2.7502472   2.5344577\n",
            "   1.7340083   1.4384526   1.4212635   0.3143406 ]\n",
            " [ 4.785963    3.9486756   3.0749145   2.427682    2.2834506   2.1121552\n",
            "   2.1050293   1.8919368   1.4853789  -1.8715912 ]\n",
            " [ 3.5164182   3.2546113   2.360936    2.2992978   2.1868212   1.9338874\n",
            "   1.810391    1.1583683   0.84790796  0.63691103]\n",
            " [ 2.7568579   2.7054691   2.477663    2.465773    1.7325523   1.6061538\n",
            "   1.360221    1.037012    0.39985502  0.35841948]\n",
            " [ 4.687452    3.0739172   2.4958704   2.266237    2.0501065   1.2087647\n",
            "   1.0399474   0.85278237  0.47858107 -1.5197104 ]\n",
            " [ 3.609223    3.000189    2.9361863   2.3336442   2.2864735   2.0922556\n",
            "   1.7917078   0.4763999  -0.7293791  -0.74419117]] [[ 2.3518488  -0.10409442 -1.3146498  -1.3970611  -1.4390004  -1.486853\n",
            "  -1.5213429  -2.4012413  -2.5842254  -2.5848315 ]\n",
            " [ 3.4115536   3.0861502   2.8016753   2.5004106   2.4000955   1.5283737\n",
            "   1.3075106   1.0803758   0.95492965 -0.08029907]\n",
            " [ 3.8802829   3.159526    2.2096994   2.0309644   1.5423824   1.4555954\n",
            "   1.3234267   0.77620506  0.30919918 -0.98470867]\n",
            " [ 3.6075718   3.5096714   3.153818    3.1277943   2.7993655   2.5558827\n",
            "   2.483896    1.9985721   0.9758086  -1.3650285 ]\n",
            " [ 3.5341537   2.933026    2.7865634   2.6538177   2.1139412   1.9947041\n",
            "   1.41041     0.17108425  0.09414454 -0.53188324]\n",
            " [ 3.8921413   3.1415412   3.026591    2.9880128   2.960376    2.8401773\n",
            "   2.6003537   2.4387147   2.2146826  -0.05147918]\n",
            " [ 2.6857972   2.6380162   2.6029804   2.583294    2.5345263   2.2150342\n",
            "   2.0204773   1.4581535   1.2893649  -0.9958864 ]\n",
            " [ 3.2778075   3.2038531   2.9330308   2.720913    2.4970698   1.9810863\n",
            "   1.571423    1.2107869   1.1165935   0.04527869]\n",
            " [ 2.7725258   2.6563025   2.6123178   2.521809    2.3261166   2.2237506\n",
            "   2.2081223   2.1577914   1.9723585  -0.23130603]\n",
            " [ 5.390417    3.7007978   3.4948716   3.369534    3.188392    3.1076705\n",
            "   2.958899    2.873453    2.6593766   0.2493442 ]] [[ 2.0303364   1.8577769   1.8336577   0.03677352 -0.1782641  -0.20157872\n",
            "  -0.36019903 -0.5154236  -0.8391258  -0.9360012 ]\n",
            " [ 2.4703162   1.896263    1.7434708   1.7014173   1.6416981   1.616728\n",
            "   1.5449183   1.3008279   0.07594603  0.00997017]\n",
            " [ 2.406196    2.1794832   2.1692429   2.1441464   1.8323896   1.7379965\n",
            "   1.5149322   1.3819319   0.6953787   0.00943146]\n",
            " [ 2.7665334   2.6152775   2.566569    2.191609    2.0782743   1.5269834\n",
            "   1.5004507   1.2686868   0.9322765  -0.32668146]\n",
            " [ 2.8975577   2.492464    1.5521193   1.484075    1.3629732   1.2339579\n",
            "   1.1117117   0.7913337  -0.5223735  -0.75108665]\n",
            " [ 4.608461    4.2106786   2.6140327   2.156302    1.9421829   1.8067638\n",
            "   1.6747181   1.5631702   1.1256423   1.0583446 ]\n",
            " [ 2.443831    2.4160697   2.1890495   2.1084352   2.08211     1.9666604\n",
            "   1.7901441   1.5581807   1.4040198   1.0204064 ]\n",
            " [ 2.5419347   2.4702833   2.2814734   2.1157253   1.9466188   1.7847257\n",
            "   1.6170082   1.4104946   1.1339206   1.1112541 ]\n",
            " [ 2.5761323   2.4792182   2.137839    1.8463246   1.720331    1.4472572\n",
            "   1.3243217   1.2411208   1.2266266   1.1666892 ]\n",
            " [ 5.4560094   5.353278    4.541738    3.3154905   2.8533223   2.8041744\n",
            "   2.6403146   2.3418133   2.1872957   1.9060035 ]] [[ 0.22612049 -0.03800961 -0.03878088 -0.04676584 -0.06920808 -0.20872909\n",
            "  -0.24101785 -0.35037673 -0.4477717  -0.5273356 ]\n",
            " [ 0.67517275  0.39312774  0.23725607 -0.06305974 -0.11039566 -0.29921988\n",
            "  -0.47187504 -0.5550632  -0.6243619  -0.72015625]\n",
            " [ 0.9336121   0.5395098   0.49287453  0.21531588  0.18740971 -0.02921304\n",
            "  -0.23901877 -0.30668795 -0.32362545 -1.2280265 ]\n",
            " [ 0.69756246  0.44989973  0.24341476 -0.00245793 -0.07840493 -0.32464612\n",
            "  -0.38152987 -0.6197981  -0.6797175  -0.70561624]\n",
            " [ 0.10249646  0.07505149 -0.03507853 -0.04885465 -0.20628366 -0.23292464\n",
            "  -0.34050646 -0.44878232 -0.46191064 -2.1298897 ]\n",
            " [ 0.3024567   0.29947233  0.2423661   0.24130446  0.18978542  0.096457\n",
            "   0.03272907  0.02645526  0.00284321 -0.13099633]\n",
            " [ 0.6062699   0.52392596 -0.00332226 -0.16046394 -0.19334584 -0.3142506\n",
            "  -0.34419575 -0.40288302 -0.43888092 -0.4598454 ]\n",
            " [ 0.04201785 -0.02999487 -0.16519366 -0.188554   -0.31032342 -0.39713255\n",
            "  -0.56612873 -0.6005166  -1.3156276  -2.612752  ]\n",
            " [ 0.3471023   0.2327159   0.1582894   0.13848405  0.0672462   0.0647919\n",
            "  -0.00930041 -0.03875374 -0.08677322 -0.1906524 ]\n",
            " [ 0.2202284   0.05504296  0.00104465 -0.02846966 -0.03995595 -0.06230865\n",
            "  -0.06644918 -0.08931216 -0.15427314 -0.25045082]] [[ 2.2500303   2.2188106   0.7274816   0.7000268   0.5726925   0.284214\n",
            "   0.13661313  0.11507649 -0.22948742 -0.4026169 ]\n",
            " [ 3.4689038   2.951157    2.3157012   1.8796558   1.4019722   1.1965826\n",
            "   1.1602786   0.6572411   0.2278574  -0.1770497 ]\n",
            " [ 3.709777    2.3455753   1.9080584   1.6395503   1.4283334   1.2921461\n",
            "   1.0153087   0.8905095   0.5606777   0.47134808]\n",
            " [ 4.1362057   3.8354084   3.003888    2.590262    2.323182    1.8637079\n",
            "   1.3310231   1.2275932   1.0532311  -0.19235559]\n",
            " [ 3.094353    1.8359743   1.7547503   1.5248697   1.3008693   0.6746429\n",
            "   0.6143206   0.54005456  0.47067168  0.2596902 ]\n",
            " [ 2.0936713   1.9916923   1.3448064   0.901352    0.87460697  0.80160993\n",
            "   0.5036669   0.45084783 -0.10966269 -0.9338605 ]\n",
            " [ 1.4810711   0.9820602   0.5728401   0.5373771   0.45082232  0.40630463\n",
            "   0.07374337  0.0408671  -0.04004947 -0.43184328]\n",
            " [ 3.1449246   2.3962045   2.0956993   1.8832694   1.0816227   0.7081071\n",
            "   0.6745899   0.6018912   0.5275235   0.19390348]\n",
            " [ 2.0125527   1.7450609   1.6686664   1.5488706   1.1293051   0.8310921\n",
            "   0.57361317  0.46006605  0.18745206 -0.3780636 ]\n",
            " [ 2.0720472   1.7020148   1.3618188   1.1978279   0.8111273   0.633571\n",
            "   0.6197194   0.29930606  0.2847378   0.12218147]] [[ 1.11368     0.10982683 -0.01029287 -0.03871024 -0.04179777 -0.1011171\n",
            "  -0.61037153 -0.7641907  -0.8519444  -3.409261  ]\n",
            " [ 1.5662173   1.5360875   1.0755258   1.0136852   0.79115003  0.6315195\n",
            "   0.5027024   0.36316153 -0.60011023 -0.84586865]\n",
            " [ 1.431718    1.3796113   0.9972024   0.7522633   0.60126495  0.53102773\n",
            "   0.42479315 -0.19636366 -0.24372143 -1.2828168 ]\n",
            " [ 1.2536769   1.2261399   1.0066447   0.60732824  0.05428234 -0.01733678\n",
            "  -0.01925345 -0.34242573 -0.3713482  -1.0930486 ]\n",
            " [ 1.9441388   1.1883222   1.0981218   0.812452    0.73339826  0.300511\n",
            "   0.27320436 -0.5859628  -0.6089171  -0.69458455]\n",
            " [ 1.6519731   0.9120517   0.87512237  0.7143033   0.6206465   0.49330038\n",
            "   0.45504218 -0.31964967 -0.3862846  -1.0343239 ]\n",
            " [ 1.585442    1.5412023   1.3740886   1.1451776   1.118077    0.7921902\n",
            "   0.45498532  0.13255627 -0.11572167 -0.8244491 ]\n",
            " [ 1.8586993   1.3764335   1.3430959   1.1695968   1.0572455   0.8649328\n",
            "   0.7645048   0.06315615 -0.42347932 -1.3920376 ]\n",
            " [ 1.6112568   1.1641402   1.0310172   1.0027801   0.95073116  0.830472\n",
            "   0.55506825 -0.04602024 -0.305408   -1.4279099 ]\n",
            " [ 1.052246    0.88820004  0.8350356   0.6750055   0.5101989   0.46982872\n",
            "   0.30827308  0.06021432 -0.1204833  -1.1874206 ]] [[ 3.5113144   1.1630836   0.70824903  0.31988123  0.23125732  0.14855024\n",
            "   0.04084282 -0.23730999 -0.34488022 -0.6694767 ]\n",
            " [ 2.819541    2.806927    2.6324604   2.600652    2.5454693   2.2246804\n",
            "   2.0883412   2.0405247   1.7904973   1.0418186 ]\n",
            " [ 3.0531595   2.6789215   2.5830665   2.552863    2.5436692   2.497571\n",
            "   2.387744    1.8923868   1.4598      1.4553257 ]\n",
            " [ 3.5424695   3.2522182   3.0475783   3.0259213   2.8534472   2.566625\n",
            "   2.431889    2.3083878   2.0304976   1.5133282 ]\n",
            " [ 3.4065237   2.9776423   2.7873087   2.764315    2.261848    2.1300118\n",
            "   1.9021384   1.51449     0.85365546  0.78977865]\n",
            " [ 4.7410984   3.6375775   3.3431032   2.7378526   2.5947425   2.352169\n",
            "   2.2832878   2.2509813   1.9672732   1.4767879 ]\n",
            " [ 3.4104338   2.9486048   2.7286584   2.63342     2.298728    1.8677042\n",
            "   1.7034984   1.3938805   1.323737    0.75743663]\n",
            " [ 4.188968    3.5719974   3.45946     3.3282526   3.1684306   2.4641638\n",
            "   2.2208533   2.1354446   1.6605146   1.5281339 ]\n",
            " [ 3.7193854   3.718595    3.097043    2.4487157   2.4170146   2.3511674\n",
            "   2.3510675   2.3213775   2.0928166   1.2444317 ]\n",
            " [ 5.245867    4.847442    3.372125    3.146039    2.9236443   2.8997252\n",
            "   2.8552227   2.7353942   2.6822622   2.6110198 ]] [[ 2.5945306   1.7404832   0.24408357  0.20622298  0.17036484  0.14028859\n",
            "  -0.05346468 -0.0875273  -0.21828583 -0.28903437]\n",
            " [ 3.8067138   2.5038111   1.9661093   0.43165812 -0.31045496 -0.3236773\n",
            "  -0.66055036 -0.9152964  -1.0867347  -1.4174232 ]\n",
            " [ 2.3395207   1.7736304   0.9409393   0.73563135  0.19052632 -0.67819226\n",
            "  -0.78984517 -1.0566123  -1.3535223  -1.5124058 ]\n",
            " [ 2.7757225   1.2547673   0.87479126  0.41058114  0.34710675 -0.15644921\n",
            "  -0.33859655 -0.44897196 -0.48662195 -0.6115687 ]\n",
            " [ 3.0947883   0.6738987   0.4476631   0.28215185  0.14923412 -0.13776019\n",
            "  -0.30546984 -0.6876085  -0.6992324  -1.602245  ]\n",
            " [ 1.7985494   1.546602   -0.46327224 -0.73712903 -0.9095844  -1.2862829\n",
            "  -1.288245   -1.491924   -1.5902119  -1.6702429 ]\n",
            " [ 1.4186683   1.2171147   0.48501337  0.2906626  -0.35724834 -0.53071135\n",
            "  -0.79060125 -0.9079117  -1.3592548  -1.503863  ]\n",
            " [ 3.1788638   1.5222133   0.40442356  0.29755515  0.21761012 -0.37342417\n",
            "  -0.4834577  -0.85203713 -0.8623995  -1.0658941 ]\n",
            " [ 1.7944585   0.9605556   0.43165296  0.07014562 -0.3501598  -0.51980543\n",
            "  -0.5650798  -0.7924533  -1.2602837  -1.6325725 ]\n",
            " [ 1.9798651   0.9559839  -0.5624908  -0.63779896 -0.6748462  -0.7449863\n",
            "  -0.8235787  -0.8677051  -0.9195779  -1.232003  ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path = \"./model/softmax_attention_scores.pkl\"\n",
        "with open(softmax_file_path, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax attention_scores가 {softmax_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "WUVvB7pr7RBf",
        "outputId": "b5f65e1b-76b3-429b-cd41-c8f2f15e29a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792055 0.09109741 0.09164357 ... 0.09258842 0.09229336\n",
            "    0.09513694]\n",
            "   [0.12004586 0.10268968 0.10120098 ... 0.09385469 0.09336554\n",
            "    0.09450836]\n",
            "   [0.09188308 0.11296417 0.10104739 ... 0.09287033 0.09284727\n",
            "    0.09269542]\n",
            "   ...\n",
            "   [0.09724706 0.09072162 0.09059814 ... 0.09612775 0.12209511\n",
            "    0.1143846 ]\n",
            "   [0.09323013 0.09044815 0.09189644 ... 0.11774409 0.09348241\n",
            "    0.13755944]\n",
            "   [0.10347308 0.09130668 0.09073301 ... 0.10249271 0.0964129\n",
            "    0.10287845]]\n",
            "\n",
            "  [[0.09785708 0.1010711  0.09990909 ... 0.1006773  0.09957507\n",
            "    0.11400125]\n",
            "   [0.09519613 0.09198768 0.10206269 ... 0.09563526 0.09920019\n",
            "    0.12259457]\n",
            "   [0.0963392  0.09690202 0.09143765 ... 0.10719077 0.10062093\n",
            "    0.12747219]\n",
            "   ...\n",
            "   [0.09908457 0.09758333 0.09906299 ... 0.0961072  0.0978529\n",
            "    0.12674263]\n",
            "   [0.09308667 0.10304288 0.09866013 ... 0.10144265 0.09808288\n",
            "    0.10579788]\n",
            "   [0.09461471 0.1043413  0.0984853  ... 0.10681042 0.09746661\n",
            "    0.11155472]]\n",
            "\n",
            "  [[0.10933199 0.09290536 0.09061925 ... 0.09214136 0.09332465\n",
            "    0.10667202]\n",
            "   [0.10829917 0.10341936 0.09385677 ... 0.09627965 0.09360978\n",
            "    0.10712849]\n",
            "   [0.10907564 0.09717342 0.0946402  ... 0.09514245 0.09607369\n",
            "    0.1086611 ]\n",
            "   ...\n",
            "   [0.10199555 0.10672598 0.09804323 ... 0.11619101 0.09668372\n",
            "    0.10503597]\n",
            "   [0.0949479  0.11661825 0.09678788 ... 0.09768786 0.09655614\n",
            "    0.10871448]\n",
            "   [0.1353592  0.0939795  0.09070874 ... 0.09208083 0.09304921\n",
            "    0.10064787]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09984183 0.10561763 0.10010299 ... 0.09757758 0.1026743\n",
            "    0.11696494]\n",
            "   [0.10077073 0.1048938  0.1072562  ... 0.09442478 0.09245645\n",
            "    0.1261673 ]\n",
            "   [0.09222058 0.10335313 0.12389978 ... 0.09829431 0.10070038\n",
            "    0.1023483 ]\n",
            "   ...\n",
            "   [0.09290123 0.09680557 0.11789276 ... 0.10309868 0.09550235\n",
            "    0.1088791 ]\n",
            "   [0.09593145 0.10086945 0.10162396 ... 0.10526626 0.09792026\n",
            "    0.10599791]\n",
            "   [0.09677328 0.09897416 0.11110785 ... 0.10325618 0.0989797\n",
            "    0.10693549]]\n",
            "\n",
            "  [[0.13062458 0.09245858 0.0914835  ... 0.09063558 0.09179717\n",
            "    0.09474251]\n",
            "   [0.09483223 0.09760492 0.10083348 ... 0.09685693 0.10389443\n",
            "    0.09879342]\n",
            "   [0.09761009 0.09560166 0.10119431 ... 0.09553706 0.09628828\n",
            "    0.11850341]\n",
            "   ...\n",
            "   [0.10222587 0.10328139 0.09508933 ... 0.09548536 0.09791066\n",
            "    0.11097045]\n",
            "   [0.09551324 0.10601512 0.09348555 ... 0.10826695 0.1075901\n",
            "    0.10964395]\n",
            "   [0.11690799 0.09121044 0.09121756 ... 0.0916934  0.09208853\n",
            "    0.09284412]]\n",
            "\n",
            "  [[0.10810776 0.0942751  0.09505253 ... 0.09378396 0.09679952\n",
            "    0.13884439]\n",
            "   [0.12123886 0.11415911 0.09557965 ... 0.09468964 0.09405801\n",
            "    0.09743701]\n",
            "   [0.132849   0.09005725 0.12850621 ... 0.0927122  0.09285689\n",
            "    0.09917664]\n",
            "   ...\n",
            "   [0.12697606 0.0912357  0.09214232 ... 0.1178524  0.09399209\n",
            "    0.10446963]\n",
            "   [0.11475074 0.09405647 0.10441453 ... 0.09398486 0.11518867\n",
            "    0.1059187 ]\n",
            "   [0.15028572 0.09182073 0.0938767  ... 0.09661791 0.09353498\n",
            "    0.10757346]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 1.0\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 1.0\n",
            "Sum of softmax values in [0, 9, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax attention_scores가 ./model/softmax_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "\n",
        "# 파일에서 데이터 로드\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(f\"Shape of attention_scores: {np.array(attention_scores).shape}\")\n"
      ],
      "metadata": {
        "id": "EvyTkAln9iH7",
        "outputId": "43197bb9-867a-4d2e-afc9-1144249f1bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_scores: (1, 12, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"./model/attention_scores.pkl\"  # 기존 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 정렬 및 인덱스 저장\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)\n",
        "original_indices = np.zeros_like(attention_scores, dtype=int)\n",
        "\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 인덱스와 정렬된 배열 저장\n",
        "            sorted_indices = np.argsort(attention_scores[i, j, k])[::-1]  # 내림차순 인덱스\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][sorted_indices]\n",
        "            original_indices[i, j, k] = sorted_indices  # 원래의 순서 저장\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "# 4. 원래 인덱스 데이터를 새로운 파일로 저장\n",
        "indices_file_path = \"./model/original_indices.pkl\"\n",
        "with open(indices_file_path, \"wb\") as f:\n",
        "    pickle.dump(original_indices, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores와 원래 인덱스가 각각 {sorted_file_path}, {indices_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "eOuBuIM67wL7",
        "outputId": "979679d1-1b75-4729-b2e0-de81d1e48f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores와 원래 인덱스가 각각 ./model/sorted_attention_scores.pkl, ./model/original_indices.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path2 = \"./model/softmax_sorted_attention_scores.pkl\"\n",
        "with open(softmax_file_path2, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax sorted_attention_scores가 {softmax_file_path2}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "jM9BFbZ2-5sn",
        "outputId": "a3b75569-7362-42d4-f0cf-79fe84b255a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.52837735 0.14622849 0.12802094 0.06640536 0.0306064  0.02925736\n",
            "    0.02679347 0.01831239 0.01404232 0.01195596]\n",
            "   [0.59860635 0.18540919 0.08261914 0.05183908 0.01988765 0.01898149\n",
            "    0.01232217 0.01205369 0.00969707 0.00858417]\n",
            "   [0.44448107 0.21865611 0.1090568  0.06677455 0.05038093 0.03270087\n",
            "    0.02891174 0.02435579 0.01309194 0.01159014]\n",
            "   [0.669667   0.15477407 0.07847571 0.03349468 0.01675291 0.01135661\n",
            "    0.01069175 0.00979296 0.00838585 0.00660843]\n",
            "   [0.39969283 0.26201427 0.08347073 0.07126267 0.06900645 0.04055686\n",
            "    0.0337236  0.01910807 0.01644492 0.00471954]\n",
            "   [0.2187059  0.21677174 0.15675072 0.09820805 0.0733844  0.06146365\n",
            "    0.05442105 0.05174557 0.04001914 0.02852982]\n",
            "   [0.35450202 0.24281408 0.1047144  0.0896138  0.05489547 0.05246472\n",
            "    0.04444693 0.0225569  0.01998892 0.01400267]\n",
            "   [0.293395   0.21439777 0.15665188 0.09623688 0.09266932 0.06062973\n",
            "    0.02581641 0.02567743 0.01836554 0.01616001]\n",
            "   [0.5748314  0.14370786 0.08371508 0.06240886 0.04999033 0.03665489\n",
            "    0.01949128 0.01707956 0.00646467 0.00565609]\n",
            "   [0.49397027 0.20655645 0.11359414 0.06373078 0.05741416 0.02030713\n",
            "    0.01577292 0.01488702 0.0079303  0.00583681]]\n",
            "\n",
            "  [[0.27761808 0.14469248 0.10874643 0.10097665 0.09814221 0.09415241\n",
            "    0.06689177 0.05368271 0.0356874  0.01940979]\n",
            "   [0.2604174  0.20440505 0.15219016 0.10470253 0.07903191 0.05519805\n",
            "    0.04940367 0.0471074  0.03030995 0.01723383]\n",
            "   [0.33725736 0.13576876 0.10322648 0.08901375 0.07730427 0.07099047\n",
            "    0.06273492 0.05898388 0.03532398 0.02939613]\n",
            "   [0.2917905  0.12967533 0.09529836 0.08528562 0.08360421 0.08223013\n",
            "    0.06401678 0.06378165 0.05878313 0.04553427]\n",
            "   [0.19012696 0.18000863 0.1691627  0.12951314 0.10327026 0.09034337\n",
            "    0.07266911 0.02805511 0.02016464 0.01668618]\n",
            "   [0.1926948  0.13416518 0.12692109 0.12625922 0.11514391 0.10090128\n",
            "    0.08820739 0.05291325 0.0369475  0.02584635]\n",
            "   [0.16616797 0.16236342 0.11066904 0.10080656 0.10017121 0.09394464\n",
            "    0.08270625 0.07606062 0.06784825 0.03926203]\n",
            "   [0.24415724 0.13758077 0.13310166 0.10092317 0.09883608 0.08453456\n",
            "    0.06442455 0.06292941 0.05104246 0.02247005]\n",
            "   [0.18009992 0.14077887 0.11384703 0.10731426 0.10706155 0.10506248\n",
            "    0.09370552 0.06478832 0.05274922 0.03459279]\n",
            "   [0.20915571 0.14809294 0.12079702 0.11930476 0.10975596 0.08305917\n",
            "    0.06445802 0.05797385 0.05027522 0.03712742]]\n",
            "\n",
            "  [[0.50648683 0.18570502 0.15359116 0.09426141 0.02138469 0.01589693\n",
            "    0.00864228 0.00729464 0.00399939 0.00273765]\n",
            "   [0.43792823 0.2239379  0.1789386  0.0741822  0.0235921  0.01585225\n",
            "    0.01458248 0.01247561 0.01049627 0.00801447]\n",
            "   [0.2603332  0.21274649 0.17485866 0.08475611 0.07450179 0.05089359\n",
            "    0.04411349 0.03428007 0.03304965 0.03046698]\n",
            "   [0.56036854 0.20774248 0.07020905 0.04074404 0.03934137 0.02488566\n",
            "    0.0200471  0.01660616 0.01312235 0.0069332 ]\n",
            "   [0.4483548  0.25610855 0.11616845 0.05915995 0.0552348  0.03890086\n",
            "    0.01053036 0.00913111 0.00341181 0.00299925]\n",
            "   [0.36553445 0.2591846  0.13918881 0.11820098 0.0344745  0.02453029\n",
            "    0.02244379 0.01493835 0.01287573 0.00862854]\n",
            "   [0.2509315  0.16767997 0.12480748 0.0902725  0.07178206 0.06749146\n",
            "    0.06599184 0.06089685 0.05712547 0.04302087]\n",
            "   [0.18211861 0.17483069 0.13898772 0.10721941 0.09105612 0.08440003\n",
            "    0.06384121 0.0596569  0.05096523 0.04692417]\n",
            "   [0.44636625 0.14896284 0.13254707 0.10599701 0.0580671  0.0315361\n",
            "    0.02307989 0.02250072 0.01801714 0.01292593]\n",
            "   [0.35479093 0.2774437  0.18958764 0.10288175 0.02069312 0.01372248\n",
            "    0.0129694  0.01270177 0.00816243 0.00704678]]\n",
            "\n",
            "  [[0.17345521 0.14967586 0.14472926 0.12823921 0.10043214 0.09729832\n",
            "    0.06519037 0.06048183 0.04627157 0.03422624]\n",
            "   [0.48765132 0.10237034 0.08777373 0.08363152 0.07504237 0.06065432\n",
            "    0.04793502 0.02665814 0.01964862 0.00863461]\n",
            "   [0.25074285 0.15283686 0.1310454  0.11628375 0.09646256 0.09467266\n",
            "    0.0589048  0.05499628 0.02344017 0.02061465]\n",
            "   [0.2399773  0.21243756 0.15876156 0.12853605 0.08174141 0.06538016\n",
            "    0.04239642 0.02751243 0.02358991 0.01966718]\n",
            "   [0.27168334 0.21156263 0.13779466 0.09841648 0.08962126 0.06478479\n",
            "    0.05574723 0.03331232 0.02818781 0.00888949]\n",
            "   [0.19332255 0.15371567 0.12642564 0.10363796 0.0996482  0.08005097\n",
            "    0.07233742 0.06452233 0.05819765 0.04814161]\n",
            "   [0.16693579 0.15997879 0.144755   0.1440193  0.12787814 0.08832397\n",
            "    0.07179868 0.03546436 0.03348807 0.0273579 ]\n",
            "   [0.29544708 0.16708738 0.10962176 0.10019989 0.07529721 0.07520694\n",
            "    0.06081216 0.05172036 0.04351636 0.02109079]\n",
            "   [0.14298777 0.13114852 0.12287569 0.11016346 0.1011219  0.0957972\n",
            "    0.08313145 0.081628   0.08090257 0.05024336]\n",
            "   [0.17079811 0.14316145 0.13273863 0.12002222 0.11659815 0.10448287\n",
            "    0.072237   0.06452653 0.04873934 0.02669579]]\n",
            "\n",
            "  [[0.5192746  0.23237996 0.17972206 0.027266   0.01530162 0.00680936\n",
            "    0.00582395 0.0056007  0.00391118 0.00391057]\n",
            "   [0.699621   0.09142186 0.08682219 0.04493132 0.02208557 0.02016141\n",
            "    0.01868313 0.00871393 0.00445426 0.00310539]\n",
            "   [0.2960213  0.1397882  0.10450712 0.09749652 0.09084274 0.08885835\n",
            "    0.0664221  0.04953998 0.04091182 0.02561195]\n",
            "   [0.8076041  0.07591385 0.0566445  0.01867041 0.01718501 0.00832534\n",
            "    0.00717799 0.00325515 0.00262444 0.00259929]\n",
            "   [0.38101527 0.17341247 0.16316602 0.1085793  0.06231563 0.05022047\n",
            "    0.02255537 0.01678386 0.01649782 0.00545376]\n",
            "   [0.4948026  0.21419172 0.08939907 0.04679975 0.04051395 0.03413595\n",
            "    0.03389356 0.02738876 0.01823923 0.00063547]\n",
            "   [0.30746588 0.23664407 0.09682274 0.09103498 0.08135051 0.06317024\n",
            "    0.05583142 0.02908767 0.02132444 0.01726804]\n",
            "   [0.2109127  0.20034795 0.15953279 0.15764718 0.07572729 0.06673571\n",
            "    0.05218564 0.03777314 0.0199742  0.01916347]\n",
            "   [0.6382935  0.12713678 0.07132285 0.05668918 0.04567051 0.01969\n",
            "    0.01663142 0.01379255 0.00948705 0.00128613]\n",
            "   [0.32775906 0.17826031 0.16720861 0.09153304 0.08731563 0.07190253\n",
            "    0.05323753 0.01428851 0.00427882 0.00421591]]\n",
            "\n",
            "  [[0.817817   0.07015417 0.02090817 0.01925419 0.01846338 0.01760067\n",
            "    0.01700397 0.00705368 0.00587417 0.00587061]\n",
            "   [0.28418595 0.2052493  0.15443146 0.11426104 0.10335509 0.04322629\n",
            "    0.03465998 0.02761754 0.02436152 0.00865187]\n",
            "   [0.4597378  0.22360915 0.08649381 0.07233716 0.04437853 0.04068945\n",
            "    0.03565182 0.02062654 0.01293029 0.00354545]\n",
            "   [0.21930066 0.19884852 0.13930833 0.13572979 0.0977328  0.07661206\n",
            "    0.07129084 0.04387935 0.01577901 0.00151868]\n",
            "   [0.3230051  0.17706919 0.15294491 0.13393198 0.07805827 0.06928431\n",
            "    0.03862596 0.01118528 0.01035696 0.00553799]\n",
            "   [0.2662634  0.12569848 0.11204894 0.1078086  0.10486991 0.09299279\n",
            "    0.07316363 0.06224383 0.04975083 0.00515963]\n",
            "   [0.15772055 0.15036172 0.14518489 0.14235465 0.13557892 0.09850053\n",
            "    0.08108556 0.04620931 0.03903242 0.00397149]\n",
            "   [0.22705087 0.21086536 0.16083796 0.13009691 0.10400474 0.0620818\n",
            "    0.04121448 0.02873609 0.02615291 0.00895888]\n",
            "   [0.15756966 0.14028054 0.1342441  0.12262746 0.10083228 0.0910212\n",
            "    0.08960975 0.08521124 0.07078877 0.00781493]\n",
            "   [0.52095336 0.09616268 0.07826614 0.06904632 0.0576065  0.05313915\n",
            "    0.04579351 0.04204315 0.03394088 0.00304831]]\n",
            "\n",
            "  [[0.30353034 0.25542325 0.24933638 0.04134365 0.0333441  0.0325757\n",
            "    0.0277975  0.02380086 0.0172191  0.01562924]\n",
            "   [0.23494782 0.13233152 0.11358121 0.10890377 0.10259051 0.10006052\n",
            "    0.09312712 0.07295736 0.02143432 0.02006581]\n",
            "   [0.18272899 0.14566234 0.14417833 0.14060499 0.10294528 0.09367248\n",
            "    0.07494392 0.06561077 0.03302242 0.01663052]\n",
            "   [0.21080445 0.18121335 0.17259824 0.11862965 0.10591871 0.06103094\n",
            "    0.05943292 0.04713823 0.03367225 0.00956123]\n",
            "   [0.3420291  0.22810408 0.0890731  0.08321378 0.07372274 0.06479937\n",
            "    0.05734294 0.04162378 0.01118937 0.00890178]\n",
            "   [0.4577818  0.30754158 0.06230019 0.03941844 0.03182063 0.02779053\n",
            "    0.02435287 0.02178239 0.01406338 0.01314809]\n",
            "   [0.15856017 0.15421888 0.12289774 0.11337924 0.11043345 0.09839239\n",
            "    0.08247105 0.06539749 0.05605442 0.03819519]\n",
            "   [0.17928226 0.16688584 0.13817212 0.11706766 0.09885415 0.08407862\n",
            "    0.07109627 0.05783079 0.04385757 0.04287465]\n",
            "   [0.20678669 0.18768664 0.13340566 0.09967152 0.08787246 0.06687416\n",
            "    0.05913821 0.05441698 0.05363394 0.05051371]\n",
            "   [0.3654403  0.3297622  0.14647162 0.04297352 0.02706973 0.02577147\n",
            "    0.0218764  0.01623074 0.01390696 0.01049708]]\n",
            "\n",
            "  [[0.1458343  0.1119823  0.11189598 0.11100604 0.10854257 0.09440759\n",
            "    0.09140797 0.08193889 0.07433476 0.06864958]\n",
            "   [0.20656607 0.15580031 0.1333135  0.09872989 0.0941653  0.07796247\n",
            "    0.06559978 0.06036348 0.05632203 0.05117705]\n",
            "   [0.21460015 0.14470167 0.1381084  0.10463523 0.10175563 0.08193705\n",
            "    0.06642979 0.06208326 0.06104058 0.02470827]\n",
            "   [0.20669404 0.16135015 0.13124843 0.10263912 0.09513266 0.07436839\n",
            "    0.07025612 0.0553612  0.05214142 0.05080836]\n",
            "   [0.14189209 0.13805082 0.12365456 0.12196275 0.10419733 0.10145807\n",
            "    0.09110967 0.08176    0.08069363 0.01522107]\n",
            "   [0.11766883 0.11731818 0.11080629 0.11068872 0.10513055 0.09576281\n",
            "    0.08985044 0.0892885  0.08720491 0.07628079]\n",
            "   [0.19142638 0.17629513 0.10405412 0.08892288 0.08604647 0.07624737\n",
            "    0.07399796 0.06978021 0.06731295 0.06591645]\n",
            "   [0.15916045 0.14810184 0.12937321 0.12638603 0.11189619 0.10259225\n",
            "    0.0866404  0.08371166 0.04094655 0.01119137]\n",
            "   [0.13065743 0.11653509 0.10817669 0.1060553  0.09876297 0.09852087\n",
            "    0.09148511 0.08882986 0.08466509 0.07631154]\n",
            "   [0.12899478 0.10935357 0.10360527 0.10059211 0.09944329 0.09724513\n",
            "    0.09684331 0.0946543  0.08870094 0.08056729]]\n",
            "\n",
            "  [[0.32052314 0.3106711  0.06992378 0.06803015 0.05989642 0.04488655\n",
            "    0.03872701 0.03790188 0.02685459 0.02258548]\n",
            "   [0.38911515 0.2318588  0.12281422 0.07941024 0.04925168 0.04010713\n",
            "    0.03867719 0.02338775 0.01522333 0.01015455]\n",
            "   [0.5135131  0.13124603 0.08473738 0.06478336 0.05244851 0.04577071\n",
            "    0.03470233 0.03063085 0.02202496 0.02014279]\n",
            "   [0.36820278 0.27255395 0.11866637 0.07846794 0.06007599 0.03794494\n",
            "    0.0222747  0.02008597 0.01687207 0.00485531]\n",
            "   [0.43434742 0.12340432 0.11377718 0.09041059 0.07226653 0.03863407\n",
            "    0.03637248 0.0337691  0.03150554 0.02551285]\n",
            "   [0.26274955 0.23727559 0.12425505 0.07974882 0.07764421 0.07217833\n",
            "    0.05358112 0.05082447 0.02901657 0.01272628]\n",
            "   [0.25344408 0.15387373 0.10219801 0.09863728 0.09045879 0.08652009\n",
            "    0.06204224 0.06003569 0.05536916 0.03742088]\n",
            "   [0.38324448 0.18126372 0.13421565 0.10852906 0.048685   0.03351039\n",
            "    0.03240583 0.03013357 0.0279739  0.02003843]\n",
            "   [0.22098409 0.16911836 0.15667981 0.13899091 0.09136322 0.0678046\n",
            "    0.05241282 0.04678694 0.03562295 0.02023623]\n",
            "   [0.26084402 0.18016808 0.12821317 0.10882089 0.07392143 0.06189544\n",
            "    0.061044   0.04430872 0.0436679  0.03711633]]\n",
            "\n",
            "  [[0.32245672 0.11816898 0.10479394 0.10185789 0.10154389 0.09569555\n",
            "    0.05750762 0.04930858 0.04516599 0.00350093]\n",
            "   [0.20571339 0.19960773 0.12593834 0.11838617 0.09476656 0.08078458\n",
            "    0.07102053 0.06177064 0.02357428 0.01843771]\n",
            "   [0.21004221 0.19937786 0.13601878 0.106469   0.09154727 0.08533786\n",
            "    0.07673696 0.0412325  0.03932534 0.01391231]\n",
            "   [0.21574429 0.2098844  0.16852123 0.11304038 0.06502029 0.06052643\n",
            "    0.06041053 0.04372811 0.0424815  0.02064284]\n",
            "   [0.31953898 0.15006413 0.1371208  0.10304777 0.09521512 0.06175973\n",
            "    0.06009609 0.02545158 0.02487401 0.02283184]\n",
            "   [0.2748221  0.13113172 0.12637746 0.1076036  0.09798332 0.08626734\n",
            "    0.08302926 0.03826368 0.03579707 0.01872439]\n",
            "   [0.1880343  0.17989706 0.15221152 0.12106892 0.11783196 0.08506133\n",
            "    0.0607136  0.04398017 0.03431082 0.01689019]\n",
            "   [0.23940286 0.14780323 0.14295705 0.12018654 0.10741436 0.08862209\n",
            "    0.08015427 0.03974979 0.02443384 0.00927582]\n",
            "   [0.22464608 0.14365427 0.12574883 0.12224771 0.1160476  0.10289833\n",
            "    0.07812715 0.04283044 0.0330447  0.01075488]\n",
            "   [0.17417422 0.1478222  0.14016856 0.11944017 0.10129215 0.09728442\n",
            "    0.08277145 0.06458773 0.05391058 0.01854851]]\n",
            "\n",
            "  [[0.73495495 0.07021614 0.04455587 0.03021613 0.0276535  0.02545838\n",
            "    0.02285883 0.01730828 0.01554307 0.01123482]\n",
            "   [0.15628102 0.15432207 0.12961586 0.12555788 0.11881696 0.08621079\n",
            "    0.07522292 0.07171068 0.05584679 0.02641504]\n",
            "   [0.18773967 0.12912983 0.11732682 0.11383611 0.11279432 0.10771273\n",
            "    0.09650943 0.05880833 0.03815652 0.03798618]\n",
            "   [0.2080896  0.15566675 0.12685917 0.12414132 0.10447486 0.07842355\n",
            "    0.068538   0.06057529 0.04587851 0.02735303]\n",
            "   [0.260628   0.16973065 0.14031349 0.13712397 0.08296496 0.07271752\n",
            "    0.0578995  0.03929355 0.02029198 0.01903633]\n",
            "   [0.4563094  0.15135837 0.11275033 0.06155465 0.05334687 0.04185627\n",
            "    0.03907022 0.03782817 0.0284841  0.01744165]\n",
            "   [0.27416113 0.17275718 0.13864833 0.12605298 0.09019827 0.05861475\n",
            "    0.04973856 0.03649454 0.03402241 0.01931185]\n",
            "   [0.29404283 0.15865861 0.14177158 0.12433877 0.10597337 0.05240076\n",
            "    0.04108367 0.03772043 0.02345941 0.02055062]\n",
            "   [0.24240194 0.24221043 0.13009368 0.06802855 0.0659058  0.06170589\n",
            "    0.06169973 0.05989478 0.04765695 0.02040222]\n",
            "   [0.40604967 0.27261236 0.06234813 0.04973195 0.03981537 0.03887432\n",
            "    0.03718225 0.03298335 0.03127662 0.02912592]]\n",
            "\n",
            "  [[0.48960426 0.20841889 0.04667228 0.04493827 0.04335542 0.04207087\n",
            "    0.03466055 0.0334998  0.02939372 0.02738602]\n",
            "   [0.65346533 0.17757389 0.10371896 0.02235911 0.01064532 0.01050549\n",
            "    0.00750092 0.00581406 0.00489807 0.00351891]\n",
            "   [0.43387496 0.24637778 0.10714414 0.0872578  0.05059041 0.02122211\n",
            "    0.01898009 0.01453593 0.01080181 0.00921498]\n",
            "   [0.5683163  0.12417884 0.08492316 0.05338537 0.05010207 0.03028057\n",
            "    0.02523821 0.02260076 0.02176566 0.01920915]\n",
            "   [0.7145239  0.06348012 0.05062731 0.04290464 0.03756461 0.02819284\n",
            "    0.02383985 0.01626832 0.01608031 0.0065181 ]\n",
            "   [0.45027953 0.34999585 0.04690137 0.03566573 0.03001613 0.02059476\n",
            "    0.02055438 0.01676671 0.01519714 0.01402829]\n",
            "   [0.31552538 0.2579293  0.12403753 0.10212865 0.05342733 0.04491894\n",
            "    0.03463863 0.03080445 0.01961542 0.01697443]\n",
            "   [0.6826026  0.13022482 0.04258374 0.03826763 0.03532741 0.0195627\n",
            "    0.01752435 0.01212188 0.01199692 0.00978798]\n",
            "   [0.4284722  0.1861072  0.1096639  0.07639468 0.05017954 0.04234973\n",
            "    0.04047512 0.03224343 0.02019598 0.01391816]\n",
            "   [0.5374471  0.19304998 0.04228677 0.03921919 0.03779282 0.03523285\n",
            "    0.03256983 0.03116389 0.02958855 0.02164906]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0\n",
            "Sum of softmax values in [0, 0, 1]: 1.0\n",
            "Sum of softmax values in [0, 0, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 5]: 1.0\n",
            "Sum of softmax values in [0, 1, 6]: 1.0\n",
            "Sum of softmax values in [0, 1, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 5]: 1.0\n",
            "Sum of softmax values in [0, 2, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 8]: 1.0\n",
            "Sum of softmax values in [0, 2, 9]: 1.0\n",
            "Sum of softmax values in [0, 3, 0]: 1.0\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 1.0\n",
            "Sum of softmax values in [0, 3, 5]: 1.0\n",
            "Sum of softmax values in [0, 3, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 0]: 1.0\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 4]: 1.0\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 5, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 1.0\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 5, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0\n",
            "Sum of softmax values in [0, 6, 3]: 1.0\n",
            "Sum of softmax values in [0, 6, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 1.0\n",
            "Sum of softmax values in [0, 6, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 1.0\n",
            "Sum of softmax values in [0, 7, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 1.0\n",
            "Sum of softmax values in [0, 8, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 5]: 1.0\n",
            "Sum of softmax values in [0, 8, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 7]: 1.0\n",
            "Sum of softmax values in [0, 8, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 7]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 9, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 1.0\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 1]: 1.0\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax sorted_attention_scores가 ./model/softmax_sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1Pr9O46V_Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "hhRL4CRO_QSf"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_SM_bert_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "6xc2_wJsIB-b"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_bert_layer1.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_bert_layer1.pkl_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1jdq5E2fjNWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/restored_softmax.pkl\"\n",
        "text_file_path = \"/./content/model/restored_softmax_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "V-oYzGDQCZvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_bert_layer1.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_bert_layer1.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "KSt61FVn6gBD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/softmax_sorted_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "THbCGtMz_twq",
        "outputId": "112c2397-825f-4837-ce06-6a4df446ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.10749399 0.09632882 0.0954031  0.09513693 0.09258841\n",
            "  0.09229334 0.09164356 0.0910974  0.0900939 ]\n",
            " [0.12004588 0.10565753 0.10268969 0.10120098 0.09709173 0.0958351\n",
            "  0.09575053 0.09450836 0.0938547  0.09336555]\n",
            " [0.13786007 0.11296417 0.10104739 0.09357624 0.09350549 0.09287033\n",
            "  0.09284727 0.09269542 0.09188308 0.09075052]\n",
            " [0.11074849 0.10814226 0.10393477 0.10047178 0.10030901 0.09913348\n",
            "  0.09670201 0.09443171 0.09372903 0.09239744]\n",
            " [0.1193184  0.10324923 0.10189565 0.09932904 0.09908514 0.09784093\n",
            "  0.09755905 0.0950703  0.09426644 0.09238588]\n",
            " [0.1328674  0.10326969 0.09898279 0.09854479 0.09625035 0.09615592\n",
            "  0.0958468  0.09484941 0.09185758 0.0913753 ]\n",
            " [0.11864013 0.1089671  0.10785589 0.10248473 0.09685351 0.09558748\n",
            "  0.09497281 0.09192704 0.0917357  0.0909756 ]\n",
            " [0.12209511 0.1143846  0.10398746 0.09853819 0.09724706 0.09612775\n",
            "  0.09440193 0.09189809 0.09072162 0.09059814]\n",
            " [0.13755944 0.11774409 0.09577599 0.0939422  0.09348241 0.09323013\n",
            "  0.09304722 0.09287393 0.09189644 0.09044815]\n",
            " [0.12786184 0.10347308 0.10287845 0.10249271 0.09869479 0.0964129\n",
            "  0.0952139  0.09130668 0.09093261 0.09073301]] [[0.11400125 0.1034065  0.1010711  0.1006773  0.09990909 0.09957507\n",
            "  0.09785708 0.09670063 0.09466569 0.09213626]\n",
            " [0.12259456 0.10524756 0.10206269 0.09920018 0.09916254 0.09589188\n",
            "  0.09563524 0.09519612 0.09302149 0.09198767]\n",
            " [0.12747219 0.10719077 0.10062093 0.09860631 0.09690202 0.0963392\n",
            "  0.09631989 0.09255879 0.0925522  0.09143765]\n",
            " [0.10658482 0.10630877 0.10104766 0.1003748  0.10008461 0.09871509\n",
            "  0.0979219  0.09733845 0.09657256 0.09505137]\n",
            " [0.11034425 0.10167924 0.10102019 0.10027704 0.10000083 0.09928491\n",
            "  0.09772887 0.09770507 0.09617376 0.0957859 ]\n",
            " [0.10516495 0.10368128 0.10063306 0.1006038  0.10018845 0.09995812\n",
            "  0.09989405 0.09896458 0.09562299 0.09528879]\n",
            " [0.11380466 0.10230775 0.1017336  0.10014401 0.09873901 0.09837577\n",
            "  0.09824028 0.09637209 0.09522659 0.0950562 ]\n",
            " [0.12674263 0.10445353 0.09908456 0.09906299 0.0978529  0.09758332\n",
            "  0.09610719 0.09558626 0.09211903 0.09140754]\n",
            " [0.10645555 0.10579788 0.10304288 0.10144265 0.09954634 0.09866013\n",
            "  0.09808288 0.097651   0.09623402 0.09308667]\n",
            " [0.11155472 0.10681042 0.1043413  0.10225179 0.0984853  0.09746661\n",
            "  0.09710175 0.09461471 0.09410094 0.09327243]] [[0.11106927 0.109332   0.10838971 0.10667203 0.10396456 0.09332467\n",
            "  0.09290537 0.09214137 0.09158181 0.09061927]\n",
            " [0.11498808 0.10829917 0.10712849 0.10341936 0.09627965 0.0959329\n",
            "  0.09385677 0.09360978 0.09335104 0.09313468]\n",
            " [0.10907564 0.1086611  0.10594706 0.10251999 0.09717342 0.09607369\n",
            "  0.09553417 0.09523229 0.09514245 0.0946402 ]\n",
            " [0.12777801 0.11388236 0.09597065 0.09547208 0.09541373 0.09527735\n",
            "  0.09474532 0.09463353 0.09392282 0.09290416]\n",
            " [0.11447315 0.10678963 0.10269815 0.10112287 0.10047487 0.09732886\n",
            "  0.0970234  0.09365991 0.09344386 0.09298529]\n",
            " [0.11844434 0.10639787 0.10390373 0.10112502 0.09893835 0.09716936\n",
            "  0.0958861  0.09353664 0.0925469  0.09205168]\n",
            " [0.11324795 0.10864487 0.10467929 0.10341784 0.10152826 0.09656344\n",
            "  0.09464015 0.0934985  0.09244199 0.09133781]\n",
            " [0.11619101 0.10672598 0.10503597 0.10199555 0.09804323 0.09668372\n",
            "  0.09610645 0.09338766 0.0933179  0.09251253]\n",
            " [0.11661826 0.11136508 0.10871449 0.09768787 0.09678789 0.09655615\n",
            "  0.09494792 0.09265881 0.09243154 0.09223206]\n",
            " [0.13535918 0.10957498 0.10064787 0.09704289 0.09668809 0.0939795\n",
            "  0.0930492  0.09208082 0.09086873 0.09070873]] [[0.1255899  0.10366833 0.10065787 0.09996307 0.09845075 0.09556752\n",
            "  0.09483397 0.09431619 0.09430879 0.09264354]\n",
            " [0.13242505 0.1023296  0.1009952  0.09722893 0.0965215  0.09473015\n",
            "  0.09469819 0.09453561 0.09363452 0.09290122]\n",
            " [0.10879505 0.10861369 0.10704175 0.0996678  0.09955349 0.0962432\n",
            "  0.09612511 0.09592903 0.09408776 0.09394309]\n",
            " [0.12335853 0.109509   0.10271551 0.09744254 0.09695764 0.09671901\n",
            "  0.09527482 0.09343539 0.09332724 0.09126032]\n",
            " [0.1051129  0.1042406  0.1015951  0.10096215 0.10058594 0.09961344\n",
            "  0.09938804 0.09867377 0.09613637 0.09369161]\n",
            " [0.11151089 0.10542171 0.10479862 0.10213321 0.0991762  0.09746461\n",
            "  0.09690585 0.09604911 0.09489696 0.09164282]\n",
            " [0.10953204 0.10539693 0.10379548 0.10073565 0.100105   0.09728067\n",
            "  0.09637927 0.09632144 0.09549578 0.09495777]\n",
            " [0.11535057 0.11265247 0.10442845 0.10190308 0.0975237  0.09578036\n",
            "  0.094757   0.0945795  0.09181842 0.09120651]\n",
            " [0.11083733 0.10423398 0.10382918 0.10361786 0.09832249 0.09829199\n",
            "  0.0961586  0.09549905 0.0948538  0.09435575]\n",
            " [0.12480727 0.10181123 0.1017132  0.09872679 0.09662166 0.09624251\n",
            "  0.09611325 0.09551828 0.094544   0.0939018 ]] [[0.13122697 0.11838867 0.09999187 0.09693875 0.09442222 0.0934737\n",
            "  0.09302619 0.09113406 0.09096654 0.090431  ]\n",
            " [0.11642858 0.11028487 0.10202178 0.09834425 0.09758889 0.09684826\n",
            "  0.09614606 0.0955855  0.09482107 0.09193079]\n",
            " [0.13121082 0.11401134 0.10236181 0.09529249 0.09509484 0.09347839\n",
            "  0.09292267 0.09219655 0.09185337 0.09157771]\n",
            " [0.11182034 0.11131455 0.10122852 0.09885452 0.09775028 0.09756619\n",
            "  0.0970481  0.09618475 0.09485637 0.09337639]\n",
            " [0.1190371  0.11268517 0.10337377 0.09892204 0.09817803 0.09598743\n",
            "  0.09449787 0.0939927  0.09308489 0.09024091]\n",
            " [0.1231669  0.11651503 0.10195184 0.09985358 0.09462189 0.09450209\n",
            "  0.0933025  0.09328135 0.09239239 0.09041242]\n",
            " [0.13613823 0.11589173 0.09990533 0.09561177 0.09451851 0.09313484\n",
            "  0.09205063 0.09152158 0.09145974 0.08976758]\n",
            " [0.1390204  0.11394679 0.10029403 0.09454747 0.09414111 0.09320738\n",
            "  0.09201896 0.09160782 0.0911697  0.09004641]\n",
            " [0.12268637 0.11812288 0.09949172 0.09598787 0.09570937 0.09495543\n",
            "  0.09386134 0.09341761 0.09317895 0.0925884 ]\n",
            " [0.11522201 0.10869771 0.10425299 0.10174679 0.09862161 0.09762945\n",
            "  0.09581748 0.09348565 0.0927586  0.09176765]] [[0.19221878 0.09784383 0.08963636 0.08957554 0.08923525 0.08854745\n",
            "  0.08842815 0.08823875 0.08822448 0.08805135]\n",
            " [0.11539409 0.10904791 0.10234714 0.10070689 0.09962562 0.09711855\n",
            "  0.09595603 0.09456613 0.09366652 0.09157109]\n",
            " [0.11589902 0.11491495 0.10738936 0.10107232 0.09720412 0.09633563\n",
            "  0.09241604 0.09182198 0.09179646 0.09115013]\n",
            " [0.11951818 0.10833368 0.10711588 0.09994849 0.09823545 0.09602655\n",
            "  0.09344209 0.09324856 0.09276845 0.09136264]\n",
            " [0.11600425 0.10421543 0.10398513 0.09926617 0.09877275 0.09778262\n",
            "  0.09739378 0.09617388 0.09505376 0.09135223]\n",
            " [0.11857469 0.10661126 0.1019878  0.09983031 0.09922573 0.09874775\n",
            "  0.09660321 0.09393042 0.09363413 0.09085469]\n",
            " [0.13629879 0.09932628 0.09855013 0.09824003 0.09734751 0.0959255\n",
            "  0.09526379 0.09510257 0.09359585 0.09034953]\n",
            " [0.1166717  0.10794695 0.10213608 0.10188431 0.10099822 0.09603059\n",
            "  0.09559518 0.09504844 0.09319708 0.09049152]\n",
            " [0.10728315 0.1037925  0.10343576 0.10218531 0.10196406 0.10056645\n",
            "  0.09859848 0.09630246 0.0945216  0.09135017]\n",
            " [0.18254873 0.09307522 0.09207456 0.09193303 0.09161045 0.09072111\n",
            "  0.0906655  0.08960212 0.08930827 0.08846102]] [[0.11651556 0.11437199 0.11160105 0.09936865 0.09705305 0.09333326\n",
            "  0.09255443 0.09213877 0.09158062 0.09148257]\n",
            " [0.11088444 0.10870033 0.10675944 0.10344209 0.10087191 0.09622392\n",
            "  0.09453411 0.09344795 0.09310738 0.09202842]\n",
            " [0.10944903 0.10575333 0.10088027 0.10072865 0.09912886 0.09830763\n",
            "  0.0975268  0.09695422 0.09693255 0.09433866]\n",
            " [0.10834975 0.10484561 0.10161021 0.10110388 0.10089392 0.0985859\n",
            "  0.09677326 0.09623311 0.09595081 0.0956535 ]\n",
            " [0.11836878 0.10995642 0.10637329 0.10316958 0.10050903 0.09407511\n",
            "  0.09224288 0.09195571 0.09188712 0.09146208]\n",
            " [0.11637533 0.107494   0.10246739 0.10176704 0.10082836 0.09627321\n",
            "  0.0941247  0.09410713 0.09370921 0.0928537 ]\n",
            " [0.17207588 0.10849798 0.09107385 0.09054288 0.09051681 0.08970771\n",
            "  0.08961482 0.0895204  0.08928338 0.08916631]\n",
            " [0.11313932 0.10984481 0.10417305 0.1018426  0.10149228 0.09582976\n",
            "  0.09468491 0.09335858 0.09303081 0.09260397]\n",
            " [0.12644607 0.10036467 0.10026442 0.09970112 0.09940325 0.0972826\n",
            "  0.09482437 0.09429312 0.09427355 0.09314673]\n",
            " [0.1405463  0.1159537  0.10057663 0.09612732 0.09178676 0.09127815\n",
            "  0.09113301 0.09111058 0.0908433  0.09064425]] [[0.10564238 0.10292613 0.10179431 0.10042136 0.09872103 0.09872036\n",
            "  0.09871954 0.09819727 0.09806671 0.09679093]\n",
            " [0.12064464 0.10207136 0.10152597 0.10133596 0.09803465 0.09705557\n",
            "  0.09630508 0.09615217 0.09468193 0.09219266]\n",
            " [0.10665165 0.10452332 0.10275489 0.10125034 0.10006174 0.09947256\n",
            "  0.09891605 0.097019   0.09581892 0.0935316 ]\n",
            " [0.11108197 0.1069545  0.10360119 0.10301835 0.09847432 0.09757042\n",
            "  0.09722493 0.0958219  0.09537969 0.09087261]\n",
            " [0.10333292 0.10259257 0.10245122 0.10149055 0.1004594  0.09958882\n",
            "  0.09949169 0.09887893 0.09800059 0.09371338]\n",
            " [0.10969684 0.10169461 0.10050323 0.09977714 0.09924264 0.0991381\n",
            "  0.09875637 0.09777958 0.09685702 0.09655443]\n",
            " [0.10171361 0.10146581 0.10124384 0.10099129 0.09960892 0.09923731\n",
            "  0.09916671 0.09902416 0.09887232 0.098676  ]\n",
            " [0.10602034 0.10511005 0.10080007 0.10076638 0.09995149 0.09937529\n",
            "  0.09768594 0.09724063 0.09691003 0.09613974]\n",
            " [0.10654233 0.10577352 0.10148946 0.10047438 0.10002071 0.0985586\n",
            "  0.09784236 0.09719845 0.0961601  0.09594019]\n",
            " [0.10370079 0.10097425 0.10082368 0.10058665 0.10050481 0.09954733\n",
            "  0.09918906 0.09886386 0.09817427 0.0976353 ]] [[0.13101614 0.10155541 0.09949803 0.09879939 0.09736524 0.09523892\n",
            "  0.09497467 0.09472965 0.0946505  0.09217209]\n",
            " [0.16043125 0.09743757 0.09690606 0.09600316 0.09286897 0.09224714\n",
            "  0.09165689 0.09157068 0.09061959 0.09025875]\n",
            " [0.12229677 0.10795741 0.09818567 0.09794795 0.09757593 0.09644455\n",
            "  0.0955545  0.09544124 0.09520435 0.09339152]\n",
            " [0.14856924 0.10204253 0.10037015 0.09949326 0.09272838 0.09220155\n",
            "  0.09164988 0.09154554 0.09090395 0.0904955 ]\n",
            " [0.13742623 0.10216511 0.10204151 0.09627024 0.0957383  0.09423456\n",
            "  0.09366982 0.09324936 0.09266366 0.09254126]\n",
            " [0.10827874 0.10729821 0.10317886 0.10045856 0.09872456 0.09777663\n",
            "  0.09749199 0.09618194 0.09610833 0.09450217]\n",
            " [0.13456634 0.10423085 0.10157086 0.09865664 0.09621219 0.09613518\n",
            "  0.09293942 0.09284518 0.09169888 0.0911445 ]\n",
            " [0.15805185 0.09799827 0.09751602 0.09492274 0.09333222 0.09234674\n",
            "  0.0920763  0.0920596  0.09175216 0.0899441 ]\n",
            " [0.15166666 0.10440575 0.09550705 0.09392787 0.0938193  0.09349321\n",
            "  0.09203372 0.0918356  0.09167873 0.09163215]\n",
            " [0.10974686 0.10353356 0.10199118 0.10157139 0.10014214 0.09902046\n",
            "  0.09866758 0.09735171 0.09568052 0.09229465]] [[0.11696494 0.10561763 0.1026743  0.10018165 0.10010299 0.09984183\n",
            "  0.09757758 0.09490325 0.09146243 0.09067347]\n",
            " [0.12616728 0.10725618 0.10489378 0.10077072 0.09898864 0.09442478\n",
            "  0.09362216 0.09245644 0.09102614 0.09039382]\n",
            " [0.12389978 0.10335313 0.1023483  0.10156903 0.10070038 0.09829431\n",
            "  0.09435275 0.09222058 0.09215761 0.09110405]\n",
            " [0.13135895 0.11509195 0.09834989 0.09702215 0.09552077 0.09462588\n",
            "  0.09443802 0.09247658 0.09081339 0.09030242]\n",
            " [0.11786105 0.10425267 0.10283441 0.10009396 0.0991247  0.098704\n",
            "  0.09789151 0.09510923 0.09314692 0.09098157]\n",
            " [0.11120586 0.11066937 0.10239101 0.1016436  0.09920651 0.09874985\n",
            "  0.09706905 0.09613745 0.0918766  0.09105068]\n",
            " [0.11243922 0.11034236 0.1020238  0.10166942 0.09871032 0.09781794\n",
            "  0.0956016  0.09512395 0.09494527 0.09132624]\n",
            " [0.11789278 0.10887911 0.1030987  0.10161806 0.09805292 0.09680559\n",
            "  0.09550236 0.09425528 0.09290124 0.09099401]\n",
            " [0.10826562 0.10599791 0.10526626 0.10162396 0.10086945 0.09868338\n",
            "  0.09792026 0.09593145 0.09358449 0.09185722]\n",
            " [0.11110785 0.10693549 0.10325618 0.10216829 0.0989797  0.09897416\n",
            "  0.09823224 0.09677328 0.09239224 0.09118057]] [[0.13062459 0.12001117 0.10074113 0.09474252 0.09386603 0.09363971\n",
            "  0.09245858 0.09179718 0.0914835  0.09063558]\n",
            " [0.10933135 0.10389441 0.10218149 0.10083347 0.0987934  0.09805172\n",
            "  0.09762    0.09760492 0.09685692 0.09483222]\n",
            " [0.11850341 0.10194103 0.10119431 0.09937377 0.09878195 0.09761009\n",
            "  0.09628828 0.09560166 0.09553706 0.09516849]\n",
            " [0.1064885  0.10433034 0.10290188 0.10156679 0.1006103  0.09858835\n",
            "  0.09808301 0.09728806 0.09667599 0.09346682]\n",
            " [0.11237273 0.10942037 0.10832172 0.0995042  0.09650969 0.0957105\n",
            "  0.09499046 0.09493661 0.09430388 0.09392986]\n",
            " [0.10560665 0.10434524 0.10314914 0.10254232 0.1011281  0.09828933\n",
            "  0.09727395 0.09697267 0.09606361 0.094629  ]\n",
            " [0.12966645 0.11357925 0.11246008 0.09314593 0.09302556 0.09259983\n",
            "  0.09171455 0.09159797 0.091246   0.09096438]\n",
            " [0.11097045 0.10328139 0.10222587 0.10110361 0.10058366 0.09976029\n",
            "  0.09791066 0.09548536 0.09508933 0.09358936]\n",
            " [0.10964395 0.10826695 0.1075901  0.10601512 0.09815793 0.0960831\n",
            "  0.09551324 0.09348555 0.09266593 0.09257816]\n",
            " [0.12031083 0.11849108 0.11690799 0.09304062 0.09284412 0.09219547\n",
            "  0.09208853 0.0916934  0.09121756 0.09121044]] [[0.13884439 0.10810776 0.09679952 0.09505253 0.0942751  0.09378396\n",
            "  0.09362106 0.0932615  0.09313487 0.09311935]\n",
            " [0.12123885 0.11415909 0.097437   0.09722511 0.09567007 0.09557963\n",
            "  0.09503611 0.09490646 0.09468962 0.09405799]\n",
            " [0.132849   0.12850621 0.09917664 0.09285689 0.0927122  0.0919118\n",
            "  0.09117553 0.0905907  0.09016381 0.09005725]\n",
            " [0.1297989  0.12024375 0.1006963  0.09401721 0.09367883 0.09252627\n",
            "  0.09244621 0.09233411 0.09221454 0.09204385]\n",
            " [0.12638246 0.12465423 0.099479   0.09614468 0.09545842 0.09220749\n",
            "  0.09193899 0.09154938 0.0913196  0.09086577]\n",
            " [0.13141826 0.12846188 0.09653927 0.09354375 0.09281931 0.09193935\n",
            "  0.09180678 0.09180298 0.09110983 0.09055864]\n",
            " [0.1273724  0.11926056 0.09824953 0.09632255 0.09553046 0.09303466\n",
            "  0.09287931 0.09279443 0.09237044 0.09218565]\n",
            " [0.12697604 0.1178524  0.10446963 0.09399208 0.09357508 0.09352376\n",
            "  0.09327863 0.09295432 0.09214232 0.0912357 ]\n",
            " [0.11518867 0.11475074 0.1059187  0.10441453 0.09405647 0.09398486\n",
            "  0.09382902 0.09279858 0.09260277 0.09245568]\n",
            " [0.15028572 0.10757346 0.09661791 0.0938767  0.09353498 0.09265015\n",
            "  0.09182073 0.09176069 0.09112944 0.09075014]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open( \"/./content/model/softmax_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "xhGzU2ZG_t3b",
        "outputId": "54c8137e-eff2-4565-b7b1-e1c1542b0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792055 0.09109741 0.09164357 0.09009392 0.09632883 0.09540311\n",
            "  0.107494   0.09258842 0.09229336 0.09513694]\n",
            " [0.12004586 0.10268968 0.10120098 0.09575053 0.09583508 0.09709172\n",
            "  0.10565752 0.09385469 0.09336554 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185757 0.09137529 0.09854478 0.09584679 0.0948494\n",
            "  0.09615591 0.13286738 0.09898278 0.10326968]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519613 0.09198768 0.10206269 0.10524758 0.0930215  0.09916256\n",
            "  0.09589189 0.09563526 0.09920019 0.12259457]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.09578589 0.0992849  0.10167923 0.10000082 0.09617375 0.10027704\n",
            "  0.09772886 0.09770505 0.10102018 0.11034424]\n",
            " [0.09562298 0.09995811 0.10516494 0.10018844 0.09989404 0.10063305\n",
            "  0.10060379 0.09528878 0.10368127 0.09896457]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908457 0.09758333 0.09906299 0.10445354 0.09140754 0.09558626\n",
            "  0.09211904 0.0961072  0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.10933199 0.09290536 0.09061925 0.0915818  0.1083897  0.10396454\n",
            "  0.11106926 0.09214136 0.09332465 0.10667202]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639788 0.09716938 0.10112503 0.09205169 0.09254691\n",
            "  0.09353665 0.11844435 0.09588612 0.09893835]\n",
            " [0.11324794 0.09464014 0.0913378  0.09244198 0.10467927 0.10152824\n",
            "  0.10341783 0.09349848 0.09656344 0.10864485]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.0949479  0.11661825 0.09678788 0.11136506 0.0926588  0.09223205\n",
            "  0.09243153 0.09768786 0.09655614 0.10871448]\n",
            " [0.1353592  0.0939795  0.09070874 0.09086874 0.0966881  0.0970429\n",
            "  0.10957499 0.09208083 0.09304921 0.10064787]] [[0.09431619 0.09845076 0.10366833 0.09264354 0.10065788 0.09556752\n",
            "  0.0943088  0.09483398 0.09996308 0.12558992]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113407 0.09302621 0.09096655 0.09999189 0.09347371\n",
            "  0.11838868 0.09693877 0.09442223 0.13122699]\n",
            " [0.11642858 0.09614605 0.11028486 0.09684824 0.09834424 0.09758888\n",
            "  0.10202176 0.09558548 0.09193078 0.09482107]\n",
            " [0.09292267 0.1023618  0.13121082 0.11401133 0.0915777  0.09347839\n",
            "  0.09219654 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024093 0.0939927  0.09598744 0.09817804 0.09449788 0.09892205\n",
            "  0.10337377 0.11268519 0.0930849  0.11903711]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152159 0.09205063 0.09145974 0.09561178 0.09990533\n",
            "  0.09451851 0.11589174 0.09313484 0.13613825]\n",
            " [0.09160781 0.09116969 0.09004641 0.09201896 0.09454746 0.0941411\n",
            "  0.10029402 0.11394678 0.09320737 0.13902038]\n",
            " [0.09258841 0.09495544 0.09341762 0.09949172 0.09386135 0.09570938\n",
            "  0.09598789 0.11812289 0.09317896 0.12268639]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.0904915  0.10794695 0.10099821 0.09559517 0.1166717  0.10213607\n",
            "  0.1018843  0.09319707 0.09603058 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912887 0.10944904 0.09433867 0.10088028 0.09830764 0.0975268\n",
            "  0.10072865 0.09693256 0.09695423 0.10575334]\n",
            " [0.10161023 0.09677327 0.10834976 0.10484561 0.10110389 0.09623312\n",
            "  0.0985859  0.0956535  0.09595082 0.10089393]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246737 0.10176703 0.09412469 0.10082835 0.0937092  0.09410712\n",
            "  0.0928537  0.11637531 0.0962732  0.10749398]\n",
            " [0.17207587 0.08952039 0.08916631 0.0897077  0.09107384 0.08961482\n",
            "  0.0905168  0.09054288 0.08928337 0.10849796]\n",
            " [0.1098448  0.10417304 0.0930308  0.0946849  0.09335857 0.09582975\n",
            "  0.09260397 0.10184258 0.10149226 0.11313931]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.14054629 0.09064424 0.09111057 0.0908433  0.09612731 0.09127814\n",
            "  0.10057662 0.09178675 0.091133   0.11595369]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665164 0.10275488 0.09353159 0.10125034 0.09947255 0.10006173\n",
            "  0.09701899 0.09581891 0.09891603 0.10452331]\n",
            " [0.11108198 0.09722494 0.09757043 0.09087262 0.09847433 0.10360121\n",
            "  0.09582192 0.10695451 0.0953797  0.10301836]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654232 0.1000207  0.09855858 0.09616009 0.10047437 0.09784234\n",
            "  0.09719844 0.10148945 0.09594018 0.1057735 ]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743756 0.16043124 0.09025874 0.09600315 0.09286896 0.09061958\n",
            "  0.09224714 0.09157067 0.09165689 0.09690605]\n",
            " [0.12229678 0.09520435 0.10795742 0.09818569 0.09339153 0.09644455\n",
            "  0.09794796 0.09544125 0.09757594 0.09555452]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872455 0.09450217 0.09777661 0.10317885 0.09749197 0.09618193\n",
            "  0.09610832 0.10827873 0.10045855 0.1072982 ]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.08994411 0.09333223 0.09175216 0.09207631\n",
            "  0.09234674 0.15805186 0.09799828 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077073 0.1048938  0.1072562  0.09898866 0.09102615 0.09362218\n",
            "  0.09039383 0.09442478 0.09245645 0.1261673 ]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135894 0.09834988 0.09081338 0.09247658\n",
            "  0.09030242 0.09443802 0.09552076 0.11509194]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290123 0.09680557 0.11789276 0.10161805 0.09425527 0.0980529\n",
            "  0.090994   0.10309868 0.09550235 0.1088791 ]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062458 0.09245858 0.0914835  0.09386603 0.10074112 0.09363971\n",
            "  0.12001116 0.09063558 0.09179717 0.09474251]\n",
            " [0.09483223 0.09760492 0.10083348 0.10933136 0.1021815  0.09805173\n",
            "  0.09762    0.09685693 0.10389443 0.09879342]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123886 0.11415911 0.09557965 0.09490647 0.09503613 0.09567008\n",
            "  0.09722512 0.09468964 0.09405801 0.09743701]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024376 0.09221455 0.09204386 0.12979892 0.09252628 0.09244622\n",
            "  0.09233411 0.09401721 0.09367883 0.10069631]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.0928193  0.09193934 0.09055864 0.09180677 0.09110983\n",
            "  0.09180297 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697606 0.0912357  0.09214232 0.09352377 0.09357508 0.09295433\n",
            "  0.09327864 0.1178524  0.09399209 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 정렬된 데이터와 원래 인덱스 로드\n",
        "sorted_file_path3 = \"./model/sorted_attention_scores.pkl\"\n",
        "indices_file_path3 = \"./model/original_indices.pkl\"\n",
        "restored_file_path3 = \"./model/restored_softmax.pkl\"\n",
        "\n",
        "with open(sorted_file_path3, \"rb\") as f:\n",
        "    sorted_attention_scores = pickle.load(f)\n",
        "\n",
        "with open(indices_file_path3, \"rb\") as f:\n",
        "    original_indices = pickle.load(f)\n",
        "\n",
        "# 2. 원래 순서로 복원\n",
        "restored_attention_scores = np.zeros_like(sorted_attention_scores)\n",
        "for i in range(sorted_attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(sorted_attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(sorted_attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 순서로 복원\n",
        "            inverse_indices = np.argsort(original_indices[i, j, k])  # 원래 순서 찾기\n",
        "            restored_attention_scores[i, j, k] = sorted_attention_scores[i, j, k][inverse_indices]\n",
        "\n",
        "# 3. 복원된 결과를 새로운 파일에 저장\n",
        "with open(restored_file_path3, \"wb\") as f:\n",
        "    pickle.dump(restored_attention_scores, f)\n",
        "\n",
        "print(f\"복원된 softmax attention_scores가 {restored_file_path3}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "MIofHJFRCG0b",
        "outputId": "ea3b115a-5c7c-49f1-89e6-6715fa22bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복원된 softmax attention_scores가 ./model/restored_softmax.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/cordic_dec_val_sortedF.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "BIQ4u34qCk1E",
        "outputId": "a20529e4-2072-43c2-a418-05a061a6d78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5814208984\n",
            "0.0137939453\n",
            "0.0335693359\n",
            "0.0335693359\n",
            "0.0123291016\n",
            "0.1212158203\n",
            "0.0123291016\n",
            "0.0301513672\n",
            "0.0928955078\n",
            "0.0675048828\n",
            "0.0101318359\n",
            "0.0509033203\n",
            "0.5772705078\n",
            "0.2122802734\n",
            "0.0780029297\n",
            "0.0181884766\n",
            "0.0101318359\n",
            "0.0198974609\n",
            "0.0098876953\n",
            "0.0101318359\n",
            "0.0662841797\n",
            "0.2620849609\n",
            "0.1075439453\n",
            "0.3985595703\n",
            "0.0235595703\n",
            "0.0372314453\n",
            "0.0333251953\n",
            "0.0140380859\n",
            "0.0391845703\n",
            "0.0140380859\n",
            "0.0118408203\n",
            "0.0892333984\n",
            "0.6593017578\n",
            "0.0323486328\n",
            "0.1541748047\n",
            "0.0118408203\n",
            "0.0118408203\n",
            "0.0086669922\n",
            "0.0052490234\n",
            "0.0130615234\n",
            "0.0054931641\n",
            "0.3140869141\n",
            "0.0699462891\n",
            "0.3175048828\n",
            "0.0743408203\n",
            "0.0426025391\n",
            "0.0155029297\n",
            "0.1024169922\n",
            "0.0145263672\n",
            "0.0426025391\n",
            "0.1353759766\n",
            "0.0496826172\n",
            "0.0281982422\n",
            "0.0496826172\n",
            "0.1234130859\n",
            "0.0684814453\n",
            "0.0482177734\n",
            "0.0496826172\n",
            "0.2249755859\n",
            "0.2210693359\n",
            "0.0208740234\n",
            "0.0570068359\n",
            "0.0208740234\n",
            "0.0128173828\n",
            "0.1951904297\n",
            "0.0985107422\n",
            "0.0479736328\n",
            "0.4158935547\n",
            "0.0570068359\n",
            "0.0721435547\n",
            "0.0181884766\n",
            "0.0181884766\n",
            "0.0196533203\n",
            "0.0198974609\n",
            "0.1031494141\n",
            "0.0955810547\n",
            "0.1878662109\n",
            "0.0496826172\n",
            "0.1348876953\n",
            "0.3521728516\n",
            "0.0472412109\n",
            "0.0054931641\n",
            "0.0194091797\n",
            "0.0040283203\n",
            "0.0147705078\n",
            "0.0286865234\n",
            "0.0782470703\n",
            "0.1444091797\n",
            "0.0740966797\n",
            "0.5811767578\n",
            "0.0716552734\n",
            "0.0106201172\n",
            "0.0079345703\n",
            "0.0198974609\n",
            "0.0042724609\n",
            "0.1951904297\n",
            "0.0118408203\n",
            "0.0594482422\n",
            "0.5308837891\n",
            "0.0858154297\n",
            "0.0350341797\n",
            "0.0892333984\n",
            "0.1580810547\n",
            "0.0953369141\n",
            "0.0953369141\n",
            "0.0208740234\n",
            "0.0953369141\n",
            "0.0916748047\n",
            "0.0589599609\n",
            "0.2593994141\n",
            "0.0164794922\n",
            "0.0628662109\n",
            "0.2257080078\n",
            "0.1761474609\n",
            "0.0833740234\n",
            "0.0306396484\n",
            "0.0828857422\n",
            "0.0457763672\n",
            "0.0504150391\n",
            "0.2257080078\n",
            "0.0933837891\n",
            "0.0933837891\n",
            "0.0653076172\n",
            "0.0738525391\n",
            "0.0933837891\n",
            "0.0338134766\n",
            "0.1273193359\n",
            "0.0933837891\n",
            "0.0338134766\n",
            "0.2899169922\n",
            "0.0528564453\n",
            "0.0709228516\n",
            "0.0640869141\n",
            "0.0653076172\n",
            "0.1573486328\n",
            "0.0709228516\n",
            "0.0677490234\n",
            "0.0850830078\n",
            "0.0709228516\n",
            "0.2930908203\n",
            "0.0150146484\n",
            "0.0723876953\n",
            "0.1229248047\n",
            "0.0780029297\n",
            "0.0723876953\n",
            "0.0218505859\n",
            "0.1968994141\n",
            "0.1968994141\n",
            "0.0264892578\n",
            "0.1968994141\n",
            "0.0260009766\n",
            "0.0858154297\n",
            "0.1356201172\n",
            "0.1116943359\n",
            "0.1343994141\n",
            "0.0311279297\n",
            "0.0655517578\n",
            "0.1517333984\n",
            "0.0640869141\n",
            "0.1932373047\n",
            "0.0748291016\n",
            "0.0811767578\n",
            "0.0748291016\n",
            "0.0714111328\n",
            "0.0821533203\n",
            "0.0338134766\n",
            "0.0992431641\n",
            "0.2032470703\n",
            "0.0748291016\n",
            "0.2032470703\n",
            "0.0765380859\n",
            "0.0819091797\n",
            "0.1585693359\n",
            "0.0853271484\n",
            "0.0765380859\n",
            "0.0281982422\n",
            "0.1485595703\n",
            "0.0765380859\n",
            "0.0594482422\n",
            "0.2083740234\n",
            "0.0269775391\n",
            "0.1075439453\n",
            "0.0914306641\n",
            "0.0948486328\n",
            "0.0953369141\n",
            "0.0626220703\n",
            "0.0726318359\n",
            "0.2076416016\n",
            "0.0762939453\n",
            "0.1641845703\n",
            "0.0538330078\n",
            "0.0748291016\n",
            "0.1717529297\n",
            "0.1141357422\n",
            "0.1114501953\n",
            "0.0294189453\n",
            "0.0941162109\n",
            "0.0748291016\n",
            "0.0714111328\n",
            "0.2034912109\n",
            "0.1632080078\n",
            "0.0072021484\n",
            "0.0037841797\n",
            "0.0216064453\n",
            "0.0025634766\n",
            "0.1732177734\n",
            "0.0216064453\n",
            "0.0076904297\n",
            "0.4747314453\n",
            "0.1212158203\n",
            "0.0220947266\n",
            "0.1497802734\n",
            "0.4476318359\n",
            "0.2344970703\n",
            "0.0198974609\n",
            "0.0145263672\n",
            "0.0101318359\n",
            "0.0699462891\n",
            "0.0079345703\n",
            "0.0220947266\n",
            "0.0357666016\n",
            "0.1385498047\n",
            "0.2650146484\n",
            "0.2049560547\n",
            "0.0311279297\n",
            "0.0357666016\n",
            "0.0963134766\n",
            "0.0885009766\n",
            "0.0357666016\n",
            "0.0682373047\n",
            "0.0528564453\n",
            "0.0621337891\n",
            "0.5311279297\n",
            "0.1981201172\n",
            "0.0250244141\n",
            "0.0250244141\n",
            "0.0157470703\n",
            "0.0567626953\n",
            "0.0089111328\n",
            "0.0250244141\n",
            "0.0093994141\n",
            "0.0704345703\n",
            "0.1795654297\n",
            "0.0616455078\n",
            "0.1004638672\n",
            "0.0032958984\n",
            "0.0303955078\n",
            "0.5301513672\n",
            "0.0032958984\n",
            "0.0093994141\n",
            "0.4061279297\n",
            "0.0264892578\n",
            "0.0098876953\n",
            "0.0264892578\n",
            "0.0096435547\n",
            "0.1153564453\n",
            "0.0264892578\n",
            "0.0135498047\n",
            "0.2039794922\n",
            "0.1600341797\n",
            "0.2161865234\n",
            "0.0794677734\n",
            "0.1072998047\n",
            "0.0345458984\n",
            "0.0794677734\n",
            "0.0692138672\n",
            "0.0794677734\n",
            "0.1934814453\n",
            "0.0611572266\n",
            "0.0794677734\n",
            "0.1607666016\n",
            "0.0518798828\n",
            "0.1092529297\n",
            "0.0938720703\n",
            "0.0535888672\n",
            "0.1412353516\n",
            "0.0518798828\n",
            "0.1412353516\n",
            "0.0467529297\n",
            "0.1483154297\n",
            "0.4530029297\n",
            "0.0145263672\n",
            "0.0440673828\n",
            "0.0230712891\n",
            "0.0157470703\n",
            "0.1368408203\n",
            "0.0562744141\n",
            "0.0238037109\n",
            "0.1207275391\n",
            "0.1099853516\n",
            "0.2606201172\n",
            "0.0120849609\n",
            "0.0081787109\n",
            "0.0120849609\n",
            "0.0059814453\n",
            "0.2479248047\n",
            "0.0213623047\n",
            "0.0120849609\n",
            "0.3184814453\n",
            "0.0955810547\n",
            "0.1236572266\n",
            "0.1773681641\n",
            "0.1180419922\n",
            "0.1180419922\n",
            "0.0587158203\n",
            "0.0433349609\n",
            "0.0679931641\n",
            "0.0433349609\n",
            "0.1319580078\n",
            "0.1180419922\n",
            "0.0662841797\n",
            "0.4918212891\n",
            "0.0662841797\n",
            "0.0704345703\n",
            "0.1058349609\n",
            "0.0242919922\n",
            "0.0242919922\n",
            "0.0780029297\n",
            "0.0086669922\n",
            "0.0626220703\n",
            "0.0697021484\n",
            "0.2401123047\n",
            "0.1727294922\n",
            "0.1268310547\n",
            "0.0882568359\n",
            "0.0233154297\n",
            "0.0606689453\n",
            "0.0999755859\n",
            "0.0299072266\n",
            "0.0882568359\n",
            "0.0284423828\n",
            "0.2108154297\n",
            "0.0775146484\n",
            "0.1866455078\n",
            "0.1224365234\n",
            "0.0284423828\n",
            "0.0360107422\n",
            "0.0775146484\n",
            "0.0211181641\n",
            "0.2108154297\n",
            "0.0789794922\n",
            "0.2393798828\n",
            "0.0880126953\n",
            "0.0587158203\n",
            "0.2393798828\n",
            "0.0323486328\n",
            "0.0323486328\n",
            "0.1317138672\n",
            "0.0108642578\n",
            "0.0880126953\n",
            "0.0665283203\n",
            "0.0777587891\n",
            "0.0789794922\n",
            "0.0789794922\n",
            "0.0455322266\n",
            "0.2149658203\n",
            "0.1156005859\n",
            "0.1707763672\n",
            "0.0716552734\n",
            "0.0789794922\n",
            "0.1578369141\n",
            "0.1278076172\n",
            "0.1102294922\n",
            "0.0863037109\n",
            "0.1009521484\n",
            "0.0340576172\n",
            "0.1290283203\n",
            "0.1719970703\n",
            "0.0404052734\n",
            "0.0404052734\n",
            "0.0238037109\n",
            "0.0933837891\n",
            "0.0933837891\n",
            "0.0738525391\n",
            "0.0882568359\n",
            "0.0533447266\n",
            "0.0933837891\n",
            "0.2054443359\n",
            "0.0374755859\n",
            "0.2364501953\n",
            "0.0987548828\n",
            "0.1173095703\n",
            "0.0987548828\n",
            "0.0987548828\n",
            "0.0987548828\n",
            "0.0987548828\n",
            "0.1392822266\n",
            "0.1029052734\n",
            "0.0987548828\n",
            "0.0467529297\n",
            "1.0394287109\n",
            "1.2156982422\n",
            "1.2156982422\n",
            "0.7882080078\n",
            "0.4468994141\n",
            "0.1641845703\n",
            "0.4468994141\n",
            "1.2156982422\n",
            "0.9815673828\n",
            "0.4468994141\n",
            "0.0079345703\n",
            "0.0079345703\n",
            "0.0035400391\n",
            "0.0230712891\n",
            "0.0035400391\n",
            "0.2659912109\n",
            "0.0267333984\n",
            "0.0079345703\n",
            "0.1593017578\n",
            "0.4898681641\n",
            "0.0098876953\n",
            "0.0760498047\n",
            "0.6749267578\n",
            "0.0841064453\n",
            "0.0548095703\n",
            "0.0030517578\n",
            "0.0252685547\n",
            "0.0301513672\n",
            "0.0028076172\n",
            "0.0303955078\n",
            "0.0428466797\n",
            "0.1165771484\n",
            "0.3167724609\n",
            "0.0902099609\n",
            "0.0943603516\n",
            "0.0428466797\n",
            "0.0203857422\n",
            "0.0504150391\n",
            "0.1165771484\n",
            "0.1087646484\n",
            "0.0150146484\n",
            "0.0675048828\n",
            "0.8446044922\n",
            "0.0150146484\n",
            "0.0374755859\n",
            "0.0013427734\n",
            "0.0013427734\n",
            "0.0050048828\n",
            "0.0018310547\n",
            "0.0054931641\n",
            "0.0162353516\n",
            "0.4239501953\n",
            "0.1558837891\n",
            "0.0938720703\n",
            "0.0545654297\n",
            "0.0045166016\n",
            "0.0572509766\n",
            "0.1558837891\n",
            "0.0157470703\n",
            "0.0208740234\n",
            "0.0001220703\n",
            "0.0286865234\n",
            "0.0411376953\n",
            "0.0291748047\n",
            "0.0225830078\n",
            "0.0548095703\n",
            "0.0738525391\n",
            "0.0262451172\n",
            "0.1942138672\n",
            "0.5281982422\n",
            "0.0194091797\n",
            "0.0533447266\n",
            "0.0194091797\n",
            "0.0238037109\n",
            "0.0860595703\n",
            "0.0533447266\n",
            "0.0687255859\n",
            "0.2147216797\n",
            "0.0975341797\n",
            "0.3624267578\n",
            "0.0196533203\n",
            "0.0738525391\n",
            "0.0738525391\n",
            "0.0179443359\n",
            "0.1705322266\n",
            "0.0260009766\n",
            "0.2008056641\n",
            "0.1666259766\n",
            "0.0494384766\n",
            "0.2008056641\n",
            "0.0010986328\n",
            "0.0103759766\n",
            "0.0164794922\n",
            "0.0123291016\n",
            "0.0118408203\n",
            "0.0513916016\n",
            "0.0950927734\n",
            "0.0330810547\n",
            "0.0814208984\n",
            "0.6844482422\n",
            "0.1331787109\n",
            "0.0040283203\n",
            "0.0037841797\n",
            "0.0545654297\n",
            "0.0167236328\n",
            "0.1478271484\n",
            "0.0858154297\n",
            "0.0582275391\n",
            "0.0938720703\n",
            "0.4017333984\n",
            "0.8116455078\n",
            "0.0076904297\n",
            "0.0052490234\n",
            "0.0052490234\n",
            "0.0218505859\n",
            "0.0218505859\n",
            "0.0196533203\n",
            "0.0218505859\n",
            "0.0186767578\n",
            "0.0609130859\n",
            "0.0074462891\n",
            "0.0201416016\n",
            "0.1600341797\n",
            "0.0213623047\n",
            "0.1514892578\n",
            "0.0335693359\n",
            "0.1346435547\n",
            "0.3070068359\n",
            "0.0523681641\n",
            "0.1104736328\n",
            "0.0025634766\n",
            "0.0504150391\n",
            "0.0601806641\n",
            "0.0137939453\n",
            "0.2071533203\n",
            "0.0386962891\n",
            "0.0587158203\n",
            "0.4603271484\n",
            "0.0225830078\n",
            "0.0841064453\n",
            "0.0013427734\n",
            "0.0335693359\n",
            "0.1051025391\n",
            "0.0123291016\n",
            "0.1107177734\n",
            "0.0909423828\n",
            "0.0916748047\n",
            "0.2491455078\n",
            "0.0787353516\n",
            "0.2257080078\n",
            "0.0059814453\n",
            "0.1470947266\n",
            "0.1470947266\n",
            "0.0543212891\n",
            "0.1470947266\n",
            "0.0089111328\n",
            "0.0401611328\n",
            "0.3804931641\n",
            "0.0076904297\n",
            "0.0606689453\n",
            "0.0047607422\n",
            "0.0982666016\n",
            "0.0982666016\n",
            "0.0982666016\n",
            "0.0491943359\n",
            "0.0921630859\n",
            "0.0982666016\n",
            "0.0772705078\n",
            "0.1158447266\n",
            "0.2669677734\n",
            "0.0274658203\n",
            "1.6649169922\n",
            "1.6649169922\n",
            "1.6649169922\n",
            "1.5858154297\n",
            "0.3575439453\n",
            "0.5001220703\n",
            "1.6649169922\n",
            "0.5665283203\n",
            "0.8370361328\n",
            "0.0069580078\n",
            "0.1451416016\n",
            "0.2249755859\n",
            "0.1451416016\n",
            "0.1939697266\n",
            "0.0264892578\n",
            "0.0533447266\n",
            "0.1280517578\n",
            "0.0218505859\n",
            "0.0533447266\n",
            "0.0704345703\n",
            "0.7286376953\n",
            "1.4237060547\n",
            "1.4237060547\n",
            "0.6385498047\n",
            "0.7059326172\n",
            "1.3221435547\n",
            "0.8936767578\n",
            "0.5235595703\n",
            "1.4237060547\n",
            "0.0020751953\n",
            "0.0479736328\n",
            "0.0408935547\n",
            "0.0694580078\n",
            "0.0369873047\n",
            "0.0894775391\n",
            "0.0369873047\n",
            "0.0369873047\n",
            "0.1014404297\n",
            "0.5352783203\n",
            "0.2694091797\n",
            "0.0360107422\n",
            "0.0157470703\n",
            "0.0360107422\n",
            "0.0347900391\n",
            "0.2694091797\n",
            "0.0311279297\n",
            "0.0130615234\n",
            "0.0360107422\n",
            "0.2540283203\n",
            "0.0155029297\n",
            "0.1097412109\n",
            "0.2498779297\n",
            "0.1097412109\n",
            "0.1097412109\n",
            "0.0135498047\n",
            "0.0653076172\n",
            "0.1097412109\n",
            "0.1068115234\n",
            "0.1097412109\n",
            "0.0374755859\n",
            "0.1268310547\n",
            "0.1207275391\n",
            "0.1019287109\n",
            "0.1295166016\n",
            "0.0123291016\n",
            "0.0714111328\n",
            "0.2039794922\n",
            "0.0933837891\n",
            "0.1019287109\n",
            "0.0662841797\n",
            "0.0975341797\n",
            "0.2030029297\n",
            "0.0274658203\n",
            "0.0775146484\n",
            "0.0098876953\n",
            "0.0701904297\n",
            "0.2030029297\n",
            "0.0418701172\n",
            "0.2030029297\n",
            "0.0125732422\n",
            "0.2613525391\n",
            "0.0943603516\n",
            "0.0740966797\n",
            "0.1082763672\n",
            "0.0079345703\n",
            "0.0447998047\n",
            "0.2984619141\n",
            "0.0574951172\n",
            "0.0404052734\n",
            "0.5174560547\n",
            "0.0701904297\n",
            "0.0255126953\n",
            "0.0255126953\n",
            "0.0106201172\n",
            "0.0313720703\n",
            "0.0255126953\n",
            "0.0091552734\n",
            "0.0255126953\n",
            "0.2576904297\n",
            "0.1842041016\n",
            "0.0892333984\n",
            "0.0853271484\n",
            "0.0850830078\n",
            "0.1107177734\n",
            "0.0853271484\n",
            "0.0626220703\n",
            "0.0941162109\n",
            "0.0291748047\n",
            "0.1741943359\n",
            "0.0821533203\n",
            "0.0919189453\n",
            "0.0821533203\n",
            "0.0350341797\n",
            "0.1871337891\n",
            "0.0335693359\n",
            "0.0821533203\n",
            "0.1282958984\n",
            "0.0609130859\n",
            "0.2159423828\n",
            "0.2442626953\n",
            "0.0897216797\n",
            "0.0718994141\n",
            "0.0474853516\n",
            "0.0408935547\n",
            "0.0462646484\n",
            "0.1053466797\n",
            "0.0897216797\n",
            "0.0560302734\n",
            "0.2081298828\n",
            "0.3807373047\n",
            "0.0233154297\n",
            "0.0079345703\n",
            "0.0233154297\n",
            "0.0108642578\n",
            "0.1661376953\n",
            "0.0150146484\n",
            "0.0233154297\n",
            "0.0389404297\n",
            "0.3099365234\n",
            "0.0977783203\n",
            "0.0977783203\n",
            "0.0977783203\n",
            "0.1365966797\n",
            "0.0821533203\n",
            "0.0977783203\n",
            "0.0977783203\n",
            "0.0977783203\n",
            "0.0977783203\n",
            "0.0963134766\n",
            "0.1612548828\n",
            "0.0472412109\n",
            "0.0826416016\n",
            "0.0777587891\n",
            "0.0572509766\n",
            "0.0657958984\n",
            "0.0826416016\n",
            "0.1180419922\n",
            "0.0826416016\n",
            "0.2247314453\n",
            "0.1844482422\n",
            "0.0677490234\n",
            "0.0247802734\n",
            "0.0677490234\n",
            "0.0926513672\n",
            "0.0677490234\n",
            "0.0877685547\n",
            "0.1614990234\n",
            "0.0677490234\n",
            "0.1773681641\n",
            "0.1783447266\n",
            "0.0814208984\n",
            "0.0479736328\n",
            "0.0504150391\n",
            "0.0814208984\n",
            "0.0814208984\n",
            "0.1180419922\n",
            "0.0814208984\n",
            "0.0570068359\n",
            "0.2215576172\n",
            "0.1121826172\n",
            "0.1087646484\n",
            "0.1087646484\n",
            "0.1087646484\n",
            "0.0145263672\n",
            "0.1041259766\n",
            "0.1185302734\n",
            "0.1087646484\n",
            "0.1070556641\n",
            "0.1087646484\n",
            "0.1173095703\n",
            "0.1170654297\n",
            "0.0811767578\n",
            "0.1314697266\n",
            "0.0738525391\n",
            "0.1055908203\n",
            "0.1322021484\n",
            "0.0760498047\n",
            "0.0770263672\n",
            "0.0875244141\n",
            "0.1917724609\n",
            "0.0755615234\n",
            "0.2056884766\n",
            "0.0755615234\n",
            "0.0728759766\n",
            "0.0755615234\n",
            "0.0755615234\n",
            "0.0755615234\n",
            "0.0755615234\n",
            "0.0755615234\n",
            "0.0980224609\n",
            "0.1258544922\n",
            "0.1258544922\n",
            "0.0462646484\n",
            "0.1258544922\n",
            "0.1258544922\n",
            "0.1258544922\n",
            "0.0120849609\n",
            "0.0916748047\n",
            "0.1219482422\n",
            "0.1219482422\n",
            "0.1531982422\n",
            "0.0860595703\n",
            "0.0870361328\n",
            "0.0860595703\n",
            "0.1009521484\n",
            "0.0875244141\n",
            "0.0860595703\n",
            "0.1051025391\n",
            "0.0860595703\n",
            "0.1343994141\n",
            "0.0972900391\n",
            "0.0972900391\n",
            "0.0972900391\n",
            "0.0880126953\n",
            "0.0972900391\n",
            "0.0972900391\n",
            "0.0972900391\n",
            "0.0965576172\n",
            "0.0972900391\n",
            "0.0777587891\n",
            "0.0313720703\n",
            "0.0447998047\n",
            "0.0284423828\n",
            "0.0284423828\n",
            "0.0777587891\n",
            "0.0777587891\n",
            "0.0330810547\n",
            "0.3094482422\n",
            "0.2904052734\n",
            "0.0523681641\n",
            "0.4434814453\n",
            "0.1202392578\n",
            "0.1951904297\n",
            "0.0347900391\n",
            "0.0321044922\n",
            "0.0093994141\n",
            "0.0262451172\n",
            "0.0133056641\n",
            "0.0716552734\n",
            "0.0421142578\n",
            "0.0262451172\n",
            "0.5313720703\n",
            "0.1275634766\n",
            "0.0240478516\n",
            "0.0550537109\n",
            "0.0262451172\n",
            "0.0220947266\n",
            "0.0716552734\n",
            "0.0716552734\n",
            "0.0389404297\n",
            "0.0965576172\n",
            "0.2889404297\n",
            "0.3377685547\n",
            "0.0196533203\n",
            "0.0660400391\n",
            "0.0047607422\n",
            "0.0137939453\n",
            "0.0245361328\n",
            "0.1063232422\n",
            "0.0438232422\n",
            "0.0455322266\n",
            "0.1246337891\n",
            "0.1246337891\n",
            "0.3626708984\n",
            "0.0455322266\n",
            "0.0250244141\n",
            "0.1163330078\n",
            "0.0379638672\n",
            "0.0740966797\n",
            "0.0106201172\n",
            "0.0706787109\n",
            "0.0789794922\n",
            "0.0635986328\n",
            "0.0789794922\n",
            "0.0289306641\n",
            "0.2152099609\n",
            "0.1405029297\n",
            "0.2308349609\n",
            "0.0789794922\n",
            "0.1204833984\n",
            "0.0443115234\n",
            "0.0970458984\n",
            "0.0443115234\n",
            "0.1204833984\n",
            "0.0426025391\n",
            "0.2803955078\n",
            "0.0887451172\n",
            "0.0455322266\n",
            "0.1153564453\n",
            "0.1160888672\n",
            "0.0394287109\n",
            "0.0394287109\n",
            "0.0372314453\n",
            "0.1077880859\n",
            "0.0394287109\n",
            "0.0413818359\n",
            "0.3480224609\n",
            "0.0191650391\n",
            "0.2117919922\n",
            "0.0235595703\n",
            "0.0308837891\n",
            "0.1763916016\n",
            "0.0528564453\n",
            "0.0645751953\n",
            "0.0645751953\n",
            "0.1607666016\n",
            "0.1763916016\n",
            "0.1729736328\n",
            "0.0743408203\n",
            "0.0753173828\n",
            "0.0435791016\n",
            "0.0753173828\n",
            "0.0447998047\n",
            "0.0313720703\n",
            "0.0753173828\n",
            "0.2052001953\n",
            "0.0997314453\n",
            "0.2105712891\n",
            "0.1383056641\n",
            "0.0528564453\n",
            "0.1014404297\n",
            "0.1014404297\n",
            "0.1014404297\n",
            "0.1121826172\n",
            "0.0045166016\n",
            "0.0445556641\n",
            "0.1014404297\n",
            "0.0721435547\n",
            "0.3074951172\n",
            "0.0887451172\n",
            "0.2413330078\n",
            "0.0809326172\n",
            "0.0887451172\n",
            "0.0792236328\n",
            "0.0145263672\n",
            "0.0235595703\n",
            "0.0916748047\n",
            "0.0599365234\n",
            "0.2305908203\n",
            "0.0382080078\n",
            "0.1981201172\n",
            "0.1043701172\n",
            "0.0797119141\n",
            "0.1043701172\n",
            "0.0140380859\n",
            "0.0382080078\n",
            "0.0985107422\n",
            "0.1043701172\n",
            "0.2196044922\n",
            "0.0545654297\n",
            "0.2071533203\n",
            "0.1483154297\n",
            "0.0545654297\n",
            "0.1331787109\n",
            "0.0196533203\n",
            "0.0545654297\n",
            "0.2188720703\n",
            "0.0545654297\n",
            "0.0540771484\n",
            "0.0291748047\n",
            "0.1109619141\n",
            "0.1109619141\n",
            "0.0626220703\n",
            "0.1199951172\n",
            "0.0245361328\n",
            "0.0660400391\n",
            "0.3013916016\n",
            "0.0303955078\n",
            "0.1436767578\n",
            "0.0394287109\n",
            "0.1075439453\n",
            "0.1075439453\n",
            "0.1075439453\n",
            "0.0943603516\n",
            "0.0145263672\n",
            "0.0394287109\n",
            "0.0875244141\n",
            "0.1075439453\n",
            "0.2928466797\n",
            "0.0296630859\n",
            "0.0914306641\n",
            "0.0965576172\n",
            "0.0657958984\n",
            "0.0811767578\n",
            "0.0137939453\n",
            "0.0345458984\n",
            "0.1524658203\n",
            "0.2130126953\n",
            "0.2208251953\n",
            "0.0318603516\n",
            "0.0870361328\n",
            "0.1085205078\n",
            "0.0870361328\n",
            "0.0867919922\n",
            "0.0115966797\n",
            "0.0321044922\n",
            "0.2366943359\n",
            "0.1641845703\n",
            "0.1536865234\n",
            "0.0379638672\n",
            "0.0977783203\n",
            "0.1275634766\n",
            "0.1033935547\n",
            "0.1026611328\n",
            "0.0140380859\n",
            "0.0379638672\n",
            "0.1033935547\n",
            "0.0938720703\n",
            "0.2811279297\n",
            "0.0509033203\n",
            "0.1387939453\n",
            "0.1387939453\n",
            "0.1160888672\n",
            "0.0841064453\n",
            "0.0186767578\n",
            "0.0511474609\n",
            "0.1387939453\n",
            "0.1256103516\n",
            "0.1368408203\n",
            "0.7806396484\n",
            "0.0220947266\n",
            "0.0186767578\n",
            "0.0264892578\n",
            "0.0155029297\n",
            "0.0526123047\n",
            "0.0155029297\n",
            "0.0098876953\n",
            "0.0152587891\n",
            "0.0428466797\n",
            "0.3670654297\n",
            "0.5108642578\n",
            "0.9981689453\n",
            "0.9715576172\n",
            "0.9981689453\n",
            "0.3536376953\n",
            "0.3890380859\n",
            "0.9981689453\n",
            "0.1297607422\n",
            "0.9981689453\n",
            "0.1329345703\n",
            "0.1290283203\n",
            "0.1329345703\n",
            "0.1314697266\n",
            "0.0489501953\n",
            "0.0943603516\n",
            "0.1177978516\n",
            "0.0401611328\n",
            "0.0396728516\n",
            "0.1317138672\n",
            "0.0343017578\n",
            "0.0928955078\n",
            "0.0968017578\n",
            "0.0989990234\n",
            "0.0601806641\n",
            "0.0989990234\n",
            "0.0770263672\n",
            "0.2608642578\n",
            "0.0333251953\n",
            "0.1458740234\n",
            "0.0194091797\n",
            "0.0609130859\n",
            "0.1436767578\n",
            "0.1436767578\n",
            "0.0528564453\n",
            "0.0792236328\n",
            "0.0194091797\n",
            "0.1436767578\n",
            "0.0482177734\n",
            "0.2882080078\n",
            "0.4525146484\n",
            "0.0352783203\n",
            "0.0614013672\n",
            "0.0614013672\n",
            "0.0225830078\n",
            "0.1663818359\n",
            "0.0328369141\n",
            "0.1080322266\n",
            "0.0189208984\n",
            "0.0404052734\n",
            "0.0377197266\n",
            "0.1431884766\n",
            "0.1431884766\n",
            "0.0526123047\n",
            "0.1431884766\n",
            "0.0325927734\n",
            "0.0191650391\n",
            "0.2891845703\n",
            "0.0526123047\n",
            "0.0850830078\n",
            "0.0245361328\n",
            "0.1954345703\n",
            "0.0894775391\n",
            "0.0594482422\n",
            "0.1600341797\n",
            "0.0306396484\n",
            "0.0362548828\n",
            "0.1231689453\n",
            "0.0262451172\n",
            "0.2535400391\n",
            "0.2562255859\n",
            "0.0623779297\n",
            "0.0584716797\n",
            "0.0623779297\n",
            "0.0755615234\n",
            "0.2562255859\n",
            "0.0709228516\n",
            "0.1016845703\n",
            "0.0184326172\n",
            "0.0369873047\n",
            "0.3946533203\n",
            "0.0364990234\n",
            "0.0364990234\n",
            "0.0364990234\n",
            "0.0364990234\n",
            "0.2716064453\n",
            "0.0364990234\n",
            "0.0684814453\n",
            "0.0364990234\n",
            "0.0435791016\n",
            "0.2012939453\n",
            "0.0362548828\n",
            "0.0335693359\n",
            "0.0316162109\n",
            "0.0272216797\n",
            "0.0272216797\n",
            "0.0272216797\n",
            "0.0272216797\n",
            "0.0391845703\n",
            "0.5472412109\n",
            "0.2095947266\n",
            "0.6358642578\n",
            "0.0042724609\n",
            "0.0040283203\n",
            "0.0074462891\n",
            "0.0115966797\n",
            "0.0115966797\n",
            "0.0040283203\n",
            "0.0242919922\n",
            "0.0860595703\n",
            "0.4427490234\n",
            "0.0106201172\n",
            "0.2523193359\n",
            "0.0208740234\n",
            "0.0123291016\n",
            "0.0443115234\n",
            "0.0164794922\n",
            "0.0123291016\n",
            "0.0928955078\n",
            "0.0928955078\n",
            "0.1141357422\n",
            "0.0506591797\n",
            "0.0277099609\n",
            "0.5701904297\n",
            "0.0281982422\n",
            "0.0281982422\n",
            "0.0198974609\n",
            "0.0257568359\n",
            "0.0572509766\n",
            "0.0772705078\n",
            "0.0821533203\n",
            "0.0655517578\n",
            "0.0076904297\n",
            "0.0174560547\n",
            "0.6600341797\n",
            "0.0303955078\n",
            "0.0177001953\n",
            "0.0303955078\n",
            "0.0360107422\n",
            "0.0469970703\n",
            "0.3988037109\n",
            "0.0528564453\n",
            "0.0198974609\n",
            "0.0181884766\n",
            "0.0198974609\n",
            "0.0125732422\n",
            "0.0306396484\n",
            "0.0150146484\n",
            "0.0213623047\n",
            "0.4088134766\n",
            "0.3350830078\n",
            "0.0950927734\n",
            "0.0233154297\n",
            "0.0194091797\n",
            "0.0599365234\n",
            "0.0296630859\n",
            "0.2235107422\n",
            "0.0218505859\n",
            "0.0501708984\n",
            "0.1405029297\n",
            "0.1690673828\n",
            "0.0098876953\n",
            "0.0238037109\n",
            "0.0101318359\n",
            "0.0081787109\n",
            "0.0218505859\n",
            "0.0328369141\n",
            "0.6295166016\n",
            "0.0484619141\n",
            "0.0389404297\n",
            "0.4351806641\n",
            "0.1243896484\n",
            "0.0589599609\n",
            "0.0291748047\n",
            "0.0604248047\n",
            "0.0460205078\n",
            "0.0504150391\n",
            "0.0147705078\n",
            "0.0216064453\n",
            "0.1600341797\n",
            "0.5135498047\n",
            "0.0545654297\n",
            "0.0374755859\n",
            "0.0252685547\n",
            "0.0467529297\n",
            "0.0430908203\n",
            "0.0294189453\n",
            "0.0264892578\n",
            "0.0318603516\n",
            "0.1885986328\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_text_file(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    # 데이터 전처리: 불필요한 문자 제거 및 정리\n",
        "    data = data.replace(\"\\n\", \" \")  # 줄바꿈 제거\n",
        "    data = data.replace(\"[\", \"\").replace(\"]\", \"\")  # 대괄호 제거\n",
        "    data = data.split()  # 공백 기준으로 나눔\n",
        "\n",
        "    # 문자열을 float으로 변환\n",
        "    try:\n",
        "        data_list = [float(value) for value in data]\n",
        "        return np.array(data_list)  # numpy 배열로 변환\n",
        "    except ValueError as e:\n",
        "        print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "        raise\n",
        "\n",
        "# 두 파일의 데이터 읽기\n",
        "try:\n",
        "    restored_data = parse_text_file('./model/cordic_dec_val.txt')\n",
        "    original_data = parse_text_file('./model/cordic_dec_val_sortedF.txt')\n",
        "\n",
        "    # 데이터 형태 확인\n",
        "    print(f\"Restored data shape: {restored_data.shape}\")\n",
        "    print(f\"Original data shape: {original_data.shape}\")\n",
        "\n",
        "    # 데이터 값 하나하나 비교\n",
        "    if np.array_equal(restored_data, original_data):\n",
        "        print(\"두 데이터는 형태와 값이 모두 동일합니다.\")\n",
        "    else:\n",
        "        print(\"데이터에 차이가 있습니다.\")\n",
        "\n",
        "        # 값이 다를 경우, 차이를 확인\n",
        "        differences = np.where(restored_data != original_data)\n",
        "        print(f\"값이 다른 위치: {differences}\")\n",
        "        print(f\"Restored data at differences: {restored_data[differences]}\")\n",
        "        print(f\"Original data at differences: {original_data[differences]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"파일 처리 중 오류 발생: {e}\")\n"
      ],
      "metadata": {
        "id": "NqnBhDHgkSWH",
        "outputId": "4bceac4f-82a0-4dc3-d3c2-3c03213049cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored data shape: (1200,)\n",
            "Original data shape: (1200,)\n",
            "데이터에 차이가 있습니다.\n",
            "값이 다른 위치: (array([   1,    4,    5,    6,    9,   10,   11,   12,   15,   16,   17,\n",
            "         18,   19,   21,   27,   29,   30,   31,   32,   33,   35,   36,\n",
            "         37,   38,   39,   40,   41,   42,   43,   45,   47,   48,   49,\n",
            "         50,   52,   56,   58,   59,   60,   61,   62,   63,   65,   68,\n",
            "         69,   70,   71,   73,   74,   75,   76,   79,   80,   81,   82,\n",
            "         83,   85,   88,   91,   94,   95,  102,  105,  109,  111,  118,\n",
            "        120,  121,  122,  123,  124,  125,  126,  127,  128,  129,  130,\n",
            "        131,  132,  133,  134,  135,  137,  138,  146,  147,  149,  153,\n",
            "        154,  156,  158,  160,  162,  163,  165,  166,  168,  171,  172,\n",
            "        176,  182,  199,  201,  203,  204,  205,  206,  208,  209,  212,\n",
            "        213,  214,  216,  217,  218,  221,  222,  227,  231,  234,  235,\n",
            "        236,  238,  239,  246,  247,  250,  251,  253,  256,  258,  265,\n",
            "        270,  271,  273,  274,  275,  276,  277,  283,  286,  287,  288,\n",
            "        289,  290,  291,  292,  293,  294,  295,  296,  297,  304,  305,\n",
            "        306,  307,  308,  311,  315,  316,  318,  320,  322,  324,  325,\n",
            "        327,  329,  333,  341,  343,  344,  345,  346,  347,  350,  352,\n",
            "        353,  357,  359,  362,  365,  370,  371,  372,  373,  374,  375,\n",
            "        376,  377,  378,  381,  386,  387,  390,  391,  392,  393,  394,\n",
            "        395,  396,  397,  398,  399,  402,  403,  404,  405,  406,  407,\n",
            "        408,  409,  411,  412,  415,  417,  418,  419,  421,  424,  428,\n",
            "        430,  431,  433,  434,  435,  436,  437,  438,  439,  440,  442,\n",
            "        443,  445,  447,  448,  449,  451,  456,  457,  458,  459,  461,\n",
            "        463,  465,  466,  470,  474,  475,  480,  481,  483,  484,  487,\n",
            "        488,  490,  491,  494,  502,  503,  504,  505,  506,  507,  508,\n",
            "        509,  513,  515,  517,  519,  520,  523,  525,  527,  530,  531,\n",
            "        533,  534,  538,  540,  541,  542,  543,  544,  545,  546,  547,\n",
            "        549,  550,  551,  552,  553,  554,  556,  558,  559,  560,  561,\n",
            "        562,  563,  564,  565,  566,  567,  568,  569,  570,  571,  572,\n",
            "        573,  574,  578,  580,  581,  582,  583,  584,  585,  586,  587,\n",
            "        588,  589,  590,  591,  593,  595,  599,  601,  602,  603,  604,\n",
            "        607,  608,  610,  615,  620,  623,  624,  625,  626,  628,  629,\n",
            "        634,  638,  640,  641,  644,  645,  648,  649,  650,  654,  655,\n",
            "        668,  671,  678,  681,  682,  683,  687,  688,  690,  694,  695,\n",
            "        698,  699,  709,  711,  712,  715,  716,  718,  733,  740,  757,\n",
            "        758,  760,  764,  773,  802,  803,  804,  807,  809,  810,  812,\n",
            "        814,  815,  816,  817,  819,  820,  821,  823,  824,  825,  826,\n",
            "        827,  831,  832,  834,  835,  836,  837,  838,  841,  842,  843,\n",
            "        844,  845,  846,  847,  851,  853,  856,  858,  861,  863,  866,\n",
            "        868,  871,  872,  873,  874,  875,  876,  877,  878,  881,  882,\n",
            "        884,  885,  886,  887,  888,  891,  894,  897,  898,  900,  904,\n",
            "        905,  906,  908,  909,  915,  921,  922,  923,  924,  925,  927,\n",
            "        928,  931,  934,  935,  939,  946,  948,  955,  957,  962,  965,\n",
            "        966,  968,  970,  971,  972,  973,  974,  976,  977,  979,  980,\n",
            "        982,  984,  986,  994,  995,  996,  998, 1000, 1001, 1002, 1003,\n",
            "       1007, 1008, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018,\n",
            "       1019, 1021, 1023, 1025, 1026, 1029, 1033, 1035, 1037, 1038, 1049,\n",
            "       1051, 1054, 1057, 1058, 1059, 1061, 1062, 1064, 1074, 1075, 1076,\n",
            "       1086, 1088, 1091, 1092, 1093, 1094, 1096, 1098, 1099, 1102, 1103,\n",
            "       1112, 1113, 1114, 1115, 1116, 1117, 1118, 1121, 1124, 1125, 1127,\n",
            "       1130, 1131, 1132, 1134, 1135, 1136, 1137, 1138, 1139, 1141, 1142,\n",
            "       1143, 1145, 1146, 1147, 1148, 1150, 1153, 1157, 1159, 1163, 1165,\n",
            "       1166, 1167, 1168, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177,\n",
            "       1178, 1179, 1180, 1181, 1182, 1185, 1186, 1191, 1192, 1193, 1196,\n",
            "       1197, 1198, 1199]),)\n",
            "Restored data at differences: [1.35498047e-02 1.20849609e-02 1.21459961e-01 1.20849609e-02\n",
            " 6.72607422e-02 9.64355470e-03 5.06591797e-02 5.77514648e-01\n",
            " 1.79443359e-02 9.64355470e-03 1.96533203e-02 9.39941410e-03\n",
            " 9.64355470e-03 2.61840820e-01 1.37939453e-02 1.37939453e-02\n",
            " 1.15966797e-02 8.94775391e-02 6.59057617e-01 3.21044922e-02\n",
            " 1.15966797e-02 1.15966797e-02 8.42285160e-03 4.76074220e-03\n",
            " 1.28173828e-02 5.73730470e-03 3.14331055e-01 7.01904297e-02\n",
            " 3.18237305e-01 4.21142578e-02 1.01684570e-01 1.37939453e-02\n",
            " 4.21142578e-02 1.35131836e-01 2.79541016e-02 4.79736328e-02\n",
            " 2.24731445e-01 2.20825195e-01 2.06298828e-02 5.72509766e-02\n",
            " 2.06298828e-02 1.25732422e-02 9.82666016e-02 5.72509766e-02\n",
            " 7.16552734e-02 1.79443359e-02 1.79443359e-02 1.96533203e-02\n",
            " 1.02905273e-01 9.53369141e-02 1.87622070e-01 3.51928711e-01\n",
            " 4.69970703e-02 5.00488280e-03 1.91650391e-02 3.78417970e-03\n",
            " 2.84423828e-02 7.38525391e-02 1.03759766e-02 4.02832030e-03\n",
            " 1.95434570e-01 1.57836914e-01 2.06298828e-02 2.59155273e-01\n",
            " 6.26220703e-02 5.01708984e-02 9.28955078e-02 9.28955078e-02\n",
            " 6.45751953e-02 7.33642578e-02 9.28955078e-02 3.35693359e-02\n",
            " 1.27075195e-01 9.28955078e-02 3.35693359e-02 2.89672852e-01\n",
            " 5.26123047e-02 7.04345703e-02 6.35986328e-02 6.45751953e-02\n",
            " 1.57104492e-01 7.04345703e-02 8.48388672e-02 7.04345703e-02\n",
            " 1.96655273e-01 1.96655273e-01 1.96655273e-01 1.11450195e-01\n",
            " 1.34155273e-01 6.53076172e-02 6.38427734e-02 7.45849609e-02\n",
            " 7.45849609e-02 7.11669922e-02 3.35693359e-02 9.89990234e-02\n",
            " 7.45849609e-02 8.16650391e-02 1.58325195e-01 1.48315430e-01\n",
            " 9.16748047e-02 2.03247070e-01 6.95800780e-03 2.23388672e-02\n",
            " 2.07519530e-03 1.72973633e-01 2.23388672e-02 4.75463867e-01\n",
            " 1.21948242e-01 4.47875977e-01 2.34741211e-01 1.96533203e-02\n",
            " 9.88769530e-03 6.97021484e-02 7.69042970e-03 1.38305664e-01\n",
            " 2.64770508e-01 8.82568359e-02 6.23779297e-02 2.45361328e-02\n",
            " 2.45361328e-02 1.55029297e-02 8.66699220e-03 2.45361328e-02\n",
            " 3.06396484e-02 5.30395508e-01 4.06372070e-01 2.69775391e-02\n",
            " 2.69775391e-02 2.69775391e-02 2.04223633e-01 6.94580078e-02\n",
            " 1.60522461e-01 5.16357422e-02 9.36279297e-02 5.33447266e-02\n",
            " 1.40991211e-01 5.16357422e-02 1.40991211e-01 2.25830078e-02\n",
            " 5.65185547e-02 2.35595703e-02 1.20971680e-01 1.09497070e-01\n",
            " 2.59887695e-01 1.18408203e-02 7.93457030e-03 1.18408203e-02\n",
            " 5.73730470e-03 2.48168945e-01 2.03857422e-02 1.18408203e-02\n",
            " 5.84716797e-02 4.30908203e-02 6.77490234e-02 4.30908203e-02\n",
            " 1.31713867e-01 4.92065430e-01 2.38037109e-02 2.38037109e-02\n",
            " 8.17871090e-03 6.94580078e-02 1.72485352e-01 8.80126953e-02\n",
            " 2.30712891e-02 9.97314453e-02 8.80126953e-02 1.86889648e-01\n",
            " 2.39135742e-01 5.84716797e-02 2.39135742e-01 3.21044922e-02\n",
            " 3.21044922e-02 1.31469727e-01 6.62841797e-02 7.87353516e-02\n",
            " 7.87353516e-02 1.71020508e-01 7.87353516e-02 1.09985352e-01\n",
            " 3.38134766e-02 2.33154297e-02 9.28955078e-02 9.28955078e-02\n",
            " 7.31201172e-02 8.77685547e-02 5.28564453e-02 9.28955078e-02\n",
            " 2.05200195e-01 3.69873047e-02 1.17065430e-01 1.39526367e-01\n",
            " 1.02661133e-01 1.30493164e-01 1.52465820e-01 1.52465820e-01\n",
            " 9.89990234e-02 5.60302734e-02 2.06298828e-02 5.60302734e-02\n",
            " 1.52465820e-01 1.23413086e-01 5.60302734e-02 3.05175780e-03\n",
            " 2.25830078e-02 3.05175780e-03 2.65747070e-01 2.64892578e-02\n",
            " 7.69042970e-03 1.59057617e-01 4.90356445e-01 7.62939453e-02\n",
            " 6.75659180e-01 2.07519530e-03 2.94189453e-02 1.83105470e-03\n",
            " 3.11279297e-02 1.16821289e-01 9.41162109e-02 1.16821289e-01\n",
            " 1.45263672e-02 6.72607422e-02 1.45263672e-02 3.72314453e-02\n",
            " 1.22070300e-04 1.22070300e-04 4.02832030e-03 8.54492200e-04\n",
            " 4.76074220e-03 1.57470703e-02 1.56127930e-01 9.36279297e-02\n",
            " 4.02832030e-03 1.56127930e-01 1.55029297e-02 2.06298828e-02\n",
            " 2.89306641e-02 7.36083984e-02 2.60009766e-02 1.94458008e-01\n",
            " 5.27954102e-01 5.31005859e-02 2.35595703e-02 5.31005859e-02\n",
            " 6.84814453e-02 1.94091797e-02 1.70776367e-01 2.57568359e-02\n",
            " 8.54492200e-04 1.01318359e-02 1.20849609e-02 1.15966797e-02\n",
            " 3.28369141e-02 8.16650391e-02 1.32934570e-01 3.78417970e-03\n",
            " 1.64794922e-02 5.00488280e-03 5.00488280e-03 2.16064453e-02\n",
            " 2.16064453e-02 1.94091797e-02 2.16064453e-02 1.77001953e-02\n",
            " 6.06689453e-02 2.11181641e-02 3.33251953e-02 3.06762695e-01\n",
            " 1.10229492e-01 2.31933590e-03 1.35498047e-02 3.84521484e-02\n",
            " 4.60571289e-01 1.09863280e-03 3.33251953e-02 1.18408203e-02\n",
            " 1.10473633e-01 7.84912109e-02 5.73730470e-03 1.47338867e-01\n",
            " 1.47338867e-01 5.45654297e-02 1.47338867e-01 8.66699220e-03\n",
            " 3.99169922e-02 3.80249023e-01 6.09130859e-02 4.51660160e-03\n",
            " 9.80224609e-02 9.80224609e-02 9.80224609e-02 4.89501953e-02\n",
            " 9.80224609e-02 1.16088867e-01 2.66723633e-01 2.31933590e-03\n",
            " 1.57836914e-01 1.57836914e-01 1.57836914e-01 1.50512695e-01\n",
            " 3.38134766e-02 4.72412109e-02 1.57836914e-01 5.38330078e-02\n",
            " 7.92236328e-02 6.71386720e-03 1.44897461e-01 2.24731445e-01\n",
            " 1.44897461e-01 1.93725586e-01 2.16064453e-02 7.69042970e-03\n",
            " 7.94677734e-02 1.55639648e-01 1.55639648e-01 6.97021484e-02\n",
            " 7.72705078e-02 1.44409180e-01 9.75341797e-02 5.72509766e-02\n",
            " 1.55639648e-01 1.83105470e-03 4.77294922e-02 6.84814453e-02\n",
            " 8.97216797e-02 5.35034180e-01 3.52783203e-02 1.55029297e-02\n",
            " 3.52783203e-02 3.43017578e-02 1.18408203e-02 3.52783203e-02\n",
            " 1.52587891e-02 1.33056641e-02 3.72314453e-02 1.01684570e-01\n",
            " 1.29272461e-01 1.20849609e-02 7.11669922e-02 9.31396484e-02\n",
            " 1.01684570e-01 7.77587891e-02 4.16259766e-02 1.23291016e-02\n",
            " 2.61108398e-01 1.08520508e-01 7.69042970e-03 5.72509766e-02\n",
            " 4.01611328e-02 5.16967773e-01 1.03759766e-02 3.11279297e-02\n",
            " 2.89306641e-02 9.21630859e-02 6.11572266e-02 8.99658203e-02\n",
            " 7.16552734e-02 4.72412109e-02 8.99658203e-02 5.62744141e-02\n",
            " 3.80249023e-01 1.03759766e-02 1.65893555e-01 3.86962891e-02\n",
            " 3.10424805e-01 9.65576172e-02 4.69970703e-02 8.23974609e-02\n",
            " 6.55517578e-02 8.23974609e-02 8.23974609e-02 5.06591797e-02\n",
            " 1.11938477e-01 7.62939453e-02 7.72705078e-02 1.91528320e-01\n",
            " 7.26318359e-02 4.65087891e-02 4.45556641e-02 2.81982422e-02\n",
            " 2.81982422e-02 3.25927734e-02 2.89916992e-01 5.21240234e-02\n",
            " 1.19750977e-01 3.43017578e-02 3.16162109e-02 9.15527340e-03\n",
            " 2.57568359e-02 7.14111328e-02 4.18701172e-02 2.60009766e-02\n",
            " 1.27075195e-01 2.35595703e-02 5.48095703e-02 2.60009766e-02\n",
            " 2.18505859e-02 9.68017578e-02 2.89184570e-01 1.94091797e-02\n",
            " 6.62841797e-02 4.02832030e-03 1.35498047e-02 2.35595703e-02\n",
            " 4.50439453e-02 1.24877930e-01 1.24877930e-01 3.63159180e-01\n",
            " 4.50439453e-02 2.45361328e-02 1.16088867e-01 7.04345703e-02\n",
            " 6.33544922e-02 2.15454102e-01 2.31079102e-01 4.40673828e-02\n",
            " 4.40673828e-02 2.80151367e-01 4.52880859e-02 3.91845703e-02\n",
            " 3.91845703e-02 3.69873047e-02 1.07543945e-01 3.91845703e-02\n",
            " 4.11376953e-02 3.47778320e-01 1.94091797e-02 3.11279297e-02\n",
            " 1.76147461e-01 6.43310547e-02 6.43310547e-02 1.60278320e-01\n",
            " 1.76147461e-01 1.72485352e-01 4.30908203e-02 3.11279297e-02\n",
            " 9.94873047e-02 2.10815430e-01 5.26123047e-02 1.11450195e-01\n",
            " 3.78417970e-03 4.40673828e-02 7.11669922e-02 3.07739258e-01\n",
            " 1.42822266e-02 1.97875977e-01 1.04125977e-01 7.94677734e-02\n",
            " 1.04125977e-01 1.37939453e-02 9.82666016e-02 1.04125977e-01\n",
            " 2.06909180e-01 1.32934570e-01 1.94091797e-02 5.38330078e-02\n",
            " 6.62841797e-02 3.06396484e-02 1.42822266e-02 8.72802734e-02\n",
            " 9.63134766e-02 1.35498047e-02 3.43017578e-02 2.13256836e-01\n",
            " 3.16162109e-02 8.67919922e-02 1.08764648e-01 8.67919922e-02\n",
            " 8.63037109e-02 3.18603516e-02 2.36450195e-01 1.53442383e-01\n",
            " 3.82080078e-02 1.27319336e-01 1.02416992e-01 3.82080078e-02\n",
            " 8.38623047e-02 1.84326172e-02 5.09033203e-02 1.25122070e-01\n",
            " 7.81127930e-01 2.16064453e-02 1.84326172e-02 2.62451172e-02\n",
            " 9.64355470e-03 1.55029297e-02 5.45654297e-02 7.60498047e-02\n",
            " 1.48559570e-01 1.44653320e-01 1.48559570e-01 5.26123047e-02\n",
            " 5.79833984e-02 1.48559570e-01 1.94091797e-02 1.48559570e-01\n",
            " 1.28784180e-01 1.31225586e-01 9.41162109e-02 1.18041992e-01\n",
            " 1.31469727e-01 9.92431641e-02 9.92431641e-02 2.60620117e-01\n",
            " 3.30810547e-02 2.87963867e-01 3.50341797e-02 2.23388672e-02\n",
            " 1.08276367e-01 1.86767578e-02 4.01611328e-02 1.42700195e-01\n",
            " 1.42700195e-01 1.42700195e-01 1.60278320e-01 3.08837891e-02\n",
            " 3.64990234e-02 7.06787109e-02 1.81884766e-02 3.69873047e-02\n",
            " 3.69873047e-02 3.69873047e-02 3.69873047e-02 3.69873047e-02\n",
            " 3.69873047e-02 4.38232422e-02 3.33251953e-02 3.13720703e-02\n",
            " 4.02832030e-03 3.78417970e-03 7.20214840e-03 1.13525391e-02\n",
            " 1.13525391e-02 3.78417970e-03 2.40478516e-02 1.03759766e-02\n",
            " 1.20849609e-02 4.40673828e-02 1.20849609e-02 1.13891602e-01\n",
            " 5.01708984e-02 2.74658203e-02 2.79541016e-02 2.79541016e-02\n",
            " 1.96533203e-02 2.55126953e-02 5.70068359e-02 7.75146484e-02\n",
            " 6.62841797e-02 5.98144530e-03 1.57470703e-02 3.11279297e-02\n",
            " 1.74560547e-02 3.11279297e-02 3.52783203e-02 3.98559570e-01\n",
            " 1.79443359e-02 1.47705078e-02 4.08569336e-01 1.89208984e-02\n",
            " 2.94189453e-02 2.23754883e-01 2.16064453e-02 4.99267578e-02\n",
            " 1.68823242e-01 8.91113280e-03 2.35595703e-02 9.64355470e-03\n",
            " 7.69042970e-03 2.16064453e-02 3.21044922e-02 6.29760742e-01\n",
            " 4.79736328e-02 3.82080078e-02 4.35424805e-01 1.24877930e-01\n",
            " 5.92041016e-02 4.62646484e-02 5.01708984e-02 5.43212891e-02\n",
            " 3.72314453e-02 2.47802734e-02 2.91748047e-02 2.57568359e-02\n",
            " 3.13720703e-02 1.88354492e-01]\n",
            "Original data at differences: [1.37939453e-02 1.23291016e-02 1.21215820e-01 1.23291016e-02\n",
            " 6.75048828e-02 1.01318359e-02 5.09033203e-02 5.77270508e-01\n",
            " 1.81884766e-02 1.01318359e-02 1.98974609e-02 9.88769530e-03\n",
            " 1.01318359e-02 2.62084961e-01 1.40380859e-02 1.40380859e-02\n",
            " 1.18408203e-02 8.92333984e-02 6.59301758e-01 3.23486328e-02\n",
            " 1.18408203e-02 1.18408203e-02 8.66699220e-03 5.24902340e-03\n",
            " 1.30615234e-02 5.49316410e-03 3.14086914e-01 6.99462891e-02\n",
            " 3.17504883e-01 4.26025391e-02 1.02416992e-01 1.45263672e-02\n",
            " 4.26025391e-02 1.35375977e-01 2.81982422e-02 4.82177734e-02\n",
            " 2.24975586e-01 2.21069336e-01 2.08740234e-02 5.70068359e-02\n",
            " 2.08740234e-02 1.28173828e-02 9.85107422e-02 5.70068359e-02\n",
            " 7.21435547e-02 1.81884766e-02 1.81884766e-02 1.98974609e-02\n",
            " 1.03149414e-01 9.55810547e-02 1.87866211e-01 3.52172852e-01\n",
            " 4.72412109e-02 5.49316410e-03 1.94091797e-02 4.02832030e-03\n",
            " 2.86865234e-02 7.40966797e-02 1.06201172e-02 4.27246090e-03\n",
            " 1.95190430e-01 1.58081055e-01 2.08740234e-02 2.59399414e-01\n",
            " 6.28662109e-02 5.04150391e-02 9.33837891e-02 9.33837891e-02\n",
            " 6.53076172e-02 7.38525391e-02 9.33837891e-02 3.38134766e-02\n",
            " 1.27319336e-01 9.33837891e-02 3.38134766e-02 2.89916992e-01\n",
            " 5.28564453e-02 7.09228516e-02 6.40869141e-02 6.53076172e-02\n",
            " 1.57348633e-01 7.09228516e-02 8.50830078e-02 7.09228516e-02\n",
            " 1.96899414e-01 1.96899414e-01 1.96899414e-01 1.11694336e-01\n",
            " 1.34399414e-01 6.55517578e-02 6.40869141e-02 7.48291016e-02\n",
            " 7.48291016e-02 7.14111328e-02 3.38134766e-02 9.92431641e-02\n",
            " 7.48291016e-02 8.19091797e-02 1.58569336e-01 1.48559570e-01\n",
            " 9.14306641e-02 2.03491211e-01 7.20214840e-03 2.16064453e-02\n",
            " 2.56347660e-03 1.73217773e-01 2.16064453e-02 4.74731445e-01\n",
            " 1.21215820e-01 4.47631836e-01 2.34497070e-01 1.98974609e-02\n",
            " 1.01318359e-02 6.99462891e-02 7.93457030e-03 1.38549805e-01\n",
            " 2.65014648e-01 8.85009766e-02 6.21337891e-02 2.50244141e-02\n",
            " 2.50244141e-02 1.57470703e-02 8.91113280e-03 2.50244141e-02\n",
            " 3.03955078e-02 5.30151367e-01 4.06127930e-01 2.64892578e-02\n",
            " 2.64892578e-02 2.64892578e-02 2.03979492e-01 6.92138672e-02\n",
            " 1.60766602e-01 5.18798828e-02 9.38720703e-02 5.35888672e-02\n",
            " 1.41235352e-01 5.18798828e-02 1.41235352e-01 2.30712891e-02\n",
            " 5.62744141e-02 2.38037109e-02 1.20727539e-01 1.09985352e-01\n",
            " 2.60620117e-01 1.20849609e-02 8.17871090e-03 1.20849609e-02\n",
            " 5.98144530e-03 2.47924805e-01 2.13623047e-02 1.20849609e-02\n",
            " 5.87158203e-02 4.33349609e-02 6.79931641e-02 4.33349609e-02\n",
            " 1.31958008e-01 4.91821289e-01 2.42919922e-02 2.42919922e-02\n",
            " 8.66699220e-03 6.97021484e-02 1.72729492e-01 8.82568359e-02\n",
            " 2.33154297e-02 9.99755859e-02 8.82568359e-02 1.86645508e-01\n",
            " 2.39379883e-01 5.87158203e-02 2.39379883e-01 3.23486328e-02\n",
            " 3.23486328e-02 1.31713867e-01 6.65283203e-02 7.89794922e-02\n",
            " 7.89794922e-02 1.70776367e-01 7.89794922e-02 1.10229492e-01\n",
            " 3.40576172e-02 2.38037109e-02 9.33837891e-02 9.33837891e-02\n",
            " 7.38525391e-02 8.82568359e-02 5.33447266e-02 9.33837891e-02\n",
            " 2.05444336e-01 3.74755859e-02 1.17309570e-01 1.39282227e-01\n",
            " 1.02905273e-01 1.03942871e+00 1.21569824e+00 1.21569824e+00\n",
            " 7.88208008e-01 4.46899414e-01 1.64184570e-01 4.46899414e-01\n",
            " 1.21569824e+00 9.81567383e-01 4.46899414e-01 3.54003910e-03\n",
            " 2.30712891e-02 3.54003910e-03 2.65991211e-01 2.67333984e-02\n",
            " 7.93457030e-03 1.59301758e-01 4.89868164e-01 7.60498047e-02\n",
            " 6.74926758e-01 3.05175780e-03 3.01513672e-02 2.80761720e-03\n",
            " 3.03955078e-02 1.16577148e-01 9.43603516e-02 1.16577148e-01\n",
            " 1.50146484e-02 6.75048828e-02 1.50146484e-02 3.74755859e-02\n",
            " 1.34277340e-03 1.34277340e-03 5.00488280e-03 1.83105470e-03\n",
            " 5.49316410e-03 1.62353516e-02 1.55883789e-01 9.38720703e-02\n",
            " 4.51660160e-03 1.55883789e-01 1.57470703e-02 2.08740234e-02\n",
            " 2.86865234e-02 7.38525391e-02 2.62451172e-02 1.94213867e-01\n",
            " 5.28198242e-01 5.33447266e-02 2.38037109e-02 5.33447266e-02\n",
            " 6.87255859e-02 1.96533203e-02 1.70532227e-01 2.60009766e-02\n",
            " 1.09863280e-03 1.03759766e-02 1.23291016e-02 1.18408203e-02\n",
            " 3.30810547e-02 8.14208984e-02 1.33178711e-01 4.02832030e-03\n",
            " 1.67236328e-02 5.24902340e-03 5.24902340e-03 2.18505859e-02\n",
            " 2.18505859e-02 1.96533203e-02 2.18505859e-02 1.86767578e-02\n",
            " 6.09130859e-02 2.13623047e-02 3.35693359e-02 3.07006836e-01\n",
            " 1.10473633e-01 2.56347660e-03 1.37939453e-02 3.86962891e-02\n",
            " 4.60327148e-01 1.34277340e-03 3.35693359e-02 1.23291016e-02\n",
            " 1.10717773e-01 7.87353516e-02 5.98144530e-03 1.47094727e-01\n",
            " 1.47094727e-01 5.43212891e-02 1.47094727e-01 8.91113280e-03\n",
            " 4.01611328e-02 3.80493164e-01 6.06689453e-02 4.76074220e-03\n",
            " 9.82666016e-02 9.82666016e-02 9.82666016e-02 4.91943359e-02\n",
            " 9.82666016e-02 1.15844727e-01 2.66967773e-01 2.74658203e-02\n",
            " 1.66491699e+00 1.66491699e+00 1.66491699e+00 1.58581543e+00\n",
            " 3.57543945e-01 5.00122070e-01 1.66491699e+00 5.66528320e-01\n",
            " 8.37036133e-01 6.95800780e-03 1.45141602e-01 2.24975586e-01\n",
            " 1.45141602e-01 1.93969727e-01 2.18505859e-02 7.04345703e-02\n",
            " 7.28637695e-01 1.42370605e+00 1.42370605e+00 6.38549805e-01\n",
            " 7.05932617e-01 1.32214355e+00 8.93676758e-01 5.23559570e-01\n",
            " 1.42370605e+00 2.07519530e-03 4.79736328e-02 6.94580078e-02\n",
            " 8.94775391e-02 5.35278320e-01 3.60107422e-02 1.57470703e-02\n",
            " 3.60107422e-02 3.47900391e-02 1.30615234e-02 3.60107422e-02\n",
            " 1.55029297e-02 1.35498047e-02 3.74755859e-02 1.01928711e-01\n",
            " 1.29516602e-01 1.23291016e-02 7.14111328e-02 9.33837891e-02\n",
            " 1.01928711e-01 7.75146484e-02 4.18701172e-02 1.25732422e-02\n",
            " 2.61352539e-01 1.08276367e-01 7.93457030e-03 5.74951172e-02\n",
            " 4.04052734e-02 5.17456055e-01 1.06201172e-02 3.13720703e-02\n",
            " 2.91748047e-02 9.19189453e-02 6.09130859e-02 8.97216797e-02\n",
            " 7.18994141e-02 4.74853516e-02 8.97216797e-02 5.60302734e-02\n",
            " 3.80737305e-01 1.08642578e-02 1.66137695e-01 3.89404297e-02\n",
            " 3.09936523e-01 9.63134766e-02 4.72412109e-02 8.26416016e-02\n",
            " 6.57958984e-02 8.26416016e-02 8.26416016e-02 5.04150391e-02\n",
            " 1.12182617e-01 7.60498047e-02 7.70263672e-02 1.91772461e-01\n",
            " 7.28759766e-02 4.62646484e-02 4.47998047e-02 2.84423828e-02\n",
            " 2.84423828e-02 3.30810547e-02 2.90405273e-01 5.23681641e-02\n",
            " 1.20239258e-01 3.47900391e-02 3.21044922e-02 9.39941410e-03\n",
            " 2.62451172e-02 7.16552734e-02 4.21142578e-02 2.62451172e-02\n",
            " 1.27563477e-01 2.40478516e-02 5.50537109e-02 2.62451172e-02\n",
            " 2.20947266e-02 9.65576172e-02 2.88940430e-01 1.96533203e-02\n",
            " 6.60400391e-02 4.76074220e-03 1.37939453e-02 2.45361328e-02\n",
            " 4.55322266e-02 1.24633789e-01 1.24633789e-01 3.62670898e-01\n",
            " 4.55322266e-02 2.50244141e-02 1.16333008e-01 7.06787109e-02\n",
            " 6.35986328e-02 2.15209961e-01 2.30834961e-01 4.43115234e-02\n",
            " 4.43115234e-02 2.80395508e-01 4.55322266e-02 3.94287109e-02\n",
            " 3.94287109e-02 3.72314453e-02 1.07788086e-01 3.94287109e-02\n",
            " 4.13818359e-02 3.48022461e-01 1.91650391e-02 3.08837891e-02\n",
            " 1.76391602e-01 6.45751953e-02 6.45751953e-02 1.60766602e-01\n",
            " 1.76391602e-01 1.72973633e-01 4.35791016e-02 3.13720703e-02\n",
            " 9.97314453e-02 2.10571289e-01 5.28564453e-02 1.12182617e-01\n",
            " 4.51660160e-03 4.45556641e-02 7.21435547e-02 3.07495117e-01\n",
            " 1.45263672e-02 1.98120117e-01 1.04370117e-01 7.97119141e-02\n",
            " 1.04370117e-01 1.40380859e-02 9.85107422e-02 1.04370117e-01\n",
            " 2.07153320e-01 1.33178711e-01 1.96533203e-02 5.40771484e-02\n",
            " 6.60400391e-02 3.03955078e-02 1.45263672e-02 8.75244141e-02\n",
            " 9.65576172e-02 1.37939453e-02 3.45458984e-02 2.13012695e-01\n",
            " 3.18603516e-02 8.70361328e-02 1.08520508e-01 8.70361328e-02\n",
            " 8.67919922e-02 3.21044922e-02 2.36694336e-01 1.53686523e-01\n",
            " 3.79638672e-02 1.27563477e-01 1.02661133e-01 3.79638672e-02\n",
            " 8.41064453e-02 1.86767578e-02 5.11474609e-02 1.25610352e-01\n",
            " 7.80639648e-01 2.20947266e-02 1.86767578e-02 2.64892578e-02\n",
            " 9.88769530e-03 1.52587891e-02 3.67065430e-01 5.10864258e-01\n",
            " 9.98168945e-01 9.71557617e-01 9.98168945e-01 3.53637695e-01\n",
            " 3.89038086e-01 9.98168945e-01 1.29760742e-01 9.98168945e-01\n",
            " 1.29028320e-01 1.31469727e-01 9.43603516e-02 1.17797852e-01\n",
            " 1.31713867e-01 9.89990234e-02 9.89990234e-02 2.60864258e-01\n",
            " 3.33251953e-02 2.88208008e-01 3.52783203e-02 2.25830078e-02\n",
            " 1.08032227e-01 1.89208984e-02 4.04052734e-02 1.43188477e-01\n",
            " 1.43188477e-01 1.43188477e-01 1.60034180e-01 3.06396484e-02\n",
            " 3.62548828e-02 7.09228516e-02 1.84326172e-02 3.64990234e-02\n",
            " 3.64990234e-02 3.64990234e-02 3.64990234e-02 3.64990234e-02\n",
            " 3.64990234e-02 4.35791016e-02 3.35693359e-02 3.16162109e-02\n",
            " 4.27246090e-03 4.02832030e-03 7.44628910e-03 1.15966797e-02\n",
            " 1.15966797e-02 4.02832030e-03 2.42919922e-02 1.06201172e-02\n",
            " 1.23291016e-02 4.43115234e-02 1.23291016e-02 1.14135742e-01\n",
            " 5.06591797e-02 2.77099609e-02 2.81982422e-02 2.81982422e-02\n",
            " 1.98974609e-02 2.57568359e-02 5.72509766e-02 7.72705078e-02\n",
            " 6.55517578e-02 7.69042970e-03 1.74560547e-02 3.03955078e-02\n",
            " 1.77001953e-02 3.03955078e-02 3.60107422e-02 3.98803711e-01\n",
            " 1.81884766e-02 1.50146484e-02 4.08813477e-01 1.94091797e-02\n",
            " 2.96630859e-02 2.23510742e-01 2.18505859e-02 5.01708984e-02\n",
            " 1.69067383e-01 9.88769530e-03 2.38037109e-02 1.01318359e-02\n",
            " 8.17871090e-03 2.18505859e-02 3.28369141e-02 6.29516602e-01\n",
            " 4.84619141e-02 3.89404297e-02 4.35180664e-01 1.24389648e-01\n",
            " 5.89599609e-02 4.60205078e-02 5.04150391e-02 5.45654297e-02\n",
            " 3.74755859e-02 2.52685547e-02 2.94189453e-02 2.64892578e-02\n",
            " 3.18603516e-02 1.88598633e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    음수의 경우 정수부를 내림하여 변환하고, 남은 값을 소수부로 변환.\n",
        "    \"\"\"\n",
        "    max_int_value = 2**(int_bits - 1) - 1  # 7비트 최대값 (63)\n",
        "    min_int_value = -2**(int_bits - 1)     # 7비트 최소값 (-64)\n",
        "    max_frac_value = 2**frac_bits           # 13비트 정밀도 (8192)\n",
        "\n",
        "    # ✅ 정수부 조정 (floor 적용하여 내림)\n",
        "    int_part = int(np.floor(value))\n",
        "    frac_part = abs(value - int_part)\n",
        "\n",
        "    # ✅ 정수부 범위 확인\n",
        "    if int_part < min_int_value or int_part > max_int_value:\n",
        "        raise ValueError(f\"정수부 {int_part}가 {min_int_value} ~ {max_int_value} 범위를 벗어남!\")\n",
        "\n",
        "    # ✅ 2의 보수 변환 (정수부 7비트)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 앞 12비트는 항상 0 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트, 항상 양수)\n",
        "    frac_binary = format(int(round(frac_part * max_frac_value)), f'0{frac_bits}b')\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "id": "gNlyfcx-D_Mi",
        "outputId": "27a8ec3b-924d-4dc5-bbf5-01d290e49526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output2.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjoyAYqcE8Rj",
        "outputId": "806da579-4f22-466b-9e74-888b7332daa3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output2.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/output.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "y9gvMWCUC7wz",
        "outputId": "03ce7d82-9770-4acd-afd6-5f56d6e16db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000000000000110111101010111 00000000000000000000001110111111 00000000000000000001001010111110 00000000000000000001010000101111 00000000000011111111011000011011 00000000000000000100011000111011\n",
            "00000000000011111111101101000000 00000000000000000000111111101101 00000000000000000100000111111001 00000000000000000010110011111000\n",
            "00000000000000000011010101110011 00000000000000000110101100010111 00000000000000001011100101100001 00000000000000001001001111011111 00000000000000000111101000000010 00000000000000000100101011110001\n",
            "00000000000000000011110001101001 00000000000000000100110001101111 00000000000000000011000110001100 00000000000000000011110100011101\n",
            "00000000000000000110101000100011 00000000000000001001000000011000 00000000000000000111100111010101 00000000000000001010011011001011 00000000000000000100100111011101 00000000000000000110000100011111\n",
            "00000000000000000100111101011010 00000000000000000011010111111111 00000000000000000101001101001010 00000000000000000011001000011001\n",
            "00000000000000000101001001001100 00000000000000001001010011100101 00000000000000001101100110000000 00000000000000000111100110100110 00000000000000001010101010100000 00000000000000000101010100011011\n",
            "00000000000000000101011100001010 00000000000000000100110101010101 00000000000000000100010110110110 00000000000000000110001101111010\n",
            "00000000000000000001010000000001 00000000000000001001010010001010 00000000000000000110100111011000 00000000000000001010001000001110 00000000000000000110101011100000 00000000000000000101100011010110\n",
            "00000000000000000011101111110011 00000000000000000110111111101111 00000000000000000100000011000001 00000000000000000101001011101111\n",
            "00000000000000000111111101011000 00000000000000000101001110100111 00000000000000000100100011010011 00000000000000000101110101111101 00000000000000000111000001100001 00000000000000000110011100001110\n",
            "00000000000000000110000101100010 00000000000000000101101111100000 00000000000000001000101000000000 00000000000000001000100110110111\n",
            "00000000000000000011100101111000 00000000000000000101010111101101 00000000000000000011010110011001 00000000000000000010101000110110 00000000000000001000010110000010 00000000000000000110101010011000\n",
            "00000000000000000100111100101100 00000000000000001001000110011110 00000000000000000101010001111010 00000000000000000110010110011100\n",
            "00000000000000000011010001110000 00000000000000000011100010001000 00000000000000000100001101000001 00000000000000000100001101101110 00000000000000000110110110001001 00000000000000000110110001010011\n",
            "00000000000000001000011100101011 00000000000000000101111011000000 00000000000000000111110100100000 00000000000000001001000100110100\n",
            "00000000000000000110100111010101 00000000000000000010100001100000 00000000000000000100101110110001 00000000000000000010010000011010 00000000000000000100011101110111 00000000000000000101111111100111\n",
            "00000000000000000111101001010101 00000000000000001000101110011111 00000000000000000111000011101111 00000000000000001011011111111100\n",
            "00000000000000001001001001000000 00000000000000000110001110111000 00000000000000000100111110010000 00000000000000000110110110100111 00000000000000000100010111000001 00000000000000001011011111100001\n",
            "00000000000000000110010110010001 00000000000000001000111011101001 00000000000000001101001111001000 00000000000000001010010010111111 00000000000011111101110100101001 00000000000000000000000011010001 00000000000000000000100111110100 00000000000011111111110000110100\n",
            "00000000000011111111110110001000 00000000000011111100100110101100 00000000000011111111111001110010 00000000000011111111000101000100\n",
            "00000000000011111110101000111010 00000000000000000001111011001111\n",
            "00000000000011111100100000111000 00000000000011111110110101111000 00000000000000000001011101011101 00000000000000000000110111101101\n",
            "00000000000000000000000111110101 00000000000011111101101001001001 00000000000011111111100011110101 00000000000011111110100001100110\n",
            "00000000000011111110100111101100 00000000000000000001111100011101\n",
            "00000000000011111111001000100101 00000000000011111111010011011111 00000000000011111110110000110111 00000000000011111110111000110000\n",
            "00000000000011111111100101100010 00000000000011111101101111001111 00000000000000000000011011100100 00000000000011111111111000100000\n",
            "00000000000011111101010111101110 00000000000000000010010000000010\n",
            "00000000000011111110110100011000 00000000000011111111011111100000 00000000000000000000000000000010 00000000000000000000000010001001\n",
            "00000000000000000000111010010101 00000000000011111111011111111110 00000000000000000000000100101100 00000000000000000000010010111010\n",
            "00000000000011111111010101000100 00000000000000000010100010001001\n",
            "00000000000011111100100011000100 00000000000011111111111011010000 00000000000000000000101001010111 00000000000000000000001100011000\n",
            "00000000000011111111011111011001 00000000000011111100111011010011 00000000000000000001011010100000 00000000000000000001010011100000\n",
            "00000000000011111101100101100100 00000000000000000001001011100011\n",
            "00000000000011111101100101001110 00000000000000000000010011100100 00000000000000000000110000111011 00000000000000000000100100011101\n",
            "00000000000000000000110000010000 00000000000011111110010010111110 00000000000000000000000010010110 00000000000000000000111000000010\n",
            "00000000000011111111000000111100 00000000000000000001100110011000\n",
            "00000000000011111111011010111111 00000000000000000000001100110110 00000000000011111111110100010101 00000000000000000000000100101001\n",
            "00000000000000000000001101101010 00000000000011111110010100111101 00000000000000000000011001100111 00000000000000000001001010101011\n",
            "00000000000011111111101001100111 00000000000000000001001101101000\n",
            "00000000000011111111010001111100 00000000000000000000001011101110 00000000000000000000110110000100 00000000000000000000001110011010\n",
            "00000000000011111111110111101110 00000000000011111101001110001000 00000000000000000000110001110101 00000000000011111111010100111100\n",
            "00000000000011111110110111001001 00000000000000000001111111011111\n",
            "00000000000011111110000100111000 00000000000000000000011101010111 00000000000000000000010011000101 00000000000000000000010101011111\n",
            "00000000000000000000010101110011 00000000000011111110111010111001 00000000000000000000000100011100 00000000000000000001011000000100\n",
            "00000000000011111111010101001101 00000000000000000000111000100010\n",
            "00000000000011111110110010010111 00000000000011111111010010001011 00000000000000000000111100101001 00000000000000000000100010100101\n",
            "00000000000000000000100000111111 00000000000011111110001011100100 00000000000000000000010110010011 00000000000011111111110010101000\n",
            "00000000000011111111000100100111 00000000000000000001101000110110 00000000000000000101110011001001 00000000000000000000000010110100 00000000000011111110100000001100 00000000000000000001010000110100 00000000000011111101101111101011 00000000000000000110001011011101\n",
            "00000000000000000001110110110010 00000000000011111111101101000111 00000000000000001000001011111000 00000000000000000100110100101010\n",
            "00000000000000000001001011001111 00000000000000000110000001011110 00000000000000000111110100000010 00000000000000000110011110001100 00000000000000000001000000100011 00000000000000000000101100100101\n",
            "00000000000000000000010110011110 00000000000000000100010000110001 00000000000011111111110011111100 00000000000000000001111110001000\n",
            "00000000000000000001001101011011 00000000000000000100011101111111 00000000000000000101010000111011 00000000000000000100110111000110 00000000000000000000111110010101 00000000000000000001101101101101\n",
            "00000000000000000010000000000000 00000000000000000011000001010010 00000000000000000001001000101111 00000000000000000010110000110010\n",
            "00000000000000000010110111001000 00000000000000000100000001010001 00000000000000001000001011001000 00000000000000000110001100000111 00000000000000000001001000101110 00000000000000000001100000110101\n",
            "00000000000000000000101010100101 00000000000000000010111011100111 00000000000011111111011000111011 00000000000000000001111100100000\n",
            "00000000000011111111010111011111 00000000000000000011000110101010 00000000000000000110000010001111 00000000000000000010111101111000 00000000000000000100011101000010 00000000000011111101011001011111\n",
            "00000000000000000010010001000000 00000000000000000111001001111010 00000000000011111101001000111111 00000000000011111111101001101111\n",
            "00000000000000000110110101100110 00000000000000000001010000011100 00000000000000000000001001010100 00000000000000000001011011110100 00000000000011111111010110000101 00000000000000000100100101000110\n",
            "00000000000000000010000111011000 00000000000000000000011100010101 00000000000000000110001001100110 00000000000000000100111010000001\n",
            "00000000000000000011110100000010 00000000000000000001110001001011 00000000000000000010011010101000 00000000000000000000010010010011 00000000000000000001001011111100 00000000000000000000111110110010\n",
            "00000000000000000001001001000100 00000000000000000011000000011011 00000000000000000000110110100110 00000000000000000001010011110101\n",
            "00000000000000000100001111110001 00000000000000000001101100110000 00000000000000000010110111000010 00000000000000000010101101010100 00000000000000000010001001100101 00000000000000000011101101001011\n",
            "00000000000000000001100010001011 00000000000000000011001011111101 00000000000000000010000000111010 00000000000000000100001010100010\n",
            "00000000000000000110011100000110 00000000000000000000000001001111 00000000000000000001001000111001 00000000000000000000011101101011 00000000000011111111010110101110 00000000000000000100001111100111\n",
            "00000000000000000010010111000010 00000000000000000000100000111100 00000000000000000011100100000100 00000000000000000100000000101011\n",
            "00000000000000000111110100110101 00000000000000000001101100110001 00000000000000000000110001011111 00000000000000000001101010000110 00000000000000000000011110101011 00000000000000000111000100000110\n",
            "00000000000000000010101000100100 00000000000000000001110011111111 00000000000000001000010100010100 00000000000000000101110101110110 00000000000011111110001010011110 00000000000011111110100001101001 00000000000011111101011011101100 00000000000011111101010111101001 00000000000011111100011010110010 00000000000011111011010001111010\n",
            "00000000000011111100100100011000 00000000000011111011111000100000 00000000000011111110001110110001 00000000000011111101111010111111\n",
            "00000000000000000001100010010100 00000000000000000101101101001000 00000000000000000001111101100100 00000000000000000010001011011100 00000000000000000010100101010100 00000000000011111111010010000010\n",
            "00000000000011111111111001000110 00000000000000000010010001101000 00000000000011111101101000110011 00000000000000000001000100001100\n",
            "00000000000000000000111000011010 00000000000000000011110001110100 00000000000000000010110010011101 00000000000000000010011110110001 00000000000000000001110111100011 00000000000011111110110010000001\n",
            "00000000000000000000101111101000 00000000000000000010001111011110 00000000000011111111000010011110 00000000000000000001110101001001\n",
            "00000000000011111111001011110010 00000000000000000011110100101101 00000000000000000001001110010001 00000000000000000010111111110100 00000000000000000010100100110010 00000000000011111111011111011110\n",
            "00000000000000000000010110110100 00000000000000000001101010110110 00000000000011111110110100100000 00000000000000000011100101000110\n",
            "00000000000000000001000000110000 00000000000000000011011000001110 00000000000000000001101010010010 00000000000000000000101101100001 00000000000000000011111000001111 00000000000011111111010110001110\n",
            "00000000000011111111101011100111 00000000000000000010100001010110 00000000000011111101000010100001 00000000000000000001110110010001\n",
            "00000000000000000000111100011110 00000000000000000010000110010101 00000000000000000001011000010100 00000000000000000001001001101011 00000000000000000000100100001100 00000000000000000011010110001001\n",
            "00000000000000000010011111110001 00000000000000000010111000110011 00000000000000000010000001010100 00000000000000000001100101010010\n",
            "00000000000000000010011110100010 00000000000000000010010001000101 00000000000000000001010010100000 00000000000000000000110111111111 00000000000000000010000001110111 00000000000011111110111100011111\n",
            "00000000000000000010010001101111 00000000000000000010100011111111 00000000000011111111011101101101 00000000000011111111010110010111\n",
            "00000000000011111110110001000010 00000000000000000001111000100000 00000000000000000001010011110001 00000000000000000000111000100101 00000000000000000010000100000000 00000000000000000000100011110110\n",
            "00000000000000000001010011111011 00000000000000000010111001111101 00000000000000000000001101110000 00000000000000000100000010111010\n",
            "00000000000000000001010100100111 00000000000000000010010010011100 00000000000000000001101010001111 00000000000000000001010101110000 00000000000000000001011000000110 00000000000000000001110001001010\n",
            "00000000000000000010011101100000 00000000000000000010001010000111 00000000000000000001111100001000 00000000000000000000010111101001\n",
            "00000000000000000000111101100010 00000000000000000001001010011011 00000000000000000001010100000111 00000000000000000000101011110010 00000000000011111111001010001100 00000000000011111101111101001000\n",
            "00000000000011111111101110000110 00000000000000000001101010101100 00000000000000000000111001110101 00000000000011111111111100100011 00000000000011111111001010001010 00000000000011111111011110001010 00000000000011111110010111001011 00000000000000000001000101110011 00000000000011111110010111001100 00000000000000000110100010000001\n",
            "00000000000000000010001111101111 00000000000011111111000101001001 00000000000000000110000001001000 00000000000000001000001000111011\n",
            "00000000000000000011011011000101 00000000000000001000000001010101 00000000000000001100001100011100 00000000000000001000000111111100 00000000000000000110101101000001 00000000000000000001010111000000\n",
            "00000000000000000100111100101101 00000000000000000101000110011100 00000000000000000010000101001011 00000000000000000101010010000111\n",
            "00000000000000000011010011111010 00000000000000000101110001001011 00000000000000000111010001001110 00000000000000000100110111001100 00000000000000000100111010000001 00000000000000000011101100011001\n",
            "00000000000000000010010111111101 00000000000000000100010001111100 00000000000000000101001011111101 00000000000000000101000011000100\n",
            "00000000000000000101110010111001 00000000000000001000100110011011 00000000000000001101010101000101 00000000000000000101101000010001 00000000000000001000000000111100 00000000000000000001110110100000\n",
            "00000000000000000001110111101111 00000000000000000011111000100010 00000000000000000010010011010100 00000000000000000100001011100000\n",
            "00000000000000000010111000000111 00000000000000001001000111110010 00000000000000000111011011001111 00000000000000000110100111000110 00000000000000000101000100011010 00000000000000000000101000001111\n",
            "00000000000000000101100000000010 00000000000000000111100011000010 00000000000000000010110101111010 00000000000000000011011101111100\n",
            "00000000000011111100010000011011 00000000000000000100001101011100 00000000000000000100100100010010 00000000000000000100001110010110 00000000000000000010111110001000 00000000000000000100110110101111\n",
            "00000000000000000110001001100101 00000000000000000011110010001010 00000000000000000111111001011011 00000000000000001001100100100110\n",
            "00000000000000000001010001100001 00000000000000000011100111101110 00000000000000000001101100100010 00000000000000000010010100010001 00000000000000000100100110010011 00000000000000000011110111100010\n",
            "00000000000000000100010111111010 00000000000000000110100000100101 00000000000000000100101110001100 00000000000000000111000010000110\n",
            "00000000000000000000110011001011 00000000000000000011001101100101 00000000000000000011011101110001 00000000000000000000101101111000 00000000000000000100111101001001 00000000000000000010000100101111\n",
            "00000000000000000101011010010011 00000000000000000100111011100111 00000000000000000010101110000110 00000000000000000101100000111000\n",
            "00000000000011111100111101011110 00000000000000000000111101010000 00000000000000000010011010101110 00000000000000000001101101001001 00000000000000000010000101000111 00000000000000000100100010000101\n",
            "00000000000000000110001001011101 00000000000000000100000110011010 00000000000000000100111111011110 00000000000000001001010111111111\n",
            "00000000000000000110000000000001 00000000000011111110100010101000 00000000000011111110100000101111 00000000000000000011100101010101 00000000000000000000111100111110 00000000000000000101110111110101\n",
            "00000000000000000100100100101010 00000000000000000100001011110011 00000000000000000100101010101101 00000000000000000111001101111110 00000000000000000100101101000010 00000000000011111011001100101001 00000000000011111010110101001001 00000000000011111010110101001110 00000000000011111101000111110011 00000000000011111101001101001011\n",
            "00000000000011111101000001101011 00000000000011111101010111101110 00000000000011111100111101010001 00000000000011111111110010101011\n",
            "00000000000011111111110101101110 00000000000000000001111010001110 00000000000000000110001011000001 00000000000000000010001010010010 00000000000000000101100110100111 00000000000000000010100111010111\n",
            "00000000000000000101000000000011 00000000000000000110110100101011 00000000000000000011000011101000 00000000000000000100110011001101\n",
            "00000000000011111110000001111101 00000000000000000010111010010100 00000000000000000011000101011011 00000000000000000000100111100100 00000000000000000110010100011010 00000000000000000010101001011001\n",
            "00000000000000000100000011111101 00000000000000000111110000101011 00000000000000000001100011010110 00000000000000000100011010110101\n",
            "00000000000011111101010001010001 00000000000000000011111111110100 00000000000000000110010000010110 00000000000000000001111100111001 00000000000000000110010011101100 00000000000000000101000111001001\n",
            "00000000000000000101100110010100 00000000000000000111001101110001 00000000000000000100111101111100 00000000000000000111000001001111\n",
            "00000000000011111110111011111010 00000000000000000101100100101011 00000000000000000101110111011011 00000000000000000011111111010100 00000000000000000101010011101100 00000000000000000000010101111001\n",
            "00000000000000000010110100100010 00000000000000000111000100010111 00000000000000000000001100000011 00000000000000000100001110100101\n",
            "00000000000011111111111001011010 00000000000000000101111010111011 00000000000000000101101011100010 00000000000000000101111110011101 00000000000000000100011011011110 00000000000000000110000011011001\n",
            "00000000000000000101001100110110 00000000000000000100111000001001 00000000000000000110010010000111 00000000000000000111110010001100\n",
            "00000000000011111110000000100001 00000000000000000101010111110010 00000000000000000101001010101010 00000000000000000101001101001011 00000000000000000101000100011010 00000000000000000010100101000010\n",
            "00000000000000000010111010101001 00000000000000000101010001101010 00000000000000000100000010100111 00000000000000000100011011100001\n",
            "00000000000000000000000101110010 00000000000000000101110111011011 00000000000000000110100011100011 00000000000000000101011100010001 00000000000000000110011010000101 00000000000000000010011010111110\n",
            "00000000000000000011111101100101 00000000000000000100111111100111 00000000000000000010001110111011 00000000000000000011001001001001\n",
            "00000000000011111111100010011001 00000000000000000100011100101000 00000000000000000101010100000000 00000000000000000101001110011000 00000000000000000100010100001100 00000000000000000100011010101000\n",
            "00000000000000000101000010110010 00000000000000000100101001101111 00000000000000000011111100011101 00000000000000000101100010111000\n",
            "00000000000000000000011111111010 00000000000000000110011000000111 00000000000000000110001101110010 00000000000000000110101111010011 00000000000000000101010100011001 00000000000000000110111111010101\n",
            "00000000000000000101101111110011 00000000000000000101111010101111 00000000000000000111011001101100 00000000000000001010110001111110 00000000000000000011101101110010 00000000000011111111101001001011 00000000000011111110010100100101 00000000000011111111100110001100 00000000000000000000000100101101 00000000000000000011101010101101\n",
            "00000000000011111110111110000001 00000000000011111110001000001100 00000000000011111111010001111001 00000000000000000100000011111000\n",
            "00000000000000000000001001101110 00000000000000000011010010001000 00000000000000000100111100001100 00000000000000000011011001110010 00000000000000000011011111001010 00000000000000000000000001010001\n",
            "00000000000000000010100110100000 00000000000000000011110010101110 00000000000000000011000101101111 00000000000000000011001110111100\n",
            "00000000000000000001011001000000 00000000000000000100010101101010 00000000000000000100010010011100 00000000000000000011011110011101 00000000000000000100010110111110 00000000000000000000000001001101\n",
            "00000000000000000010110000111000 00000000000000000100110011111111 00000000000000000011000001111010 00000000000000000011101010100010\n",
            "00000000000000000011000000000011 00000000000000000100011000100001 00000000000000000101100010000111 00000000000000000001110111010101 00000000000000000100001010000001 00000000000011111111010110001011\n",
            "00000000000000000011000011011101 00000000000000000101001110110000 00000000000000000010100010011001 00000000000000000101001000100001\n",
            "00000000000011111110111101001000 00000000000000000100111111000010 00000000000000000010111101111101 00000000000000000010101110011101 00000000000000000011000110101010 00000000000011111110011111110111\n",
            "00000000000000000010001110010011 00000000000000000101110010111000 00000000000000000010011101111100 00000000000000000001100101010010\n",
            "00000000000000001001001101111000 00000000000000000101001110100110 00000000000000000011010110010111 00000000000000000011001000000101 00000000000000000010010000000101 00000000000000000100010100000000\n",
            "00000000000000000011100111010001 00000000000000000010000111011101 00000000000000000011111000100110 00000000000000001000011010111101\n",
            "00000000000000000100111000110011 00000000000000000100001010100000 00000000000000000011100101001000 00000000000000000011000111011100 00000000000000000100011000001100 00000000000000000011111011101110\n",
            "00000000000000000010110011101101 00000000000000000100001101111000 00000000000000000010000010100111 00000000000000000100110101010000\n",
            "00000000000000000011001110111110 00000000000000000100001110110100 00000000000000000011100100011100 00000000000000000010010001001001 00000000000000000100111100001100 00000000000000000010001110001111\n",
            "00000000000000000011111001001010 00000000000000000100100100000001 00000000000000000010110100100010 00000000000000000101000101010111\n",
            "00000000000000000101001001101111 00000000000000000011101100010101 00000000000000000010111001001111 00000000000000000010011110110111 00000000000000000010010101010101 00000000000000000010011101000000\n",
            "00000000000000000100010001101001 00000000000000000011011100001100 00000000000000000010101001100000 00000000000000000100111101010101\n",
            "00000000000000001010111010010111 00000000000000000101101101001110 00000000000000000011110011111101 00000000000000000101100110111011 00000000000000000100010111111110 00000000000000001001000101010101\n",
            "00000000000000000100101011110000 00000000000000000101010001111101 00000000000000000110101000011000 00000000000000001010101101001110 00000000000011111111100101010010 00000000000011111111111010000000 00000000000011111111110111001001 00000000000000000000011100111100\n",
            "00000000000011111110111100100000 00000000000011111111111011000010 00000000000011111111010011001001 00000000000011111111100001001001\n",
            "00000000000011111111111011001000 00000000000011111111000110101011\n",
            "00000000000000000000110010010100 00000000000011111110100011110100 00000000000011111111110001110111 00000000000011111111000011100110\n",
            "00000000000011111110110000000101 00000000000011111110111000111100 00000000000011111111110111111011 00000000000000000000011110010111\n",
            "00000000000011111111011001101100 00000000000000000001010110011011\n",
            "00000000000000000001110111100000 00000000000011111111011000101111 00000000000011111101100010110100 00000000000011111111100001011001\n",
            "00000000000000000000011011100011 00000000000011111111111100010000 00000000000000000000010111111111 00000000000000000000111111000101\n",
            "00000000000011111111010110100100 00000000000000000001000101000011\n",
            "00000000000000000000111001100101 00000000000011111111110101111101 00000000000011111110100101101011 00000000000011111110101000111111\n",
            "00000000000011111111010110011100 00000000000011111111111111101011 00000000000000000000011111001010 00000000000011111111001111001010\n",
            "00000000000011111110110000101010 00000000000000000001011001010010\n",
            "00000000000000000000001001100110 00000000000011111111010100011010 00000000000011111111100101100110 00000000000011111111111011100000\n",
            "00000000000011111011101111010111 00000000000011111111000100111000 00000000000000000000001101000111 00000000000011111111100010001011\n",
            "00000000000011111111000110100011 00000000000011111111111001101111\n",
            "00000000000000000000011111000001 00000000000000000000011110111000 00000000000011111111101111001110 00000000000000000000100110010101\n",
            "00000000000000000000000000010111 00000000000000000000011000010010 00000000000000000000100110101101 00000000000000000000000011011000\n",
            "00000000000000000000000100001100 00000000000000000000001100010110\n",
            "00000000000000000001000011000100 00000000000011111111000111110100 00000000000000000001001101100110 00000000000011111111101011011101\n",
            "00000000000011111111000101001000 00000000000011111111001100011011 00000000000011111111010011111100 00000000000011111111010111110001\n",
            "00000000000011111111111111100100 00000000000011111111100111010000\n",
            "00000000000011111110110111100010 00000000000011111111100111110111 00000000000011111111111100001010 00000000000011111101010111100110\n",
            "00000000000011111111001101001010 00000000000011111111101010110110 00000000000011111111011000010001 00000000000011111010110001100100\n",
            "00000000000011111110110011001000 00000000000000000000000101011000\n",
            "00000000000000000000011101110010 00000000000000000000101100011011 00000000000011111111111011000010 00000000000000000000001000010010\n",
            "00000000000011111111100111100110 00000000000000000000010001101110 00000000000000000000001000100110 00000000000011111111110100111001\n",
            "00000000000000000000010100010000 00000000000011111111111110110011\n",
            "00000000000000000000011100001100 00000000000011111111101100010000 00000000000011111111110100100100 00000000000011111111111010111000\n",
            "00000000000000000000000000001000 00000000000011111111111100010110 00000000000011111111110111011111 00000000000011111111111000000001\n",
            "00000000000000000000000111000010 00000000000011111111011111111100 00000000000000000001011101000111 00000000000000000000001110101110 00000000000000000000100100011000 00000000000011111111001100011101 00000000000011111111100010101000 00000000000000000001001001010011\n",
            "00000000000000000001011001100110 00000000000000000000010001011111 00000000000000000100100000000000 00000000000000000100011100000000\n",
            "00000000000000000010110011011100 00000000000000000110111100000001 00000000000000000100101000011010 00000000000000000101111001101111 00000000000000000010011001001010 00000000000000000010010100100001\n",
            "00000000000011111111101001010101 00000000000000000001010100001000 00000000000000000000011101001010 00000000000000000011110000100110\n",
            "00000000000000000010100101011001 00000000000000000001110001111111 00000000000000000111011010110110 00000000000000000100101100001110 00000000000000000010000001111101 00000000000000000010110110110100\n",
            "00000000000000000001000111110001 00000000000000000000111100010101 00000000000000000011010001110111 00000000000000000011110100001110\n",
            "00000000000000000011101110100011 00000000000000000110000000011111 00000000000000000111101010111011 00000000000000001000010001011011 00000000000000000010011101001000 00000000000000000100101001010111\n",
            "00000000000011111111100111011000 00000000000000000010000110110100 00000000000000000010101010010111 00000000000000000101001011100011\n",
            "00000000000000000001000101001000 00000000000000000001001110101000 00000000000000000011100000100110 00000000000000000011101011000000 00000000000000000110001100000100 00000000000000000001010110010110\n",
            "00000000000000000000100001001111 00000000000000000011000011001011 00000000000000000000111100001111 00000000000000000010100110100000\n",
            "00000000000011111110001000011101 00000000000000000001000000011110 00000000000000000001101111111100 00000000000000000000111001101101 00000000000000000001110011010111 00000000000011111111110001111101\n",
            "00000000000000000011111110111011 00000000000000000010101100001000 00000000000000000100001011111111 00000000000000000001100110100110\n",
            "00000000000000000001001001010100 00000000000011111111111010110111 00000000000000000000111001101101 00000000000011111111001000101110 00000000000000000001111101101101 00000000000000000000000101001110\n",
            "00000000000000000010111101100100 00000000000000000000110100000000 00000000000000000000001001011100 00000000000000000001000100110010\n",
            "00000000000000000100001100001111 00000000000000000001001101000010 00000000000000000001010110010110 00000000000000000001000011100001 00000000000000000011110001000011 00000000000000000001011010101000\n",
            "00000000000000000010001010011100 00000000000000000110010010100011 00000000000000000000011000110100 00000000000000000100110010101101\n",
            "00000000000011111111001111100110 00000000000000000000010111111111 00000000000000000011011111010111 00000000000000000000111010111000 00000000000000000001101010011000 00000000000000000001001001011011\n",
            "00000000000000000100000001100110 00000000000000000011010101100101 00000000000000000011000110010000 00000000000000000010010000100011\n",
            "00000000000000000001001111010100 00000000000000000000100100011100 00000000000000000001100111110100 00000000000000000000100110010011 00000000000000000000001111101000 00000000000000000001010001000110\n",
            "00000000000000000011011001110110 00000000000000000010011001010100 00000000000000000100001001001110 00000000000000000010101110010100 00000000000011111110011110001011 00000000000011111111111010101001 00000000000011111111111011000010 00000000000011111111111110101011 00000000000000000000001110000011 00000000000011111001001011100111\n",
            "00000000000011111110010010111100 00000000000011111111110011000011 00000000000011111110110001110111 00000000000000000010001110100011\n",
            "00000000000000000001010000110101 00000000000000000011001000011110 00000000000000000010000001110000 00000000000000000001100101010001 00000000000000000001000000010110 00000000000011111110010011101110\n",
            "00000000000011111110110011001011 00000000000000000010001001101010 00000000000000000000101110011111 00000000000000000011000100100111\n",
            "00000000000011111111100110110111 00000000000000000010110000100101 00000000000000000001111111101001 00000000000000000000110110010111 00000000000000000001100000010010 00000000000011111101011011110011\n",
            "00000000000011111111100000110011 00000000000000000001000011111110 00000000000000000001001100111101 00000000000000000010110111010000\n",
            "00000000000011111111111101110001 00000000000000000010011100111100 00000000000000000001001101101111 00000000000011111111010000011101 00000000000000000010000000110110 00000000000011111101110100000101\n",
            "00000000000011111111010100001010 00000000000000000010100000011110 00000000000011111111111101100010 00000000000000000000000110111100\n",
            "00000000000011111110110010000011 00000000000000000001100111111111 00000000000000000001011101110111 00000000000000000000100010111110 00000000000000000010001100100011 00000000000011111110100111000101\n",
            "00000000000000000000100110011101 00000000000000000011111000110110 00000000000011111110110100111111 00000000000000000010011000000110\n",
            "00000000000011111111001110100011 00000000000000000001110100101111 00000000000000000001001111011100 00000000000000000001011011011011 00000000000000000000111111001001 00000000000011111101111011100110\n",
            "00000000000011111111010111000101 00000000000000000000111010001111 00000000000000000001110000000001 00000000000000000011010011011100\n",
            "00000000000011111111110001001100 00000000000000000010001111000111 00000000000000000010010010100101 00000000000000000000111010001111 00000000000000000001100101011001 00000000000011111110010110011110\n",
            "00000000000000000000010000111101 00000000000000000010101111111000 00000000000000000011000101010001 00000000000000000011001010111011\n",
            "00000000000011111111001001110010 00000000000000000001100001110110 00000000000000000010010101101101 00000000000000000001101110101101 00000000000000000010000111010100 00000000000011111101001101110100\n",
            "00000000000000000000001000000101 00000000000000000011101101111010 00000000000000000010110000001011 00000000000000000010101011111010\n",
            "00000000000011111111111010000111 00000000000000000010000011111110 00000000000000000010010101000000 00000000000000000001101010010011 00000000000000000001000111000011 00000000000011111101001001001110\n",
            "00000000000011111111011000111010 00000000000000000001111001101100 00000000000000000010000000010110 00000000000000000011001110001111\n",
            "00000000000011111111110000100101 00000000000000000001110001101100 00000000000000000001101010111000 00000000000000000000111100001000 00000000000000000000100111011101 00000000000011111101101000000000\n",
            "00000000000000000000000111101101 00000000000000000001010110011001 00000000000000000001000001010011 00000000000000000010000110101011 00000000000000000111000001011100 00000000000000000000011101100110 00000000000000000000010011000000 00000000000000000000101000111100 00000000000011111111010011110110 00000000000000000010010100110111\n",
            "00000000000011111111100001100111 00000000000011111110101010010011 00000000000000000000000101001110 00000000000000000001011010101001\n",
            "00000000000000000011100101001011 00000000000000000100011100110000 00000000000000000101100111010010 00000000000000000101000101110100 00000000000000000101001100111000 00000000000000000100000101001011\n",
            "00000000000000000100001011010011 00000000000000000101010000111101 00000000000000000010000101010110 00000000000000000101101000111001\n",
            "00000000000000000101001010101000 00000000000000000101000101100101 00000000000000000101010110111001 00000000000000000101000110110001 00000000000000000011110010001110 00000000000000000100110001101000\n",
            "00000000000000000100111111101100 00000000000000000010111010110110 00000000000000000010111010010010 00000000000000000110000110110011\n",
            "00000000000000000100000011111001 00000000000000000110000011010100 00000000000000000110000110000101 00000000000000000101001000100001 00000000000000000100100111011110 00000000000000000101101101001111\n",
            "00000000000000000100110111010010 00000000000000000111000101011011 00000000000000000011000001101101 00000000000000000110100000010010\n",
            "00000000000000000001101101010001 00000000000000000100010000101001 00000000000000000101111101001000 00000000000000000101100001110101 00000000000000000011110011011110 00000000000000000100100001100001\n",
            "00000000000000000001100101000101 00000000000000000101100100110001 00000000000000000011000001110110 00000000000000000110110100000010\n",
            "00000000000000001001011110110111 00000000000000000100100100010000 00000000000000000101001100001000 00000000000000000101011110011100 00000000000000000011111011110011 00000000000000000111010001100111\n",
            "00000000000000000100100000001000 00000000000000000110101011111010 00000000000000000010111101000001 00000000000000000100101101000100\n",
            "00000000000000000010110010011010 00000000000000000101010001000100 00000000000000000101011101010001 00000000000000000011101111000100 00000000000000000101111001011010 00000000000000000010101001011100\n",
            "00000000000000000001100000111100 00000000000000000110110100100010 00000000000000000011011010000011 00000000000000000100100110001111\n",
            "00000000000000000011000011100110 00000000000000000111001001001101 00000000000000000110010101100011 00000000000000000100111011011010 00000000000000000110111010110011 00000000000000000100010001010101\n",
            "00000000000000000100011100010001 00000000000000000110101010000001 00000000000000000011010100100010 00000000000000001000011000001100\n",
            "00000000000000000111011100000101 00000000000000000100101100111011 00000000000000000100101001001000 00000000000000000100101100111100 00000000000000000100111001011011 00000000000000000111011011111110\n",
            "00000000000000000100110101011000 00000000000000000110001100011010 00000000000000000010011111010010 00000000000000000100001011111000\n",
            "00000000000000001010011111011110 00000000000000000101110110001110 00000000000000000101001110001101 00000000000000000101110011001010 00000000000000000101011110001000 00000000000000001001101100011110\n",
            "00000000000000000101010111010101 00000000000000000110101111101000 00000000000000000101101101011101 00000000000000000110010010101100 00000000000000000011011110110010 00000000000000000000011010011001 00000000000000000000010101110011 00000000000000000000010001111101 00000000000011111111110100110010 00000000000011111111011011000000\n",
            "00000000000011111111111001001010 00000000000011111111100100000011 00000000000000000000011111001111 00000000000000000101001100000110\n",
            "00000000000000000101000000011111 00000000000000000111100111010000 00000000000011111110001010110101 00000000000011111101110100111001 00000000000011111110101011011100 00000000000011111111010110100100\n",
            "00000000000011111111011000010000 00000000000011111101001010100100 00000000000000000000110111010000 00000000000000000011111011101010\n",
            "00000000000000000100101011011101 00000000000011111100111110011010 00000000000000000011100011000001 00000000000011111110101001001100 00000000000011111101111000110000 00000000000000000000011000011000\n",
            "00000000000011111110011010111001 00000000000011111101010010101111 00000000000000000001111000011100 00000000000000000001011110001010\n",
            "00000000000000000010100000100111 00000000000000000000101100011011 00000000000011111111000110100010 00000000000000000101100011010010 00000000000011111111010100101010 00000000000011111111101011111110\n",
            "00000000000011111110110001101110 00000000000011111111000001101101 00000000000000000000110100100011 00000000000000000001101111111110\n",
            "00000000000000000001010110010000 00000000000000000000111001010011 00000000000011111100110010111010 00000000000011111110100110011111 00000000000000000110001100001000 00000000000011111111011000111001\n",
            "00000000000011111110100111111111 00000000000011111111101110010111 00000000000000000000010011000110 00000000000000000000100100000111\n",
            "00000000000000000011000101111101 00000000000011111111000100101100 00000000000011111101011011010110 00000000000011111101000001000010 00000000000011111101011011000110 00000000000011111100101010001101\n",
            "00000000000011111110100001101001 00000000000011111100110100011100 00000000000011111110001011100100 00000000000000000011100110001101\n",
            "00000000000000000010110101100101 00000000000000000000100101001101 00000000000011111110001011110010 00000000000011111100111111100000 00000000000011111111010010010001 00000000000011111110011010110011\n",
            "00000000000000000010011011110010 00000000000011111101010010000000 00000000000011111110111100000100 00000000000000000000111110000101\n",
            "00000000000000000011000010110101 00000000000011111110010001100111 00000000000011111111010000001100 00000000000011111110010010111100 00000000000011111101110111100100 00000000000011111111000010000111\n",
            "00000000000000000000011011110110 00000000000000000110010110111001 00000000000000000000110011110001 00000000000000000000100110000101\n",
            "00000000000000000011100101101100 00000000000000000000110111010000 00000000000011111111010011001011 00000000000011111110011010100100 00000000000000000000001000111110 00000000000011111110110111101010\n",
            "00000000000011111110111101011101 00000000000011111100101111000001 00000000000011111101011110101011 00000000000000000001111010111100\n",
            "00000000000000000011111101011011 00000000000011111110111000000000 00000000000011111110100000101001 00000000000011111101100010010011 00000000000011111110101110010111 00000000000011111110101001100111\n",
            "00000000000011111110010000111011 00000000000011111110001010010010 00000000000011111110010110100101 00000000000000000001111010010111\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt(input_file, output_file):\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # txt 파일 읽기 및 값 분리\n",
        "    with open(input_file, 'r') as f:\n",
        "        content = f.read()  # 파일 전체 내용을 읽음\n",
        "        binary_values = content.split()  # 스페이스와 줄바꿈을 기준으로 값을 분리\n",
        "\n",
        "    # 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            # 줄 생성\n",
        "            line = template.format(index=i+1, binary_value=binary_value)  # index는 1부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "# 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output2.txt'  # 입력 파일 경로 (값들이 스페이스/줄바꿈으로 구별됨)\n",
        "output_code_file = './model/generated_code.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# 코드 생성 함수 호출\n",
        "generate_code_from_txt(input_txt_file, output_code_file)\n",
        "print(f\"코드가 성공적으로 생성되어 {output_code_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "bBrrgb7-GxN3",
        "outputId": "f1afb6e4-e5be-4d5e-c5b1-672cea34dbf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코드가 성공적으로 생성되어 ./model/generated_code.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt_with_msb(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일에서 1200개의 32비트 값을 읽고,\n",
        "    10개 단위의 첫 번째 값(총 120개)의 MSB(최상위 비트)를 1로 변경한 후\n",
        "    코드 파일을 생성하는 함수.\n",
        "\n",
        "    Args:\n",
        "    - input_file: 입력 TXT 파일 (각 줄에 32비트 바이너리 값 존재)\n",
        "    - output_file: 출력 코드가 저장될 TXT 파일\n",
        "    \"\"\"\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # TXT 파일 읽기\n",
        "    with open(input_file, 'r') as f:\n",
        "        binary_values = f.read().split()  # 스페이스와 줄바꿈을 기준으로 값 분리\n",
        "\n",
        "    # ✅ 10개 단위의 첫 번째 값(총 120개)의 MSB를 1로 변경\n",
        "    for i in range(0, len(binary_values), 10):  # 10개씩 건너뛰며 첫 번째 값 선택\n",
        "        if i < len(binary_values):  # 범위 초과 방지\n",
        "            original_value = binary_values[i]  # 원본 값\n",
        "            modified_value = '1' + original_value[1:]  # MSB(최상위 비트)만 1로 변경\n",
        "            binary_values[i] = modified_value  # 변경된 값 반영\n",
        "\n",
        "    # ✅ 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            line = template.format(index=i+1, binary_value=binary_value)  # index는 1부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "    print(f\"✅ 코드가 성공적으로 생성되어 {output_file}에 저장되었습니다.\")\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output2.txt'  # 입력 파일 (각 줄에 32비트 값이 존재)\n",
        "output_code_file = './model/generated_code2.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# ✅ 함수 실행\n",
        "generate_code_from_txt_with_msb(input_txt_file, output_code_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBfF8wke255-",
        "outputId": "07b81d52-830e-4561-8d76-b62891cd16eb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 코드가 성공적으로 생성되어 ./model/generated_code2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/generated_code.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEWA6mjj3Umy",
        "outputId": "c578518b-97c8-4d04-af42-7c39ab2866a4"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1), 0b10000000000000000110111101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 2), 0b00000000000000000000001110111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 3), 0b00000000000000000001001010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 4), 0b00000000000000000001010000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 5), 0b00000000000011111111011000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 6), 0b00000000000000000100011000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 7), 0b00000000000011111111101101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 8), 0b00000000000000000000111111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 9), 0b00000000000000000100000111111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 10), 0b00000000000000000010110011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 11), 0b10000000000000000011010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 12), 0b00000000000000000110101100010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 13), 0b00000000000000001011100101100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 14), 0b00000000000000001001001111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 15), 0b00000000000000000111101000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 16), 0b00000000000000000100101011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 17), 0b00000000000000000011110001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 18), 0b00000000000000000100110001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 19), 0b00000000000000000011000110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 20), 0b00000000000000000011110100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 21), 0b10000000000000000110101000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 22), 0b00000000000000001001000000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 23), 0b00000000000000000111100111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 24), 0b00000000000000001010011011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 25), 0b00000000000000000100100111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 26), 0b00000000000000000110000100011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 27), 0b00000000000000000100111101011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 28), 0b00000000000000000011010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 29), 0b00000000000000000101001101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 30), 0b00000000000000000011001000011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 31), 0b10000000000000000101001001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 32), 0b00000000000000001001010011100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 33), 0b00000000000000001101100110000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 34), 0b00000000000000000111100110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 35), 0b00000000000000001010101010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 36), 0b00000000000000000101010100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 37), 0b00000000000000000101011100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 38), 0b00000000000000000100110101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 39), 0b00000000000000000100010110110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 40), 0b00000000000000000110001101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 41), 0b10000000000000000001010000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 42), 0b00000000000000001001010010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 43), 0b00000000000000000110100111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 44), 0b00000000000000001010001000001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 45), 0b00000000000000000110101011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 46), 0b00000000000000000101100011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 47), 0b00000000000000000011101111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 48), 0b00000000000000000110111111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 49), 0b00000000000000000100000011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 50), 0b00000000000000000101001011101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 51), 0b10000000000000000111111101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 52), 0b00000000000000000101001110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 53), 0b00000000000000000100100011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 54), 0b00000000000000000101110101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 55), 0b00000000000000000111000001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 56), 0b00000000000000000110011100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 57), 0b00000000000000000110000101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 58), 0b00000000000000000101101111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 59), 0b00000000000000001000101000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 60), 0b00000000000000001000100110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 61), 0b10000000000000000011100101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 62), 0b00000000000000000101010111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 63), 0b00000000000000000011010110011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 64), 0b00000000000000000010101000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 65), 0b00000000000000001000010110000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 66), 0b00000000000000000110101010011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 67), 0b00000000000000000100111100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 68), 0b00000000000000001001000110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 69), 0b00000000000000000101010001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 70), 0b00000000000000000110010110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 71), 0b10000000000000000011010001110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 72), 0b00000000000000000011100010001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 73), 0b00000000000000000100001101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 74), 0b00000000000000000100001101101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 75), 0b00000000000000000110110110001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 76), 0b00000000000000000110110001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 77), 0b00000000000000001000011100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 78), 0b00000000000000000101111011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 79), 0b00000000000000000111110100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 80), 0b00000000000000001001000100110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 81), 0b10000000000000000110100111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 82), 0b00000000000000000010100001100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 83), 0b00000000000000000100101110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 84), 0b00000000000000000010010000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 85), 0b00000000000000000100011101110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 86), 0b00000000000000000101111111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 87), 0b00000000000000000111101001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 88), 0b00000000000000001000101110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 89), 0b00000000000000000111000011101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 90), 0b00000000000000001011011111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 91), 0b10000000000000001001001001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 92), 0b00000000000000000110001110111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 93), 0b00000000000000000100111110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 94), 0b00000000000000000110110110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 95), 0b00000000000000000100010111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 96), 0b00000000000000001011011111100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 97), 0b00000000000000000110010110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 98), 0b00000000000000001000111011101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 99), 0b00000000000000001101001111001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 100), 0b00000000000000001010010010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 101), 0b10000000000011111101110100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 102), 0b00000000000000000000000011010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 103), 0b00000000000000000000100111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 104), 0b00000000000011111111110000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 105), 0b00000000000011111111110110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 106), 0b00000000000011111100100110101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 107), 0b00000000000011111111111001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 108), 0b00000000000011111111000101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 109), 0b00000000000011111110101000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 110), 0b00000000000000000001111011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 111), 0b10000000000011111100100000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 112), 0b00000000000011111110110101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 113), 0b00000000000000000001011101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 114), 0b00000000000000000000110111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 115), 0b00000000000000000000000111110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 116), 0b00000000000011111101101001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 117), 0b00000000000011111111100011110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 118), 0b00000000000011111110100001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 119), 0b00000000000011111110100111101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 120), 0b00000000000000000001111100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 121), 0b10000000000011111111001000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 122), 0b00000000000011111111010011011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 123), 0b00000000000011111110110000110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 124), 0b00000000000011111110111000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 125), 0b00000000000011111111100101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 126), 0b00000000000011111101101111001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 127), 0b00000000000000000000011011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 128), 0b00000000000011111111111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 129), 0b00000000000011111101010111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 130), 0b00000000000000000010010000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 131), 0b10000000000011111110110100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 132), 0b00000000000011111111011111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 133), 0b00000000000000000000000000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 134), 0b00000000000000000000000010001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 135), 0b00000000000000000000111010010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 136), 0b00000000000011111111011111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 137), 0b00000000000000000000000100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 138), 0b00000000000000000000010010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 139), 0b00000000000011111111010101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 140), 0b00000000000000000010100010001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 141), 0b10000000000011111100100011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 142), 0b00000000000011111111111011010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 143), 0b00000000000000000000101001010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 144), 0b00000000000000000000001100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 145), 0b00000000000011111111011111011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 146), 0b00000000000011111100111011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 147), 0b00000000000000000001011010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 148), 0b00000000000000000001010011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 149), 0b00000000000011111101100101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 150), 0b00000000000000000001001011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 151), 0b10000000000011111101100101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 152), 0b00000000000000000000010011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 153), 0b00000000000000000000110000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 154), 0b00000000000000000000100100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 155), 0b00000000000000000000110000010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 156), 0b00000000000011111110010010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 157), 0b00000000000000000000000010010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 158), 0b00000000000000000000111000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 159), 0b00000000000011111111000000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 160), 0b00000000000000000001100110011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 161), 0b10000000000011111111011010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 162), 0b00000000000000000000001100110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 163), 0b00000000000011111111110100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 164), 0b00000000000000000000000100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 165), 0b00000000000000000000001101101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 166), 0b00000000000011111110010100111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 167), 0b00000000000000000000011001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 168), 0b00000000000000000001001010101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 169), 0b00000000000011111111101001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 170), 0b00000000000000000001001101101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 171), 0b10000000000011111111010001111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 172), 0b00000000000000000000001011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 173), 0b00000000000000000000110110000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 174), 0b00000000000000000000001110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 175), 0b00000000000011111111110111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 176), 0b00000000000011111101001110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 177), 0b00000000000000000000110001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 178), 0b00000000000011111111010100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 179), 0b00000000000011111110110111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 180), 0b00000000000000000001111111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 181), 0b10000000000011111110000100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 182), 0b00000000000000000000011101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 183), 0b00000000000000000000010011000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 184), 0b00000000000000000000010101011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 185), 0b00000000000000000000010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 186), 0b00000000000011111110111010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 187), 0b00000000000000000000000100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 188), 0b00000000000000000001011000000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 189), 0b00000000000011111111010101001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 190), 0b00000000000000000000111000100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 191), 0b10000000000011111110110010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 192), 0b00000000000011111111010010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 193), 0b00000000000000000000111100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 194), 0b00000000000000000000100010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 195), 0b00000000000000000000100000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 196), 0b00000000000011111110001011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 197), 0b00000000000000000000010110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 198), 0b00000000000011111111110010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 199), 0b00000000000011111111000100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 200), 0b00000000000000000001101000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 201), 0b10000000000000000101110011001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 202), 0b00000000000000000000000010110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 203), 0b00000000000011111110100000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 204), 0b00000000000000000001010000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 205), 0b00000000000011111101101111101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 206), 0b00000000000000000110001011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 207), 0b00000000000000000001110110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 208), 0b00000000000011111111101101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 209), 0b00000000000000001000001011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 210), 0b00000000000000000100110100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 211), 0b10000000000000000001001011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 212), 0b00000000000000000110000001011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 213), 0b00000000000000000111110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 214), 0b00000000000000000110011110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 215), 0b00000000000000000001000000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 216), 0b00000000000000000000101100100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 217), 0b00000000000000000000010110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 218), 0b00000000000000000100010000110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 219), 0b00000000000011111111110011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 220), 0b00000000000000000001111110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 221), 0b10000000000000000001001101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 222), 0b00000000000000000100011101111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 223), 0b00000000000000000101010000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 224), 0b00000000000000000100110111000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 225), 0b00000000000000000000111110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 226), 0b00000000000000000001101101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 227), 0b00000000000000000010000000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 228), 0b00000000000000000011000001010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 229), 0b00000000000000000001001000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 230), 0b00000000000000000010110000110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 231), 0b10000000000000000010110111001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 232), 0b00000000000000000100000001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 233), 0b00000000000000001000001011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 234), 0b00000000000000000110001100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 235), 0b00000000000000000001001000101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 236), 0b00000000000000000001100000110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 237), 0b00000000000000000000101010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 238), 0b00000000000000000010111011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 239), 0b00000000000011111111011000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 240), 0b00000000000000000001111100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 241), 0b10000000000011111111010111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 242), 0b00000000000000000011000110101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 243), 0b00000000000000000110000010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 244), 0b00000000000000000010111101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 245), 0b00000000000000000100011101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 246), 0b00000000000011111101011001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 247), 0b00000000000000000010010001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 248), 0b00000000000000000111001001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 249), 0b00000000000011111101001000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 250), 0b00000000000011111111101001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 251), 0b10000000000000000110110101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 252), 0b00000000000000000001010000011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 253), 0b00000000000000000000001001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 254), 0b00000000000000000001011011110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 255), 0b00000000000011111111010110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 256), 0b00000000000000000100100101000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 257), 0b00000000000000000010000111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 258), 0b00000000000000000000011100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 259), 0b00000000000000000110001001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 260), 0b00000000000000000100111010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 261), 0b10000000000000000011110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 262), 0b00000000000000000001110001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 263), 0b00000000000000000010011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 264), 0b00000000000000000000010010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 265), 0b00000000000000000001001011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 266), 0b00000000000000000000111110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 267), 0b00000000000000000001001001000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 268), 0b00000000000000000011000000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 269), 0b00000000000000000000110110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 270), 0b00000000000000000001010011110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 271), 0b10000000000000000100001111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 272), 0b00000000000000000001101100110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 273), 0b00000000000000000010110111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 274), 0b00000000000000000010101101010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 275), 0b00000000000000000010001001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 276), 0b00000000000000000011101101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 277), 0b00000000000000000001100010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 278), 0b00000000000000000011001011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 279), 0b00000000000000000010000000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 280), 0b00000000000000000100001010100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 281), 0b10000000000000000110011100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 282), 0b00000000000000000000000001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 283), 0b00000000000000000001001000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 284), 0b00000000000000000000011101101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 285), 0b00000000000011111111010110101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 286), 0b00000000000000000100001111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 287), 0b00000000000000000010010111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 288), 0b00000000000000000000100000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 289), 0b00000000000000000011100100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 290), 0b00000000000000000100000000101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 291), 0b10000000000000000111110100110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 292), 0b00000000000000000001101100110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 293), 0b00000000000000000000110001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 294), 0b00000000000000000001101010000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 295), 0b00000000000000000000011110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 296), 0b00000000000000000111000100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 297), 0b00000000000000000010101000100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 298), 0b00000000000000000001110011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 299), 0b00000000000000001000010100010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 300), 0b00000000000000000101110101110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 301), 0b10000000000011111110001010011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 302), 0b00000000000011111110100001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 303), 0b00000000000011111101011011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 304), 0b00000000000011111101010111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 305), 0b00000000000011111100011010110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 306), 0b00000000000011111011010001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 307), 0b00000000000011111100100100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 308), 0b00000000000011111011111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 309), 0b00000000000011111110001110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 310), 0b00000000000011111101111010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 311), 0b10000000000000000001100010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 312), 0b00000000000000000101101101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 313), 0b00000000000000000001111101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 314), 0b00000000000000000010001011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 315), 0b00000000000000000010100101010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 316), 0b00000000000011111111010010000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 317), 0b00000000000011111111111001000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 318), 0b00000000000000000010010001101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 319), 0b00000000000011111101101000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 320), 0b00000000000000000001000100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 321), 0b10000000000000000000111000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 322), 0b00000000000000000011110001110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 323), 0b00000000000000000010110010011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 324), 0b00000000000000000010011110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 325), 0b00000000000000000001110111100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 326), 0b00000000000011111110110010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 327), 0b00000000000000000000101111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 328), 0b00000000000000000010001111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 329), 0b00000000000011111111000010011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 330), 0b00000000000000000001110101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 331), 0b10000000000011111111001011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 332), 0b00000000000000000011110100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 333), 0b00000000000000000001001110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 334), 0b00000000000000000010111111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 335), 0b00000000000000000010100100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 336), 0b00000000000011111111011111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 337), 0b00000000000000000000010110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 338), 0b00000000000000000001101010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 339), 0b00000000000011111110110100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 340), 0b00000000000000000011100101000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 341), 0b10000000000000000001000000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 342), 0b00000000000000000011011000001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 343), 0b00000000000000000001101010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 344), 0b00000000000000000000101101100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 345), 0b00000000000000000011111000001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 346), 0b00000000000011111111010110001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 347), 0b00000000000011111111101011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 348), 0b00000000000000000010100001010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 349), 0b00000000000011111101000010100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 350), 0b00000000000000000001110110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 351), 0b10000000000000000000111100011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 352), 0b00000000000000000010000110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 353), 0b00000000000000000001011000010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 354), 0b00000000000000000001001001101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 355), 0b00000000000000000000100100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 356), 0b00000000000000000011010110001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 357), 0b00000000000000000010011111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 358), 0b00000000000000000010111000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 359), 0b00000000000000000010000001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 360), 0b00000000000000000001100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 361), 0b10000000000000000010011110100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 362), 0b00000000000000000010010001000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 363), 0b00000000000000000001010010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 364), 0b00000000000000000000110111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 365), 0b00000000000000000010000001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 366), 0b00000000000011111110111100011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 367), 0b00000000000000000010010001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 368), 0b00000000000000000010100011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 369), 0b00000000000011111111011101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 370), 0b00000000000011111111010110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 371), 0b10000000000011111110110001000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 372), 0b00000000000000000001111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 373), 0b00000000000000000001010011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 374), 0b00000000000000000000111000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 375), 0b00000000000000000010000100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 376), 0b00000000000000000000100011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 377), 0b00000000000000000001010011111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 378), 0b00000000000000000010111001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 379), 0b00000000000000000000001101110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 380), 0b00000000000000000100000010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 381), 0b10000000000000000001010100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 382), 0b00000000000000000010010010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 383), 0b00000000000000000001101010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 384), 0b00000000000000000001010101110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 385), 0b00000000000000000001011000000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 386), 0b00000000000000000001110001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 387), 0b00000000000000000010011101100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 388), 0b00000000000000000010001010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 389), 0b00000000000000000001111100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 390), 0b00000000000000000000010111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 391), 0b10000000000000000000111101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 392), 0b00000000000000000001001010011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 393), 0b00000000000000000001010100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 394), 0b00000000000000000000101011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 395), 0b00000000000011111111001010001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 396), 0b00000000000011111101111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 397), 0b00000000000011111111101110000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 398), 0b00000000000000000001101010101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 399), 0b00000000000000000000111001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 400), 0b00000000000011111111111100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 401), 0b10000000000011111111001010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 402), 0b00000000000011111111011110001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 403), 0b00000000000011111110010111001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 404), 0b00000000000000000001000101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 405), 0b00000000000011111110010111001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 406), 0b00000000000000000110100010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 407), 0b00000000000000000010001111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 408), 0b00000000000011111111000101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 409), 0b00000000000000000110000001001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 410), 0b00000000000000001000001000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 411), 0b10000000000000000011011011000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 412), 0b00000000000000001000000001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 413), 0b00000000000000001100001100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 414), 0b00000000000000001000000111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 415), 0b00000000000000000110101101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 416), 0b00000000000000000001010111000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 417), 0b00000000000000000100111100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 418), 0b00000000000000000101000110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 419), 0b00000000000000000010000101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 420), 0b00000000000000000101010010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 421), 0b10000000000000000011010011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 422), 0b00000000000000000101110001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 423), 0b00000000000000000111010001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 424), 0b00000000000000000100110111001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 425), 0b00000000000000000100111010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 426), 0b00000000000000000011101100011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 427), 0b00000000000000000010010111111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 428), 0b00000000000000000100010001111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 429), 0b00000000000000000101001011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 430), 0b00000000000000000101000011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 431), 0b10000000000000000101110010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 432), 0b00000000000000001000100110011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 433), 0b00000000000000001101010101000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 434), 0b00000000000000000101101000010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 435), 0b00000000000000001000000000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 436), 0b00000000000000000001110110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 437), 0b00000000000000000001110111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 438), 0b00000000000000000011111000100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 439), 0b00000000000000000010010011010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 440), 0b00000000000000000100001011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 441), 0b10000000000000000010111000000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 442), 0b00000000000000001001000111110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 443), 0b00000000000000000111011011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 444), 0b00000000000000000110100111000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 445), 0b00000000000000000101000100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 446), 0b00000000000000000000101000001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 447), 0b00000000000000000101100000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 448), 0b00000000000000000111100011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 449), 0b00000000000000000010110101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 450), 0b00000000000000000011011101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 451), 0b10000000000011111100010000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 452), 0b00000000000000000100001101011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 453), 0b00000000000000000100100100010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 454), 0b00000000000000000100001110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 455), 0b00000000000000000010111110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 456), 0b00000000000000000100110110101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 457), 0b00000000000000000110001001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 458), 0b00000000000000000011110010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 459), 0b00000000000000000111111001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 460), 0b00000000000000001001100100100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 461), 0b10000000000000000001010001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 462), 0b00000000000000000011100111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 463), 0b00000000000000000001101100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 464), 0b00000000000000000010010100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 465), 0b00000000000000000100100110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 466), 0b00000000000000000011110111100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 467), 0b00000000000000000100010111111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 468), 0b00000000000000000110100000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 469), 0b00000000000000000100101110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 470), 0b00000000000000000111000010000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 471), 0b10000000000000000000110011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 472), 0b00000000000000000011001101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 473), 0b00000000000000000011011101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 474), 0b00000000000000000000101101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 475), 0b00000000000000000100111101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 476), 0b00000000000000000010000100101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 477), 0b00000000000000000101011010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 478), 0b00000000000000000100111011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 479), 0b00000000000000000010101110000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 480), 0b00000000000000000101100000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 481), 0b10000000000011111100111101011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 482), 0b00000000000000000000111101010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 483), 0b00000000000000000010011010101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 484), 0b00000000000000000001101101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 485), 0b00000000000000000010000101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 486), 0b00000000000000000100100010000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 487), 0b00000000000000000110001001011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 488), 0b00000000000000000100000110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 489), 0b00000000000000000100111111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 490), 0b00000000000000001001010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 491), 0b10000000000000000110000000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 492), 0b00000000000011111110100010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 493), 0b00000000000011111110100000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 494), 0b00000000000000000011100101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 495), 0b00000000000000000000111100111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 496), 0b00000000000000000101110111110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 497), 0b00000000000000000100100100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 498), 0b00000000000000000100001011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 499), 0b00000000000000000100101010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 500), 0b00000000000000000111001101111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 501), 0b10000000000000000100101101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 502), 0b00000000000011111011001100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 503), 0b00000000000011111010110101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 504), 0b00000000000011111010110101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 505), 0b00000000000011111101000111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 506), 0b00000000000011111101001101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 507), 0b00000000000011111101000001101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 508), 0b00000000000011111101010111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 509), 0b00000000000011111100111101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 510), 0b00000000000011111111110010101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 511), 0b10000000000011111111110101101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 512), 0b00000000000000000001111010001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 513), 0b00000000000000000110001011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 514), 0b00000000000000000010001010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 515), 0b00000000000000000101100110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 516), 0b00000000000000000010100111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 517), 0b00000000000000000101000000000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 518), 0b00000000000000000110110100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 519), 0b00000000000000000011000011101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 520), 0b00000000000000000100110011001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 521), 0b10000000000011111110000001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 522), 0b00000000000000000010111010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 523), 0b00000000000000000011000101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 524), 0b00000000000000000000100111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 525), 0b00000000000000000110010100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 526), 0b00000000000000000010101001011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 527), 0b00000000000000000100000011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 528), 0b00000000000000000111110000101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 529), 0b00000000000000000001100011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 530), 0b00000000000000000100011010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 531), 0b10000000000011111101010001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 532), 0b00000000000000000011111111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 533), 0b00000000000000000110010000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 534), 0b00000000000000000001111100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 535), 0b00000000000000000110010011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 536), 0b00000000000000000101000111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 537), 0b00000000000000000101100110010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 538), 0b00000000000000000111001101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 539), 0b00000000000000000100111101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 540), 0b00000000000000000111000001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 541), 0b10000000000011111110111011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 542), 0b00000000000000000101100100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 543), 0b00000000000000000101110111011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 544), 0b00000000000000000011111111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 545), 0b00000000000000000101010011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 546), 0b00000000000000000000010101111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 547), 0b00000000000000000010110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 548), 0b00000000000000000111000100010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 549), 0b00000000000000000000001100000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 550), 0b00000000000000000100001110100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 551), 0b10000000000011111111111001011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 552), 0b00000000000000000101111010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 553), 0b00000000000000000101101011100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 554), 0b00000000000000000101111110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 555), 0b00000000000000000100011011011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 556), 0b00000000000000000110000011011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 557), 0b00000000000000000101001100110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 558), 0b00000000000000000100111000001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 559), 0b00000000000000000110010010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 560), 0b00000000000000000111110010001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 561), 0b10000000000011111110000000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 562), 0b00000000000000000101010111110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 563), 0b00000000000000000101001010101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 564), 0b00000000000000000101001101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 565), 0b00000000000000000101000100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 566), 0b00000000000000000010100101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 567), 0b00000000000000000010111010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 568), 0b00000000000000000101010001101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 569), 0b00000000000000000100000010100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 570), 0b00000000000000000100011011100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 571), 0b10000000000000000000000101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 572), 0b00000000000000000101110111011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 573), 0b00000000000000000110100011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 574), 0b00000000000000000101011100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 575), 0b00000000000000000110011010000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 576), 0b00000000000000000010011010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 577), 0b00000000000000000011111101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 578), 0b00000000000000000100111111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 579), 0b00000000000000000010001110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 580), 0b00000000000000000011001001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 581), 0b10000000000011111111100010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 582), 0b00000000000000000100011100101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 583), 0b00000000000000000101010100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 584), 0b00000000000000000101001110011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 585), 0b00000000000000000100010100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 586), 0b00000000000000000100011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 587), 0b00000000000000000101000010110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 588), 0b00000000000000000100101001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 589), 0b00000000000000000011111100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 590), 0b00000000000000000101100010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 591), 0b10000000000000000000011111111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 592), 0b00000000000000000110011000000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 593), 0b00000000000000000110001101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 594), 0b00000000000000000110101111010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 595), 0b00000000000000000101010100011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 596), 0b00000000000000000110111111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 597), 0b00000000000000000101101111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 598), 0b00000000000000000101111010101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 599), 0b00000000000000000111011001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 600), 0b00000000000000001010110001111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 601), 0b10000000000000000011101101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 602), 0b00000000000011111111101001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 603), 0b00000000000011111110010100100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 604), 0b00000000000011111111100110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 605), 0b00000000000000000000000100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 606), 0b00000000000000000011101010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 607), 0b00000000000011111110111110000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 608), 0b00000000000011111110001000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 609), 0b00000000000011111111010001111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 610), 0b00000000000000000100000011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 611), 0b10000000000000000000001001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 612), 0b00000000000000000011010010001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 613), 0b00000000000000000100111100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 614), 0b00000000000000000011011001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 615), 0b00000000000000000011011111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 616), 0b00000000000000000000000001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 617), 0b00000000000000000010100110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 618), 0b00000000000000000011110010101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 619), 0b00000000000000000011000101101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 620), 0b00000000000000000011001110111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 621), 0b10000000000000000001011001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 622), 0b00000000000000000100010101101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 623), 0b00000000000000000100010010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 624), 0b00000000000000000011011110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 625), 0b00000000000000000100010110111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 626), 0b00000000000000000000000001001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 627), 0b00000000000000000010110000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 628), 0b00000000000000000100110011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 629), 0b00000000000000000011000001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 630), 0b00000000000000000011101010100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 631), 0b10000000000000000011000000000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 632), 0b00000000000000000100011000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 633), 0b00000000000000000101100010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 634), 0b00000000000000000001110111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 635), 0b00000000000000000100001010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 636), 0b00000000000011111111010110001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 637), 0b00000000000000000011000011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 638), 0b00000000000000000101001110110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 639), 0b00000000000000000010100010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 640), 0b00000000000000000101001000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 641), 0b10000000000011111110111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 642), 0b00000000000000000100111111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 643), 0b00000000000000000010111101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 644), 0b00000000000000000010101110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 645), 0b00000000000000000011000110101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 646), 0b00000000000011111110011111110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 647), 0b00000000000000000010001110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 648), 0b00000000000000000101110010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 649), 0b00000000000000000010011101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 650), 0b00000000000000000001100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 651), 0b10000000000000001001001101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 652), 0b00000000000000000101001110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 653), 0b00000000000000000011010110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 654), 0b00000000000000000011001000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 655), 0b00000000000000000010010000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 656), 0b00000000000000000100010100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 657), 0b00000000000000000011100111010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 658), 0b00000000000000000010000111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 659), 0b00000000000000000011111000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 660), 0b00000000000000001000011010111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 661), 0b10000000000000000100111000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 662), 0b00000000000000000100001010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 663), 0b00000000000000000011100101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 664), 0b00000000000000000011000111011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 665), 0b00000000000000000100011000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 666), 0b00000000000000000011111011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 667), 0b00000000000000000010110011101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 668), 0b00000000000000000100001101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 669), 0b00000000000000000010000010100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 670), 0b00000000000000000100110101010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 671), 0b10000000000000000011001110111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 672), 0b00000000000000000100001110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 673), 0b00000000000000000011100100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 674), 0b00000000000000000010010001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 675), 0b00000000000000000100111100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 676), 0b00000000000000000010001110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 677), 0b00000000000000000011111001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 678), 0b00000000000000000100100100000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 679), 0b00000000000000000010110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 680), 0b00000000000000000101000101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 681), 0b10000000000000000101001001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 682), 0b00000000000000000011101100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 683), 0b00000000000000000010111001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 684), 0b00000000000000000010011110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 685), 0b00000000000000000010010101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 686), 0b00000000000000000010011101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 687), 0b00000000000000000100010001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 688), 0b00000000000000000011011100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 689), 0b00000000000000000010101001100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 690), 0b00000000000000000100111101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 691), 0b10000000000000001010111010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 692), 0b00000000000000000101101101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 693), 0b00000000000000000011110011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 694), 0b00000000000000000101100110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 695), 0b00000000000000000100010111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 696), 0b00000000000000001001000101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 697), 0b00000000000000000100101011110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 698), 0b00000000000000000101010001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 699), 0b00000000000000000110101000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 700), 0b00000000000000001010101101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 701), 0b10000000000011111111100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 702), 0b00000000000011111111111010000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 703), 0b00000000000011111111110111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 704), 0b00000000000000000000011100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 705), 0b00000000000011111110111100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 706), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 707), 0b00000000000011111111010011001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 708), 0b00000000000011111111100001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 709), 0b00000000000011111111111011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 710), 0b00000000000011111111000110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 711), 0b10000000000000000000110010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 712), 0b00000000000011111110100011110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 713), 0b00000000000011111111110001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 714), 0b00000000000011111111000011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 715), 0b00000000000011111110110000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 716), 0b00000000000011111110111000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 717), 0b00000000000011111111110111111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 718), 0b00000000000000000000011110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 719), 0b00000000000011111111011001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 720), 0b00000000000000000001010110011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 721), 0b10000000000000000001110111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 722), 0b00000000000011111111011000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 723), 0b00000000000011111101100010110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 724), 0b00000000000011111111100001011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 725), 0b00000000000000000000011011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 726), 0b00000000000011111111111100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 727), 0b00000000000000000000010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 728), 0b00000000000000000000111111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 729), 0b00000000000011111111010110100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 730), 0b00000000000000000001000101000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 731), 0b10000000000000000000111001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 732), 0b00000000000011111111110101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 733), 0b00000000000011111110100101101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 734), 0b00000000000011111110101000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 735), 0b00000000000011111111010110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 736), 0b00000000000011111111111111101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 737), 0b00000000000000000000011111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 738), 0b00000000000011111111001111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 739), 0b00000000000011111110110000101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 740), 0b00000000000000000001011001010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 741), 0b10000000000000000000001001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 742), 0b00000000000011111111010100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 743), 0b00000000000011111111100101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 744), 0b00000000000011111111111011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 745), 0b00000000000011111011101111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 746), 0b00000000000011111111000100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 747), 0b00000000000000000000001101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 748), 0b00000000000011111111100010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 749), 0b00000000000011111111000110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 750), 0b00000000000011111111111001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 751), 0b10000000000000000000011111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 752), 0b00000000000000000000011110111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 753), 0b00000000000011111111101111001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 754), 0b00000000000000000000100110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 755), 0b00000000000000000000000000010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 756), 0b00000000000000000000011000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 757), 0b00000000000000000000100110101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 758), 0b00000000000000000000000011011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 759), 0b00000000000000000000000100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 760), 0b00000000000000000000001100010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 761), 0b10000000000000000001000011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 762), 0b00000000000011111111000111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 763), 0b00000000000000000001001101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 764), 0b00000000000011111111101011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 765), 0b00000000000011111111000101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 766), 0b00000000000011111111001100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 767), 0b00000000000011111111010011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 768), 0b00000000000011111111010111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 769), 0b00000000000011111111111111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 770), 0b00000000000011111111100111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 771), 0b10000000000011111110110111100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 772), 0b00000000000011111111100111110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 773), 0b00000000000011111111111100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 774), 0b00000000000011111101010111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 775), 0b00000000000011111111001101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 776), 0b00000000000011111111101010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 777), 0b00000000000011111111011000010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 778), 0b00000000000011111010110001100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 779), 0b00000000000011111110110011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 780), 0b00000000000000000000000101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 781), 0b10000000000000000000011101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 782), 0b00000000000000000000101100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 783), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 784), 0b00000000000000000000001000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 785), 0b00000000000011111111100111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 786), 0b00000000000000000000010001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 787), 0b00000000000000000000001000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 788), 0b00000000000011111111110100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 789), 0b00000000000000000000010100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 790), 0b00000000000011111111111110110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 791), 0b10000000000000000000011100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 792), 0b00000000000011111111101100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 793), 0b00000000000011111111110100100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 794), 0b00000000000011111111111010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 795), 0b00000000000000000000000000001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 796), 0b00000000000011111111111100010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 797), 0b00000000000011111111110111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 798), 0b00000000000011111111111000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 799), 0b00000000000000000000000111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 800), 0b00000000000011111111011111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 801), 0b10000000000000000001011101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 802), 0b00000000000000000000001110101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 803), 0b00000000000000000000100100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 804), 0b00000000000011111111001100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 805), 0b00000000000011111111100010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 806), 0b00000000000000000001001001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 807), 0b00000000000000000001011001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 808), 0b00000000000000000000010001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 809), 0b00000000000000000100100000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 810), 0b00000000000000000100011100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 811), 0b10000000000000000010110011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 812), 0b00000000000000000110111100000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 813), 0b00000000000000000100101000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 814), 0b00000000000000000101111001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 815), 0b00000000000000000010011001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 816), 0b00000000000000000010010100100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 817), 0b00000000000011111111101001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 818), 0b00000000000000000001010100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 819), 0b00000000000000000000011101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 820), 0b00000000000000000011110000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 821), 0b10000000000000000010100101011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 822), 0b00000000000000000001110001111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 823), 0b00000000000000000111011010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 824), 0b00000000000000000100101100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 825), 0b00000000000000000010000001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 826), 0b00000000000000000010110110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 827), 0b00000000000000000001000111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 828), 0b00000000000000000000111100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 829), 0b00000000000000000011010001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 830), 0b00000000000000000011110100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 831), 0b10000000000000000011101110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 832), 0b00000000000000000110000000011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 833), 0b00000000000000000111101010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 834), 0b00000000000000001000010001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 835), 0b00000000000000000010011101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 836), 0b00000000000000000100101001010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 837), 0b00000000000011111111100111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 838), 0b00000000000000000010000110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 839), 0b00000000000000000010101010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 840), 0b00000000000000000101001011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 841), 0b10000000000000000001000101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 842), 0b00000000000000000001001110101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 843), 0b00000000000000000011100000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 844), 0b00000000000000000011101011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 845), 0b00000000000000000110001100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 846), 0b00000000000000000001010110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 847), 0b00000000000000000000100001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 848), 0b00000000000000000011000011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 849), 0b00000000000000000000111100001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 850), 0b00000000000000000010100110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 851), 0b10000000000011111110001000011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 852), 0b00000000000000000001000000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 853), 0b00000000000000000001101111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 854), 0b00000000000000000000111001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 855), 0b00000000000000000001110011010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 856), 0b00000000000011111111110001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 857), 0b00000000000000000011111110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 858), 0b00000000000000000010101100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 859), 0b00000000000000000100001011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 860), 0b00000000000000000001100110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 861), 0b10000000000000000001001001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 862), 0b00000000000011111111111010110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 863), 0b00000000000000000000111001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 864), 0b00000000000011111111001000101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 865), 0b00000000000000000001111101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 866), 0b00000000000000000000000101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 867), 0b00000000000000000010111101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 868), 0b00000000000000000000110100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 869), 0b00000000000000000000001001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 870), 0b00000000000000000001000100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 871), 0b10000000000000000100001100001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 872), 0b00000000000000000001001101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 873), 0b00000000000000000001010110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 874), 0b00000000000000000001000011100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 875), 0b00000000000000000011110001000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 876), 0b00000000000000000001011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 877), 0b00000000000000000010001010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 878), 0b00000000000000000110010010100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 879), 0b00000000000000000000011000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 880), 0b00000000000000000100110010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 881), 0b10000000000011111111001111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 882), 0b00000000000000000000010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 883), 0b00000000000000000011011111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 884), 0b00000000000000000000111010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 885), 0b00000000000000000001101010011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 886), 0b00000000000000000001001001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 887), 0b00000000000000000100000001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 888), 0b00000000000000000011010101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 889), 0b00000000000000000011000110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 890), 0b00000000000000000010010000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 891), 0b10000000000000000001001111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 892), 0b00000000000000000000100100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 893), 0b00000000000000000001100111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 894), 0b00000000000000000000100110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 895), 0b00000000000000000000001111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 896), 0b00000000000000000001010001000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 897), 0b00000000000000000011011001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 898), 0b00000000000000000010011001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 899), 0b00000000000000000100001001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 900), 0b00000000000000000010101110010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 901), 0b10000000000011111110011110001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 902), 0b00000000000011111111111010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 903), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 904), 0b00000000000011111111111110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 905), 0b00000000000000000000001110000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 906), 0b00000000000011111001001011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 907), 0b00000000000011111110010010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 908), 0b00000000000011111111110011000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 909), 0b00000000000011111110110001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 910), 0b00000000000000000010001110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 911), 0b10000000000000000001010000110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 912), 0b00000000000000000011001000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 913), 0b00000000000000000010000001110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 914), 0b00000000000000000001100101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 915), 0b00000000000000000001000000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 916), 0b00000000000011111110010011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 917), 0b00000000000011111110110011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 918), 0b00000000000000000010001001101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 919), 0b00000000000000000000101110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 920), 0b00000000000000000011000100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 921), 0b10000000000011111111100110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 922), 0b00000000000000000010110000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 923), 0b00000000000000000001111111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 924), 0b00000000000000000000110110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 925), 0b00000000000000000001100000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 926), 0b00000000000011111101011011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 927), 0b00000000000011111111100000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 928), 0b00000000000000000001000011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 929), 0b00000000000000000001001100111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 930), 0b00000000000000000010110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 931), 0b10000000000011111111111101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 932), 0b00000000000000000010011100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 933), 0b00000000000000000001001101101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 934), 0b00000000000011111111010000011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 935), 0b00000000000000000010000000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 936), 0b00000000000011111101110100000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 937), 0b00000000000011111111010100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 938), 0b00000000000000000010100000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 939), 0b00000000000011111111111101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 940), 0b00000000000000000000000110111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 941), 0b10000000000011111110110010000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 942), 0b00000000000000000001100111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 943), 0b00000000000000000001011101110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 944), 0b00000000000000000000100010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 945), 0b00000000000000000010001100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 946), 0b00000000000011111110100111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 947), 0b00000000000000000000100110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 948), 0b00000000000000000011111000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 949), 0b00000000000011111110110100111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 950), 0b00000000000000000010011000000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 951), 0b10000000000011111111001110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 952), 0b00000000000000000001110100101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 953), 0b00000000000000000001001111011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 954), 0b00000000000000000001011011011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 955), 0b00000000000000000000111111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 956), 0b00000000000011111101111011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 957), 0b00000000000011111111010111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 958), 0b00000000000000000000111010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 959), 0b00000000000000000001110000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 960), 0b00000000000000000011010011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 961), 0b10000000000011111111110001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 962), 0b00000000000000000010001111000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 963), 0b00000000000000000010010010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 964), 0b00000000000000000000111010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 965), 0b00000000000000000001100101011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 966), 0b00000000000011111110010110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 967), 0b00000000000000000000010000111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 968), 0b00000000000000000010101111111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 969), 0b00000000000000000011000101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 970), 0b00000000000000000011001010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 971), 0b10000000000011111111001001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 972), 0b00000000000000000001100001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 973), 0b00000000000000000010010101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 974), 0b00000000000000000001101110101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 975), 0b00000000000000000010000111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 976), 0b00000000000011111101001101110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 977), 0b00000000000000000000001000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 978), 0b00000000000000000011101101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 979), 0b00000000000000000010110000001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 980), 0b00000000000000000010101011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 981), 0b10000000000011111111111010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 982), 0b00000000000000000010000011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 983), 0b00000000000000000010010101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 984), 0b00000000000000000001101010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 985), 0b00000000000000000001000111000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 986), 0b00000000000011111101001001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 987), 0b00000000000011111111011000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 988), 0b00000000000000000001111001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 989), 0b00000000000000000010000000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 990), 0b00000000000000000011001110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 991), 0b10000000000011111111110000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 992), 0b00000000000000000001110001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 993), 0b00000000000000000001101010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 994), 0b00000000000000000000111100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 995), 0b00000000000000000000100111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 996), 0b00000000000011111101101000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 997), 0b00000000000000000000000111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 998), 0b00000000000000000001010110011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 999), 0b00000000000000000001000001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1000), 0b00000000000000000010000110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1001), 0b10000000000000000111000001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1002), 0b00000000000000000000011101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1003), 0b00000000000000000000010011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1004), 0b00000000000000000000101000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1005), 0b00000000000011111111010011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1006), 0b00000000000000000010010100110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1007), 0b00000000000011111111100001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1008), 0b00000000000011111110101010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1009), 0b00000000000000000000000101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1010), 0b00000000000000000001011010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1011), 0b10000000000000000011100101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1012), 0b00000000000000000100011100110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1013), 0b00000000000000000101100111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1014), 0b00000000000000000101000101110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1015), 0b00000000000000000101001100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1016), 0b00000000000000000100000101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1017), 0b00000000000000000100001011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1018), 0b00000000000000000101010000111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1019), 0b00000000000000000010000101010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1020), 0b00000000000000000101101000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1021), 0b10000000000000000101001010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1022), 0b00000000000000000101000101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1023), 0b00000000000000000101010110111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1024), 0b00000000000000000101000110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1025), 0b00000000000000000011110010001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1026), 0b00000000000000000100110001101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1027), 0b00000000000000000100111111101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1028), 0b00000000000000000010111010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1029), 0b00000000000000000010111010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1030), 0b00000000000000000110000110110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1031), 0b10000000000000000100000011111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1032), 0b00000000000000000110000011010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1033), 0b00000000000000000110000110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1034), 0b00000000000000000101001000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1035), 0b00000000000000000100100111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1036), 0b00000000000000000101101101001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1037), 0b00000000000000000100110111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1038), 0b00000000000000000111000101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1039), 0b00000000000000000011000001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1040), 0b00000000000000000110100000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1041), 0b10000000000000000001101101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1042), 0b00000000000000000100010000101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1043), 0b00000000000000000101111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1044), 0b00000000000000000101100001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1045), 0b00000000000000000011110011011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1046), 0b00000000000000000100100001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1047), 0b00000000000000000001100101000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1048), 0b00000000000000000101100100110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1049), 0b00000000000000000011000001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1050), 0b00000000000000000110110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1051), 0b10000000000000001001011110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1052), 0b00000000000000000100100100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1053), 0b00000000000000000101001100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1054), 0b00000000000000000101011110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1055), 0b00000000000000000011111011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1056), 0b00000000000000000111010001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1057), 0b00000000000000000100100000001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1058), 0b00000000000000000110101011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1059), 0b00000000000000000010111101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1060), 0b00000000000000000100101101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1061), 0b10000000000000000010110010011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1062), 0b00000000000000000101010001000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1063), 0b00000000000000000101011101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1064), 0b00000000000000000011101111000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1065), 0b00000000000000000101111001011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1066), 0b00000000000000000010101001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1067), 0b00000000000000000001100000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1068), 0b00000000000000000110110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1069), 0b00000000000000000011011010000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1070), 0b00000000000000000100100110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1071), 0b10000000000000000011000011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1072), 0b00000000000000000111001001001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1073), 0b00000000000000000110010101100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1074), 0b00000000000000000100111011011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1075), 0b00000000000000000110111010110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1076), 0b00000000000000000100010001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1077), 0b00000000000000000100011100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1078), 0b00000000000000000110101010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1079), 0b00000000000000000011010100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1080), 0b00000000000000001000011000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1081), 0b10000000000000000111011100000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1082), 0b00000000000000000100101100111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1083), 0b00000000000000000100101001001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1084), 0b00000000000000000100101100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1085), 0b00000000000000000100111001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1086), 0b00000000000000000111011011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1087), 0b00000000000000000100110101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1088), 0b00000000000000000110001100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1089), 0b00000000000000000010011111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1090), 0b00000000000000000100001011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1091), 0b10000000000000001010011111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1092), 0b00000000000000000101110110001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1093), 0b00000000000000000101001110001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1094), 0b00000000000000000101110011001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1095), 0b00000000000000000101011110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1096), 0b00000000000000001001101100011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1097), 0b00000000000000000101010111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1098), 0b00000000000000000110101111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1099), 0b00000000000000000101101101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1100), 0b00000000000000000110010010101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1101), 0b10000000000000000011011110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1102), 0b00000000000000000000011010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1103), 0b00000000000000000000010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1104), 0b00000000000000000000010001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1105), 0b00000000000011111111110100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1106), 0b00000000000011111111011011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1107), 0b00000000000011111111111001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1108), 0b00000000000011111111100100000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1109), 0b00000000000000000000011111001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1110), 0b00000000000000000101001100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1111), 0b10000000000000000101000000011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1112), 0b00000000000000000111100111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1113), 0b00000000000011111110001010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1114), 0b00000000000011111101110100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1115), 0b00000000000011111110101011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1116), 0b00000000000011111111010110100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1117), 0b00000000000011111111011000010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1118), 0b00000000000011111101001010100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1119), 0b00000000000000000000110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1120), 0b00000000000000000011111011101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1121), 0b10000000000000000100101011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1122), 0b00000000000011111100111110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1123), 0b00000000000000000011100011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1124), 0b00000000000011111110101001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1125), 0b00000000000011111101111000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1126), 0b00000000000000000000011000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1127), 0b00000000000011111110011010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1128), 0b00000000000011111101010010101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1129), 0b00000000000000000001111000011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1130), 0b00000000000000000001011110001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1131), 0b10000000000000000010100000100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1132), 0b00000000000000000000101100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1133), 0b00000000000011111111000110100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1134), 0b00000000000000000101100011010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1135), 0b00000000000011111111010100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1136), 0b00000000000011111111101011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1137), 0b00000000000011111110110001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1138), 0b00000000000011111111000001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1139), 0b00000000000000000000110100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1140), 0b00000000000000000001101111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1141), 0b10000000000000000001010110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1142), 0b00000000000000000000111001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1143), 0b00000000000011111100110010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1144), 0b00000000000011111110100110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1145), 0b00000000000000000110001100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1146), 0b00000000000011111111011000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1147), 0b00000000000011111110100111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1148), 0b00000000000011111111101110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1149), 0b00000000000000000000010011000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1150), 0b00000000000000000000100100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1151), 0b10000000000000000011000101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1152), 0b00000000000011111111000100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1153), 0b00000000000011111101011011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1154), 0b00000000000011111101000001000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1155), 0b00000000000011111101011011000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1156), 0b00000000000011111100101010001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1157), 0b00000000000011111110100001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1158), 0b00000000000011111100110100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1159), 0b00000000000011111110001011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1160), 0b00000000000000000011100110001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1161), 0b10000000000000000010110101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1162), 0b00000000000000000000100101001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1163), 0b00000000000011111110001011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1164), 0b00000000000011111100111111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1165), 0b00000000000011111111010010010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1166), 0b00000000000011111110011010110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1167), 0b00000000000000000010011011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1168), 0b00000000000011111101010010000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1169), 0b00000000000011111110111100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1170), 0b00000000000000000000111110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1171), 0b10000000000000000011000010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1172), 0b00000000000011111110010001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1173), 0b00000000000011111111010000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1174), 0b00000000000011111110010010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1175), 0b00000000000011111101110111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1176), 0b00000000000011111111000010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1177), 0b00000000000000000000011011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1178), 0b00000000000000000110010110111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1179), 0b00000000000000000000110011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1180), 0b00000000000000000000100110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1181), 0b10000000000000000011100101101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1182), 0b00000000000000000000110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1183), 0b00000000000011111111010011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1184), 0b00000000000011111110011010100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1185), 0b00000000000000000000001000111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1186), 0b00000000000011111110110111101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1187), 0b00000000000011111110111101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1188), 0b00000000000011111100101111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1189), 0b00000000000011111101011110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1190), 0b00000000000000000001111010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1191), 0b10000000000000000011111101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1192), 0b00000000000011111110111000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1193), 0b00000000000011111110100000101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1194), 0b00000000000011111101100010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1195), 0b00000000000011111110101110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1196), 0b00000000000011111110101001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1197), 0b00000000000011111110010000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1198), 0b00000000000011111110001010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1199), 0b00000000000011111110010110100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1200), 0b00000000000000000001111010010111);\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hex_to_16bit_binary(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일 내용 읽기 및 분리 (스페이스 및 줄바꿈 기준)\n",
        "        hex_values = f.read().split()\n",
        "\n",
        "    # 16진수 -> 16비트 2진수 변환\n",
        "    binary_values = [format(int(hex_value, 16), '016b') for hex_value in hex_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for binary_value in binary_values:\n",
        "            f.write(binary_value + \"\\n\")  # 각 값을 줄바꿈으로 저장\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/RESULT_overflowx.txt'  # 16진수 값이 저장된 입력 파일\n",
        "output_txt_file = './model/binary_values.txt'  # 변환된 16비트 2진수를 저장할 출력 파일https://github.com/MMujtabaRoohani/RISC-V-Processor/blob/master/PipelinedProcessor/Control_Unit.v\n",
        "# 함수 호출\n",
        "convert_hex_to_16bit_binary(input_txt_file, output_txt_file)\n",
        "print(f\"16진수 값이 16비트 2진수로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "cCw_Fb3iL9zA",
        "outputId": "b3623799-c467-4c2d-9420-eab42a6f698b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16진수 값이 16비트 2진수로 변환되어 ./model/binary_values.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary_to_decimal(input_file, output_file):\n",
        "    def binary_to_decimal(binary_str):\n",
        "        # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "        int_part = int(binary_str[:3], 2)  # 정수부\n",
        "        frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "        return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 16비트 바이너리 값 읽기\n",
        "        binary_values = f.read().splitlines()\n",
        "\n",
        "    # 16비트 이진수를 10진수로 변환\n",
        "    decimal_values = [binary_to_decimal(binary) for binary in binary_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for decimal in decimal_values:\n",
        "            f.write(f\"{decimal:.10f}\\n\")  # 소수점 10자리까지 출력\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/binary_values.txt'  # 16비트 바이너리 입력 파일\n",
        "output_txt_file = './model/cordic_dec_val.txt'  # 변환된 10진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_binary_to_decimal(input_txt_file, output_txt_file)\n",
        "print(f\"16비트 바이너리 값이 10진수 소수점 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "6YmJ4ZPhM_Nb",
        "outputId": "90c6c634-ca67-4be7-d89e-34c1bd7b55bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16비트 바이너리 값이 10진수 소수점 값으로 변환되어 ./model/cordic_dec_val.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_fixed_point_hex(input_file, output_file):\n",
        "    def float_to_fixed_point(value):\n",
        "        \"\"\"\n",
        "        10진수 소수를 16비트 고정소수점 표현으로 변환:\n",
        "        - 앞 3비트: 정수부 (0~7)\n",
        "        - 뒤 13비트: 소수부\n",
        "        \"\"\"\n",
        "        # 정수부: value의 정수 부분 (0~7 사이 값)\n",
        "        int_part = int(value)\n",
        "        if int_part > 7:\n",
        "            raise ValueError(f\"정수부가 3비트를 초과했습니다: {value}\")\n",
        "\n",
        "        # 소수부: value의 소수 부분을 13비트로 표현\n",
        "        frac_part = value - int_part\n",
        "        frac_binary = int(round(frac_part * (2 ** 13)))  # 소수부를 2^13로 스케일링\n",
        "\n",
        "        # 16비트 바이너리 표현\n",
        "        binary_value = f\"{int_part:03b}{frac_binary:013b}\"\n",
        "        return binary_value\n",
        "\n",
        "    def binary_to_hex(binary_str):\n",
        "        \"\"\"\n",
        "        16비트 바이너리를 16진수(hex)로 변환.\n",
        "        \"\"\"\n",
        "        return f\"0x{int(binary_str, 2):04X}\"\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 10진수 소수점 값 읽기 (불필요한 문자 제거)\n",
        "        raw_data = f.read()\n",
        "        cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "        decimal_values = [float(value) for value in cleaned_data.split()]\n",
        "\n",
        "    # 10진수를 16비트 고정소수점 -> 16진수로 변환\n",
        "    hex_values = []\n",
        "    for value in decimal_values:\n",
        "        binary_value = float_to_fixed_point(value)  # 16비트 바이너리 변환\n",
        "        hex_value = binary_to_hex(binary_value)  # 16진수 변환\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for hex_value in hex_values:\n",
        "            f.write(f\"{hex_value}\\n\")\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/softmax_sorted_attention_scores_2.txt'  # 입력 파일\n",
        "output_txt_file = './model/converted_fixed_point_hex.txt'  # 변환된 16진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "decimal_to_fixed_point_hex(input_txt_file, output_txt_file)\n",
        "print(f\"소수점 값이 16비트 16진수 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jaDSmkz7Rmej",
        "outputId": "1be6d348-7a2d-4fe4-b519-52be78856cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소수점 값이 16비트 16진수 값으로 변환되어 ./model/converted_fixed_point_hex.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_bert_layer1.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_OFX.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"각 값의 오차율 (퍼센트):\\n{error_rates}\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "ubtP_IPwR_KR",
        "outputId": "bc3bca74-ef3b-4d84-dca7-87ee709f0aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "[10.03896239 26.00744796 14.73808949 ... 12.94998944  3.6775129\n",
            "  2.43226031]\n",
            "전체 평균 오차율 (퍼센트): 13.207395\n",
            "최대 오차율 (퍼센트): 95.348713 (위치: 436)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_sortedf1.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# numpy 배열 전체 출력 설정 (생략 없이)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# ✅ 결과 출력 (10개 단위 줄바꿈)\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "tVsIMaMrF_jQ",
        "outputId": "e7f9bafe-a8a4-4f67-f83a-ceaf4c1e862e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "120.101028, 65.873099, 45.220852, 103.863026, 119.760384, 129.893409, 125.520639, 52.651301, 76.468514, 107.262933\n",
            "92.932656, 129.051547, 88.973052, 96.154273, 100.712463, 92.287452, 65.439547, 69.124494, 110.225792, 131.792484\n",
            "79.309564, 139.890921, 97.113615, 98.714075, 49.011227, 139.281237, 132.641627, 92.960645, 117.251093, 145.401546\n",
            "96.959060, 99.462274, 127.572188, 93.521287, 58.117353, 109.602257, 122.636455, 143.069622, 108.160827, 60.705602\n",
            "58.843876, 139.701328, 145.542366, 108.467560, 102.546990, 109.786918, 152.295077, 52.683158, 89.285990, 130.197388\n",
            "105.789274, 104.021420, 72.805601, 151.454175, 87.136642, 57.097109, 82.810370, 92.262495, 148.599307, 98.103439\n",
            "134.738648, 60.823821, 88.267837, 61.146140, 108.359382, 118.012907, 116.693204, 85.619997, 109.466631, 83.942319\n",
            "140.025778, 75.307098, 72.291247, 114.238822, 106.152435, 64.089968, 54.618739, 53.553961, 97.407008, 124.349383\n",
            "102.228964, 101.060979, 87.374069, 137.651240, 89.733922, 57.521296, 99.783851, 75.105369, 71.832412, 40.283664\n",
            "114.970356, 89.172031, 51.413682, 125.443275, 107.723487, 97.768630, 50.915055, 45.136134, 104.725566, 48.488510\n",
            "86.831031, 118.421853, 64.225009, 88.950476, 94.407583, 102.645772, 174.281354, 119.888247, 96.681210, 115.716487\n",
            "73.296387, 120.784147, 131.403168, 59.142249, 109.907055, 128.005323, 104.341395, 94.608076, 101.772773, 91.954166\n",
            "71.890050, 87.643082, 81.048148, 109.955908, 141.758444, 163.260156, 135.637741, 121.235263, 91.793290, 130.469192\n",
            "100.933105, 142.586771, 78.433252, 59.018720, 56.084441, 55.723648, 121.766502, 122.584075, 141.511082, 131.893129\n",
            "107.059956, 118.698837, 132.720795, 89.731744, 51.183811, 60.115055, 99.057509, 89.272421, 117.327174, 80.696644\n",
            "100.626420, 126.279941, 113.996307, 112.797733, 94.114237, 70.218782, 48.492598, 142.003199, 68.828553, 101.668798\n",
            "144.701933, 150.435850, 79.461588, 63.113106, 62.197903, 52.158070, 80.803931, 96.601254, 120.397954, 72.556089\n",
            "70.638387, 130.422158, 123.135512, 69.214232, 65.624003, 81.225575, 137.794819, 143.444587, 132.697276, 151.528389\n",
            "130.517111, 133.164963, 88.819859, 77.791731, 77.299243, 74.166249, 55.151737, 135.706005, 137.201700, 55.619156\n",
            "94.641835, 132.035322, 89.274300, 86.730470, 71.612070, 80.329605, 132.368752, 146.566962, 113.910485, 58.146783\n",
            "87.581036, 86.748725, 112.920073, 157.838301, 104.928115, 175.671103, 70.909850, 115.871795, 98.394513, 109.570424\n",
            "104.515220, 109.593977, 67.477923, 88.415156, 88.858406, 181.068392, 173.732535, 133.854735, 94.218920, 96.482990\n",
            "103.549615, 92.733699, 58.400831, 108.692781, 83.346843, 278.249762, 61.880488, 108.316765, 116.072282, 103.938129\n",
            "89.585577, 90.794992, 76.822632, 178.331065, 168.396399, 100.624527, 149.047283, 200.652034, 139.073568, 155.295820\n",
            "136.569086, 40.273680, 73.067447, 138.322019, 123.433571, 57.213045, 81.997948, 109.887288, 103.938900, 131.991591\n",
            "122.310666, 57.542247, 130.040353, 95.496790, 54.736767, 117.464721, 137.681349, 83.861015, 54.534624, 124.941644\n",
            "72.355870, 130.701894, 71.846703, 76.197200, 121.584111, 135.670731, 141.026189, 127.916461, 113.901755, 60.884397\n",
            "76.484537, 69.597706, 103.322145, 163.564964, 140.102427, 122.301005, 68.072976, 56.944034, 103.349844, 120.862122\n",
            "103.000995, 83.642827, 65.864561, 127.679071, 93.615245, 179.085541, 106.801212, 104.529045, 61.928057, 142.706485\n",
            "79.497492, 87.916433, 161.605493, 86.163552, 107.057610, 78.802467, 89.184795, 93.170974, 104.885467, 78.425355\n",
            "104.582138, 76.243457, 70.796400, 84.001378, 134.946616, 142.513838, 108.786018, 93.958336, 87.570883, 153.583193\n",
            "101.785310, 107.126510, 77.875444, 68.294287, 76.820681, 118.764975, 162.042919, 82.706125, 147.885372, 102.163789\n",
            "91.569442, 125.951357, 93.661280, 71.846125, 82.860170, 86.317361, 136.867568, 120.407308, 155.700037, 125.610375\n",
            "75.645253, 98.415360, 135.357463, 90.414252, 89.508875, 136.933080, 70.740113, 106.316546, 140.622670, 115.375956\n",
            "76.174842, 126.239212, 91.262713, 78.733603, 96.274099, 144.009482, 110.431209, 93.847788, 129.089082, 143.056073\n",
            "122.453982, 122.277117, 82.778669, 49.940710, 43.938995, 97.170520, 118.195358, 144.623705, 128.419138, 89.413116\n",
            "105.990621, 97.245996, 78.355655, 77.571551, 57.792600, 149.464516, 140.574746, 128.208247, 141.675968, 149.424498\n",
            "60.103955, 145.985509, 61.132007, 86.516820, 148.202621, 148.500568, 142.686673, 106.045323, 71.956252, 126.304905\n",
            "94.902350, 78.802709, 67.594285, 79.398719, 95.439203, 106.302309, 137.734109, 142.112829, 144.283725, 86.348862\n",
            "1070.901743, 1296.939057, 1406.628424, 1566.256545, 1583.571192, 1408.662564, 1137.145449, 1284.975696, 1733.584037, 1129.583655\n",
            "88.791572, 129.085431, 77.615295, 97.436324, 205.542352, 142.012351, 182.960743, 181.162539, 96.626842, 96.657513\n",
            "93.167516, 85.732211, 75.606994, 147.502365, 182.437619, 200.916332, 172.456062, 145.151208, 34.285949, 147.647790\n",
            "113.978823, 66.878464, 123.215808, 123.240139, 107.610045, 103.179569, 51.985805, 73.224595, 109.757109, 58.712687\n",
            "109.178144, 77.685249, 32.534036, 61.492796, 75.451657, 30.496266, 37.750196, 16.252084, 6.979668, 8.014773\n",
            "122.505077, 79.854191, 91.148676, 72.797274, 83.941049, 117.546609, 85.632589, 92.736550, 90.158883, 63.394297\n",
            "113.523242, 81.402830, 65.356472, 134.491020, 102.777859, 71.290618, 70.354657, 92.094511, 148.300427, 42.371646\n",
            "135.711177, 81.523859, 101.595648, 89.471531, 69.111714, 68.698714, 90.873495, 64.088400, 82.609390, 125.505919\n",
            "90.358056, 100.396020, 113.866106, 111.313596, 94.887481, 121.145482, 90.173320, 37.345963, 96.175918, 89.187463\n",
            "114.519292, 49.879333, 128.487599, 81.956088, 45.670162, 69.249341, 43.124946, 79.664191, 122.599903, 80.334484\n",
            "145.102218, 49.488948, 76.890632, 104.977427, 96.703556, 61.792649, 105.217879, 133.230724, 85.438282, 82.414466\n",
            "98.565396, 74.176935, 110.766331, 128.871652, 138.674516, 126.792458, 123.264727, 119.785299, 84.949666, 85.061822\n",
            "116.189394, 56.000741, 96.426769, 135.997586, 113.656796, 143.144945, 94.058803, 55.142999, 66.859104, 70.720408\n",
            "100.336041, 85.227039, 94.338555, 62.845580, 171.490287, 148.103989, 117.421294, 120.745828, 112.414573, 48.049568\n",
            "127.273865, 127.076413, 59.041184, 54.960196, 87.478022, 137.569432, 120.713675, 52.729249, 55.498557, 84.872205\n",
            "135.709139, 66.212724, 92.429748, 119.746979, 55.288889, 56.983087, 107.632885, 62.610830, 49.686102, 113.810792\n",
            "100.574926, 84.418716, 64.613985, 82.185032, 87.290248, 111.211141, 168.454603, 148.087152, 98.008239, 82.172251\n",
            "1167.988259, 1230.044772, 1277.470027, 1304.856160, 1375.065541, 1599.433024, 1297.208961, 2064.331177, 1731.723484, 1280.075747\n",
            "98.118202, 83.917074, 80.405877, 123.034625, 146.359527, 72.049656, 159.160187, 83.937499, 67.565517, 53.969529\n",
            "1169.202173, 1325.627177, 1389.732346, 1530.856256, 1672.479278, 1500.894078, 1475.707049, 1398.888738, 1379.043603, 1701.002316\n",
            "105.476085, 111.103696, 128.493456, 101.015732, 66.344415, 54.140929, 61.806072, 76.239601, 118.311015, 32.149299\n",
            "67.342295, 110.998971, 116.149955, 68.001675, 116.360780, 121.464395, 159.532529, 162.082671, 82.193438, 67.923182\n",
            "112.761255, 65.765761, 93.130846, 101.425857, 113.821311, 119.227675, 129.257550, 79.196869, 44.085696, 34.445303\n",
            "123.325878, 77.747500, 76.021065, 71.812667, 97.906472, 117.497599, 149.046898, 117.495111, 126.600902, 49.004802\n",
            "92.656232, 124.115887, 135.302447, 64.331828, 46.712061, 129.815876, 123.671612, 77.389274, 62.773709, 108.105661\n",
            "74.488612, 129.098492, 143.255094, 126.936901, 101.180056, 77.267381, 56.465085, 93.851872, 125.826429, 76.897995\n",
            "126.044382, 67.620564, 125.525684, 58.864913, 60.736795, 84.046367, 110.026419, 134.811060, 51.900217, 40.192356\n",
            "132.422981, 125.984456, 80.079356, 65.912518, 61.716280, 73.318495, 106.778290, 160.389330, 123.215351, 52.447308\n",
            "140.964604, 124.338761, 85.616119, 57.348410, 66.087686, 95.275030, 130.932716, 111.292951, 60.041766, 56.308182\n",
            "136.187020, 121.849481, 57.842845, 80.157192, 104.347790, 114.846449, 89.695659, 74.299700, 72.747643, 62.152406\n",
            "108.338418, 88.012791, 126.769777, 80.945822, 72.713016, 81.413515, 113.714099, 85.767052, 55.364259, 52.339612\n",
            "87.415052, 74.522702, 74.657365, 76.057585, 80.053367, 107.011502, 113.804737, 138.512563, 159.627006, 139.518888\n",
            "117.528851, 106.923615, 77.180870, 67.285830, 75.394862, 111.846946, 136.884118, 117.796762, 103.515433, 84.380173\n",
            "71.956336, 145.234487, 133.961200, 77.210699, 72.388534, 65.517432, 104.155571, 118.448769, 122.180220, 101.076956\n",
            "114.559367, 120.989764, 79.782643, 58.773609, 71.301704, 119.130527, 131.956828, 106.165586, 94.080424, 89.081712\n",
            "66.984979, 62.612076, 75.818204, 78.257057, 108.649478, 114.282791, 138.621462, 162.027151, 158.531111, 93.277774\n",
            "124.805849, 124.229140, 111.627960, 111.632199, 100.759542, 82.921655, 71.590503, 70.482981, 69.237059, 112.996755\n",
            "114.837077, 117.489191, 45.352344, 70.085697, 75.771397, 98.361094, 104.390900, 116.744970, 124.689480, 120.930983\n",
            "53.162663, 70.039113, 94.654716, 99.255420, 125.057756, 145.467889, 126.415125, 119.170944, 126.870171, 117.060040\n",
            "134.597110, 109.185399, 94.203565, 90.491551, 77.117758, 76.561773, 88.005555, 93.625286, 103.149929, 125.388022\n",
            "108.284952, 76.485440, 69.782197, 93.313342, 95.546616, 99.966834, 100.796511, 105.440204, 119.228802, 141.360989\n",
            "93.203765, 87.071418, 122.584750, 128.780432, 159.848042, 99.885444, 71.157494, 65.865724, 112.279673, 152.404801\n",
            "127.912227, 68.422763, 95.707390, 80.622342, 112.407491, 73.181240, 66.328150, 124.956675, 75.608201, 86.329265\n",
            "106.979376, 94.481329, 69.555346, 121.780343, 110.632548, 83.756042, 38.946749, 71.762471, 138.875824, 119.987020\n",
            "83.501937, 112.158780, 62.840832, 171.153521, 120.870983, 105.568726, 119.756923, 95.084379, 62.788682, 98.618723\n",
            "67.023869, 101.893668, 118.976694, 157.208747, 105.233916, 135.394259, 150.030745, 159.907888, 141.385498, 95.692670\n",
            "75.846593, 81.555176, 126.250689, 98.529828, 103.911142, 119.352780, 164.047235, 150.507946, 100.669959, 69.778170\n",
            "121.219981, 56.679680, 135.903681, 134.024077, 114.698700, 105.284466, 46.974905, 42.127372, 59.838063, 136.501591\n",
            "81.650900, 133.751189, 73.079534, 98.747010, 70.249034, 135.686580, 143.720010, 162.098113, 165.750647, 90.673660\n",
            "45.555825, 108.673493, 125.239746, 148.811322, 63.137642, 90.654355, 146.642827, 126.727969, 73.735326, 132.242222\n",
            "61.500597, 127.719761, 115.648094, 83.182494, 103.942018, 143.566951, 146.964256, 102.492196, 99.313759, 68.718424\n",
            "90.758109, 89.971417, 93.716287, 99.300152, 99.916459, 112.134160, 151.113122, 114.142894, 97.027095, 154.536160\n",
            "134.689675, 131.105134, 45.683748, 37.035820, 87.420863, 119.859167, 123.272532, 94.259145, 100.393017, 56.910289\n",
            "109.163232, 98.677137, 53.374541, 95.942653, 127.880268, 131.015376, 107.594564, 85.625625, 94.627906, 100.930842\n",
            "102.842935, 97.339378, 58.128143, 162.519356, 66.527044, 80.504470, 80.850805, 149.845934, 157.177604, 91.004294\n",
            "88.756131, 91.405798, 75.110052, 115.241707, 132.948067, 114.454126, 108.203312, 140.288527, 135.071385, 114.394439\n",
            "113.161689, 64.117368, 70.291412, 100.002566, 119.639384, 118.904134, 110.974900, 106.408511, 120.631102, 54.507912\n",
            "134.812636, 136.884061, 100.414325, 59.407673, 55.291810, 90.722867, 116.942937, 57.375170, 73.975390, 62.613944\n",
            "97.686261, 122.083797, 114.925361, 80.688313, 61.488555, 96.283089, 117.019223, 61.839986, 160.289143, 151.357074\n",
            "150.339525, 77.682866, 55.416611, 53.476961, 78.296819, 101.081203, 162.649022, 78.130193, 130.881035, 159.920163\n",
            "57.060884, 87.702415, 97.951538, 132.305279, 148.136453, 138.784180, 103.078284, 58.192356, 88.617096, 100.724723\n",
            "112.448596, 50.031979, 92.601850, 74.927912, 59.355535, 46.244362, 32.970532, 79.844154, 100.268864, 74.932222\n",
            "1177.793197, 1194.013385, 1440.666465, 1490.460432, 1535.693629, 1085.859528, 934.847197, 886.120085, 1215.199922, 883.862585\n",
            "40.250399, 105.798358, 126.501554, 131.087962, 128.676894, 118.612611, 95.419881, 66.266078, 110.187340, 109.201748\n",
            "150.781676, 87.496763, 52.709170, 49.759231, 89.634250, 152.628314, 124.591707, 98.495555, 49.799080, 143.221026\n",
            "121.117434, 69.227820, 104.706921, 109.468459, 91.128081, 68.037083, 82.790803, 146.355338, 91.900592, 104.558493\n",
            "98.363515, 119.932166, 91.739149, 99.700306, 130.425567, 92.775124, 80.276871, 73.933601, 58.137155, 117.662132\n",
            "111.093145, 65.697821, 106.461126, 127.090929, 88.793073, 80.143770, 112.291671, 107.717880, 92.672294, 100.375879\n",
            "72.492609, 146.281683, 126.021693, 98.412869, 69.213554, 127.131352, 77.384334, 63.427373, 125.310207, 140.569270\n",
            "111.455916, 111.623109, 56.231294, 122.325946, 115.039697, 102.376029, 102.000542, 95.859423, 55.479274, 80.093951\n",
            "94.537007, 99.217211, 120.653322, 76.483165, 84.261102, 88.721649, 97.309893, 122.428090, 134.565812, 151.886404\n",
            "123.619126, 93.221440, 68.175223, 61.625794, 55.701139, 51.170270, 57.428055, 62.882852, 85.636353, 99.245636\n",
            "94.631685, 136.133546, 65.829906, 116.743484, 116.727060, 119.611737, 100.170758, 44.870393, 61.993812, 125.483752\n",
            "104.118744, 104.872672, 73.516803, 113.061829, 75.418853, 98.445196, 75.579754, 70.476009, 129.408529, 131.821498\n",
            "100.681052, 83.923086, 81.833747, 114.710594, 101.980296, 85.843312, 122.973168, 144.672531, 136.113224, 106.531010\n",
            "84.765048, 161.331508, 162.092593, 118.792299, 92.701842, 121.254509, 161.654036, 127.357863, 119.388310, 137.844306\n",
            "81.554946, 127.925415, 125.133717, 72.157887, 43.558881, 95.006559, 95.389563, 116.231347, 98.401589, 81.866039\n",
            "112.358197, 73.453635, 126.647475, 86.580120, 124.595010, 123.655967, 71.624115, 52.565897, 123.412204, 129.406405\n",
            "84.535417, 160.123314, 129.040896, 104.473259, 87.628189, 145.230121, 151.463722, 70.187156, 69.924799, 70.858878\n",
            "103.102842, 72.046207, 126.967459, 58.031343, 135.239240, 137.800826, 127.703002, 81.344478, 114.572211, 113.124900\n",
            "61.920914, 65.858834, 119.102493, 102.002216, 95.414206, 80.509476, 68.283256, 60.207079, 53.884616, 100.170173\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 142.370306\n",
            "최대 오차율 (퍼센트): 2064.331177 (위치: 567)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2, output_file):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 오차율을 계산하고 저장.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "    output_file: 오차율 결과를 저장할 파일 경로\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 오차율 결과를 TXT 파일로 저장\n",
        "    np.savetxt(output_file, error_rates, fmt=\"%.6f\", delimiter=\"\\n\")\n",
        "\n",
        "    # ✅ 전체 평균 및 최대 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)\n",
        "\n",
        "    return mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_bert_layer1.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_OFX.txt'  # 두 번째 파일\n",
        "output_file = './model/error_rates_output.txt'  # 저장할 파일\n",
        "\n",
        "# ✅ 함수 실행 (오차율 계산 및 저장)\n",
        "mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path, output_file)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"오차율 결과가 '{output_file}'에 저장되었습니다!\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "FlxQvesTKOA6",
        "outputId": "ba716262-eace-4f96-f9cf-5f5b244fc04f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차율 결과가 './model/error_rates_output.txt'에 저장되었습니다!\n",
            "전체 평균 오차율 (퍼센트): 13.207395\n",
            "최대 오차율 (퍼센트): 95.348713 (위치: 436)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_values_from_files(file1, file2, section):\n",
        "    \"\"\"\n",
        "    두 파일에서 section 값(1부터 시작)을 기준으로 10개 단위의 값을 가져와 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "    section: 출력할 10개 단위의 번호 (1부터 시작)\n",
        "\n",
        "    출력:\n",
        "    - 두 파일에서 해당 범위의 10개 값을 한 줄씩 출력\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 시작 및 끝 인덱스 계산\n",
        "    start_idx = (section - 1) * 10\n",
        "    end_idx = start_idx + 10\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    if start_idx >= len(values1) or start_idx >= len(values2):\n",
        "        raise ValueError(f\"입력한 section={section}이 데이터 길이를 초과했습니다.\")\n",
        "\n",
        "    # 해당 구간의 데이터 추출\n",
        "    extracted_values1 = values1[start_idx:end_idx]\n",
        "    extracted_values2 = values2[start_idx:end_idx]\n",
        "\n",
        "    # 출력\n",
        "    print(f\"파일1 ({file1}) [{start_idx + 1}~{min(end_idx, len(values1))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values1))\n",
        "\n",
        "    print(f\"\\n파일2 ({file2}) [{start_idx + 1}~{min(end_idx, len(values2))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values2))\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_bert_layer1.txt'\n",
        "file2_path = './model/cordic_dec_val_OFX.txt'\n",
        "\n",
        "# ✅ section 번호 입력\n",
        "section_number = 44  # 원하는 section 값 입력 (1부터 시작)\n",
        "\n",
        "# 함수 실행\n",
        "extract_values_from_files(file1_path, file2_path, section_number)\n"
      ],
      "metadata": {
        "id": "6iGJh7Z_Imbo",
        "outputId": "73151815-5a9c-4375-d8e6-378214d10350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일1 (./model/softmax_bert_layer1.txt) [431~440]:\n",
            "0.018670, 0.075914, 0.807604, 0.017185, 0.056644, 0.002599, 0.002624, 0.007178, 0.003255, 0.008325\n",
            "\n",
            "파일2 (./model/cordic_dec_val_OFX.txt) [431~440]:\n",
            "0.014526, 0.067261, 0.844604, 0.014526, 0.037231, 0.000122, 0.000122, 0.004028, 0.000854, 0.004761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_values_from_files(file1, file2, section):\n",
        "    \"\"\"\n",
        "    두 파일에서 section 값(1부터 시작)을 기준으로 10개 단위의 값을 가져와 출력하는 함수.\n",
        "    값 변형 없이 파일에서 읽은 그대로 출력.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "    section: 출력할 10개 단위의 번호 (1부터 시작)\n",
        "\n",
        "    출력:\n",
        "    - 두 파일에서 해당 범위의 10개 값을 한 줄씩 출력\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # ✅ 공백 & 개행 기준으로 값을 분리하여 리스트로 저장\n",
        "            values = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").split()\n",
        "        return values  # 값 변형 없이 원본 리스트 반환\n",
        "\n",
        "    # 파일에서 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # ✅ 1200개 값이 있는 경우, section=57이면 561~570번째 값 출력\n",
        "    start_idx = (section - 1) * 10\n",
        "    end_idx = start_idx + 10\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    if start_idx >= len(values1) or start_idx >= len(values2):\n",
        "        raise ValueError(f\"입력한 section={section}이 데이터 길이를 초과했습니다. (최대 {len(values1)//10}개)\")\n",
        "\n",
        "    # 해당 구간의 데이터 추출\n",
        "    extracted_values1 = values1[start_idx:end_idx]\n",
        "    extracted_values2 = values2[start_idx:end_idx]\n",
        "\n",
        "    # ✅ 출력 (값 변형 없이 원본 유지)\n",
        "    print(f\"파일1 ({file1}) [{start_idx + 1}~{min(end_idx, len(values1))}]:\")\n",
        "    print(\"\\n\".join(extracted_values1))  # 개행으로 출력\n",
        "\n",
        "    print(f\"\\n파일2 ({file2}) [{start_idx + 1}~{min(end_idx, len(values2))}]:\")\n",
        "    print(\"\\n\".join(extracted_values2))  # 개행으로 출력\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_bert_layer1.txt'\n",
        "file2_path = './model/cordic_dec_val_sortedF.txt'\n",
        "\n",
        "# ✅ section 번호 입력\n",
        "section_number = 57  # 원하는 section 값 입력 (1부터 시작)\n",
        "\n",
        "# ✅ 함수 실행\n",
        "extract_values_from_files(file1_path, file2_path, section_number)\n"
      ],
      "metadata": {
        "id": "Mmw-q0DIQTmU",
        "outputId": "9114257f-b37d-40b7-853d-0212ea1270de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일1 (./model/softmax_bert_layer1.txt) [561~570]:\n",
            "0.00397149\n",
            "0.15772054\n",
            "0.14235464\n",
            "0.14518486\n",
            "0.13557892\n",
            "0.03903241\n",
            "0.04620929\n",
            "0.1503617\n",
            "0.08108555\n",
            "0.09850051\n",
            "\n",
            "파일2 (./model/cordic_dec_val_sortedF.txt) [561~570]:\n",
            "0.0274658203\n",
            "1.6649169922\n",
            "1.6649169922\n",
            "1.6649169922\n",
            "1.5858154297\n",
            "0.3575439453\n",
            "0.5001220703\n",
            "1.6649169922\n",
            "0.5665283203\n",
            "0.8370361328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 1대1 오차율을 계산하고,\n",
        "    정수 부분별 개수를 세어 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    - 오차율 정수 부분별 개수\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 불일치 예외 처리\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    # ✅ 오차율의 정수 부분 개수 세기\n",
        "    integer_parts = [int(x) for x in error_rates]  # 정수 부분만 추출\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "    sorted_counts = sorted(count_dict.items())  # 키(정수 부분) 기준 정렬\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index, sorted_counts\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_02_11.txt'  # 두 번째 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "error_rates, mean_error_rate, max_error, max_error_index, sorted_counts = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 오차율 10개 단위 출력\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "# ✅ 전체 평균 및 최대 오차율 출력\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n",
        "\n",
        "# ✅ 오차율 정수 부분 개수 출력\n",
        "print(\"\\n오차율 정수 부분 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "t7FLq284LuIe",
        "outputId": "751585ab-f39d-4ba7-86f4-c8106588ae2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "0.103197, 0.158920, 1.215494, 0.733964, 0.507472, 1.533857, 3.413383, 12.008857, 0.839151, 6.068030\n",
            "0.240297, 0.189093, 1.302581, 2.982521, 4.247265, 9.965741, 8.859651, 6.829620, 14.399079, 14.677612\n",
            "0.077202, 0.266254, 0.739496, 0.179681, 0.174592, 2.943648, 3.734500, 5.775061, 6.759188, 11.529057\n",
            "0.034847, 0.007182, 0.175317, 2.328239, 3.818016, 1.110729, 4.095066, 5.265172, 1.014433, 3.946078\n",
            "0.191927, 0.671869, 2.309529, 3.388904, 4.475655, 4.888571, 5.887059, 10.562167, 7.955048, 89.654051\n",
            "0.203086, 0.236856, 0.630939, 1.059059, 2.189915, 0.891696, 0.407602, 0.919941, 1.170337, 2.445823\n",
            "0.410430, 0.056969, 0.678516, 1.378017, 3.047289, 2.278100, 4.424290, 11.248748, 14.503416, 12.823546\n",
            "0.021143, 0.019726, 0.568235, 1.062001, 0.414543, 0.942007, 7.323325, 6.821745, 12.263552, 6.332244\n",
            "0.191522, 1.805454, 2.594647, 0.636354, 5.255133, 5.420617, 17.330821, 11.375242, 47.128488, 74.101476\n",
            "0.331032, 0.479319, 1.564987, 2.697380, 3.898653, 20.652100, 22.607664, 18.002184, 56.899880, 74.903350\n",
            "0.274705, 0.448905, 1.027005, 0.870512, 0.992683, 0.946021, 1.455801, 0.857005, 2.856585, 1.889877\n",
            "0.062781, 0.387353, 0.219916, 0.667256, 0.529696, 1.809541, 2.153334, 1.529868, 1.731424, 6.502030\n",
            "0.246583, 1.817803, 1.138960, 1.810300, 3.359786, 3.018466, 1.152789, 1.489256, 4.621715, 5.320764\n",
            "1.102257, 2.475788, 2.137111, 0.953237, 1.038759, 2.727134, 3.132087, 2.774970, 2.814113, 4.561903\n",
            "0.097584, 0.092863, 0.417148, 0.091581, 0.235233, 0.012540, 1.227160, 0.795145, 5.562565, 3.433373\n",
            "0.415304, 0.644272, 1.128897, 0.610600, 0.345503, 0.796446, 1.301568, 1.260849, 3.526541, 3.652377\n",
            "0.385523, 0.457200, 0.154347, 0.703232, 0.073418, 0.312579, 0.225749, 0.495692, 1.405650, 1.751848\n",
            "0.193181, 0.271658, 0.584096, 0.817963, 0.699703, 0.073229, 0.713557, 0.093551, 1.468368, 2.213586\n",
            "0.042122, 0.237522, 0.068082, 0.354730, 0.119526, 0.078069, 0.568548, 0.236287, 0.897504, 0.217325\n",
            "0.151541, 0.097048, 0.158565, 0.546840, 0.097773, 0.649704, 2.280134, 1.457440, 1.907110, 3.994053\n",
            "1.184344, 0.703642, 1.130059, 1.060541, 24.650387, 23.211392, 94.350088, 93.306302, 87.791108, 82.164221\n",
            "0.209283, 0.790367, 2.874423, 1.925386, 2.724985, 4.513752, 9.592924, 9.980604, 11.612946, 8.612562\n",
            "0.405579, 0.161764, 0.310098, 0.334435, 1.035306, 4.576345, 1.488113, 1.717219, 3.967875, 0.967404\n",
            "0.229583, 1.987667, 0.842799, 5.325493, 9.396823, 7.781391, 19.622882, 8.848772, 36.743181, 50.701496\n",
            "0.787461, 0.855966, 1.224408, 1.782441, 1.874871, 5.860452, 21.172864, 19.788297, 85.688500, 83.719890\n",
            "0.318648, 0.340988, 0.020586, 0.444319, 7.936935, 6.445383, 10.801508, 5.209433, 12.778003, 15.116360\n",
            "0.176617, 0.118965, 0.236974, 1.015848, 1.367011, 0.884451, 0.111940, 1.376518, 1.703489, 1.256137\n",
            "0.005670, 0.294144, 0.578545, 0.266562, 0.795201, 1.070991, 1.336001, 3.947287, 1.319039, 1.145340\n",
            "0.783024, 1.336027, 2.042162, 1.880340, 3.297489, 2.455539, 4.797396, 6.687014, 10.566931, 20.671811\n",
            "0.053423, 0.212018, 0.186598, 0.807693, 3.255134, 11.043549, 5.878212, 11.583434, 10.269138, 23.779460\n",
            "0.066516, 0.501149, 0.474197, 0.622122, 0.639316, 0.133981, 1.879934, 0.914847, 0.248854, 1.562643\n",
            "0.029041, 1.266120, 1.535720, 1.329629, 1.748214, 0.982182, 3.230020, 2.923061, 8.052544, 26.485896\n",
            "0.101526, 0.003146, 0.514552, 0.357297, 0.281097, 0.458822, 0.300877, 0.326388, 2.094487, 2.886873\n",
            "0.310582, 0.016587, 0.659313, 0.851632, 0.242767, 2.164749, 0.198245, 2.387871, 2.715996, 3.173922\n",
            "0.252959, 0.064699, 0.426453, 0.276324, 0.296572, 1.265661, 1.025071, 1.793559, 4.726657, 17.608110\n",
            "0.738672, 0.574866, 0.741431, 0.589192, 2.411063, 0.576041, 0.774269, 0.864021, 0.158393, 1.616749\n",
            "0.843705, 0.804722, 1.166512, 1.339721, 1.949484, 1.043439, 1.389857, 2.245638, 5.225111, 1.836512\n",
            "1.309651, 1.518127, 0.220322, 2.051259, 2.080743, 1.963198, 1.239170, 2.759825, 2.380464, 5.079273\n",
            "0.627974, 0.592768, 0.258054, 0.272485, 0.047152, 0.607905, 0.736098, 1.300514, 0.415529, 1.844928\n",
            "0.227136, 0.066375, 0.312201, 0.327693, 0.086690, 0.458414, 0.636317, 0.870473, 0.819659, 3.059972\n",
            "0.796858, 1.032572, 4.056073, 12.250523, 26.606014, 92.829264, 91.615979, 91.281783, 87.515757, 87.513810\n",
            "0.546035, 2.260260, 0.456564, 5.454640, 27.041555, 24.922283, 18.981890, 94.396544, 89.037883, 84.276332\n",
            "0.123450, 0.249334, 0.481492, 0.336988, 0.562179, 0.539548, 2.229204, 2.422561, 3.326738, 6.583524\n",
            "0.062093, 2.876117, 4.303209, 8.465621, 11.919006, 35.484992, 38.777691, 84.999733, 81.394842, 81.214824\n",
            "0.169068, 0.041898, 0.348322, 0.616272, 0.487697, 1.800190, 6.913104, 9.813840, 8.250188, 37.328214\n",
            "0.359624, 0.076459, 1.141135, 2.969233, 2.377376, 4.163078, 3.477700, 5.512677, 11.655913, 23.162195\n",
            "0.109597, 0.072829, 1.660660, 0.300570, 2.164296, 1.833967, 1.174319, 0.959431, 6.119311, 6.687206\n",
            "0.219736, 0.167545, 0.084747, 0.042934, 0.057702, 0.237985, 0.115844, 2.120763, 0.226949, 0.628807\n",
            "0.170215, 1.296634, 2.101194, 2.669643, 0.570092, 18.165154, 8.987213, 11.495473, 22.797721, 62.034849\n",
            "0.931181, 3.265842, 1.589529, 1.312104, 1.019106, 1.532281, 3.696638, 14.567501, 42.942068, 42.090647\n",
            "0.245448, 4.646394, 22.933087, 21.384806, 18.017618, 13.999190, 28.210699, 93.077629, 91.687656, 91.682616\n",
            "0.517656, 0.321295, 0.229031, 0.424505, 0.317117, 1.725388, 2.794502, 2.759374, 5.797262, 15.345251\n",
            "0.154744, 0.207773, 1.207706, 0.576130, 2.076452, 2.798437, 5.498776, 7.677348, 13.146041, 58.683840\n",
            "0.028444, 0.059367, 0.807372, 1.070101, 0.577944, 1.211906, 0.687408, 0.962455, 4.070542, 67.848316\n",
            "0.380104, 0.099907, 0.073810, 0.471298, 0.540047, 2.039735, 2.662209, 17.057563, 19.853111, 38.281420\n",
            "0.423145, 0.944133, 0.664012, 0.811629, 0.825798, 0.760956, 1.894775, 0.372906, 2.836106, 33.755544\n",
            "0.622784, 0.954976, 0.786508, 0.872019, 0.960014, 0.361398, 1.768479, 1.729379, 1.173874, 13.937369\n",
            "0.000039, 0.197345, 0.727435, 1.290524, 0.939761, 0.112885, 1.667220, 3.146075, 4.781711, 18.246267\n",
            "0.527645, 0.102545, 0.702697, 0.056175, 0.728570, 0.757174, 0.283776, 0.866768, 1.362604, 6.279150\n",
            "0.366711, 2.001171, 0.804206, 3.116428, 2.524292, 1.680599, 2.969670, 5.928121, 6.489516, 83.981905\n",
            "0.542114, 1.549744, 0.070330, 4.336480, 7.744642, 8.566308, 10.415168, 15.887362, 17.764830, 21.896195\n",
            "0.035982, 0.743484, 0.165803, 0.015657, 0.526090, 0.938858, 0.904112, 1.617405, 6.600577, 0.230635\n",
            "0.328385, 0.441287, 0.093864, 0.333026, 0.868897, 0.438487, 0.316088, 1.020189, 3.888688, 3.110178\n",
            "0.168517, 0.033671, 0.136142, 0.019122, 0.036189, 0.006908, 0.590395, 0.477428, 0.056890, 2.969139\n",
            "0.210645, 0.033641, 0.779331, 0.834295, 1.314145, 1.287877, 0.373252, 2.634158, 8.360290, 6.751445\n",
            "0.156034, 0.134185, 0.463034, 2.141691, 3.327751, 3.364676, 5.763802, 8.093046, 13.199877, 14.584789\n",
            "0.082767, 0.266054, 0.275966, 0.517089, 0.516301, 0.251919, 0.058786, 0.697403, 0.174694, 0.992347\n",
            "0.046330, 0.228865, 0.008304, 0.314725, 0.717844, 0.692847, 0.415632, 1.213685, 0.913272, 0.919404\n",
            "0.117861, 0.359600, 0.078616, 0.552250, 0.534998, 1.429837, 0.094996, 0.400171, 1.053957, 0.436973\n",
            "0.344494, 0.348408, 0.991365, 3.419812, 4.399062, 7.161752, 8.487958, 6.740427, 12.223583, 20.922950\n",
            "0.558695, 0.148161, 0.071114, 0.149727, 0.317054, 0.179338, 0.108717, 0.483203, 0.812959, 1.134000\n",
            "0.011188, 0.024789, 0.742086, 0.592899, 0.959590, 0.417844, 1.003652, 0.505100, 0.301279, 0.180689\n",
            "0.114017, 0.455213, 0.054431, 0.329955, 0.290059, 0.480968, 0.770469, 0.115234, 0.008902, 3.166871\n",
            "0.073094, 0.437340, 0.668462, 0.573230, 0.940139, 0.857799, 0.614752, 0.334926, 1.672162, 1.014402\n",
            "0.548874, 0.611216, 0.096562, 0.312168, 0.185651, 0.378354, 0.853520, 0.265449, 0.157675, 6.970034\n",
            "0.005924, 0.527583, 0.851034, 0.745712, 0.142738, 0.572202, 0.536003, 1.168730, 3.585958, 0.782879\n",
            "0.265601, 0.014520, 0.048267, 0.611748, 0.694126, 0.541378, 0.361498, 0.063053, 0.621602, 1.479227\n",
            "0.318860, 0.103052, 0.016480, 0.062344, 0.071302, 0.424090, 0.247724, 0.257534, 1.023789, 0.349366\n",
            "0.966573, 0.140832, 0.246397, 0.092649, 0.626185, 0.381989, 0.192934, 0.507660, 0.227288, 0.822872\n",
            "1.204230, 0.426937, 4.155074, 0.491563, 1.306040, 1.083575, 1.681558, 0.439524, 0.363056, 1.213205\n",
            "0.218044, 0.431536, 0.142371, 1.669273, 1.359645, 3.184738, 2.916192, 3.379190, 3.633211, 2.713353\n",
            "0.262557, 0.032276, 0.208116, 1.003585, 3.834181, 1.387132, 0.266232, 1.875047, 0.568872, 18.255548\n",
            "0.254340, 0.666638, 0.840053, 2.770895, 0.385933, 0.787739, 0.099046, 0.427245, 0.237475, 0.611925\n",
            "0.408343, 1.288168, 4.925868, 1.059301, 0.028957, 3.488861, 10.124351, 14.916470, 10.285349, 69.830066\n",
            "0.163734, 0.106022, 1.723345, 1.167033, 3.379588, 5.210365, 4.686266, 6.013838, 2.360922, 6.220628\n",
            "0.206478, 0.193528, 0.206558, 1.423894, 0.009648, 1.908549, 1.153557, 1.045758, 4.082284, 11.753719\n",
            "0.395619, 0.042331, 0.144062, 0.490508, 0.140140, 0.109002, 0.049194, 1.664787, 0.349236, 0.472400\n",
            "0.014699, 0.600186, 1.409241, 0.570256, 4.720717, 5.288237, 5.073504, 4.396979, 7.489102, 14.714657\n",
            "2.303373, 0.968512, 0.585986, 1.986080, 0.059823, 2.782482, 0.318102, 0.855433, 2.680803, 5.896658\n",
            "0.600618, 0.537754, 1.363609, 0.060493, 1.579399, 0.187863, 1.614240, 1.922148, 2.719231, 3.965341\n",
            "0.210681, 0.417376, 0.753893, 0.769377, 0.462520, 1.522807, 2.356690, 3.945153, 3.783751, 86.052815\n",
            "1.020891, 0.439493, 1.132786, 2.699531, 0.557453, 1.478916, 1.684458, 1.190669, 2.651454, 12.606928\n",
            "0.193780, 0.324691, 0.562322, 0.480852, 0.260714, 0.130503, 0.100087, 1.710195, 1.910018, 5.237856\n",
            "0.643739, 0.661462, 2.859351, 1.082793, 1.623257, 0.772962, 0.582574, 0.619942, 2.301245, 3.019492\n",
            "0.216350, 0.107811, 0.649304, 0.019812, 1.025918, 0.408015, 0.062410, 5.994908, 3.812127, 3.763095\n",
            "0.029198, 0.580063, 0.703590, 0.622662, 0.832133, 0.948356, 0.613915, 1.740616, 3.154199, 3.514047\n",
            "0.024479, 0.154934, 0.233925, 0.423809, 0.132552, 0.692081, 0.529628, 1.189488, 1.805302, 4.599820\n",
            "0.264554, 0.098759, 0.076489, 0.463998, 0.447590, 0.274417, 0.704187, 0.500654, 2.079324, 10.511618\n",
            "0.668406, 1.089022, 0.207198, 2.650824, 1.121528, 0.823666, 0.627735, 3.097175, 3.953490, 13.738286\n",
            "0.479047, 0.085934, 0.022716, 0.659599, 0.215161, 0.119702, 0.304343, 0.964403, 1.276046, 7.864061\n",
            "0.012466, 6.121357, 6.849746, 11.122077, 13.480098, 13.691852, 16.693161, 23.830711, 27.746135, 43.500152\n",
            "0.332287, 0.332730, 0.170765, 0.055424, 0.138546, 0.883383, 0.685827, 0.092976, 1.201535, 2.029654\n",
            "0.132413, 0.551276, 0.534917, 0.058478, 0.001207, 0.723356, 1.341419, 1.195190, 1.464687, 1.022829\n",
            "0.273954, 0.566334, 1.080638, 1.085022, 0.450782, 1.003322, 0.973046, 0.852982, 1.107727, 1.819035\n",
            "0.518231, 0.175004, 0.125990, 0.651594, 1.713966, 1.292902, 1.330916, 1.830660, 6.155196, 10.225113\n",
            "0.051186, 0.328425, 0.037817, 0.742558, 0.232823, 0.841842, 1.269512, 3.190945, 2.289238, 7.616073\n",
            "0.085843, 0.228007, 0.335183, 0.447985, 0.148297, 0.868862, 0.848746, 2.329113, 0.972899, 1.392312\n",
            "0.199222, 1.210346, 1.153180, 0.139103, 0.936925, 4.022444, 3.731115, 5.503381, 2.174783, 7.336281\n",
            "0.112970, 0.211061, 0.537435, 0.231456, 0.018464, 0.495623, 0.505657, 0.273503, 0.616214, 1.875721\n",
            "0.070930, 0.123552, 0.539585, 4.762910, 3.117291, 3.284080, 6.762047, 3.774870, 1.646281, 1.089532\n",
            "0.228441, 0.431510, 0.611843, 3.296163, 2.018090, 3.668849, 5.613605, 5.258296, 1.990650, 1.937271\n",
            "0.052530, 0.734544, 1.608374, 10.463649, 22.024127, 20.986254, 28.394200, 41.212014, 50.155751, 86.124078\n",
            "0.722964, 0.875637, 0.196507, 0.953529, 4.448602, 10.268259, 15.104295, 9.303403, 23.153794, 31.115898\n",
            "0.250155, 0.268064, 1.680409, 3.963313, 5.466400, 4.861124, 9.069511, 11.420982, 12.509114, 16.116636\n",
            "0.523120, 2.313167, 6.447170, 7.817029, 7.711091, 1.279789, 3.735893, 6.955858, 5.867991, 92.508842\n",
            "0.089721, 0.249933, 1.097326, 2.797535, 4.022958, 7.534884, 7.353277, 9.721592, 6.823546, 6.021377\n",
            "0.494574, 0.234580, 0.382295, 0.076246, 0.383088, 1.080471, 2.734588, 0.138685, 2.918373, 5.073212\n",
            "0.073669, 3.637201, 7.122340, 6.854615, 10.159615, 17.632631, 13.624649, 39.578524, 38.949174, 25.171294\n",
            "0.169672, 0.486004, 0.181811, 0.930806, 1.720111, 1.997235, 2.283745, 1.566672, 5.709112, 12.294280\n",
            "0.028013, 0.092658, 1.851321, 1.644530, 3.100394, 4.375019, 2.553126, 1.290504, 2.636007, 3.016141\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n",
            "\n",
            "오차율 정수 부분 개수:\n",
            "0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차 및 평균 오차를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - 전체 평균 오차\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ 오차율 계산 (음수값 유지)\n",
        "    error_rates = (differences / np.abs(values1)) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차 계산\n",
        "    mean_error = np.mean(np.abs(differences))  # 전체 차이 평균\n",
        "\n",
        "    return differences, mean_error\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, mean_error = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"전체 평균 차이: {mean_error:.6f}\")\n"
      ],
      "metadata": {
        "id": "OrQuhc19gboQ",
        "outputId": "8ad31a67-9ee8-4715-f49c-70cd629d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "전체 평균 차이: 0.000800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 RMSE(Root Mean Squared Error) 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - RMSE 값\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ RMSE 계산\n",
        "    rmse = np.sqrt(np.mean(differences ** 2))  # (차이 제곱 → 평균 → 루트)\n",
        "\n",
        "    return differences, rmse\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, rmse = calculate_rmse(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"✅ RMSE (Root Mean Squared Error): {rmse:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JGwrIV7NNw",
        "outputId": "9118d0f8-b468-41d8-d5e1-317c4db2cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "✅ RMSE (Root Mean Squared Error): 0.001001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def count_integer_parts(file_path):\n",
        "    \"\"\"\n",
        "    파일을 읽어 정수 부분별 개수를 세는 함수 (음수 0과 양수 0을 구별하여 정렬).\n",
        "\n",
        "    Args:\n",
        "    file_path: 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 정수 부분별 개수 딕셔너리 (출력 순서: -3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ... )\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 값 읽기\n",
        "    values = read_file(file_path)\n",
        "\n",
        "    # ✅ 음수와 양수의 0을 구별하여 저장\n",
        "    integer_parts = []\n",
        "    for x in values:\n",
        "        if x < 0:\n",
        "            integer_part = int(x) if abs(x) >= 1 else \"-0\"  # 음수 정수 또는 -0\n",
        "        else:\n",
        "            integer_part = int(x) if x >= 1 else \"+0\"  # 양수 정수 또는 +0\n",
        "        integer_parts.append(integer_part)\n",
        "\n",
        "    # ✅ 정수 부분 개수 세기\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "\n",
        "    # ✅ 정렬 (-3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ...)\n",
        "    sorted_counts = sorted(count_dict.items(), key=lambda x: (float(x[0]) if x[0] not in [\"-0\", \"+0\"] else -0.5 if x[0] == \"-0\" else 0.5))\n",
        "\n",
        "    return sorted_counts\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file_path = './model/error_rates_output.txt'  # 읽어올 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "sorted_counts = count_integer_parts(file_path)\n",
        "\n",
        "# ✅ 정수 부분 개수 출력\n",
        "print(\"\\n정수 부분별 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "3ABGD8kb1_-Q",
        "outputId": "1e931fbf-2e56-4d2b-b3f7-c7a3485e5bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "정수 부분별 개수:\n",
            "+0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_values_in_file(file_path):\n",
        "    \"\"\"\n",
        "    주어진 텍스트 파일에서 숫자 값을 추출하여\n",
        "    값의 순서를 변경하지 않고 한 줄씩 정리된 형태로 다시 저장하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file_path: 변환할 텍스트 파일 경로\n",
        "    \"\"\"\n",
        "    # 1. 파일 읽기\n",
        "    with open(file_path, 'r') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    # 2. 모든 숫자 값 추출 (형식 유지, 순서 변경 X)\n",
        "    cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "    values = cleaned_data.split()  # 공백 기준으로 숫자 분리\n",
        "\n",
        "    # 3. 같은 파일에 다시 한 줄씩 저장 (순서 유지)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(\"\\n\".join(values))\n",
        "\n",
        "    print(f\"✅ 파일이 성공적으로 변환되었습니다: {file_path}\")\n",
        "\n",
        "# ✅ 변환할 파일 경로 설정\n",
        "file_path = './model/attention_scores_2 (4).txt'  # 파일 경로 변경 가능\n",
        "\n",
        "# ✅ 함수 실행\n",
        "reformat_values_in_file(file_path)\n"
      ],
      "metadata": {
        "id": "kXzSpyHfbSSU",
        "outputId": "189c3b11-ad93-4f68-97d4-1b7dbd712e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되었습니다: ./model/attention_scores_2 (4).txt\n"
          ]
        }
      ]
    }
  ]
}