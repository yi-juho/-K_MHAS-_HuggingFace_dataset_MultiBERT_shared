{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9moVKInibnca",
        "dryCfxh4btMS",
        "wqqbD-tBcehO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbc9ca1c89fc4ff7976aae19531655c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_920a4c091b274fbea972bb6389e9f107",
              "IPY_MODEL_c2dcf1e9dced4dceb4043268b716c095",
              "IPY_MODEL_72cafa78f4f046088e253434d0d7c250"
            ],
            "layout": "IPY_MODEL_81f9a0b9f33b4edbb05a0f058d1e2a9a"
          }
        },
        "920a4c091b274fbea972bb6389e9f107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a84b48c7044315a055ace5453fe2e1",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2f9de00e8b4f2eb25010203bd3d536",
            "value": "README.md: 100%"
          }
        },
        "c2dcf1e9dced4dceb4043268b716c095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9163e63613f24374910a35936f236832",
            "max": 10565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ae6b53d666f4c8ebd68bfb1074751df",
            "value": 10565
          }
        },
        "72cafa78f4f046088e253434d0d7c250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4c5dfcdb3e4c9eb910d7a3d055468e",
            "placeholder": "​",
            "style": "IPY_MODEL_879d29e6e66444bfa89a74f8877cfa48",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 493kB/s]"
          }
        },
        "81f9a0b9f33b4edbb05a0f058d1e2a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a84b48c7044315a055ace5453fe2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2f9de00e8b4f2eb25010203bd3d536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9163e63613f24374910a35936f236832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae6b53d666f4c8ebd68bfb1074751df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4c5dfcdb3e4c9eb910d7a3d055468e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879d29e6e66444bfa89a74f8877cfa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1683d36dbc64a7ea420a57b87f242fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14fbfb8903de4269a05a20d2b0e3c762",
              "IPY_MODEL_0a6fb321c8444faaabcc45076d6fd040",
              "IPY_MODEL_38d54750cf194e50b8d2e8f41bb094b0"
            ],
            "layout": "IPY_MODEL_6539f842ef534068be4c7c051eb7366b"
          }
        },
        "14fbfb8903de4269a05a20d2b0e3c762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dde5ff71a354c1fabaad7ce9a855117",
            "placeholder": "​",
            "style": "IPY_MODEL_dc1c880a0f7b47d98540ffd424bea47f",
            "value": "kmhas_korean_hate_speech.py: 100%"
          }
        },
        "0a6fb321c8444faaabcc45076d6fd040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c443f12fa644489527b4a8967af799",
            "max": 4730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d237d77670494f77839b983d92e43e47",
            "value": 4730
          }
        },
        "38d54750cf194e50b8d2e8f41bb094b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e54488dcda9493a9bd509381991a4c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9a9d16792aa942978301250ad7e2f0db",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 437kB/s]"
          }
        },
        "6539f842ef534068be4c7c051eb7366b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dde5ff71a354c1fabaad7ce9a855117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1c880a0f7b47d98540ffd424bea47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c443f12fa644489527b4a8967af799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d237d77670494f77839b983d92e43e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e54488dcda9493a9bd509381991a4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9d16792aa942978301250ad7e2f0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "964943c1797b415e9120e8c04ff038a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93f8be103de54eab953255281b78e31b",
              "IPY_MODEL_d05d59fe6eee4368b5f7cd8cafd72d75",
              "IPY_MODEL_608a71e3f2264fe9af5f70cfa8ef9a4b"
            ],
            "layout": "IPY_MODEL_cec0ed6846cd416d88a4a9ac0b72894a"
          }
        },
        "93f8be103de54eab953255281b78e31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977fb9474d6742ad81bc6ddf687f02b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e037fcd4b82a4cd1892d3dd4e749a693",
            "value": "0000.parquet: 100%"
          }
        },
        "d05d59fe6eee4368b5f7cd8cafd72d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7446c9abec04a728a8c63c5ee419797",
            "max": 5244851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8552fb6096e44acf8a6b5148d829bf92",
            "value": 5244851
          }
        },
        "608a71e3f2264fe9af5f70cfa8ef9a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c264cde1bf4984b13e24e7641c7115",
            "placeholder": "​",
            "style": "IPY_MODEL_22f363868faa4d69acaba559bcb69c3c",
            "value": " 5.24M/5.24M [00:00&lt;00:00, 24.2MB/s]"
          }
        },
        "cec0ed6846cd416d88a4a9ac0b72894a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977fb9474d6742ad81bc6ddf687f02b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e037fcd4b82a4cd1892d3dd4e749a693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7446c9abec04a728a8c63c5ee419797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8552fb6096e44acf8a6b5148d829bf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86c264cde1bf4984b13e24e7641c7115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f363868faa4d69acaba559bcb69c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c03e0442b7e2458ea1a67942f3778bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27f82a790cb549c3843eaca879bb7b07",
              "IPY_MODEL_0304038c148b4c659f0736de4d0b0467",
              "IPY_MODEL_87ee99cd4f8e40258efd22f60bfb169c"
            ],
            "layout": "IPY_MODEL_449dbf375f6f46d6bba69691b4a8ed5d"
          }
        },
        "27f82a790cb549c3843eaca879bb7b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a489feb8de3e460191cbba0adfa3f45d",
            "placeholder": "​",
            "style": "IPY_MODEL_eb61bfe360164535920bc24cce2a820f",
            "value": "default/validation/0000.parquet: 100%"
          }
        },
        "0304038c148b4c659f0736de4d0b0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2778847e889049029123a13d94fcf2f3",
            "max": 578860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5da80f6bb8940ceb1d38f37bd9b1ac5",
            "value": 578860
          }
        },
        "87ee99cd4f8e40258efd22f60bfb169c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da51434bbb64bb08546866e88d8afd8",
            "placeholder": "​",
            "style": "IPY_MODEL_f52f422e3e684eb184e939c1cff46c91",
            "value": " 579k/579k [00:00&lt;00:00, 1.37MB/s]"
          }
        },
        "449dbf375f6f46d6bba69691b4a8ed5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a489feb8de3e460191cbba0adfa3f45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb61bfe360164535920bc24cce2a820f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2778847e889049029123a13d94fcf2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5da80f6bb8940ceb1d38f37bd9b1ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3da51434bbb64bb08546866e88d8afd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52f422e3e684eb184e939c1cff46c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8988f0ed6e604a698222ed36a40723b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a133afa115b480aac0e3dd6916500a1",
              "IPY_MODEL_ff3e5294383944bb8e69f6e6bc1ffc47",
              "IPY_MODEL_acff041d53c845d884729da8bdafde7a"
            ],
            "layout": "IPY_MODEL_24e57a15ebc7434f9733499d94884dc5"
          }
        },
        "5a133afa115b480aac0e3dd6916500a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99101716c6f044db9b0e2285734a2df9",
            "placeholder": "​",
            "style": "IPY_MODEL_da571b148e244631a0233adf3e75624f",
            "value": "0000.parquet: 100%"
          }
        },
        "ff3e5294383944bb8e69f6e6bc1ffc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d54cd571064dcdb4a92599447edfbf",
            "max": 1458266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c9b8322db824b46b4d2ca2632094cf6",
            "value": 1458266
          }
        },
        "acff041d53c845d884729da8bdafde7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d1e02498bd41839b4b1c0bc901285e",
            "placeholder": "​",
            "style": "IPY_MODEL_e759807a94b84202b0a1fff08aa01023",
            "value": " 1.46M/1.46M [00:00&lt;00:00, 64.4MB/s]"
          }
        },
        "24e57a15ebc7434f9733499d94884dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99101716c6f044db9b0e2285734a2df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da571b148e244631a0233adf3e75624f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88d54cd571064dcdb4a92599447edfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9b8322db824b46b4d2ca2632094cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3d1e02498bd41839b4b1c0bc901285e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e759807a94b84202b0a1fff08aa01023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d821363b7844bf79d892d0a45fba48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2f3070ac96347b9adaf1998bc13d4c0",
              "IPY_MODEL_16d14344da17438d90724fa96a75ff97",
              "IPY_MODEL_79e47fdc0c894255bc8f384d45a15f1f"
            ],
            "layout": "IPY_MODEL_35ec7436d9f540b5ba5f1282b2af014f"
          }
        },
        "b2f3070ac96347b9adaf1998bc13d4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3582e497b3db4eb48d04c8e98812ffe0",
            "placeholder": "​",
            "style": "IPY_MODEL_eaf39abd322e4f43b165ee3e34c55783",
            "value": "Generating train split: 100%"
          }
        },
        "16d14344da17438d90724fa96a75ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4ec03d95f64b0d854d91f3bd317f35",
            "max": 78977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ed4860a25cf4581991ffe4fed4bf2de",
            "value": 78977
          }
        },
        "79e47fdc0c894255bc8f384d45a15f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06d362d1eae4a4db026ee2f0412581f",
            "placeholder": "​",
            "style": "IPY_MODEL_2482fb8c6b60481c8fa3399a332f5cf7",
            "value": " 78977/78977 [00:00&lt;00:00, 745639.99 examples/s]"
          }
        },
        "35ec7436d9f540b5ba5f1282b2af014f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3582e497b3db4eb48d04c8e98812ffe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf39abd322e4f43b165ee3e34c55783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4ec03d95f64b0d854d91f3bd317f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed4860a25cf4581991ffe4fed4bf2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e06d362d1eae4a4db026ee2f0412581f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2482fb8c6b60481c8fa3399a332f5cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572827a2045f497cb1ceea0b18bc994b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149aacf311bd4d239a587e41e8e4fc61",
              "IPY_MODEL_482ab4e36d67430b879d930bf9ac2eae",
              "IPY_MODEL_eedac08ca1084056910f71fc6c78a274"
            ],
            "layout": "IPY_MODEL_f46ee324226840d9b0e910e29439fbf7"
          }
        },
        "149aacf311bd4d239a587e41e8e4fc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c11455e20f43daad06a3dc2573582a",
            "placeholder": "​",
            "style": "IPY_MODEL_5222d4a5d54b46e1ab5fd451e86db76d",
            "value": "Generating validation split: 100%"
          }
        },
        "482ab4e36d67430b879d930bf9ac2eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5884795388c438887e7666cd9054a85",
            "max": 8776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b071801c1314cb2acdf68400af1d1d2",
            "value": 8776
          }
        },
        "eedac08ca1084056910f71fc6c78a274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c73062ea5724f90aa415b326ca43e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_d63b4e7349a14a7ca7a3d45b87b18ea1",
            "value": " 8776/8776 [00:00&lt;00:00, 266449.59 examples/s]"
          }
        },
        "f46ee324226840d9b0e910e29439fbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c11455e20f43daad06a3dc2573582a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5222d4a5d54b46e1ab5fd451e86db76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5884795388c438887e7666cd9054a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b071801c1314cb2acdf68400af1d1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c73062ea5724f90aa415b326ca43e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63b4e7349a14a7ca7a3d45b87b18ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df558f6459e94efcb90677883b2ffcb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbce1eeb83f34661b975d4f71e815447",
              "IPY_MODEL_6a255b83744b4a09ace3d7e8f5e754e4",
              "IPY_MODEL_eaa3e788ffd94aad8f9fb4c3ad83cb6b"
            ],
            "layout": "IPY_MODEL_4c7a0b5d91144071b7e46eeb686a2659"
          }
        },
        "fbce1eeb83f34661b975d4f71e815447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d92035c7f94b08a02ca8bf1ca4ba32",
            "placeholder": "​",
            "style": "IPY_MODEL_06757748368d4ea1965a4362429e91ca",
            "value": "Generating test split: 100%"
          }
        },
        "6a255b83744b4a09ace3d7e8f5e754e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa0e4f430f44fcda33fc615cd7989ad",
            "max": 21939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c342ea011943568317aec41a0eed2f",
            "value": 21939
          }
        },
        "eaa3e788ffd94aad8f9fb4c3ad83cb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a5478c2daf4850bd036c72e80a2942",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c641699800475ab7a638303044e20d",
            "value": " 21939/21939 [00:00&lt;00:00, 498701.12 examples/s]"
          }
        },
        "4c7a0b5d91144071b7e46eeb686a2659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d92035c7f94b08a02ca8bf1ca4ba32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06757748368d4ea1965a4362429e91ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aa0e4f430f44fcda33fc615cd7989ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c342ea011943568317aec41a0eed2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97a5478c2daf4850bd036c72e80a2942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c641699800475ab7a638303044e20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c85fefc0387404a9d3d2b638869de16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20f31647753b496e92356e2946788f84",
              "IPY_MODEL_ca67d6408f974a6296cc3de9a85c8b39",
              "IPY_MODEL_4cb556b7c1c942119a7f814f78697899"
            ],
            "layout": "IPY_MODEL_aa8f387696a543c4a07f519aaa4e3549"
          }
        },
        "20f31647753b496e92356e2946788f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879e324249b8444cbe08e42549eaf606",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7123357c124f46807eb5e333798166",
            "value": ""
          }
        },
        "ca67d6408f974a6296cc3de9a85c8b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99deef2c523146a2b81b5061be1af6c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1db05e87413949b8acd069857a395c15",
            "value": 0
          }
        },
        "4cb556b7c1c942119a7f814f78697899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f7b01b33f746e0a249f5fcfac3be45",
            "placeholder": "​",
            "style": "IPY_MODEL_b09cd4c4ac5946f4a2825ca95cec7860",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "aa8f387696a543c4a07f519aaa4e3549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879e324249b8444cbe08e42549eaf606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7123357c124f46807eb5e333798166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99deef2c523146a2b81b5061be1af6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1db05e87413949b8acd069857a395c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60f7b01b33f746e0a249f5fcfac3be45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09cd4c4ac5946f4a2825ca95cec7860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3155474e44aa4deca90de1f7e847e111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccdeb411067d4cd790e306c938b79783",
              "IPY_MODEL_44e1e262ebf74ca2a0d88e1049b471c0",
              "IPY_MODEL_6dcc3d95e83249479b01780a0c0278f9"
            ],
            "layout": "IPY_MODEL_f1967cef57464988963aa53729ca9002"
          }
        },
        "ccdeb411067d4cd790e306c938b79783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83fa3e5bf0844e37a975455608f4aa25",
            "placeholder": "​",
            "style": "IPY_MODEL_1694b1385754431a9873a7417de12eab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "44e1e262ebf74ca2a0d88e1049b471c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9dec8193c0463a949fac5a84395e5e",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cfcf7bbccdc40f5b64f6abb272b4bdd",
            "value": 289
          }
        },
        "6dcc3d95e83249479b01780a0c0278f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970262c304c247efbf5be781e82d94a9",
            "placeholder": "​",
            "style": "IPY_MODEL_30bafde4bfd14bd9877646c73d61e6af",
            "value": " 289/289 [00:00&lt;00:00, 13.0kB/s]"
          }
        },
        "f1967cef57464988963aa53729ca9002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fa3e5bf0844e37a975455608f4aa25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1694b1385754431a9873a7417de12eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9dec8193c0463a949fac5a84395e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cfcf7bbccdc40f5b64f6abb272b4bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "970262c304c247efbf5be781e82d94a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bafde4bfd14bd9877646c73d61e6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24b841d12bd34bfebfe0f9627a2c5cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c6f2d54b12147c09f101f8c8e9230cf",
              "IPY_MODEL_d8fb9fa49a2a479aa05c2b31afbe8ee3",
              "IPY_MODEL_29e71004a125406f837f461340031e05"
            ],
            "layout": "IPY_MODEL_17d5b34f21544bfeb8b76588c8ce60cc"
          }
        },
        "5c6f2d54b12147c09f101f8c8e9230cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244b8ae6f7bd4366a6259cf59b9aa15e",
            "placeholder": "​",
            "style": "IPY_MODEL_59ae442bfb224cf08eb70498852da889",
            "value": "vocab.txt: 100%"
          }
        },
        "d8fb9fa49a2a479aa05c2b31afbe8ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab744e8f06e489d8c952a7946b483f6",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e290e4769cc84437b212fb2253a2780a",
            "value": 248477
          }
        },
        "29e71004a125406f837f461340031e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c9ef84e15841fbb17b77a0d6b34b44",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff94128c03f4d36b83bb9d137f7de41",
            "value": " 248k/248k [00:00&lt;00:00, 14.5MB/s]"
          }
        },
        "17d5b34f21544bfeb8b76588c8ce60cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244b8ae6f7bd4366a6259cf59b9aa15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ae442bfb224cf08eb70498852da889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eab744e8f06e489d8c952a7946b483f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e290e4769cc84437b212fb2253a2780a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66c9ef84e15841fbb17b77a0d6b34b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff94128c03f4d36b83bb9d137f7de41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3bdfe503a984a26bf02000aa4efd4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5edc21c3169b445c9691987d70dd719a",
              "IPY_MODEL_77e8bafc033f4561b7817ab8f703043b",
              "IPY_MODEL_5d81bc31507e40db964fe2cefa0ec1b1"
            ],
            "layout": "IPY_MODEL_ad31bb6d9db24e0f97032aa22f60eaa4"
          }
        },
        "5edc21c3169b445c9691987d70dd719a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588247e5a2e24186bf0ab16af283f7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c5fa160c502044ea991bdd7fa71601ee",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "77e8bafc033f4561b7817ab8f703043b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e05738fb774e38adbc6347183427dc",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e9ec652a27347898cc62a3e1bdcb0a2",
            "value": 125
          }
        },
        "5d81bc31507e40db964fe2cefa0ec1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1ecac9619b47a5a0c3e948bf6301c2",
            "placeholder": "​",
            "style": "IPY_MODEL_bcaece7affb94c1cbef7e5cd5755c5d0",
            "value": " 125/125 [00:00&lt;00:00, 8.21kB/s]"
          }
        },
        "ad31bb6d9db24e0f97032aa22f60eaa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588247e5a2e24186bf0ab16af283f7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fa160c502044ea991bdd7fa71601ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10e05738fb774e38adbc6347183427dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9ec652a27347898cc62a3e1bdcb0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c1ecac9619b47a5a0c3e948bf6301c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcaece7affb94c1cbef7e5cd5755c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be2ab138d914e9eaf266cc7a5b215e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c450e71047494c9b9662e148d5858b59",
              "IPY_MODEL_020d38200d25449793ef8efdd1ea90aa",
              "IPY_MODEL_43dd39eaed724c478a60e0be65cd061c"
            ],
            "layout": "IPY_MODEL_f48d9030a9b94c64b6381b372bd712c7"
          }
        },
        "c450e71047494c9b9662e148d5858b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672c6bbcb65040c392a7aa7b564c62af",
            "placeholder": "​",
            "style": "IPY_MODEL_c94bddb7f5ec4b33967a5898d30fac80",
            "value": "tokenizer.json: 100%"
          }
        },
        "020d38200d25449793ef8efdd1ea90aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e082766ee24def9f1fb05a6a7f3dba",
            "max": 494860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_457fb60f90cb4433b86e031d30927ea9",
            "value": 494860
          }
        },
        "43dd39eaed724c478a60e0be65cd061c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4ee25a6fde4699b6c23d8e59c04cb8",
            "placeholder": "​",
            "style": "IPY_MODEL_87cf407f27ec4098b03ca61222ce20ed",
            "value": " 495k/495k [00:00&lt;00:00, 29.6MB/s]"
          }
        },
        "f48d9030a9b94c64b6381b372bd712c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672c6bbcb65040c392a7aa7b564c62af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94bddb7f5ec4b33967a5898d30fac80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e082766ee24def9f1fb05a6a7f3dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457fb60f90cb4433b86e031d30927ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e4ee25a6fde4699b6c23d8e59c04cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cf407f27ec4098b03ca61222ce20ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eefe6a34b3924a8b8e00f6b0b815bc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f04643a6a846569e9d247d76c76709",
              "IPY_MODEL_9c0e63695901421cb091a576a5f6e1a8",
              "IPY_MODEL_3e4ef2f1b0624d19bcde8997225d16ee"
            ],
            "layout": "IPY_MODEL_980037e5c43342fdbec3929c7f74d915"
          }
        },
        "89f04643a6a846569e9d247d76c76709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdde2723b5454f2ca016af3a0e38566c",
            "placeholder": "​",
            "style": "IPY_MODEL_670788c274ad4daba4dacd7c6890bb2d",
            "value": "config.json: 100%"
          }
        },
        "9c0e63695901421cb091a576a5f6e1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f46853d35824e918b3fc73b3a9de56b",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bca974e87c8f4c45980e1d3df527c388",
            "value": 425
          }
        },
        "3e4ef2f1b0624d19bcde8997225d16ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a773eae1a644d8b447b4a4695535f7",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdce5eead644dacbe5e141dfdd21ac9",
            "value": " 425/425 [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "980037e5c43342fdbec3929c7f74d915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdde2723b5454f2ca016af3a0e38566c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670788c274ad4daba4dacd7c6890bb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f46853d35824e918b3fc73b3a9de56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca974e87c8f4c45980e1d3df527c388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78a773eae1a644d8b447b4a4695535f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdce5eead644dacbe5e141dfdd21ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77d79972ac1b4812ac705fc40712492c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bcba738d2a54b4cb0e8f75f9351da65",
              "IPY_MODEL_08bfa423587e46e5804e7e37f1f2b989",
              "IPY_MODEL_d631698f5f7e4084907eee87ae0e07ae"
            ],
            "layout": "IPY_MODEL_0c00f2838ad34863a27716d22c571d28"
          }
        },
        "2bcba738d2a54b4cb0e8f75f9351da65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cdd98a5e3b4508940c478bdd522e35",
            "placeholder": "​",
            "style": "IPY_MODEL_23d9778c842e44bdb76a66be32ab97e4",
            "value": "model.safetensors: 100%"
          }
        },
        "08bfa423587e46e5804e7e37f1f2b989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf47e55edf4a4111b242b3ed6390f156",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0804b796d9834043a13d807aeb961d26",
            "value": 445000316
          }
        },
        "d631698f5f7e4084907eee87ae0e07ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0163dcf8bd5469fb0bef99cc5abc336",
            "placeholder": "​",
            "style": "IPY_MODEL_09a21be481c64a6a882170c93c7497bd",
            "value": " 445M/445M [00:02&lt;00:00, 119MB/s]"
          }
        },
        "0c00f2838ad34863a27716d22c571d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cdd98a5e3b4508940c478bdd522e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d9778c842e44bdb76a66be32ab97e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf47e55edf4a4111b242b3ed6390f156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0804b796d9834043a13d807aeb961d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0163dcf8bd5469fb0bef99cc5abc336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a21be481c64a6a882170c93c7497bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/%5BK_MHAS%5D_HuggingFace_dataset_MultiBERT_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the K-MHaS dataset from [HuggingFace](https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech) and checking meta information (published @COLING2022)\n"
      ],
      "metadata": {
        "id": "4Lyor-OIrwd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets fsspec -y\n",
        "!pip install datasets==3.2.0 fsspec[http]==2024.9.0\n"
      ],
      "metadata": {
        "id": "WMoJHDlhbklf",
        "outputId": "53b98920-a39e-422f-deba-0aaa978e5cb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.10.0\n",
            "Uninstalling fsspec-2024.10.0:\n",
            "  Successfully uninstalled fsspec-2024.10.0\n",
            "Collecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec==2024.9.0 (from fsspec[http]==2024.9.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "outputId": "4f1cf07b-c25b-4b05-f016-f90ce9c04799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "outputId": "49cf6e4e-ec1a-4379-adf3-4903def26373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "dbc9ca1c89fc4ff7976aae19531655c7",
            "920a4c091b274fbea972bb6389e9f107",
            "c2dcf1e9dced4dceb4043268b716c095",
            "72cafa78f4f046088e253434d0d7c250",
            "81f9a0b9f33b4edbb05a0f058d1e2a9a",
            "20a84b48c7044315a055ace5453fe2e1",
            "2c2f9de00e8b4f2eb25010203bd3d536",
            "9163e63613f24374910a35936f236832",
            "0ae6b53d666f4c8ebd68bfb1074751df",
            "8a4c5dfcdb3e4c9eb910d7a3d055468e",
            "879d29e6e66444bfa89a74f8877cfa48",
            "d1683d36dbc64a7ea420a57b87f242fc",
            "14fbfb8903de4269a05a20d2b0e3c762",
            "0a6fb321c8444faaabcc45076d6fd040",
            "38d54750cf194e50b8d2e8f41bb094b0",
            "6539f842ef534068be4c7c051eb7366b",
            "9dde5ff71a354c1fabaad7ce9a855117",
            "dc1c880a0f7b47d98540ffd424bea47f",
            "a5c443f12fa644489527b4a8967af799",
            "d237d77670494f77839b983d92e43e47",
            "4e54488dcda9493a9bd509381991a4c1",
            "9a9d16792aa942978301250ad7e2f0db",
            "964943c1797b415e9120e8c04ff038a6",
            "93f8be103de54eab953255281b78e31b",
            "d05d59fe6eee4368b5f7cd8cafd72d75",
            "608a71e3f2264fe9af5f70cfa8ef9a4b",
            "cec0ed6846cd416d88a4a9ac0b72894a",
            "977fb9474d6742ad81bc6ddf687f02b3",
            "e037fcd4b82a4cd1892d3dd4e749a693",
            "a7446c9abec04a728a8c63c5ee419797",
            "8552fb6096e44acf8a6b5148d829bf92",
            "86c264cde1bf4984b13e24e7641c7115",
            "22f363868faa4d69acaba559bcb69c3c",
            "c03e0442b7e2458ea1a67942f3778bfa",
            "27f82a790cb549c3843eaca879bb7b07",
            "0304038c148b4c659f0736de4d0b0467",
            "87ee99cd4f8e40258efd22f60bfb169c",
            "449dbf375f6f46d6bba69691b4a8ed5d",
            "a489feb8de3e460191cbba0adfa3f45d",
            "eb61bfe360164535920bc24cce2a820f",
            "2778847e889049029123a13d94fcf2f3",
            "f5da80f6bb8940ceb1d38f37bd9b1ac5",
            "3da51434bbb64bb08546866e88d8afd8",
            "f52f422e3e684eb184e939c1cff46c91",
            "8988f0ed6e604a698222ed36a40723b8",
            "5a133afa115b480aac0e3dd6916500a1",
            "ff3e5294383944bb8e69f6e6bc1ffc47",
            "acff041d53c845d884729da8bdafde7a",
            "24e57a15ebc7434f9733499d94884dc5",
            "99101716c6f044db9b0e2285734a2df9",
            "da571b148e244631a0233adf3e75624f",
            "88d54cd571064dcdb4a92599447edfbf",
            "7c9b8322db824b46b4d2ca2632094cf6",
            "a3d1e02498bd41839b4b1c0bc901285e",
            "e759807a94b84202b0a1fff08aa01023",
            "2d821363b7844bf79d892d0a45fba48e",
            "b2f3070ac96347b9adaf1998bc13d4c0",
            "16d14344da17438d90724fa96a75ff97",
            "79e47fdc0c894255bc8f384d45a15f1f",
            "35ec7436d9f540b5ba5f1282b2af014f",
            "3582e497b3db4eb48d04c8e98812ffe0",
            "eaf39abd322e4f43b165ee3e34c55783",
            "4a4ec03d95f64b0d854d91f3bd317f35",
            "6ed4860a25cf4581991ffe4fed4bf2de",
            "e06d362d1eae4a4db026ee2f0412581f",
            "2482fb8c6b60481c8fa3399a332f5cf7",
            "572827a2045f497cb1ceea0b18bc994b",
            "149aacf311bd4d239a587e41e8e4fc61",
            "482ab4e36d67430b879d930bf9ac2eae",
            "eedac08ca1084056910f71fc6c78a274",
            "f46ee324226840d9b0e910e29439fbf7",
            "f8c11455e20f43daad06a3dc2573582a",
            "5222d4a5d54b46e1ab5fd451e86db76d",
            "d5884795388c438887e7666cd9054a85",
            "5b071801c1314cb2acdf68400af1d1d2",
            "8c73062ea5724f90aa415b326ca43e9c",
            "d63b4e7349a14a7ca7a3d45b87b18ea1",
            "df558f6459e94efcb90677883b2ffcb8",
            "fbce1eeb83f34661b975d4f71e815447",
            "6a255b83744b4a09ace3d7e8f5e754e4",
            "eaa3e788ffd94aad8f9fb4c3ad83cb6b",
            "4c7a0b5d91144071b7e46eeb686a2659",
            "e8d92035c7f94b08a02ca8bf1ca4ba32",
            "06757748368d4ea1965a4362429e91ca",
            "2aa0e4f430f44fcda33fc615cd7989ad",
            "51c342ea011943568317aec41a0eed2f",
            "97a5478c2daf4850bd036c72e80a2942",
            "a0c641699800475ab7a638303044e20d"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbc9ca1c89fc4ff7976aae19531655c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "kmhas_korean_hate_speech.py:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1683d36dbc64a7ea420a57b87f242fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "964943c1797b415e9120e8c04ff038a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "default/validation/0000.parquet:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c03e0442b7e2458ea1a67942f3778bfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8988f0ed6e604a698222ed36a40723b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d821363b7844bf79d892d0a45fba48e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "572827a2045f497cb1ceea0b18bc994b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df558f6459e94efcb90677883b2ffcb8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "be82a12f-31e1-472f-cff1-f30b24fb3685"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "049c3346-ae92-41e5-d53f-c5dd8af174a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "0075612e-aa93-4da0-95d6-6e20c101b2f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meta information\n",
        "\n",
        "print(dataset.info.description)\n",
        "print(dataset.info.homepage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AveWSDOj88",
        "outputId": "cc999361-9b39-44b7-ecd2-6f1d6ce7a9ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\n",
            "The fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.\n",
            "\n",
            "https://github.com/adlnlp/K-MHaS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bsDpBwOxPx",
        "outputId": "8df7f654-1f6f-4232-9827-85ee0a0b7853"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@inproceedings{lee-etal-2022-k,\n",
            "    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n",
            "    author = \"Lee, Jean  and\n",
            "      Lim, Taejun  and\n",
            "      Lee, Heejun  and\n",
            "      Jo, Bogeun  and\n",
            "      Kim, Yangsok  and\n",
            "      Yoon, Heegeun  and\n",
            "      Han, Soyeon Caren\",\n",
            "    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n",
            "    month = oct,\n",
            "    year = \"2022\",\n",
            "    address = \"Gyeongju, Republic of Korea\",\n",
            "    publisher = \"International Committee on Computational Linguistics\",\n",
            "    url = \"https://aclanthology.org/2022.coling-1.311\",\n",
            "    pages = \"3530--3538\",\n",
            "    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare data from train, validation, and test dataset\n",
        "- Multi-label is converted to multi-label one hot encodding\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin\n",
        "          1: physical\n",
        "          2: politics\n",
        "          3: profanity\n",
        "          4: age\n",
        "          5: gender\n",
        "          6: race\n",
        "          7: religion\n",
        "          8: not_hate_speech"
      ],
      "metadata": {
        "id": "qqO0w2cKsjN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fykcu8FKZiOI",
        "outputId": "333620c1-c23b-4cbf-9a3a-9ceb74088161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "-IczFOCZZfvx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "id": "A5Jq_uiYcIWM",
        "outputId": "1645835b-6bea-481f-866f-35f87a237059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "0c85fefc0387404a9d3d2b638869de16",
            "20f31647753b496e92356e2946788f84",
            "ca67d6408f974a6296cc3de9a85c8b39",
            "4cb556b7c1c942119a7f814f78697899",
            "aa8f387696a543c4a07f519aaa4e3549",
            "879e324249b8444cbe08e42549eaf606",
            "2b7123357c124f46807eb5e333798166",
            "99deef2c523146a2b81b5061be1af6c1",
            "1db05e87413949b8acd069857a395c15",
            "60f7b01b33f746e0a249f5fcfac3be45",
            "b09cd4c4ac5946f4a2825ca95cec7860"
          ]
        },
        "outputId": "42e2fac6-93bb-4fa8-e6f8-8d8a78e5df4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c85fefc0387404a9d3d2b638869de16"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, validation, and test dataset from HuggingFace\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding masking (able to remove this step depending on the model)\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multi-label to multi-label binary (one hot encoding)\n",
        "# [8] -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-xu24pnaxek",
        "outputId": "a0022d8d-d22b-46da-9731-db317fc27d6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그만큼 길예르모가 잘했다고 보면되겠지 기대되네 셰이프 오브 워터 [SEP]',\n",
              " '[CLS] \"1. 8넘의 문재앙\" [SEP]',\n",
              " '[CLS] \"문재인 정권의 내로남불은 타의 추종을 불허하네. 자한당 욕할거리도 없음.\" [SEP]',\n",
              " '[CLS] \"짱개들 지나간 곳은 폐허된다 ㅋㅋ\" [SEP]',\n",
              " '[CLS] 곱창은 자갈치~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "23eaf053-ebb3-406f-a3e6-d95dd480c09c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for Pytorch"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing : bert-base-multilingual-cased\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)"
      ],
      "metadata": {
        "id": "VKYP2VNkR-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "3155474e44aa4deca90de1f7e847e111",
            "ccdeb411067d4cd790e306c938b79783",
            "44e1e262ebf74ca2a0d88e1049b471c0",
            "6dcc3d95e83249479b01780a0c0278f9",
            "f1967cef57464988963aa53729ca9002",
            "83fa3e5bf0844e37a975455608f4aa25",
            "1694b1385754431a9873a7417de12eab",
            "9f9dec8193c0463a949fac5a84395e5e",
            "1cfcf7bbccdc40f5b64f6abb272b4bdd",
            "970262c304c247efbf5be781e82d94a9",
            "30bafde4bfd14bd9877646c73d61e6af",
            "24b841d12bd34bfebfe0f9627a2c5cb2",
            "5c6f2d54b12147c09f101f8c8e9230cf",
            "d8fb9fa49a2a479aa05c2b31afbe8ee3",
            "29e71004a125406f837f461340031e05",
            "17d5b34f21544bfeb8b76588c8ce60cc",
            "244b8ae6f7bd4366a6259cf59b9aa15e",
            "59ae442bfb224cf08eb70498852da889",
            "eab744e8f06e489d8c952a7946b483f6",
            "e290e4769cc84437b212fb2253a2780a",
            "66c9ef84e15841fbb17b77a0d6b34b44",
            "9ff94128c03f4d36b83bb9d137f7de41",
            "e3bdfe503a984a26bf02000aa4efd4dd",
            "5edc21c3169b445c9691987d70dd719a",
            "77e8bafc033f4561b7817ab8f703043b",
            "5d81bc31507e40db964fe2cefa0ec1b1",
            "ad31bb6d9db24e0f97032aa22f60eaa4",
            "588247e5a2e24186bf0ab16af283f7ee",
            "c5fa160c502044ea991bdd7fa71601ee",
            "10e05738fb774e38adbc6347183427dc",
            "5e9ec652a27347898cc62a3e1bdcb0a2",
            "5c1ecac9619b47a5a0c3e948bf6301c2",
            "bcaece7affb94c1cbef7e5cd5755c5d0",
            "1be2ab138d914e9eaf266cc7a5b215e8",
            "c450e71047494c9b9662e148d5858b59",
            "020d38200d25449793ef8efdd1ea90aa",
            "43dd39eaed724c478a60e0be65cd061c",
            "f48d9030a9b94c64b6381b372bd712c7",
            "672c6bbcb65040c392a7aa7b564c62af",
            "c94bddb7f5ec4b33967a5898d30fac80",
            "d2e082766ee24def9f1fb05a6a7f3dba",
            "457fb60f90cb4433b86e031d30927ea9",
            "7e4ee25a6fde4699b6c23d8e59c04cb8",
            "87cf407f27ec4098b03ca61222ce20ed",
            "eefe6a34b3924a8b8e00f6b0b815bc77",
            "89f04643a6a846569e9d247d76c76709",
            "9c0e63695901421cb091a576a5f6e1a8",
            "3e4ef2f1b0624d19bcde8997225d16ee",
            "980037e5c43342fdbec3929c7f74d915",
            "cdde2723b5454f2ca016af3a0e38566c",
            "670788c274ad4daba4dacd7c6890bb2d",
            "9f46853d35824e918b3fc73b3a9de56b",
            "bca974e87c8f4c45980e1d3df527c388",
            "78a773eae1a644d8b447b4a4695535f7",
            "dbdce5eead644dacbe5e141dfdd21ac9"
          ]
        },
        "outputId": "fcc32a2b-fcff-4ffd-b58a-337e03f21b3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3155474e44aa4deca90de1f7e847e111"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24b841d12bd34bfebfe0f9627a2c5cb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bdfe503a984a26bf02000aa4efd4dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1be2ab138d914e9eaf266cc7a5b215e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eefe6a34b3924a8b8e00f6b0b815bc77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks\n"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('testset size:', len(test_labels))\n",
        "print('trainset size:', len(train_labels))\n",
        "print('validset size:', len(validation_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "ae6de24f-6ac4-4279-b8b6-cb5f87b49377"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset size: 21939\n",
            "trainset size: 78977\n",
            "validset size: 8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-BERT model"
      ],
      "metadata": {
        "id": "pXGKAsSXut0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setting"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfq1f2Y3Yhck",
        "outputId": "6457fb1a-bb2b-4d14-ae66-15b5c10781a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "f6e65466-dfc9-49bd-875c-f26e037b2806"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setting"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936,
          "referenced_widgets": [
            "77d79972ac1b4812ac705fc40712492c",
            "2bcba738d2a54b4cb0e8f75f9351da65",
            "08bfa423587e46e5804e7e37f1f2b989",
            "d631698f5f7e4084907eee87ae0e07ae",
            "0c00f2838ad34863a27716d22c571d28",
            "08cdd98a5e3b4508940c478bdd522e35",
            "23d9778c842e44bdb76a66be32ab97e4",
            "bf47e55edf4a4111b242b3ed6390f156",
            "0804b796d9834043a13d807aeb961d26",
            "a0163dcf8bd5469fb0bef99cc5abc336",
            "09a21be481c64a6a882170c93c7497bd"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "7bacc8c2-7e21-4f83-c25a-fc2c5ebab95f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77d79972ac1b4812ac705fc40712492c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "# change epochs for improving results (our paper : epochs = 4)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "yO_GNYxCSYfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b169d4c4-8072-416b-f564-0f5ae4147aa7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming_loss': hamming}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFH3QM6ctmP",
        "outputId": "31525220-5836-44cc-fe3f-53885b326162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:36,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:37.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [15:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:15:59.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:21,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.1362\n",
            "  Training epcoh took: 0:26:23\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0863\n",
            "  Training epcoh took: 0:26:33\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0641\n",
            "  Training epcoh took: 0:26:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:44.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:06,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:29.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0499\n",
            "  Training epcoh took: 0:26:31\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "PXTAMK1sc0Sq",
        "outputId": "ed123a8b-6629-4cf9-9602-6214ec84620a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n",
            "Hamming Loss: 0.0360\n",
            "Validation took: 0:00:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "\n",
        "# torch.save(model.state_dict(), path+\"BERT_model.pt\")"
      ],
      "metadata": {
        "id": "sdghDBnXdYlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "path = '/content/model/'\n",
        "#torch.save(model.state_dict(), path+\"BERT_multilabel_model.pt\")\n",
        "model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "ad416117-3eff-4b0c-a2d1-4898f04c756e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d28ce5f3d4a8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "sgx14gm68ElU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "for batch in validation_dataloader:\n",
        " batch = tuple(t.to(device) for t in batch)\n",
        " b_input_ids, b_input_mask, b_labels = batch\n",
        " with torch.no_grad():\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " logits = outputs[0]\n",
        " logits = logits.detach().cpu().numpy()\n",
        " label_ids = b_labels.to('cpu').numpy()\n",
        " for b in logits:\n",
        "  accum_logits.append(list(b))\n",
        " for b in label_ids:\n",
        "  accum_label_ids.append(list(b))\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))"
      ],
      "metadata": {
        "id": "1jqF9y4E7YjT",
        "outputId": "cf18cc10-509e-4cd9-c4de-851e02c4514b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "accum_results = []\n",
        "accum_results.append(list(results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "5226812c-3752-4d94-8503-350f86408c23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:20,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    686.    Elapsed: 0:00:20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "201it [00:40,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    686.    Elapsed: 0:00:41.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "301it [01:00,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    686.    Elapsed: 0:01:01.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "401it [01:21,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    686.    Elapsed: 0:01:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [01:41,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    686.    Elapsed: 0:01:42.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "601it [02:01,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    686.    Elapsed: 0:02:02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "686it [02:19,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down evaluation"
      ],
      "metadata": {
        "id": "lInDyL-9hjhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_labels):\n",
        "    ith_label_ids, ith_logits = [], []\n",
        "\n",
        "    for j, labels in enumerate(accum_label_ids):\n",
        "        if len(np.where(labels)[0]) == i+1:\n",
        "            ith_label_ids.append(accum_label_ids[j].tolist())\n",
        "            ith_logits.append(accum_logits[j].tolist())\n",
        "\n",
        "    ith_label_ids = np.array(ith_label_ids)\n",
        "    ith_logits = np.array(ith_logits)\n",
        "\n",
        "    if len(ith_label_ids) == 0 and len(ith_logits) == 0:\n",
        "        continue\n",
        "\n",
        "    results = multi_label_metrics(ith_logits, ith_label_ids)\n",
        "    accum_results.append(list(results.values()))\n",
        "\n",
        "    print('# of labels:', i+1)\n",
        "    print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "    print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "    print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "    print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "    print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "    print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uVtTwWhnHy",
        "outputId": "20dbc434-b41c-4d14-a69c-cb949ec53aa9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer,\n",
        "device=0, max_length=10,\n",
        " return_all_scores=True, function_to_apply='sigmoid')\n",
        "result = pipe('틀니들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)\n",
        "label_dict = {'LABEL_0' : '출신차별', 'LABEL_1' : '외모차별', 'LABEL_2' : '정치성향차별', 'LABEL_3': '혐오욕설', 'LABEL_4': '연령차별', 'LABEL_5': '성차별', 'LABEL_6' : '인종차별', 'LABEL_7': '종교차별', 'LABEL_8': '해당사항없음'}\n",
        "def prediction(text):\n",
        " result = pipe(text)\n",
        " return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]\n",
        "prediction('틀니들은 왜 그렇게 민폐를 끼치냐?')"
      ],
      "metadata": {
        "id": "798meQSe6c-Y",
        "outputId": "94f72f70-150e-4589-883b-d0b15c1cec4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "def predict_labels(text, model, tokenizer, label_names, threshold=0.1):\n",
        "    # 텍스트를 모델의 입력 형식으로 인코딩\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 10,\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 모델을 사용하여 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    # 예측 결과에서 확률 추출\n",
        "    logits = outputs.logits\n",
        "    #print(logits)\n",
        "    probs = sigmoid(logits)\n",
        "    #print(probs)\n",
        "\n",
        "    # CPU로 이동 후 numpy 배열로 변환\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    #print(probs)\n",
        "\n",
        "    # 예측된 레이블 결정\n",
        "    predicted_labels = [label_names[i] for i in range(len(label_names)) if probs[0][i] >= threshold]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "2FStXOPPcqnO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"늙은 천주교 신자들은 다 속물이다\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "t18ZXNVec82c",
        "outputId": "03c077fc-2d9e-46a5-ee29-1a3898bfbc64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 늙은 천주교 신자들은 다 속물이다 & Predicted labels: ['연령차별', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1\n",
        "text = \"못생긴 경상도 여자들은 나가라\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} -> Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "Q4wfueAfdARU",
        "outputId": "66b7787f-05ef-4aa0-f41f-d37cf583c769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 못생긴 경상도 여자들은 나가라 -> Predicted labels: ['출신차별', '외모차별', '성차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LV_-RJXdR5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VSCode 쪽 코드 (receive_data.py)\n",
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "xCHlbhrqdDuu",
        "outputId": "dfab927a-95c7-4912-c8ac-f2abdd2b3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1b184333c58d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/./content/model/attention_scores.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutputs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('문재앙')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f-0wLH1NexAK",
        "outputId": "04a688d7-36e6-4da8-d4bf-ce2445731148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.007721984758973122}, {'label': 'LABEL_1', 'score': 0.0032311684917658567}, {'label': 'LABEL_2', 'score': 0.985312283039093}, {'label': 'LABEL_3', 'score': 0.005993321072310209}, {'label': 'LABEL_4', 'score': 0.0053891874849796295}, {'label': 'LABEL_5', 'score': 0.002821417059749365}, {'label': 'LABEL_6', 'score': 0.0012292619794607162}, {'label': 'LABEL_7', 'score': 0.002137931529432535}, {'label': 'LABEL_8', 'score': 0.007046678103506565}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = \"cpu\"\n",
        "\n",
        "# 모델을 CPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, max_length=10, return_all_scores=True)\n",
        "\n",
        "result = pipe('깜둥이들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PmW6CiNigW55",
        "outputId": "58a9ebda-049b-4f56-a0a1-df64cdc26632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.14709047973155975}, {'label': 'LABEL_1', 'score': 0.26493778824806213}, {'label': 'LABEL_2', 'score': 0.026825927197933197}, {'label': 'LABEL_3', 'score': 0.03060534968972206}, {'label': 'LABEL_4', 'score': 0.08758819103240967}, {'label': 'LABEL_5', 'score': 0.09902970492839813}, {'label': 'LABEL_6', 'score': 0.8641231060028076}, {'label': 'LABEL_7', 'score': 0.14547504484653473}, {'label': 'LABEL_8', 'score': 0.11148741096258163}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "lEvK_zHWgiKj",
        "outputId": "40027b4f-3050-491a-a215-f6dd0a5aaefd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ㅅ발 천주교도들은 너무 말이 많아 & Predicted labels: ['혐오욕설', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = '/home/jyhan/HW-output-files/example.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "NH4-k_-Zgp5L",
        "outputId": "1675b92e-3162-4d6f-8956-2b22a852f997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file /home/jyhan/HW-output-files/example.txt does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def pickle_to_text(pickle_file_path, text_file_path):\n",
        "    # 피클 파일 불러오기\n",
        "    with open(pickle_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 텍스트 파일로 저장하기\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        for sublist in data:\n",
        "            # 각 서브리스트를 반복하고 숫자를 문자열로 변환하여 저장\n",
        "            for number in sublist:\n",
        "                f.write(f\"{number} \")\n",
        "            f.write(\"\\n\\n\\n\")  # 각 서브리스트 끝에 줄바꿈 추가"
      ],
      "metadata": {
        "id": "OpUp0tFHhvQQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def tanh_new(x) :\n",
        "    result = (F.tanh(x) + 1) /2\n",
        "    return result"
      ],
      "metadata": {
        "id": "_c7Qzz8DhxOh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number(num):\n",
        "    \"\"\"숫자를 7비트 2의 보수 형식으로 인코딩하는 함수, 음수 소수 부분을 고려\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = abs(num - int_num)\n",
        "\n",
        "    # Round integer part towards zero if num is negative and has a fractional part\n",
        "    if num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num = int_num - 1  # Round integer part one more negative\n",
        "            frac_num = 1 - frac_num  # Subtract fractional part from 1 to make it positive\n",
        "\n",
        "    # Clamp the values to fit within the 7-bit range\n",
        "    if int_num < -64:\n",
        "        int_num = -64\n",
        "    elif int_num > 63:\n",
        "        int_num = 63\n",
        "\n",
        "    # Apply 2's complement if the number is negative\n",
        "    if int_num < 0:\n",
        "        int_num = (1 << 7) + int_num  # 1 << 7 is 128, representing the range of 7-bit integers\n",
        "\n",
        "    # Format the number into 7-bit binary\n",
        "    int_part_bin = format(int_num & 0b1111111, '07b')  # Only the last 7 bits are used\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = int_part_bin + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "4RMAodqch2WA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_input(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number(num) for num in numbers]"
      ],
      "metadata": {
        "id": "_sD86m8Zh5dr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools"
      ],
      "metadata": {
        "id": "6TPxkyv6h-nI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number_output(num):\n",
        "    \"\"\"숫자를 3비트 정수와 13비트 소수 형식으로 인코딩하는 함수, 값은 0부터 1 사이의 양수\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Clamp the values to fit within the 0 to 1 range\n",
        "    if num < 0:\n",
        "        num = 0\n",
        "    elif num > 1:\n",
        "        num = 1\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = num - int_num\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = '000' + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jYW_te9oh_oY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_output(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number_output(num) for num in numbers]"
      ],
      "metadata": {
        "id": "5a7CeXJmh_p6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.0301, 0.0112, 0.0040, 0.7632, 0.0040, 0.0072, 0.0068, 0.8885, 0.0117]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "FFeQcYAWiMA8",
        "outputId": "4a9eecf1-be85-4ce2-eebf-24ba23e57a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000_0000011110110', '000_0000001011011', '000_0000000100000', '000_1100001101100', '000_0000000100000', '000_0000000111010', '000_0000000110111', '000_1110001101110', '000_0000001011111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [-3.0061, -4.5561, -3.7781, -4.6988, -1.8251, -4.0483, -4.8075,  4.6085, -5.1693]\n",
        "encoded_numbers = encode_numbers_input(probs)\n",
        "print(encoded_numbers)\n",
        "\n",
        "probs = [0.0472, 0.0104, 0.0224, 0.0090, 0.1388, 0.0172, 0.0081, 0.9901, 0.0057]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "W-j1Du8UiEQp",
        "outputId": "5ba2d29f-010b-4dc7-a083-5b4aa76dac6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1111100_1111111001110', '1111011_0111000110100', '1111100_0011100011001', '1111011_0100110100011', '1111110_0010110011000', '1111011_1111001110100', '1111011_0011000101000', '0000100_1001101111000', '1111010_1101010010101']\n",
            "['000_0000110000010', '000_0000001010101', '000_0000010110111', '000_0000001001001', '000_0010001110001', '000_0000010001100', '000_0000001000010', '000_1111110101110', '000_0000000101110']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin, decimal_part_bin = encoded.split('.')\n",
        "\n",
        "    # Integer part processing\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # Negative number (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # Positive number\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # Fractional part processing\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # Adjust for negative numbers\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the function with provided values\n",
        "encoded_values = [\n",
        "    \"0000000.0101010000101\",\n",
        "    \"0000000.0010111100000\",\n",
        "    \"0000000.0010110110000\",\n",
        "    \"0000000.0010001111011\",\n",
        "    \"0000000.0010001101110\",\n",
        "    \"0000000.0001110010000\",\n",
        "    \"0000000.0001100000110\",\n",
        "    \"0000000.0000000000010\",\n",
        "    \"1111111.1101100010111\",\n",
        "    \"1111111.1101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "kzwvRVHhiM6-",
        "outputId": "87f403af-2f96-487f-d532-346fc79d999f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3287353515625,\n",
              " 0.18359375,\n",
              " 0.177734375,\n",
              " 0.1400146484375,\n",
              " 0.138427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " -0.1534423828125,\n",
              " -0.1597900390625]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    # 입력 문자열을 반으로 나누어 정수 부분과 소수 부분으로 분리\n",
        "    mid_index = len(encoded) // 2\n",
        "    int_part_bin = encoded[:mid_index]\n",
        "    decimal_part_bin = encoded[mid_index:]\n",
        "\n",
        "    # 정수 부분 처리\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"00000000101010000101\",\n",
        "    \"00000000010111100000\",\n",
        "    \"00000000010110110000\",\n",
        "    \"00000000010001111011\",\n",
        "    \"00000000010001101110\",\n",
        "    \"00000000001110010000\",\n",
        "    \"00000000001100000110\",\n",
        "    \"00000000000000000010\",\n",
        "    \"11111111101100010111\",\n",
        "    \"11111111101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "Fy0SQbOSiad-",
        "outputId": "58c9d2d5-64d7-40f1-8e26-e8b720de1731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0787353515625,\n",
              " 1.05859375,\n",
              " 1.052734375,\n",
              " 1.0150146484375,\n",
              " 1.013427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " 894.0965576171875,\n",
              " 894.0902099609375]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    if int(int_part_bin, 2) & (1 << 2):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 3)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0001000101001100\",\n",
        "    \"0000011001010100\",\n",
        "    \"0000000111011100\",\n",
        "    \"0000000111010100\",\n",
        "    \"0000000110110100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000011010100\",\n",
        "    \"0000000001100100\",\n",
        "    \"0000000001010100\",\n",
        "    \"0000000001000100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for encoded, decoded in zip(encoded_values, decoded_values):\n",
        "    print(f\"Encoded: {encoded} -> Decoded: {decoded}\")"
      ],
      "metadata": {
        "id": "i6y3VbyOiiIq",
        "outputId": "d18ed430-6ee4-45cf-de99-3c19ce9fc963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: 0001000101001100 -> Decoded: 0.54052734375\n",
            "Encoded: 0000011001010100 -> Decoded: 0.19775390625\n",
            "Encoded: 0000000111011100 -> Decoded: 0.05810546875\n",
            "Encoded: 0000000111010100 -> Decoded: 0.05712890625\n",
            "Encoded: 0000000110110100 -> Decoded: 0.05322265625\n",
            "Encoded: 0000000100000100 -> Decoded: 0.03173828125\n",
            "Encoded: 0000000011010100 -> Decoded: 0.02587890625\n",
            "Encoded: 0000000001100100 -> Decoded: 0.01220703125\n",
            "Encoded: 0000000001010100 -> Decoded: 0.01025390625\n",
            "Encoded: 0000000001000100 -> Decoded: 0.00830078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "\n",
        "    # 리스트를 문자열 형식으로 변환\n",
        "    formatted_hex_list = \"[\" + \", \".join(f'\"{hex_value}\"' for hex_value in hex_list) + \"]\"\n",
        "\n",
        "    return formatted_hex_list\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"06dc 05c4 0494 03c4 039c 02e4 017c 0144 00e4 00ac\"\n",
        "formatted_hex_list = format_hex_input(hex_input)\n",
        "\n",
        "print(formatted_hex_list)"
      ],
      "metadata": {
        "id": "KiL0Vi9sikfX",
        "outputId": "11a20eaa-1053-4fff-9e76-a57406a3d9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n",
        "\n",
        "float_values = hexa_to_float(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, float_value in zip(hex_strings, float_values):\n",
        "    print(f\"{float_value}\")"
      ],
      "metadata": {
        "id": "6FquW2OFiogU",
        "outputId": "64437692-6e83-421a-acc9-3845b358764f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21435546875\n",
            "0.18017578125\n",
            "0.14306640625\n",
            "0.11767578125\n",
            "0.11279296875\n",
            "0.09033203125\n",
            "0.04638671875\n",
            "0.03955078125\n",
            "0.02783203125\n",
            "0.02099609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "    return hex_list\n",
        "\n",
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "def convert_hex_input_to_float(hex_input):\n",
        "    hex_strings = format_hex_input(hex_input)\n",
        "    float_values = hexa_to_float(hex_strings)\n",
        "    return float_values\n",
        "\n",
        "def chunk_floats(float_values, chunk_size=10):\n",
        "    # float 값을 chunk_size 크기로 분할하고 각 chunk 사이에 두 개의 엔터를 추가\n",
        "    chunked_result = \"\"\n",
        "    for i in range(0, len(float_values), chunk_size):\n",
        "        chunk = float_values[i:i + chunk_size]\n",
        "        chunked_result += \"\\n\".join(map(str, chunk)) + \"\\n\\n\"\n",
        "    return chunked_result.strip()\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"\"\"\n",
        "1404\n",
        "026c\n",
        "0234\n",
        "0214\n",
        "0184\n",
        "017c\n",
        "015c\n",
        "001c\n",
        "001c\n",
        "0004\n",
        "\"\"\"\n",
        "\n",
        "float_values = convert_hex_input_to_float(hex_input)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "chunked_result = chunk_floats(float_values)\n",
        "\n",
        "print(chunked_result)"
      ],
      "metadata": {
        "id": "w7Z4vjWsiwnS",
        "outputId": "3c58dfca-79d2-4391-b371-dae1ce3a8e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62548828125\n",
            "0.07568359375\n",
            "0.06884765625\n",
            "0.06494140625\n",
            "0.04736328125\n",
            "0.04638671875\n",
            "0.04248046875\n",
            "0.00341796875\n",
            "0.00341796875\n",
            "0.00048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0000110101000100\",\n",
        "    \"0000100000100100\",\n",
        "    \"0000001101111100\",\n",
        "    \"0000001011111100\",\n",
        "    \"0000000111000100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000001110100\",\n",
        "    \"0000000001000100\",\n",
        "    \"0000000000111100\",\n",
        "    \"0000000000110100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for decoded in decoded_values:\n",
        "    print(decoded)\n"
      ],
      "metadata": {
        "id": "8BR8NGmgi0Ny",
        "outputId": "5007fe73-fb15-4b6d-8e01-8f0754f04ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41455078125\n",
            "0.25439453125\n",
            "0.10888671875\n",
            "0.09326171875\n",
            "0.05517578125\n",
            "0.03173828125\n",
            "0.01416015625\n",
            "0.00830078125\n",
            "0.00732421875\n",
            "0.00634765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "new_hex_strings = [\"0d44\", \"0824\", \"037c\", \"02fc\", \"01c4\", \"0104\", \"0074\", \"0044\", \"003c\", \"0034\"]\n",
        "new_binary_strings = hexa_to_binary(new_hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(new_hex_strings, new_binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "1W-StNJci3XU",
        "outputId": "a05245c4-c9b1-4bb6-f50d-33781a626908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000110101000100\n",
            "0000100000100100\n",
            "0000001101111100\n",
            "0000001011111100\n",
            "0000000111000100\n",
            "0000000100000100\n",
            "0000000001110100\n",
            "0000000001000100\n",
            "0000000000111100\n",
            "0000000000110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"069c\", \"046c\", \"045c\", \"0434\", \"02fc\", \"02a4\", \"026c\", \"01d4\", \"00e4\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")"
      ],
      "metadata": {
        "id": "xyNYFw6ki5gk",
        "outputId": "5e7147bc-284e-4384-faf7-0830c1eb0b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000011010011100\n",
            "0000010001101100\n",
            "0000010001011100\n",
            "0000010000110100\n",
            "0000001011111100\n",
            "0000001010100100\n",
            "0000001001101100\n",
            "0000000111010100\n",
            "0000000011100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "hex_strings = [\"045c\", \"0404\", \"03b4\", \"039c\", \"0374\", \"034c\", \"031c\", \"027c\", \"022c\", \"01bc\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "LCmwYD9Qi79m",
        "outputId": "2e98ba7e-cba3-4bd9-a7bc-55602c0d475e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000010001011100\n",
            "0000010000000100\n",
            "0000001110110100\n",
            "0000001110011100\n",
            "0000001101110100\n",
            "0000001101001100\n",
            "0000001100011100\n",
            "0000001001111100\n",
            "0000001000101100\n",
            "0000000110111100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error_rates(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    list of float: 각 데이터에 대한 오차율 (백분율) 리스트\n",
        "    \"\"\"\n",
        "    if len(actual_values) != len(predicted_values):\n",
        "        raise ValueError(\"실제 값 리스트와 예측 값 리스트의 길이는 같아야 합니다.\")\n",
        "\n",
        "    error_rates = []\n",
        "    for actual, predicted in zip(actual_values, predicted_values):\n",
        "        if actual == 0:\n",
        "            error_rate = 0\n",
        "        else:\n",
        "            error = actual - predicted\n",
        "            error_rate = abs((error / actual) * 100)\n",
        "        error_rates.append(error_rate)\n",
        "\n",
        "    return error_rates\n",
        "\n",
        "def calculate_average_error_rate(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 평균 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    float: 평균 오차율 (백분율)\n",
        "    \"\"\"\n",
        "    error_rates = calculate_error_rates(actual_values, predicted_values)\n",
        "    average_error_rate = sum(error_rates) / len(error_rates)\n",
        "    return average_error_rate"
      ],
      "metadata": {
        "id": "D2-wjc8yi_Ij"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용\n",
        "actual_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "predicted_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "average_error_rate = calculate_average_error_rate(actual_values, predicted_values)\n",
        "\n",
        "print(f\"최종 오차율: {average_error_rate}%\")"
      ],
      "metadata": {
        "id": "clf_RoSfjBeq",
        "outputId": "a64c4b96-f498-4d5e-dba9-b4ef00611485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 오차율: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정\n",
        "start_time = time.time()\n",
        "softmax_values = softmax(values)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Softmax output: {softmax_values}\")\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "i7BTwvyNjE92",
        "outputId": "34aa7c73-366c-430c-c8cf-847d61cf3ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output: [0.07587164 0.0910116  0.07831849 0.06958124 0.12896939 0.12623521\n",
            " 0.12722802 0.1129899  0.10400488 0.08578965]\n",
            "Execution time: 0.0046842098236083984 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정 (timeit 모듈 사용)\n",
        "execution_time = timeit.timeit(lambda: softmax(values), number=100000)\n",
        "print(f\"Average execution time over 1000 runs: {execution_time / 100000} seconds\")\n"
      ],
      "metadata": {
        "id": "I7TbeCl0jFAe",
        "outputId": "d1c34d21-a55f-4579-bad9-144d183991ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time over 1000 runs: 8.994136329999946e-06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "start_time = time.time()\n",
        "my_function()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "_Y3J9uF8jFCp",
        "outputId": "d16b08d5-bee5-4ddb-866b-a78fc3168b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0002713203430176 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "execution_time = timeit.timeit(my_function, number=1)\n",
        "print(f\"Execution time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "id": "9a5zh7itjK_1",
        "outputId": "2ec4da21-f3b1-493d-e78f-5c5ee500a4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001646370000117 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "id": "XarrC_jbjPME",
        "outputId": "82c3ebea-96f1-4ac0-dab5-960e78901f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001087188720703 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import socket\n",
        "\n",
        "# HW -> SW connect\n",
        "# This should be fixed later when connecting with hardware.\n",
        "def receive_from_hardware(host: str, port: int, buffer_size: int = 1024) -> bytes:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.connect((host, port))\n",
        "        attention_probs_hw = s.recv(buffer_size)\n",
        "    return attention_probs_hw\n",
        "\n",
        "# HW 2진수 -> SW Decode\n",
        "def decode_values(encoded_values_list: list) -> list:\n",
        "    encoded_values = tuple(encoded_values_list)\n",
        "    decoded_values = []\n",
        "\n",
        "    for encoded_value in encoded_values:\n",
        "        special_value_bit = encoded_value[0]\n",
        "        if special_value_bit == '1':\n",
        "            decoded_values.append(0.0)\n",
        "        else:\n",
        "            sign_bit = encoded_value[1]\n",
        "            sign = -1 if sign_bit == '1' else 1\n",
        "\n",
        "            integer_part = int(encoded_value[2:5], 2)\n",
        "            fractional_part = int(encoded_value[5:], 2) / (1 << 13)\n",
        "\n",
        "            decoded_value = sign * (integer_part + fractional_part)\n",
        "            decoded_values.append(round(decoded_value, 7))\n",
        "\n",
        "    return decoded_values\n",
        "\n",
        "# 1D -> 4D 변환 코드\n",
        "def convert_to_4d(input_list):\n",
        "    # Step 1: Divide the list into sublists of 10 elements each\n",
        "    sublists = [input_list[i:i + 10] for i in range(0, len(input_list), 10)]\n",
        "\n",
        "    # Step 2: Group every 10 sublists into a larger list to form a [12, 10, 10] shape\n",
        "    grouped_sublists = [sublists[i:i + 10] for i in range(0, len(sublists), 10)]\n",
        "\n",
        "    # Step 3: Convert the final list to a tensor and add an extra dimension to form [1, 12, 10, 10]\n",
        "    attention_probs_4d = torch.tensor(grouped_sublists).unsqueeze(0)\n",
        "    return attention_probs_4d"
      ],
      "metadata": {
        "id": "vh30Ck9JjWVj"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_raw_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "GEln6Bi7whyh",
        "outputId": "bb945a28-f5cc-44a6-eb12-552898c49c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/softmax_bert_layer1.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_softmax_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "YgDd7AmYGVMO",
        "outputId": "26c7570d-67c1-45bb-bc49-cee2211d6bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/softmax_bert_layer1.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "05VQ55mWooaT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import math\n",
        "attention_scores = layer_1_attention\n",
        "attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        " #Pickle 파일 저장\n",
        "if attention_mask is not None:\n",
        " # Apply the attention mask is (precomputed for all layers in BertModel\n",
        " attention_scores = attention_scores + attention_mask\n",
        " # attention_scores를 피클 파일로 저장합니다.\n",
        "attention_scores_list = attention_scores.tolist()  # torch.Tensor를 Python 리스트로 변환\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"wb\") as f:\n",
        " pickle.dump(attention_scores_list, f)\n",
        " #저장된 Pickle 파일 불러와서 plot\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        " outputs = pickle.load(f)\n",
        "out_chain3 = list(itertools.chain(*outputs))\n",
        "out_chain2 = list(itertools.chain(*out_chain3))\n",
        "out_chain1 = list(itertools.chain(*out_chain2))\n",
        "print(out_chain1)\n",
        "max_value = torch.max(attention_scores)\n",
        "min_value = torch.min(attention_scores)\n",
        "print(\"Max value in attention_scores:\", max_value.item())"
      ],
      "metadata": {
        "id": "YAV18-7XnknO",
        "outputId": "6677399f-036a-4de7-ea6f-d211165a955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b97d7302ca28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;31m#Pickle 파일 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "if2KlEtgI6bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#아무래도 진짜..코드 위에선  outputs.last_hidden_state 로 써서 12번째 레이어의 값으로 KQV 계산했을 수 있다.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        # BERT 모델의 기본 동작 수행\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # 어텐션 값 반환 활성화\n",
        "            output_hidden_states=True,  # 히든 스테이트 반환 활성화\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # 모델 설정값 가져오기\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 멀티헤드 개수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기 (64)\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        # === 첫 번째 Transformer 레이어에서 Query (Q), Key (K) 직접 가져오기 ===\n",
        "        first_layer = self.encoder.layer[0]  # 첫 번째 Transformer 레이어\n",
        "        input_tensor = outputs.hidden_states[0]  # 첫 번째 레이어 입력 (Embedding 후 결과)\n",
        "\n",
        "        # Query, Key 생성\n",
        "        Q = first_layer.attention.self.query(input_tensor)  # (1, 10, 768)\n",
        "        K = first_layer.attention.self.key(input_tensor)  # (1, 10, 768)\n",
        "\n",
        "        # === Multi-Head 형태로 변환 ===\n",
        "        # Query, Key의 shape을 (batch_size, num_heads, sequence_length, head_dim)로 변환\n",
        "        Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "        K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 계산 ===\n",
        "        raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # (1, 12, 10, 10)\n",
        "\n",
        "        return raw_attention, outputs.attentions[0]  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === 첫 번째 레이어의 Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "_beDp4MY8Ib_",
        "outputId": "8ee17bfc-a22d-4111-bb48-935ea4541144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder\n",
        "\n",
        "# === Softmax 이전 Attention Score 추출을 위한 BertSelfAttention 수정 ===\n",
        "class BertSelfAttentionWithRawScores(BertSelfAttention):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.raw_attention_scores = None  # Softmax 이전 Attention Score 저장\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        # === Query, Key, Value 생성 ===\n",
        "        mixed_query_layer = self.query(hidden_states)  # (batch, seq_len, hidden_dim)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        # === Multi-Head Attention 변환 ===\n",
        "        batch_size, seq_length, hidden_dim = hidden_states.shape\n",
        "        num_heads = self.num_attention_heads\n",
        "        head_dim = self.attention_head_size  # hidden_dim // num_heads (768/12=64)\n",
        "\n",
        "        assert hidden_dim == num_heads * head_dim  # 차원 검증\n",
        "\n",
        "        # Query, Key, Value를 (batch, num_heads, seq_len, head_dim) 형태로 변환\n",
        "        query_layer = mixed_query_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        key_layer = mixed_key_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        value_layer = mixed_value_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 저장 ===\n",
        "        self.raw_attention_scores = torch.matmul(query_layer, key_layer.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "\n",
        "        # === Softmax 적용 ===\n",
        "        attention_probs = nn.functional.softmax(self.raw_attention_scores, dim=-1)\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.transpose(1, 2).contiguous()\n",
        "        context_layer = context_layer.view(batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Softmax 이전과 이후 값 반환 (BERT 내부 연산 유지)\n",
        "        if output_attentions:\n",
        "            return context_layer, attention_probs, self.raw_attention_scores  # Softmax 이후 값, Softmax 이전 값\n",
        "        return context_layer, attention_probs\n",
        "\n",
        "# === BERT Encoder에서 Custom BertSelfAttention 적용 ===\n",
        "class BertEncoderWithRawAttention(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # 기존 BERT의 레이어를 유지하면서, BertSelfAttention을 수정한 레이어로 교체\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionWithRawScores(config)\n",
        "\n",
        "# === 새로운 BERT 모델 정의 ===\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.encoder = BertEncoderWithRawAttention(config)  # 수정된 Encoder 적용\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, inputs_embeds=None,\n",
        "                output_attentions=True, output_hidden_states=True, return_dict=True):\n",
        "\n",
        "        # BERT의 기본 forward 호출\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        softmax_attention = outputs.attentions[0]\n",
        "\n",
        "        # === Softmax 이전 Attention Score ===\n",
        "        raw_attention = self.encoder.layer[0].attention.self.raw_attention_scores\n",
        "\n",
        "        return raw_attention, softmax_attention\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name)  # 모델 설정값 로드\n",
        "model = BertWithRawAttention.from_pretrained(model_name, config=config)  # 기존 가중치 로드\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Softmax 이전 Attention Score (Shape: {raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n",
        "\n",
        "# === Softmax 이후 Attention Score 확인 ===\n",
        "layer_1_softmax_attention = softmax_attention.numpy()\n",
        "print(f\"Softmax 이후 Attention Score (Shape: {softmax_attention.shape}):\")\n",
        "print(layer_1_softmax_attention)\n"
      ],
      "metadata": {
        "id": "PtMgJMl6-cXT",
        "outputId": "957f6a04-62ac-45d9-c3f7-f5a3f87bc920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 이전 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n",
            "Softmax 이후 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[0.5283773  0.01831239 0.02925736 ... 0.02679347 0.12802093\n",
            "    0.06640536]\n",
            "   [0.00969707 0.05183908 0.5986064  ... 0.01988765 0.00858417\n",
            "    0.01232217]\n",
            "   [0.06677455 0.2186561  0.10905681 ... 0.01309194 0.03270088\n",
            "    0.01159014]\n",
            "   ...\n",
            "   [0.01616001 0.01836555 0.02567743 ... 0.06062973 0.15665187\n",
            "    0.293395  ]\n",
            "   [0.04999034 0.00646467 0.01949128 ... 0.14370786 0.06240886\n",
            "    0.5748314 ]\n",
            "   [0.06373078 0.01488702 0.0079303  ... 0.05741416 0.49397027\n",
            "    0.11359414]]\n",
            "\n",
            "  [[0.03568741 0.10874645 0.1446925  ... 0.06689178 0.05368272\n",
            "    0.2776181 ]\n",
            "   [0.01723383 0.05519805 0.20440505 ... 0.0471074  0.04940367\n",
            "    0.2604174 ]\n",
            "   [0.07099048 0.07730429 0.05898389 ... 0.10322649 0.02939613\n",
            "    0.3372574 ]\n",
            "   ...\n",
            "   [0.06292941 0.09883609 0.13758078 ... 0.06442455 0.05104246\n",
            "    0.24415724]\n",
            "   [0.03459279 0.11384704 0.10506249 ... 0.18009992 0.06478832\n",
            "    0.1407789 ]\n",
            "   [0.05027521 0.06445801 0.14809294 ... 0.08305917 0.05797384\n",
            "    0.2091557 ]]\n",
            "\n",
            "  [[0.15359114 0.00864228 0.00399939 ... 0.00729464 0.50648683\n",
            "    0.0942614 ]\n",
            "   [0.01585225 0.17893858 0.43792823 ... 0.0741822  0.00801447\n",
            "    0.0235921 ]\n",
            "   [0.03428007 0.17485864 0.2603332  ... 0.08475611 0.03304965\n",
            "    0.07450179]\n",
            "   ...\n",
            "   [0.18211858 0.05096522 0.09105611 ... 0.1072194  0.05965689\n",
            "    0.17483066]\n",
            "   [0.44636625 0.01801714 0.0315361  ... 0.02307989 0.10599701\n",
            "    0.13254708]\n",
            "   [0.2774437  0.0129694  0.00816243 ... 0.01372248 0.35479093\n",
            "    0.10288175]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.04930858 0.10154388 0.10185789 ... 0.09569554 0.05750762\n",
            "    0.3224567 ]\n",
            "   [0.08078458 0.20571339 0.11838616 ... 0.12593833 0.06177064\n",
            "    0.19960773]\n",
            "   [0.0412325  0.19937783 0.13601877 ... 0.08533785 0.09154727\n",
            "    0.2100422 ]\n",
            "   ...\n",
            "   [0.02443384 0.08015428 0.12018657 ... 0.23940288 0.14780325\n",
            "    0.14295706]\n",
            "   [0.04283044 0.12574883 0.14365427 ... 0.1160476  0.12224771\n",
            "    0.22464608]\n",
            "   [0.05391058 0.14782219 0.14016856 ... 0.11944017 0.10129216\n",
            "    0.17417422]]\n",
            "\n",
            "  [[0.7349549  0.0276535  0.02545838 ... 0.01123482 0.02285883\n",
            "    0.04455587]\n",
            "   [0.0558468  0.08621079 0.15432207 ... 0.12961587 0.02641504\n",
            "    0.15628102]\n",
            "   [0.11732682 0.11279433 0.12912983 ... 0.03815653 0.03798619\n",
            "    0.18773969]\n",
            "   ...\n",
            "   [0.02055062 0.1586586  0.10597336 ... 0.12433876 0.02345941\n",
            "    0.29404283]\n",
            "   [0.24240194 0.06169973 0.05989478 ... 0.1300937  0.02040222\n",
            "    0.04765695]\n",
            "   [0.40604973 0.03981538 0.02912593 ... 0.06234814 0.03718225\n",
            "    0.04973197]]\n",
            "\n",
            "  [[0.20841888 0.04493827 0.04335542 ... 0.02939372 0.04667228\n",
            "    0.4896042 ]\n",
            "   [0.17757389 0.65346533 0.00581406 ... 0.00351891 0.02235911\n",
            "    0.10371897]\n",
            "   [0.43387496 0.00921498 0.24637778 ... 0.01080181 0.10714414\n",
            "    0.08725781]\n",
            "   ...\n",
            "   [0.13022482 0.01199692 0.0195627  ... 0.6826026  0.04258374\n",
            "    0.03826763]\n",
            "   [0.42847222 0.1096639  0.05017955 ... 0.01391817 0.02019598\n",
            "    0.18610723]\n",
            "   [0.5374471  0.04228677 0.03523285 ... 0.02958855 0.03256983\n",
            "    0.19304997]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './model/attention_scores_2.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "Q0nZ4Onl21iB",
        "outputId": "71229106-fba1-4c96-bac1-f0616740206b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    0.11714409  0.5856975   0.6307755  -0.30920362  2.1947367\n",
            "  -0.14835791  0.49772462  2.0617602   1.4053444 ]\n",
            " [ 1.6703308   3.3466518   5.793112    4.621073    3.812749    2.3419719\n",
            "   1.8878778   2.3886065   1.5484276   1.9099072 ]\n",
            " [ 3.3168168   4.502995    3.8073637   5.2124023   2.3082643   3.0351076\n",
            "   2.4797425   1.6874914   2.6028967   1.5656495 ]\n",
            " [ 2.5718498   4.652975    6.7969666   3.8015726   5.3321524   2.659658\n",
            "   2.719986    2.416732    2.1785326   3.108758  ]\n",
            " [ 0.62522817  4.6419153   3.3077164   5.064213    3.339889    2.7762215\n",
            "   1.873533    3.4980125   2.023627    2.5917144 ]\n",
            " [ 3.9795005   2.6142015   2.2757936   2.9215946   3.511932    3.220555\n",
            "   3.0432897   2.8711824   4.3125715   4.3036885 ]\n",
            " [ 1.7959094   2.6852992   1.6750463   1.3191165   4.1721644   3.331105\n",
            "   2.4741642   4.5505824   2.6400094   3.1753776 ]\n",
            " [ 1.6387088   1.7666457   2.1017816   2.1071794   3.422982    3.3852067\n",
            "   4.2240024   2.9609547   3.9101954   4.537689  ]\n",
            " [ 3.3072975   1.2618201   2.365435    1.1282016   2.2333503   2.9970148\n",
            "   3.822887    4.3632503   3.529175    5.7495446 ]\n",
            " [ 4.5703983   3.1162205   2.4864216   3.426703    2.1799157   5.7463045\n",
            "   3.174025    4.4660215   6.618206    5.1483626 ]] [[-1.0886638e+00  2.5557250e-02  3.1114900e-01 -1.1854680e-01\n",
            "  -7.7044167e-02 -1.6976843e+00 -4.8572365e-02 -4.6038562e-01\n",
            "  -6.8037063e-01  9.6278471e-01]\n",
            " [-1.7430696e+00 -5.7901633e-01  7.3015982e-01  4.3518707e-01\n",
            "   6.1179582e-02 -1.1784676e+00 -2.2009215e-01 -7.3751372e-01\n",
            "  -6.8991911e-01  9.7234195e-01]\n",
            " [-4.3296996e-01 -3.4776625e-01 -6.1825126e-01 -5.5659747e-01\n",
            "  -2.0672473e-01 -1.1309534e+00  2.1543759e-01 -5.8590204e-02\n",
            "  -1.3146526e+00  1.1253307e+00]\n",
            " [-5.9080738e-01 -2.5380707e-01  2.4927259e-04  1.6821440e-02\n",
            "   4.5576128e-01 -2.5012723e-01  3.6733337e-02  1.4773999e-01\n",
            "  -3.3541751e-01  1.2667636e+00]\n",
            " [-1.7260594e+00 -3.7022546e-02  3.2314226e-01  9.6709438e-02\n",
            "  -2.5472367e-01 -1.5367095e+00  7.0705187e-01  6.5236461e-01\n",
            "  -1.2064693e+00  5.9022087e-01]\n",
            " [-1.2091219e+00  1.5285142e-01  3.8227442e-01  2.8489169e-01\n",
            "   3.7704596e-01 -8.5179329e-01  1.8399542e-02  4.3778053e-01\n",
            "  -4.9263728e-01  7.9981643e-01]\n",
            " [-2.8917280e-01  1.0043441e-01 -9.1151148e-02  3.6259271e-02\n",
            "   1.0675713e-01 -8.3618826e-01  2.0009780e-01  5.8339089e-01\n",
            "  -1.7491554e-01  6.0655284e-01]\n",
            " [-3.5978922e-01  9.1659956e-02  4.2240837e-01  1.1255670e-01\n",
            "  -6.4642429e-02 -1.3896195e+00  3.8931042e-01 -3.3630806e-01\n",
            "  -5.6914496e-01  9.9600965e-01]\n",
            " [-9.6181583e-01  2.2939461e-01  1.4909410e-01  1.6794282e-01\n",
            "   1.7030033e-01 -5.3991210e-01  3.4695931e-02  6.8805063e-01\n",
            "  -3.3433583e-01  4.4172931e-01]\n",
            " [-6.0645354e-01 -3.5795161e-01  4.7387433e-01  2.7014586e-01\n",
            "   2.5771543e-01 -9.0960979e-01  1.7429377e-01 -1.0441241e-01\n",
            "  -4.6397370e-01  8.1911325e-01]] [[ 2.8996303   0.02200214 -0.74852276  0.631462   -1.1275623   3.0894957\n",
            "   0.9280114  -0.14752409  4.0928345   2.411408  ]\n",
            " [ 0.5878507   3.011582    3.9065943   3.235908    0.50435984  0.34831482\n",
            "   0.17555894  2.1310635  -0.09421223  0.98545116]\n",
            " [ 0.6049058   2.2343197   2.6323042   2.430443    0.4869851   0.8571075\n",
            "   1.0000788   1.5101197   0.56835276  1.3811649 ]\n",
            " [ 1.430701    2.0099015   4.087019    3.0947237   0.56819826  0.75650877\n",
            "   0.33274144  1.465734   -0.30525357  0.9727164 ]\n",
            " [-0.3164355   1.5521222   3.0174787   1.4834703   2.2269187  -1.30088\n",
            "   1.1328936   3.5774622  -1.429762   -0.17385992]\n",
            " [ 3.4188118   0.62846535  0.07279523  0.71736014 -0.32747287  2.2898376\n",
            "   1.0576711   0.22138332  3.0749917   2.4532826 ]\n",
            " [ 1.9065028   0.88415587  1.2080953   0.14300826  0.593324    0.49050444\n",
            "   0.5708541   1.5033801   0.42657304  0.6549574 ]\n",
            " [ 2.1231966   0.84968215  1.4300145   1.3541062   1.0749373   1.852924\n",
            "   0.76707125  1.5934157   1.0071483   2.0823565 ]\n",
            " [ 3.2195091   0.0096926   0.56950235  0.23191671 -0.32239503  2.1220663\n",
            "   1.1799686   0.2573312   1.7817802   2.0053072 ]\n",
            " [ 3.912785    0.8497595   0.3867088   0.8289084   0.23973835  3.5320184\n",
            "   1.3169683   0.9062026   4.1586957   2.9207473 ]] [[-0.91819704 -0.73714244 -1.2835796  -1.3152801  -1.7907189  -2.3600693\n",
            "  -1.71575    -2.0585341  -0.88458973 -1.0391645 ]\n",
            " [ 0.76816994  2.8525796   0.98103195  1.0893993   1.291576   -0.3590138\n",
            "  -0.05392636  1.1377413  -1.1812421   0.5328254 ]\n",
            " [ 0.44077566  1.889281    1.394224    1.2403969   0.93400806 -0.6091448\n",
            "   0.37211862  1.1208864  -0.48069543  0.9152784 ]\n",
            " [-0.4079485   1.9117765   0.61145085  1.4986356   1.2874416  -0.2541298\n",
            "   0.17829615  0.8347929  -0.5898164   1.7898803 ]\n",
            " [ 0.5058691   1.6893194   0.8303908   0.35562584  1.9394354  -0.32631215\n",
            "  -0.15927449  1.2605628  -1.4803319   0.92400664]\n",
            " [ 0.47246826  1.049527    0.68996495  0.5756347   0.2827701   1.6729834\n",
            "   1.2482777   1.4437281   1.0102694   0.7912869 ]\n",
            " [ 1.2386009   1.133507    0.64457095  0.43742573  1.0146374  -0.527435\n",
            "   1.1386023   1.2811688  -0.267912   -0.3252511 ]\n",
            " [-0.6168757   0.9414549   0.6545312   0.44207764  1.0313237   0.28013933\n",
            "   0.6557309   1.4528047   0.10742482  2.0227776 ]\n",
            " [ 0.6610696   1.1441543   0.83005744  0.6699963   0.68824714  0.8841506\n",
            "   1.2305831   1.0789971   0.96978915  0.1847023 ]\n",
            " [ 0.48081017  0.5815153   0.65710616  0.34215644 -0.4203801  -1.0223608\n",
            "  -0.1397903   0.8336154   0.45186663 -0.02691434]] [[-0.4206367  -0.26431718 -0.8189321   0.5453431  -0.81877565  3.265758\n",
            "   1.123025   -0.45972508  3.0087957   4.069817  ]\n",
            " [ 1.711552    4.0104914   6.097168    4.062114    3.3517642   0.6797678\n",
            "   2.4742503   2.5503993   1.0404894   2.6415534 ]\n",
            " [ 1.6555488   2.8842583   3.6345613   2.4311733   2.4532597   1.8469099\n",
            "   1.1871887   2.1401596   2.593385    2.5239465 ]\n",
            " [ 2.897587    4.3002462   6.664719    2.8146844   4.007442    0.92588633\n",
            "   0.9355154   1.9416659   1.1508867   2.0899508 ]\n",
            " [ 1.4384526   4.5608745   3.7128031   3.3055158   2.5344577   0.3143406\n",
            "   2.7502472   3.773708    1.4212635   1.7340083 ]\n",
            " [-1.8715912   2.1050293   2.2834506   2.1121552   1.4853789   2.427682\n",
            "   3.0749145   1.8919368   3.9486756   4.785963  ]\n",
            " [ 0.63691103  1.810391    0.84790796  1.1583683   2.2992978   1.9338874\n",
            "   2.1868212   3.2546113   2.360936    3.5164182 ]\n",
            " [ 0.39985502  1.6061538   1.7325523   0.35841948  2.477663    1.037012\n",
            "   2.7054691   2.465773    1.360221    2.7568579 ]\n",
            " [-1.5197104   0.47858107  1.2087647   0.85278237  1.0399474   2.266237\n",
            "   3.0739172   2.0501065   2.4958704   4.687452  ]\n",
            " [ 3.000189   -0.7293791  -0.74419117  1.7917078   0.4763999   2.9361863\n",
            "   2.2864735   2.0922556   2.3336442   3.609223  ]] [[ 2.3518488  -2.4012413  -2.5848315  -2.5842254  -1.4390004  -1.3970611\n",
            "  -1.486853   -1.3146498  -1.5213429  -0.10409442]\n",
            " [-0.08029907  0.95492965  3.0861502   1.0803758   2.8016753   1.3075106\n",
            "   2.5004106   3.4115536   1.5283737   2.4000955 ]\n",
            " [-0.98470867  1.4555954   1.5423824   0.30919918  3.159526    1.3234267\n",
            "   2.0309644   3.8802829   0.77620506  2.2096994 ]\n",
            " [-1.3650285   1.9985721   3.1277943   0.9758086   3.153818    2.5558827\n",
            "   2.7993655   3.6075718   2.483896    3.5096714 ]\n",
            " [-0.53188324  2.7865634   2.933026    1.9947041   2.6538177   0.17108425\n",
            "   1.41041     3.5341537   0.09414454  2.1139412 ]\n",
            " [-0.05147918  2.960376    2.8401773   2.9880128   2.2146826   3.026591\n",
            "   2.6003537   2.4387147   3.1415412   3.8921413 ]\n",
            " [-0.9958864   2.6857972   2.583294    2.6029804   2.5345263   1.2893649\n",
            "   1.4581535   2.6380162   2.0204773   2.2150342 ]\n",
            " [ 0.04527869  2.9330308   3.2778075   2.720913    3.2038531   1.2107869\n",
            "   1.9810863   2.4970698   1.1165935   1.571423  ]\n",
            " [-0.23130603  2.2237506   2.6563025   2.6123178   2.1577914   2.2081223\n",
            "   2.521809    2.3261166   1.9723585   2.7725258 ]\n",
            " [ 0.2493442   3.188392    3.1076705   3.369534    2.6593766   3.4948716\n",
            "   2.873453    2.958899    3.7007978   5.390417  ]] [[ 1.8577769  -0.1782641  -0.8391258  -0.20157872  0.03677352  1.8336577\n",
            "  -0.5154236  -0.9360012  -0.36019903  2.0303364 ]\n",
            " [ 0.07594603  1.6416981   2.4703162   1.7014173   1.7434708   0.00997017\n",
            "   1.3008279   1.896263    1.5449183   1.616728  ]\n",
            " [ 0.6953787   2.1692429   2.1441464   1.7379965   2.1794832   0.00943146\n",
            "   1.3819319   2.406196    1.5149322   1.8323896 ]\n",
            " [ 1.5004507   2.191609    2.7665334   0.9322765   2.0782743  -0.32668146\n",
            "   1.5269834   2.6152775   1.2686868   2.566569  ]\n",
            " [-0.5223735   2.492464    1.484075    1.3629732   1.5521193  -0.75108665\n",
            "   1.1117117   2.8975577   1.2339579   0.7913337 ]\n",
            " [ 4.608461    2.6140327   1.6747181   1.5631702   1.1256423   2.156302\n",
            "   1.8067638   1.0583446   1.9421829   4.2106786 ]\n",
            " [ 2.443831    2.08211     1.7901441   1.5581807   2.1890495   1.9666604\n",
            "   1.4040198   2.1084352   1.0204064   2.4160697 ]\n",
            " [ 1.6170082   2.1157253   1.7847257   1.1339206   2.4702833   1.1112541\n",
            "   1.9466188   2.2814734   1.4104946   2.5419347 ]\n",
            " [ 2.5761323   1.8463246   1.4472572   1.2411208   1.1666892   1.2266266\n",
            "   2.137839    1.720331    1.3243217   2.4792182 ]\n",
            " [ 5.4560094   2.8533223   1.9060035   2.8041744   2.1872957   4.541738\n",
            "   2.3418133   2.6403146   3.3154905   5.353278  ]] [[-2.0872909e-01 -4.6765838e-02 -6.9208078e-02  2.2612049e-01\n",
            "  -5.2733558e-01 -3.8780876e-02 -3.5037673e-01 -2.4101785e-01\n",
            "  -3.8009610e-02 -4.4777170e-01]\n",
            " [ 3.9312774e-01 -7.2015625e-01 -1.1039566e-01 -4.7187504e-01\n",
            "  -6.2436187e-01 -5.5506319e-01 -6.3059740e-02  2.3725607e-01\n",
            "  -2.9921988e-01  6.7517275e-01]\n",
            " [ 9.3361211e-01 -3.0668795e-01 -1.2280265e+00 -2.3901877e-01\n",
            "   2.1531588e-01 -2.9213035e-02  1.8740971e-01  4.9287453e-01\n",
            "  -3.2362545e-01  5.3950977e-01]\n",
            " [ 4.4989973e-01 -7.8404926e-02 -7.0561624e-01 -6.7971748e-01\n",
            "  -3.2464612e-01 -2.4579277e-03  2.4341476e-01 -3.8152987e-01\n",
            "  -6.1979812e-01  6.9756246e-01]\n",
            " [ 7.5051486e-02 -3.4050646e-01 -2.0628366e-01 -3.5078533e-02\n",
            "  -2.1298897e+00 -4.6191064e-01  1.0249646e-01 -2.3292464e-01\n",
            "  -4.4878232e-01 -4.8854653e-02]\n",
            " [ 2.4236611e-01  2.4130446e-01 -1.3099633e-01  2.9947233e-01\n",
            "   2.8432137e-03  1.8978542e-01  3.0245671e-01  2.6455259e-02\n",
            "   3.2729067e-02  9.6456997e-02]\n",
            " [ 5.2392596e-01 -4.3888092e-01  6.0626990e-01 -1.6046394e-01\n",
            "  -4.5984539e-01 -4.0288302e-01 -3.4419575e-01 -3.1425059e-01\n",
            "  -3.3222637e-03 -1.9334584e-01]\n",
            " [-5.6612873e-01 -1.8855400e-01 -2.9994866e-02 -1.3156276e+00\n",
            "  -3.9713255e-01 -1.6519366e-01 -3.1032342e-01 -2.6127520e+00\n",
            "  -6.0051662e-01  4.2017855e-02]\n",
            " [ 2.3271590e-01  3.4710231e-01 -3.8753740e-02  6.4791903e-02\n",
            "  -1.9065240e-01  1.3848405e-01  6.7246199e-02 -8.6773224e-02\n",
            "   1.5828940e-01 -9.3004052e-03]\n",
            " [ 2.2022840e-01 -1.5427314e-01 -8.9312159e-02 -3.9955951e-02\n",
            "   1.0446525e-03 -2.8469656e-02 -6.6449180e-02 -6.2308647e-02\n",
            "   5.5042960e-02 -2.5045082e-01]] [[ 0.7274816   0.11507649  0.284214   -0.4026169  -0.22948742  0.5726925\n",
            "   0.7000268   0.13661313  2.2500303   2.2188106 ]\n",
            " [ 1.4019722   3.4689038   2.3157012   2.951157    1.1965826   1.1602786\n",
            "  -0.1770497   0.6572411   0.2278574   1.8796558 ]\n",
            " [ 1.2921461   0.8905095   3.709777    2.3455753   1.0153087   1.4283334\n",
            "   0.5606777   0.47134808  1.6395503   1.9080584 ]\n",
            " [ 1.8637079   3.003888    3.8354084   4.1362057   1.2275932   2.323182\n",
            "  -0.19235559  1.0532311   1.3310231   2.590262  ]\n",
            " [ 0.54005456  0.6143206   1.7547503   1.8359743   3.094353    0.6746429\n",
            "   0.2596902   1.5248697   0.47067168  1.3008693 ]\n",
            " [-0.9338605   0.5036669   0.87460697  0.45084783  0.901352   -0.10966269\n",
            "   1.9916923   1.3448064   2.0936713   0.80160993]\n",
            " [ 0.5728401  -0.04004947  0.45082232 -0.43184328  0.9820602   0.0408671\n",
            "   1.4810711   0.40630463  0.07374337  0.5373771 ]\n",
            " [ 2.0956993   0.6018912   0.6745899   0.5275235   1.8832694   0.7081071\n",
            "   1.0816227   3.1449246   0.19390348  2.3962045 ]\n",
            " [-0.3780636   0.18745206  1.7450609   0.46006605  0.8310921   0.57361317\n",
            "   2.0125527   1.6686664   1.5488706   1.1293051 ]\n",
            " [ 0.6197194   0.2847378   0.8111273   0.29930606  0.12218147  0.633571\n",
            "   1.7020148   1.1978279   2.0720472   1.3618188 ]] [[-0.7641907  -0.04179777 -0.03871024 -0.01029287  0.10982683 -3.409261\n",
            "  -0.8519444  -0.1011171  -0.61037153  1.11368   ]\n",
            " [ 0.6315195   1.5662173   1.0136852   0.79115003  0.5027024  -0.84586865\n",
            "  -0.60011023  1.0755258   0.36316153  1.5360875 ]\n",
            " [-0.19636366  1.3796113   0.9972024   0.42479315  0.7522633  -1.2828168\n",
            "  -0.24372143  0.53102773  0.60126495  1.431718  ]\n",
            " [-0.01733678  1.2261399   0.60732824 -0.3713482   1.0066447  -1.0930486\n",
            "  -0.34242573  1.2536769  -0.01925345  0.05428234]\n",
            " [-0.6089171   0.812452    0.73339826  0.27320436  1.0981218  -0.69458455\n",
            "   0.300511    1.9441388  -0.5859628   1.1883222 ]\n",
            " [-0.3862846   0.9120517   0.6206465   0.7143033   0.49330038 -1.0343239\n",
            "  -0.31964967  0.45504218  0.87512237  1.6519731 ]\n",
            " [-0.11572167  1.118077    1.1451776   0.45498532  0.7921902  -0.8244491\n",
            "   0.13255627  1.3740886   1.5412023   1.585442  ]\n",
            " [-0.42347932  0.7645048   1.1695968   0.8649328   1.0572455  -1.3920376\n",
            "   0.06315615  1.8586993   1.3764335   1.3430959 ]\n",
            " [-0.04602024  1.0310172   1.1641402   0.830472    0.55506825 -1.4279099\n",
            "  -0.305408    0.95073116  1.0027801   1.6112568 ]\n",
            " [-0.1204833   0.88820004  0.8350356   0.46982872  0.30827308 -1.1874206\n",
            "   0.06021432  0.6750055   0.5101989   1.052246  ]] [[ 3.5113144   0.23125732  0.14855024  0.31988123 -0.34488022  1.1630836\n",
            "  -0.23730999 -0.6694767   0.04084282  0.70824903]\n",
            " [ 1.7904973   2.2246804   2.806927    2.5454693   2.600652    2.0405247\n",
            "   2.0883412   2.6324604   1.0418186   2.819541  ]\n",
            " [ 2.5830665   2.5436692   2.6789215   2.552863    1.8923868   2.387744\n",
            "   2.497571    1.4598      1.4553257   3.0531595 ]\n",
            " [ 2.0304976   3.0259213   3.0475783   2.566625    2.3083878   2.8534472\n",
            "   2.431889    3.5424695   1.5133282   3.2522182 ]\n",
            " [ 0.85365546  2.1300118   2.9776423   2.764315    1.9021384   2.261848\n",
            "   0.78977865  2.7873087   1.51449     3.4065237 ]\n",
            " [ 4.7410984   2.2832878   2.5947425   2.7378526   1.9672732   3.6375775\n",
            "   2.2509813   3.3431032   1.4767879   2.352169  ]\n",
            " [ 1.3938805   2.63342     2.7286584   1.8677042   2.9486048   1.323737\n",
            "   0.75743663  3.4104338   1.7034984   2.298728  ]\n",
            " [ 1.5281339   3.5719974   3.1684306   2.4641638   3.45946     2.1354446\n",
            "   2.2208533   3.3282526   1.6605146   4.188968  ]\n",
            " [ 3.7193854   2.3510675   2.3213775   2.3511674   2.4487157   3.718595\n",
            "   2.4170146   3.097043    1.2444317   2.0928166 ]\n",
            " [ 5.245867    2.9236443   2.6110198   2.8997252   2.7353942   4.847442\n",
            "   2.6822622   3.372125    2.8552227   3.146039  ]] [[ 1.7404832   0.20622298  0.17036484  0.14028859 -0.0875273  -0.28903437\n",
            "  -0.05346468 -0.21828583  0.24408357  2.5945306 ]\n",
            " [ 2.5038111   3.8067138  -0.9152964  -1.0867347  -0.66055036 -0.3236773\n",
            "  -0.31045496 -1.4174232   0.43165812  1.9661093 ]\n",
            " [ 2.3395207  -1.5124058   1.7736304  -0.67819226 -1.0566123   0.19052632\n",
            "  -0.78984517 -1.3535223   0.9409393   0.73563135]\n",
            " [ 1.2547673   0.34710675 -0.44897196  2.7757225  -0.33859655 -0.15644921\n",
            "  -0.6115687  -0.48662195  0.41058114  0.87479126]\n",
            " [ 0.6738987   0.4476631  -1.602245   -0.6992324   3.0947883  -0.30546984\n",
            "  -0.6876085  -0.13776019  0.14923412  0.28215185]\n",
            " [ 1.546602   -0.46327224 -1.2862829  -1.491924   -1.288245   -1.6702429\n",
            "  -0.73712903 -1.5902119  -0.9095844   1.7985494 ]\n",
            " [ 1.4186683   0.2906626  -0.9079117  -1.503863   -0.35724834 -0.79060125\n",
            "   1.2171147  -1.3592548  -0.53071135  0.48501337]\n",
            " [ 1.5222133  -0.8623995  -0.37342417 -0.85203713 -1.0658941  -0.4834577\n",
            "   0.21761012  3.1788638   0.40442356  0.29755515]\n",
            " [ 1.7944585   0.43165296 -0.3501598  -0.7924533   0.07014562 -0.5650798\n",
            "  -0.51980543 -1.6325725  -1.2602837   0.9605556 ]\n",
            " [ 1.9798651  -0.5624908  -0.7449863  -1.232003   -0.63779896 -0.6748462\n",
            "  -0.8677051  -0.9195779  -0.8235787   0.9559839 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEeT1XRCxsN",
        "outputId": "2280526b-746f-4618-f369-331b71dbc8fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/softmax_bert_layer1.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rL1fG-obHzeW",
        "outputId": "70b2e98b-de4c-40b7-b43f-390571802adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_SM_bert.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/sorted_attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "-vdLamvD6Vcc",
        "outputId": "ebb7c8f2-0e95-4d80-fab9-5fec8ed982d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.50276214 0.18352194 0.07385454 ... 0.02399363 0.01801627\n",
            "    0.00693945]\n",
            "   [0.28548524 0.15781423 0.12932299 ... 0.0462996  0.03935906\n",
            "    0.03413377]\n",
            "   [0.42965856 0.23049009 0.119009   ... 0.03273839 0.02393627\n",
            "    0.01153364]\n",
            "   ...\n",
            "   [0.3043518  0.23911789 0.14382176 ... 0.02023179 0.00734722\n",
            "    0.00598513]\n",
            "   [0.42806664 0.27252406 0.0660226  ... 0.03525357 0.02467276\n",
            "    0.0087873 ]\n",
            "   [0.35068387 0.13904521 0.13328184 ... 0.01395757 0.00985229\n",
            "    0.00765489]]\n",
            "\n",
            "  [[0.2325552  0.13501358 0.11216996 ... 0.06796568 0.04669739\n",
            "    0.01961427]\n",
            "   [0.3069954  0.1544281  0.12369999 ... 0.0540519  0.03094326\n",
            "    0.01976733]\n",
            "   [0.3473453  0.17405728 0.11080742 ... 0.02729124 0.0272199\n",
            "    0.01510452]\n",
            "   ...\n",
            "   [0.34108797 0.14767179 0.09490318 ... 0.05895856 0.02201105\n",
            "    0.01425752]\n",
            "   [0.16335478 0.15715772 0.1307724  ... 0.07702713 0.06241015\n",
            "    0.02915837]\n",
            "   [0.21095937 0.16749963 0.14411137 ... 0.04625707 0.04081224\n",
            "    0.03196875]]\n",
            "\n",
            "  [[0.20825657 0.19249158 0.18383561 ... 0.02142655 0.01533512\n",
            "    0.00476936]\n",
            "   [0.24235135 0.18242025 0.17155178 ... 0.03665771 0.03388991\n",
            "    0.03156955]\n",
            "   [0.18842699 0.1846192  0.15932496 ... 0.0527045  0.05176065\n",
            "    0.04646761]\n",
            "   ...\n",
            "   [0.25251973 0.16754884 0.15158708 ... 0.03404357 0.03329607\n",
            "    0.02462847]\n",
            "   [0.2571161  0.21102408 0.18693537 ... 0.02713428 0.02467851\n",
            "    0.02251801]\n",
            "   [0.41005656 0.19873372 0.1137526  ... 0.02479132 0.01154065\n",
            "    0.00977826]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2592011  0.15715222 0.12888864 ... 0.05018471 0.01325505\n",
            "    0.0045917 ]\n",
            "   [0.33733252 0.17494407 0.15267216 ... 0.02646148 0.01087068\n",
            "    0.00389986]\n",
            "   [0.3181143  0.13679282 0.12702297 ... 0.02282469 0.02214158\n",
            "    0.01064354]\n",
            "   ...\n",
            "   [0.26751333 0.18797602 0.13342448 ... 0.04374462 0.0292747\n",
            "    0.00853144]\n",
            "   [0.18074659 0.15957834 0.15265188 ... 0.05979285 0.03502361\n",
            "    0.01639437]\n",
            "   [0.20700881 0.16873328 0.13372055 ... 0.06887838 0.02255044\n",
            "    0.00934925]]\n",
            "\n",
            "  [[0.37489742 0.2901547  0.11512411 ... 0.02215154 0.01872855\n",
            "    0.00941682]\n",
            "   [0.18999724 0.13898917 0.12236455 ... 0.07654192 0.06884889\n",
            "    0.0477233 ]\n",
            "   [0.27175546 0.12120829 0.1138563  ... 0.0570039  0.05632794\n",
            "    0.05246266]\n",
            "   ...\n",
            "   [0.20520656 0.13339986 0.12312736 ... 0.05491564 0.05075939\n",
            "    0.03485935]\n",
            "   [0.19427177 0.18163337 0.17536202 ... 0.03484033 0.02603423\n",
            "    0.0250867 ]\n",
            "   [0.2918996  0.27665862 0.26320818 ... 0.02027144 0.01506835\n",
            "    0.01499027]]\n",
            "\n",
            "  [[0.43601793 0.18579273 0.07530626 ... 0.03807148 0.03671275\n",
            "    0.03654618]\n",
            "   [0.29635048 0.23618098 0.07779395 ... 0.05147965 0.04919232\n",
            "    0.04249952]\n",
            "   [0.39474365 0.36150783 0.1024332  ... 0.01188225 0.00715878\n",
            "    0.00597612]\n",
            "   ...\n",
            "   [0.34529865 0.27073318 0.1501966  ... 0.03340842 0.02463462\n",
            "    0.01474646]\n",
            "   [0.2451356  0.24132645 0.16123603 ... 0.02899556 0.02688335\n",
            "    0.02529364]\n",
            "   [0.51953447 0.18517023 0.07776037 ... 0.02618033 0.01927708\n",
            "    0.01510626]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "3IpQeei26iui"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = \"/./content/model/sorted_attention_scores_2.txt\"  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "dhImdkUJ62U5",
        "outputId": "dcc9a8e2-3659-477e-fc1a-dc245a6b6edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    2.1947367   2.0617602   1.4053444   0.6307755   0.5856975\n",
            "   0.49772462  0.11714409 -0.14835791 -0.30920362]\n",
            " [ 5.793112    4.621073    3.812749    3.3466518   2.3886065   2.3419719\n",
            "   1.9099072   1.8878778   1.6703308   1.5484276 ]\n",
            " [ 5.2124023   4.502995    3.8073637   3.3168168   3.0351076   2.6028967\n",
            "   2.4797425   2.3082643   1.6874914   1.5656495 ]\n",
            " [ 6.7969666   5.3321524   4.652975    3.8015726   3.108758    2.719986\n",
            "   2.659658    2.5718498   2.416732    2.1785326 ]\n",
            " [ 5.064213    4.6419153   3.4980125   3.339889    3.3077164   2.7762215\n",
            "   2.5917144   2.023627    1.873533    0.62522817]\n",
            " [ 4.3125715   4.3036885   3.9795005   3.511932    3.220555    3.0432897\n",
            "   2.9215946   2.8711824   2.6142015   2.2757936 ]\n",
            " [ 4.5505824   4.1721644   3.331105    3.1753776   2.6852992   2.6400094\n",
            "   2.4741642   1.7959094   1.6750463   1.3191165 ]\n",
            " [ 4.537689    4.2240024   3.9101954   3.422982    3.3852067   2.9609547\n",
            "   2.1071794   2.1017816   1.7666457   1.6387088 ]\n",
            " [ 5.7495446   4.3632503   3.822887    3.529175    3.3072975   2.9970148\n",
            "   2.365435    2.2333503   1.2618201   1.1282016 ]\n",
            " [ 6.618206    5.7463045   5.1483626   4.5703983   4.4660215   3.426703\n",
            "   3.174025    3.1162205   2.4864216   2.1799157 ]] [[ 0.9627847   0.311149    0.02555725 -0.04857237 -0.07704417 -0.1185468\n",
            "  -0.46038562 -0.6803706  -1.0886638  -1.6976843 ]\n",
            " [ 0.97234195  0.7301598   0.43518707  0.06117958 -0.22009215 -0.5790163\n",
            "  -0.6899191  -0.7375137  -1.1784676  -1.7430696 ]\n",
            " [ 1.1253307   0.21543759 -0.0585902  -0.20672473 -0.34776625 -0.43296996\n",
            "  -0.5565975  -0.61825126 -1.1309534  -1.3146526 ]\n",
            " [ 1.2667636   0.45576128  0.14773999  0.03673334  0.01682144  0.00024927\n",
            "  -0.25012723 -0.25380707 -0.3354175  -0.5908074 ]\n",
            " [ 0.7070519   0.6523646   0.59022087  0.32314226  0.09670944 -0.03702255\n",
            "  -0.25472367 -1.2064693  -1.5367095  -1.7260594 ]\n",
            " [ 0.7998164   0.43778053  0.38227442  0.37704596  0.2848917   0.15285142\n",
            "   0.01839954 -0.49263728 -0.8517933  -1.209122  ]\n",
            " [ 0.60655284  0.5833909   0.2000978   0.10675713  0.10043441  0.03625927\n",
            "  -0.09115115 -0.17491554 -0.2891728  -0.83618826]\n",
            " [ 0.99600965  0.42240837  0.38931042  0.1125567   0.09165996 -0.06464243\n",
            "  -0.33630806 -0.35978922 -0.56914496 -1.3896195 ]\n",
            " [ 0.6880506   0.4417293   0.22939461  0.17030033  0.16794282  0.1490941\n",
            "   0.03469593 -0.33433583 -0.5399121  -0.96181583]\n",
            " [ 0.81911325  0.47387433  0.27014586  0.25771543  0.17429377 -0.10441241\n",
            "  -0.3579516  -0.4639737  -0.60645354 -0.9096098 ]] [[ 4.0928345   3.0894957   2.8996303   2.411408    0.9280114   0.631462\n",
            "   0.02200214 -0.14752409 -0.74852276 -1.1275623 ]\n",
            " [ 3.9065943   3.235908    3.011582    2.1310635   0.98545116  0.5878507\n",
            "   0.50435984  0.34831482  0.17555894 -0.09421223]\n",
            " [ 2.6323042   2.430443    2.2343197   1.5101197   1.3811649   1.0000788\n",
            "   0.8571075   0.6049058   0.56835276  0.4869851 ]\n",
            " [ 4.087019    3.0947237   2.0099015   1.465734    1.430701    0.9727164\n",
            "   0.75650877  0.56819826  0.33274144 -0.30525357]\n",
            " [ 3.5774622   3.0174787   2.2269187   1.5521222   1.4834703   1.1328936\n",
            "  -0.17385992 -0.3164355  -1.30088    -1.429762  ]\n",
            " [ 3.4188118   3.0749917   2.4532826   2.2898376   1.0576711   0.71736014\n",
            "   0.62846535  0.22138332  0.07279523 -0.32747287]\n",
            " [ 1.9065028   1.5033801   1.2080953   0.88415587  0.6549574   0.593324\n",
            "   0.5708541   0.49050444  0.42657304  0.14300826]\n",
            " [ 2.1231966   2.0823565   1.852924    1.5934157   1.4300145   1.3541062\n",
            "   1.0749373   1.0071483   0.84968215  0.76707125]\n",
            " [ 3.2195091   2.1220663   2.0053072   1.7817802   1.1799686   0.56950235\n",
            "   0.2573312   0.23191671  0.0096926  -0.32239503]\n",
            " [ 4.1586957   3.912785    3.5320184   2.9207473   1.3169683   0.9062026\n",
            "   0.8497595   0.8289084   0.3867088   0.23973835]] [[-0.73714244 -0.88458973 -0.91819704 -1.0391645  -1.2835796  -1.3152801\n",
            "  -1.71575    -1.7907189  -2.0585341  -2.3600693 ]\n",
            " [ 2.8525796   1.291576    1.1377413   1.0893993   0.98103195  0.76816994\n",
            "   0.5328254  -0.05392636 -0.3590138  -1.1812421 ]\n",
            " [ 1.889281    1.394224    1.2403969   1.1208864   0.93400806  0.9152784\n",
            "   0.44077566  0.37211862 -0.48069543 -0.6091448 ]\n",
            " [ 1.9117765   1.7898803   1.4986356   1.2874416   0.8347929   0.61145085\n",
            "   0.17829615 -0.2541298  -0.4079485  -0.5898164 ]\n",
            " [ 1.9394354   1.6893194   1.2605628   0.92400664  0.8303908   0.5058691\n",
            "   0.35562584 -0.15927449 -0.32631215 -1.4803319 ]\n",
            " [ 1.6729834   1.4437281   1.2482777   1.049527    1.0102694   0.7912869\n",
            "   0.68996495  0.5756347   0.47246826  0.2827701 ]\n",
            " [ 1.2811688   1.2386009   1.1386023   1.133507    1.0146374   0.64457095\n",
            "   0.43742573 -0.267912   -0.3252511  -0.527435  ]\n",
            " [ 2.0227776   1.4528047   1.0313237   0.9414549   0.6557309   0.6545312\n",
            "   0.44207764  0.28013933  0.10742482 -0.6168757 ]\n",
            " [ 1.2305831   1.1441543   1.0789971   0.96978915  0.8841506   0.83005744\n",
            "   0.68824714  0.6699963   0.6610696   0.1847023 ]\n",
            " [ 0.8336154   0.65710616  0.5815153   0.48081017  0.45186663  0.34215644\n",
            "  -0.02691434 -0.1397903  -0.4203801  -1.0223608 ]] [[ 4.069817    3.265758    3.0087957   1.123025    0.5453431  -0.26431718\n",
            "  -0.4206367  -0.45972508 -0.81877565 -0.8189321 ]\n",
            " [ 6.097168    4.062114    4.0104914   3.3517642   2.6415534   2.5503993\n",
            "   2.4742503   1.711552    1.0404894   0.6797678 ]\n",
            " [ 3.6345613   2.8842583   2.593385    2.5239465   2.4532597   2.4311733\n",
            "   2.1401596   1.8469099   1.6555488   1.1871887 ]\n",
            " [ 6.664719    4.3002462   4.007442    2.897587    2.8146844   2.0899508\n",
            "   1.9416659   1.1508867   0.9355154   0.92588633]\n",
            " [ 4.5608745   3.773708    3.7128031   3.3055158   2.7502472   2.5344577\n",
            "   1.7340083   1.4384526   1.4212635   0.3143406 ]\n",
            " [ 4.785963    3.9486756   3.0749145   2.427682    2.2834506   2.1121552\n",
            "   2.1050293   1.8919368   1.4853789  -1.8715912 ]\n",
            " [ 3.5164182   3.2546113   2.360936    2.2992978   2.1868212   1.9338874\n",
            "   1.810391    1.1583683   0.84790796  0.63691103]\n",
            " [ 2.7568579   2.7054691   2.477663    2.465773    1.7325523   1.6061538\n",
            "   1.360221    1.037012    0.39985502  0.35841948]\n",
            " [ 4.687452    3.0739172   2.4958704   2.266237    2.0501065   1.2087647\n",
            "   1.0399474   0.85278237  0.47858107 -1.5197104 ]\n",
            " [ 3.609223    3.000189    2.9361863   2.3336442   2.2864735   2.0922556\n",
            "   1.7917078   0.4763999  -0.7293791  -0.74419117]] [[ 2.3518488  -0.10409442 -1.3146498  -1.3970611  -1.4390004  -1.486853\n",
            "  -1.5213429  -2.4012413  -2.5842254  -2.5848315 ]\n",
            " [ 3.4115536   3.0861502   2.8016753   2.5004106   2.4000955   1.5283737\n",
            "   1.3075106   1.0803758   0.95492965 -0.08029907]\n",
            " [ 3.8802829   3.159526    2.2096994   2.0309644   1.5423824   1.4555954\n",
            "   1.3234267   0.77620506  0.30919918 -0.98470867]\n",
            " [ 3.6075718   3.5096714   3.153818    3.1277943   2.7993655   2.5558827\n",
            "   2.483896    1.9985721   0.9758086  -1.3650285 ]\n",
            " [ 3.5341537   2.933026    2.7865634   2.6538177   2.1139412   1.9947041\n",
            "   1.41041     0.17108425  0.09414454 -0.53188324]\n",
            " [ 3.8921413   3.1415412   3.026591    2.9880128   2.960376    2.8401773\n",
            "   2.6003537   2.4387147   2.2146826  -0.05147918]\n",
            " [ 2.6857972   2.6380162   2.6029804   2.583294    2.5345263   2.2150342\n",
            "   2.0204773   1.4581535   1.2893649  -0.9958864 ]\n",
            " [ 3.2778075   3.2038531   2.9330308   2.720913    2.4970698   1.9810863\n",
            "   1.571423    1.2107869   1.1165935   0.04527869]\n",
            " [ 2.7725258   2.6563025   2.6123178   2.521809    2.3261166   2.2237506\n",
            "   2.2081223   2.1577914   1.9723585  -0.23130603]\n",
            " [ 5.390417    3.7007978   3.4948716   3.369534    3.188392    3.1076705\n",
            "   2.958899    2.873453    2.6593766   0.2493442 ]] [[ 2.0303364   1.8577769   1.8336577   0.03677352 -0.1782641  -0.20157872\n",
            "  -0.36019903 -0.5154236  -0.8391258  -0.9360012 ]\n",
            " [ 2.4703162   1.896263    1.7434708   1.7014173   1.6416981   1.616728\n",
            "   1.5449183   1.3008279   0.07594603  0.00997017]\n",
            " [ 2.406196    2.1794832   2.1692429   2.1441464   1.8323896   1.7379965\n",
            "   1.5149322   1.3819319   0.6953787   0.00943146]\n",
            " [ 2.7665334   2.6152775   2.566569    2.191609    2.0782743   1.5269834\n",
            "   1.5004507   1.2686868   0.9322765  -0.32668146]\n",
            " [ 2.8975577   2.492464    1.5521193   1.484075    1.3629732   1.2339579\n",
            "   1.1117117   0.7913337  -0.5223735  -0.75108665]\n",
            " [ 4.608461    4.2106786   2.6140327   2.156302    1.9421829   1.8067638\n",
            "   1.6747181   1.5631702   1.1256423   1.0583446 ]\n",
            " [ 2.443831    2.4160697   2.1890495   2.1084352   2.08211     1.9666604\n",
            "   1.7901441   1.5581807   1.4040198   1.0204064 ]\n",
            " [ 2.5419347   2.4702833   2.2814734   2.1157253   1.9466188   1.7847257\n",
            "   1.6170082   1.4104946   1.1339206   1.1112541 ]\n",
            " [ 2.5761323   2.4792182   2.137839    1.8463246   1.720331    1.4472572\n",
            "   1.3243217   1.2411208   1.2266266   1.1666892 ]\n",
            " [ 5.4560094   5.353278    4.541738    3.3154905   2.8533223   2.8041744\n",
            "   2.6403146   2.3418133   2.1872957   1.9060035 ]] [[ 0.22612049 -0.03800961 -0.03878088 -0.04676584 -0.06920808 -0.20872909\n",
            "  -0.24101785 -0.35037673 -0.4477717  -0.5273356 ]\n",
            " [ 0.67517275  0.39312774  0.23725607 -0.06305974 -0.11039566 -0.29921988\n",
            "  -0.47187504 -0.5550632  -0.6243619  -0.72015625]\n",
            " [ 0.9336121   0.5395098   0.49287453  0.21531588  0.18740971 -0.02921304\n",
            "  -0.23901877 -0.30668795 -0.32362545 -1.2280265 ]\n",
            " [ 0.69756246  0.44989973  0.24341476 -0.00245793 -0.07840493 -0.32464612\n",
            "  -0.38152987 -0.6197981  -0.6797175  -0.70561624]\n",
            " [ 0.10249646  0.07505149 -0.03507853 -0.04885465 -0.20628366 -0.23292464\n",
            "  -0.34050646 -0.44878232 -0.46191064 -2.1298897 ]\n",
            " [ 0.3024567   0.29947233  0.2423661   0.24130446  0.18978542  0.096457\n",
            "   0.03272907  0.02645526  0.00284321 -0.13099633]\n",
            " [ 0.6062699   0.52392596 -0.00332226 -0.16046394 -0.19334584 -0.3142506\n",
            "  -0.34419575 -0.40288302 -0.43888092 -0.4598454 ]\n",
            " [ 0.04201785 -0.02999487 -0.16519366 -0.188554   -0.31032342 -0.39713255\n",
            "  -0.56612873 -0.6005166  -1.3156276  -2.612752  ]\n",
            " [ 0.3471023   0.2327159   0.1582894   0.13848405  0.0672462   0.0647919\n",
            "  -0.00930041 -0.03875374 -0.08677322 -0.1906524 ]\n",
            " [ 0.2202284   0.05504296  0.00104465 -0.02846966 -0.03995595 -0.06230865\n",
            "  -0.06644918 -0.08931216 -0.15427314 -0.25045082]] [[ 2.2500303   2.2188106   0.7274816   0.7000268   0.5726925   0.284214\n",
            "   0.13661313  0.11507649 -0.22948742 -0.4026169 ]\n",
            " [ 3.4689038   2.951157    2.3157012   1.8796558   1.4019722   1.1965826\n",
            "   1.1602786   0.6572411   0.2278574  -0.1770497 ]\n",
            " [ 3.709777    2.3455753   1.9080584   1.6395503   1.4283334   1.2921461\n",
            "   1.0153087   0.8905095   0.5606777   0.47134808]\n",
            " [ 4.1362057   3.8354084   3.003888    2.590262    2.323182    1.8637079\n",
            "   1.3310231   1.2275932   1.0532311  -0.19235559]\n",
            " [ 3.094353    1.8359743   1.7547503   1.5248697   1.3008693   0.6746429\n",
            "   0.6143206   0.54005456  0.47067168  0.2596902 ]\n",
            " [ 2.0936713   1.9916923   1.3448064   0.901352    0.87460697  0.80160993\n",
            "   0.5036669   0.45084783 -0.10966269 -0.9338605 ]\n",
            " [ 1.4810711   0.9820602   0.5728401   0.5373771   0.45082232  0.40630463\n",
            "   0.07374337  0.0408671  -0.04004947 -0.43184328]\n",
            " [ 3.1449246   2.3962045   2.0956993   1.8832694   1.0816227   0.7081071\n",
            "   0.6745899   0.6018912   0.5275235   0.19390348]\n",
            " [ 2.0125527   1.7450609   1.6686664   1.5488706   1.1293051   0.8310921\n",
            "   0.57361317  0.46006605  0.18745206 -0.3780636 ]\n",
            " [ 2.0720472   1.7020148   1.3618188   1.1978279   0.8111273   0.633571\n",
            "   0.6197194   0.29930606  0.2847378   0.12218147]] [[ 1.11368     0.10982683 -0.01029287 -0.03871024 -0.04179777 -0.1011171\n",
            "  -0.61037153 -0.7641907  -0.8519444  -3.409261  ]\n",
            " [ 1.5662173   1.5360875   1.0755258   1.0136852   0.79115003  0.6315195\n",
            "   0.5027024   0.36316153 -0.60011023 -0.84586865]\n",
            " [ 1.431718    1.3796113   0.9972024   0.7522633   0.60126495  0.53102773\n",
            "   0.42479315 -0.19636366 -0.24372143 -1.2828168 ]\n",
            " [ 1.2536769   1.2261399   1.0066447   0.60732824  0.05428234 -0.01733678\n",
            "  -0.01925345 -0.34242573 -0.3713482  -1.0930486 ]\n",
            " [ 1.9441388   1.1883222   1.0981218   0.812452    0.73339826  0.300511\n",
            "   0.27320436 -0.5859628  -0.6089171  -0.69458455]\n",
            " [ 1.6519731   0.9120517   0.87512237  0.7143033   0.6206465   0.49330038\n",
            "   0.45504218 -0.31964967 -0.3862846  -1.0343239 ]\n",
            " [ 1.585442    1.5412023   1.3740886   1.1451776   1.118077    0.7921902\n",
            "   0.45498532  0.13255627 -0.11572167 -0.8244491 ]\n",
            " [ 1.8586993   1.3764335   1.3430959   1.1695968   1.0572455   0.8649328\n",
            "   0.7645048   0.06315615 -0.42347932 -1.3920376 ]\n",
            " [ 1.6112568   1.1641402   1.0310172   1.0027801   0.95073116  0.830472\n",
            "   0.55506825 -0.04602024 -0.305408   -1.4279099 ]\n",
            " [ 1.052246    0.88820004  0.8350356   0.6750055   0.5101989   0.46982872\n",
            "   0.30827308  0.06021432 -0.1204833  -1.1874206 ]] [[ 3.5113144   1.1630836   0.70824903  0.31988123  0.23125732  0.14855024\n",
            "   0.04084282 -0.23730999 -0.34488022 -0.6694767 ]\n",
            " [ 2.819541    2.806927    2.6324604   2.600652    2.5454693   2.2246804\n",
            "   2.0883412   2.0405247   1.7904973   1.0418186 ]\n",
            " [ 3.0531595   2.6789215   2.5830665   2.552863    2.5436692   2.497571\n",
            "   2.387744    1.8923868   1.4598      1.4553257 ]\n",
            " [ 3.5424695   3.2522182   3.0475783   3.0259213   2.8534472   2.566625\n",
            "   2.431889    2.3083878   2.0304976   1.5133282 ]\n",
            " [ 3.4065237   2.9776423   2.7873087   2.764315    2.261848    2.1300118\n",
            "   1.9021384   1.51449     0.85365546  0.78977865]\n",
            " [ 4.7410984   3.6375775   3.3431032   2.7378526   2.5947425   2.352169\n",
            "   2.2832878   2.2509813   1.9672732   1.4767879 ]\n",
            " [ 3.4104338   2.9486048   2.7286584   2.63342     2.298728    1.8677042\n",
            "   1.7034984   1.3938805   1.323737    0.75743663]\n",
            " [ 4.188968    3.5719974   3.45946     3.3282526   3.1684306   2.4641638\n",
            "   2.2208533   2.1354446   1.6605146   1.5281339 ]\n",
            " [ 3.7193854   3.718595    3.097043    2.4487157   2.4170146   2.3511674\n",
            "   2.3510675   2.3213775   2.0928166   1.2444317 ]\n",
            " [ 5.245867    4.847442    3.372125    3.146039    2.9236443   2.8997252\n",
            "   2.8552227   2.7353942   2.6822622   2.6110198 ]] [[ 2.5945306   1.7404832   0.24408357  0.20622298  0.17036484  0.14028859\n",
            "  -0.05346468 -0.0875273  -0.21828583 -0.28903437]\n",
            " [ 3.8067138   2.5038111   1.9661093   0.43165812 -0.31045496 -0.3236773\n",
            "  -0.66055036 -0.9152964  -1.0867347  -1.4174232 ]\n",
            " [ 2.3395207   1.7736304   0.9409393   0.73563135  0.19052632 -0.67819226\n",
            "  -0.78984517 -1.0566123  -1.3535223  -1.5124058 ]\n",
            " [ 2.7757225   1.2547673   0.87479126  0.41058114  0.34710675 -0.15644921\n",
            "  -0.33859655 -0.44897196 -0.48662195 -0.6115687 ]\n",
            " [ 3.0947883   0.6738987   0.4476631   0.28215185  0.14923412 -0.13776019\n",
            "  -0.30546984 -0.6876085  -0.6992324  -1.602245  ]\n",
            " [ 1.7985494   1.546602   -0.46327224 -0.73712903 -0.9095844  -1.2862829\n",
            "  -1.288245   -1.491924   -1.5902119  -1.6702429 ]\n",
            " [ 1.4186683   1.2171147   0.48501337  0.2906626  -0.35724834 -0.53071135\n",
            "  -0.79060125 -0.9079117  -1.3592548  -1.503863  ]\n",
            " [ 3.1788638   1.5222133   0.40442356  0.29755515  0.21761012 -0.37342417\n",
            "  -0.4834577  -0.85203713 -0.8623995  -1.0658941 ]\n",
            " [ 1.7944585   0.9605556   0.43165296  0.07014562 -0.3501598  -0.51980543\n",
            "  -0.5650798  -0.7924533  -1.2602837  -1.6325725 ]\n",
            " [ 1.9798651   0.9559839  -0.5624908  -0.63779896 -0.6748462  -0.7449863\n",
            "  -0.8235787  -0.8677051  -0.9195779  -1.232003  ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path = \"./model/softmax_attention_scores.pkl\"\n",
        "with open(softmax_file_path, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax attention_scores가 {softmax_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "WUVvB7pr7RBf",
        "outputId": "b5f65e1b-76b3-429b-cd41-c8f2f15e29a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792055 0.09109741 0.09164357 ... 0.09258842 0.09229336\n",
            "    0.09513694]\n",
            "   [0.12004586 0.10268968 0.10120098 ... 0.09385469 0.09336554\n",
            "    0.09450836]\n",
            "   [0.09188308 0.11296417 0.10104739 ... 0.09287033 0.09284727\n",
            "    0.09269542]\n",
            "   ...\n",
            "   [0.09724706 0.09072162 0.09059814 ... 0.09612775 0.12209511\n",
            "    0.1143846 ]\n",
            "   [0.09323013 0.09044815 0.09189644 ... 0.11774409 0.09348241\n",
            "    0.13755944]\n",
            "   [0.10347308 0.09130668 0.09073301 ... 0.10249271 0.0964129\n",
            "    0.10287845]]\n",
            "\n",
            "  [[0.09785708 0.1010711  0.09990909 ... 0.1006773  0.09957507\n",
            "    0.11400125]\n",
            "   [0.09519613 0.09198768 0.10206269 ... 0.09563526 0.09920019\n",
            "    0.12259457]\n",
            "   [0.0963392  0.09690202 0.09143765 ... 0.10719077 0.10062093\n",
            "    0.12747219]\n",
            "   ...\n",
            "   [0.09908457 0.09758333 0.09906299 ... 0.0961072  0.0978529\n",
            "    0.12674263]\n",
            "   [0.09308667 0.10304288 0.09866013 ... 0.10144265 0.09808288\n",
            "    0.10579788]\n",
            "   [0.09461471 0.1043413  0.0984853  ... 0.10681042 0.09746661\n",
            "    0.11155472]]\n",
            "\n",
            "  [[0.10933199 0.09290536 0.09061925 ... 0.09214136 0.09332465\n",
            "    0.10667202]\n",
            "   [0.10829917 0.10341936 0.09385677 ... 0.09627965 0.09360978\n",
            "    0.10712849]\n",
            "   [0.10907564 0.09717342 0.0946402  ... 0.09514245 0.09607369\n",
            "    0.1086611 ]\n",
            "   ...\n",
            "   [0.10199555 0.10672598 0.09804323 ... 0.11619101 0.09668372\n",
            "    0.10503597]\n",
            "   [0.0949479  0.11661825 0.09678788 ... 0.09768786 0.09655614\n",
            "    0.10871448]\n",
            "   [0.1353592  0.0939795  0.09070874 ... 0.09208083 0.09304921\n",
            "    0.10064787]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09984183 0.10561763 0.10010299 ... 0.09757758 0.1026743\n",
            "    0.11696494]\n",
            "   [0.10077073 0.1048938  0.1072562  ... 0.09442478 0.09245645\n",
            "    0.1261673 ]\n",
            "   [0.09222058 0.10335313 0.12389978 ... 0.09829431 0.10070038\n",
            "    0.1023483 ]\n",
            "   ...\n",
            "   [0.09290123 0.09680557 0.11789276 ... 0.10309868 0.09550235\n",
            "    0.1088791 ]\n",
            "   [0.09593145 0.10086945 0.10162396 ... 0.10526626 0.09792026\n",
            "    0.10599791]\n",
            "   [0.09677328 0.09897416 0.11110785 ... 0.10325618 0.0989797\n",
            "    0.10693549]]\n",
            "\n",
            "  [[0.13062458 0.09245858 0.0914835  ... 0.09063558 0.09179717\n",
            "    0.09474251]\n",
            "   [0.09483223 0.09760492 0.10083348 ... 0.09685693 0.10389443\n",
            "    0.09879342]\n",
            "   [0.09761009 0.09560166 0.10119431 ... 0.09553706 0.09628828\n",
            "    0.11850341]\n",
            "   ...\n",
            "   [0.10222587 0.10328139 0.09508933 ... 0.09548536 0.09791066\n",
            "    0.11097045]\n",
            "   [0.09551324 0.10601512 0.09348555 ... 0.10826695 0.1075901\n",
            "    0.10964395]\n",
            "   [0.11690799 0.09121044 0.09121756 ... 0.0916934  0.09208853\n",
            "    0.09284412]]\n",
            "\n",
            "  [[0.10810776 0.0942751  0.09505253 ... 0.09378396 0.09679952\n",
            "    0.13884439]\n",
            "   [0.12123886 0.11415911 0.09557965 ... 0.09468964 0.09405801\n",
            "    0.09743701]\n",
            "   [0.132849   0.09005725 0.12850621 ... 0.0927122  0.09285689\n",
            "    0.09917664]\n",
            "   ...\n",
            "   [0.12697606 0.0912357  0.09214232 ... 0.1178524  0.09399209\n",
            "    0.10446963]\n",
            "   [0.11475074 0.09405647 0.10441453 ... 0.09398486 0.11518867\n",
            "    0.1059187 ]\n",
            "   [0.15028572 0.09182073 0.0938767  ... 0.09661791 0.09353498\n",
            "    0.10757346]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 1.0\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 1.0\n",
            "Sum of softmax values in [0, 9, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax attention_scores가 ./model/softmax_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "\n",
        "# 파일에서 데이터 로드\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(f\"Shape of attention_scores: {np.array(attention_scores).shape}\")\n"
      ],
      "metadata": {
        "id": "EvyTkAln9iH7",
        "outputId": "43197bb9-867a-4d2e-afc9-1144249f1bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_scores: (1, 12, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"./model/attention_scores.pkl\"  # 기존 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 정렬 및 인덱스 저장\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)\n",
        "original_indices = np.zeros_like(attention_scores, dtype=int)\n",
        "\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 인덱스와 정렬된 배열 저장\n",
        "            sorted_indices = np.argsort(attention_scores[i, j, k])[::-1]  # 내림차순 인덱스\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][sorted_indices]\n",
        "            original_indices[i, j, k] = sorted_indices  # 원래의 순서 저장\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "# 4. 원래 인덱스 데이터를 새로운 파일로 저장\n",
        "indices_file_path = \"./model/original_indices.pkl\"\n",
        "with open(indices_file_path, \"wb\") as f:\n",
        "    pickle.dump(original_indices, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores와 원래 인덱스가 각각 {sorted_file_path}, {indices_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "eOuBuIM67wL7",
        "outputId": "979679d1-1b75-4729-b2e0-de81d1e48f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores와 원래 인덱스가 각각 ./model/sorted_attention_scores.pkl, ./model/original_indices.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path2 = \"./model/softmax_sorted_attention_scores.pkl\"\n",
        "with open(softmax_file_path2, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax sorted_attention_scores가 {softmax_file_path2}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "jM9BFbZ2-5sn",
        "outputId": "a3b75569-7362-42d4-f0cf-79fe84b255a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.52837735 0.14622849 0.12802094 0.06640536 0.0306064  0.02925736\n",
            "    0.02679347 0.01831239 0.01404232 0.01195596]\n",
            "   [0.59860635 0.18540919 0.08261914 0.05183908 0.01988765 0.01898149\n",
            "    0.01232217 0.01205369 0.00969707 0.00858417]\n",
            "   [0.44448107 0.21865611 0.1090568  0.06677455 0.05038093 0.03270087\n",
            "    0.02891174 0.02435579 0.01309194 0.01159014]\n",
            "   [0.669667   0.15477407 0.07847571 0.03349468 0.01675291 0.01135661\n",
            "    0.01069175 0.00979296 0.00838585 0.00660843]\n",
            "   [0.39969283 0.26201427 0.08347073 0.07126267 0.06900645 0.04055686\n",
            "    0.0337236  0.01910807 0.01644492 0.00471954]\n",
            "   [0.2187059  0.21677174 0.15675072 0.09820805 0.0733844  0.06146365\n",
            "    0.05442105 0.05174557 0.04001914 0.02852982]\n",
            "   [0.35450202 0.24281408 0.1047144  0.0896138  0.05489547 0.05246472\n",
            "    0.04444693 0.0225569  0.01998892 0.01400267]\n",
            "   [0.293395   0.21439777 0.15665188 0.09623688 0.09266932 0.06062973\n",
            "    0.02581641 0.02567743 0.01836554 0.01616001]\n",
            "   [0.5748314  0.14370786 0.08371508 0.06240886 0.04999033 0.03665489\n",
            "    0.01949128 0.01707956 0.00646467 0.00565609]\n",
            "   [0.49397027 0.20655645 0.11359414 0.06373078 0.05741416 0.02030713\n",
            "    0.01577292 0.01488702 0.0079303  0.00583681]]\n",
            "\n",
            "  [[0.27761808 0.14469248 0.10874643 0.10097665 0.09814221 0.09415241\n",
            "    0.06689177 0.05368271 0.0356874  0.01940979]\n",
            "   [0.2604174  0.20440505 0.15219016 0.10470253 0.07903191 0.05519805\n",
            "    0.04940367 0.0471074  0.03030995 0.01723383]\n",
            "   [0.33725736 0.13576876 0.10322648 0.08901375 0.07730427 0.07099047\n",
            "    0.06273492 0.05898388 0.03532398 0.02939613]\n",
            "   [0.2917905  0.12967533 0.09529836 0.08528562 0.08360421 0.08223013\n",
            "    0.06401678 0.06378165 0.05878313 0.04553427]\n",
            "   [0.19012696 0.18000863 0.1691627  0.12951314 0.10327026 0.09034337\n",
            "    0.07266911 0.02805511 0.02016464 0.01668618]\n",
            "   [0.1926948  0.13416518 0.12692109 0.12625922 0.11514391 0.10090128\n",
            "    0.08820739 0.05291325 0.0369475  0.02584635]\n",
            "   [0.16616797 0.16236342 0.11066904 0.10080656 0.10017121 0.09394464\n",
            "    0.08270625 0.07606062 0.06784825 0.03926203]\n",
            "   [0.24415724 0.13758077 0.13310166 0.10092317 0.09883608 0.08453456\n",
            "    0.06442455 0.06292941 0.05104246 0.02247005]\n",
            "   [0.18009992 0.14077887 0.11384703 0.10731426 0.10706155 0.10506248\n",
            "    0.09370552 0.06478832 0.05274922 0.03459279]\n",
            "   [0.20915571 0.14809294 0.12079702 0.11930476 0.10975596 0.08305917\n",
            "    0.06445802 0.05797385 0.05027522 0.03712742]]\n",
            "\n",
            "  [[0.50648683 0.18570502 0.15359116 0.09426141 0.02138469 0.01589693\n",
            "    0.00864228 0.00729464 0.00399939 0.00273765]\n",
            "   [0.43792823 0.2239379  0.1789386  0.0741822  0.0235921  0.01585225\n",
            "    0.01458248 0.01247561 0.01049627 0.00801447]\n",
            "   [0.2603332  0.21274649 0.17485866 0.08475611 0.07450179 0.05089359\n",
            "    0.04411349 0.03428007 0.03304965 0.03046698]\n",
            "   [0.56036854 0.20774248 0.07020905 0.04074404 0.03934137 0.02488566\n",
            "    0.0200471  0.01660616 0.01312235 0.0069332 ]\n",
            "   [0.4483548  0.25610855 0.11616845 0.05915995 0.0552348  0.03890086\n",
            "    0.01053036 0.00913111 0.00341181 0.00299925]\n",
            "   [0.36553445 0.2591846  0.13918881 0.11820098 0.0344745  0.02453029\n",
            "    0.02244379 0.01493835 0.01287573 0.00862854]\n",
            "   [0.2509315  0.16767997 0.12480748 0.0902725  0.07178206 0.06749146\n",
            "    0.06599184 0.06089685 0.05712547 0.04302087]\n",
            "   [0.18211861 0.17483069 0.13898772 0.10721941 0.09105612 0.08440003\n",
            "    0.06384121 0.0596569  0.05096523 0.04692417]\n",
            "   [0.44636625 0.14896284 0.13254707 0.10599701 0.0580671  0.0315361\n",
            "    0.02307989 0.02250072 0.01801714 0.01292593]\n",
            "   [0.35479093 0.2774437  0.18958764 0.10288175 0.02069312 0.01372248\n",
            "    0.0129694  0.01270177 0.00816243 0.00704678]]\n",
            "\n",
            "  [[0.17345521 0.14967586 0.14472926 0.12823921 0.10043214 0.09729832\n",
            "    0.06519037 0.06048183 0.04627157 0.03422624]\n",
            "   [0.48765132 0.10237034 0.08777373 0.08363152 0.07504237 0.06065432\n",
            "    0.04793502 0.02665814 0.01964862 0.00863461]\n",
            "   [0.25074285 0.15283686 0.1310454  0.11628375 0.09646256 0.09467266\n",
            "    0.0589048  0.05499628 0.02344017 0.02061465]\n",
            "   [0.2399773  0.21243756 0.15876156 0.12853605 0.08174141 0.06538016\n",
            "    0.04239642 0.02751243 0.02358991 0.01966718]\n",
            "   [0.27168334 0.21156263 0.13779466 0.09841648 0.08962126 0.06478479\n",
            "    0.05574723 0.03331232 0.02818781 0.00888949]\n",
            "   [0.19332255 0.15371567 0.12642564 0.10363796 0.0996482  0.08005097\n",
            "    0.07233742 0.06452233 0.05819765 0.04814161]\n",
            "   [0.16693579 0.15997879 0.144755   0.1440193  0.12787814 0.08832397\n",
            "    0.07179868 0.03546436 0.03348807 0.0273579 ]\n",
            "   [0.29544708 0.16708738 0.10962176 0.10019989 0.07529721 0.07520694\n",
            "    0.06081216 0.05172036 0.04351636 0.02109079]\n",
            "   [0.14298777 0.13114852 0.12287569 0.11016346 0.1011219  0.0957972\n",
            "    0.08313145 0.081628   0.08090257 0.05024336]\n",
            "   [0.17079811 0.14316145 0.13273863 0.12002222 0.11659815 0.10448287\n",
            "    0.072237   0.06452653 0.04873934 0.02669579]]\n",
            "\n",
            "  [[0.5192746  0.23237996 0.17972206 0.027266   0.01530162 0.00680936\n",
            "    0.00582395 0.0056007  0.00391118 0.00391057]\n",
            "   [0.699621   0.09142186 0.08682219 0.04493132 0.02208557 0.02016141\n",
            "    0.01868313 0.00871393 0.00445426 0.00310539]\n",
            "   [0.2960213  0.1397882  0.10450712 0.09749652 0.09084274 0.08885835\n",
            "    0.0664221  0.04953998 0.04091182 0.02561195]\n",
            "   [0.8076041  0.07591385 0.0566445  0.01867041 0.01718501 0.00832534\n",
            "    0.00717799 0.00325515 0.00262444 0.00259929]\n",
            "   [0.38101527 0.17341247 0.16316602 0.1085793  0.06231563 0.05022047\n",
            "    0.02255537 0.01678386 0.01649782 0.00545376]\n",
            "   [0.4948026  0.21419172 0.08939907 0.04679975 0.04051395 0.03413595\n",
            "    0.03389356 0.02738876 0.01823923 0.00063547]\n",
            "   [0.30746588 0.23664407 0.09682274 0.09103498 0.08135051 0.06317024\n",
            "    0.05583142 0.02908767 0.02132444 0.01726804]\n",
            "   [0.2109127  0.20034795 0.15953279 0.15764718 0.07572729 0.06673571\n",
            "    0.05218564 0.03777314 0.0199742  0.01916347]\n",
            "   [0.6382935  0.12713678 0.07132285 0.05668918 0.04567051 0.01969\n",
            "    0.01663142 0.01379255 0.00948705 0.00128613]\n",
            "   [0.32775906 0.17826031 0.16720861 0.09153304 0.08731563 0.07190253\n",
            "    0.05323753 0.01428851 0.00427882 0.00421591]]\n",
            "\n",
            "  [[0.817817   0.07015417 0.02090817 0.01925419 0.01846338 0.01760067\n",
            "    0.01700397 0.00705368 0.00587417 0.00587061]\n",
            "   [0.28418595 0.2052493  0.15443146 0.11426104 0.10335509 0.04322629\n",
            "    0.03465998 0.02761754 0.02436152 0.00865187]\n",
            "   [0.4597378  0.22360915 0.08649381 0.07233716 0.04437853 0.04068945\n",
            "    0.03565182 0.02062654 0.01293029 0.00354545]\n",
            "   [0.21930066 0.19884852 0.13930833 0.13572979 0.0977328  0.07661206\n",
            "    0.07129084 0.04387935 0.01577901 0.00151868]\n",
            "   [0.3230051  0.17706919 0.15294491 0.13393198 0.07805827 0.06928431\n",
            "    0.03862596 0.01118528 0.01035696 0.00553799]\n",
            "   [0.2662634  0.12569848 0.11204894 0.1078086  0.10486991 0.09299279\n",
            "    0.07316363 0.06224383 0.04975083 0.00515963]\n",
            "   [0.15772055 0.15036172 0.14518489 0.14235465 0.13557892 0.09850053\n",
            "    0.08108556 0.04620931 0.03903242 0.00397149]\n",
            "   [0.22705087 0.21086536 0.16083796 0.13009691 0.10400474 0.0620818\n",
            "    0.04121448 0.02873609 0.02615291 0.00895888]\n",
            "   [0.15756966 0.14028054 0.1342441  0.12262746 0.10083228 0.0910212\n",
            "    0.08960975 0.08521124 0.07078877 0.00781493]\n",
            "   [0.52095336 0.09616268 0.07826614 0.06904632 0.0576065  0.05313915\n",
            "    0.04579351 0.04204315 0.03394088 0.00304831]]\n",
            "\n",
            "  [[0.30353034 0.25542325 0.24933638 0.04134365 0.0333441  0.0325757\n",
            "    0.0277975  0.02380086 0.0172191  0.01562924]\n",
            "   [0.23494782 0.13233152 0.11358121 0.10890377 0.10259051 0.10006052\n",
            "    0.09312712 0.07295736 0.02143432 0.02006581]\n",
            "   [0.18272899 0.14566234 0.14417833 0.14060499 0.10294528 0.09367248\n",
            "    0.07494392 0.06561077 0.03302242 0.01663052]\n",
            "   [0.21080445 0.18121335 0.17259824 0.11862965 0.10591871 0.06103094\n",
            "    0.05943292 0.04713823 0.03367225 0.00956123]\n",
            "   [0.3420291  0.22810408 0.0890731  0.08321378 0.07372274 0.06479937\n",
            "    0.05734294 0.04162378 0.01118937 0.00890178]\n",
            "   [0.4577818  0.30754158 0.06230019 0.03941844 0.03182063 0.02779053\n",
            "    0.02435287 0.02178239 0.01406338 0.01314809]\n",
            "   [0.15856017 0.15421888 0.12289774 0.11337924 0.11043345 0.09839239\n",
            "    0.08247105 0.06539749 0.05605442 0.03819519]\n",
            "   [0.17928226 0.16688584 0.13817212 0.11706766 0.09885415 0.08407862\n",
            "    0.07109627 0.05783079 0.04385757 0.04287465]\n",
            "   [0.20678669 0.18768664 0.13340566 0.09967152 0.08787246 0.06687416\n",
            "    0.05913821 0.05441698 0.05363394 0.05051371]\n",
            "   [0.3654403  0.3297622  0.14647162 0.04297352 0.02706973 0.02577147\n",
            "    0.0218764  0.01623074 0.01390696 0.01049708]]\n",
            "\n",
            "  [[0.1458343  0.1119823  0.11189598 0.11100604 0.10854257 0.09440759\n",
            "    0.09140797 0.08193889 0.07433476 0.06864958]\n",
            "   [0.20656607 0.15580031 0.1333135  0.09872989 0.0941653  0.07796247\n",
            "    0.06559978 0.06036348 0.05632203 0.05117705]\n",
            "   [0.21460015 0.14470167 0.1381084  0.10463523 0.10175563 0.08193705\n",
            "    0.06642979 0.06208326 0.06104058 0.02470827]\n",
            "   [0.20669404 0.16135015 0.13124843 0.10263912 0.09513266 0.07436839\n",
            "    0.07025612 0.0553612  0.05214142 0.05080836]\n",
            "   [0.14189209 0.13805082 0.12365456 0.12196275 0.10419733 0.10145807\n",
            "    0.09110967 0.08176    0.08069363 0.01522107]\n",
            "   [0.11766883 0.11731818 0.11080629 0.11068872 0.10513055 0.09576281\n",
            "    0.08985044 0.0892885  0.08720491 0.07628079]\n",
            "   [0.19142638 0.17629513 0.10405412 0.08892288 0.08604647 0.07624737\n",
            "    0.07399796 0.06978021 0.06731295 0.06591645]\n",
            "   [0.15916045 0.14810184 0.12937321 0.12638603 0.11189619 0.10259225\n",
            "    0.0866404  0.08371166 0.04094655 0.01119137]\n",
            "   [0.13065743 0.11653509 0.10817669 0.1060553  0.09876297 0.09852087\n",
            "    0.09148511 0.08882986 0.08466509 0.07631154]\n",
            "   [0.12899478 0.10935357 0.10360527 0.10059211 0.09944329 0.09724513\n",
            "    0.09684331 0.0946543  0.08870094 0.08056729]]\n",
            "\n",
            "  [[0.32052314 0.3106711  0.06992378 0.06803015 0.05989642 0.04488655\n",
            "    0.03872701 0.03790188 0.02685459 0.02258548]\n",
            "   [0.38911515 0.2318588  0.12281422 0.07941024 0.04925168 0.04010713\n",
            "    0.03867719 0.02338775 0.01522333 0.01015455]\n",
            "   [0.5135131  0.13124603 0.08473738 0.06478336 0.05244851 0.04577071\n",
            "    0.03470233 0.03063085 0.02202496 0.02014279]\n",
            "   [0.36820278 0.27255395 0.11866637 0.07846794 0.06007599 0.03794494\n",
            "    0.0222747  0.02008597 0.01687207 0.00485531]\n",
            "   [0.43434742 0.12340432 0.11377718 0.09041059 0.07226653 0.03863407\n",
            "    0.03637248 0.0337691  0.03150554 0.02551285]\n",
            "   [0.26274955 0.23727559 0.12425505 0.07974882 0.07764421 0.07217833\n",
            "    0.05358112 0.05082447 0.02901657 0.01272628]\n",
            "   [0.25344408 0.15387373 0.10219801 0.09863728 0.09045879 0.08652009\n",
            "    0.06204224 0.06003569 0.05536916 0.03742088]\n",
            "   [0.38324448 0.18126372 0.13421565 0.10852906 0.048685   0.03351039\n",
            "    0.03240583 0.03013357 0.0279739  0.02003843]\n",
            "   [0.22098409 0.16911836 0.15667981 0.13899091 0.09136322 0.0678046\n",
            "    0.05241282 0.04678694 0.03562295 0.02023623]\n",
            "   [0.26084402 0.18016808 0.12821317 0.10882089 0.07392143 0.06189544\n",
            "    0.061044   0.04430872 0.0436679  0.03711633]]\n",
            "\n",
            "  [[0.32245672 0.11816898 0.10479394 0.10185789 0.10154389 0.09569555\n",
            "    0.05750762 0.04930858 0.04516599 0.00350093]\n",
            "   [0.20571339 0.19960773 0.12593834 0.11838617 0.09476656 0.08078458\n",
            "    0.07102053 0.06177064 0.02357428 0.01843771]\n",
            "   [0.21004221 0.19937786 0.13601878 0.106469   0.09154727 0.08533786\n",
            "    0.07673696 0.0412325  0.03932534 0.01391231]\n",
            "   [0.21574429 0.2098844  0.16852123 0.11304038 0.06502029 0.06052643\n",
            "    0.06041053 0.04372811 0.0424815  0.02064284]\n",
            "   [0.31953898 0.15006413 0.1371208  0.10304777 0.09521512 0.06175973\n",
            "    0.06009609 0.02545158 0.02487401 0.02283184]\n",
            "   [0.2748221  0.13113172 0.12637746 0.1076036  0.09798332 0.08626734\n",
            "    0.08302926 0.03826368 0.03579707 0.01872439]\n",
            "   [0.1880343  0.17989706 0.15221152 0.12106892 0.11783196 0.08506133\n",
            "    0.0607136  0.04398017 0.03431082 0.01689019]\n",
            "   [0.23940286 0.14780323 0.14295705 0.12018654 0.10741436 0.08862209\n",
            "    0.08015427 0.03974979 0.02443384 0.00927582]\n",
            "   [0.22464608 0.14365427 0.12574883 0.12224771 0.1160476  0.10289833\n",
            "    0.07812715 0.04283044 0.0330447  0.01075488]\n",
            "   [0.17417422 0.1478222  0.14016856 0.11944017 0.10129215 0.09728442\n",
            "    0.08277145 0.06458773 0.05391058 0.01854851]]\n",
            "\n",
            "  [[0.73495495 0.07021614 0.04455587 0.03021613 0.0276535  0.02545838\n",
            "    0.02285883 0.01730828 0.01554307 0.01123482]\n",
            "   [0.15628102 0.15432207 0.12961586 0.12555788 0.11881696 0.08621079\n",
            "    0.07522292 0.07171068 0.05584679 0.02641504]\n",
            "   [0.18773967 0.12912983 0.11732682 0.11383611 0.11279432 0.10771273\n",
            "    0.09650943 0.05880833 0.03815652 0.03798618]\n",
            "   [0.2080896  0.15566675 0.12685917 0.12414132 0.10447486 0.07842355\n",
            "    0.068538   0.06057529 0.04587851 0.02735303]\n",
            "   [0.260628   0.16973065 0.14031349 0.13712397 0.08296496 0.07271752\n",
            "    0.0578995  0.03929355 0.02029198 0.01903633]\n",
            "   [0.4563094  0.15135837 0.11275033 0.06155465 0.05334687 0.04185627\n",
            "    0.03907022 0.03782817 0.0284841  0.01744165]\n",
            "   [0.27416113 0.17275718 0.13864833 0.12605298 0.09019827 0.05861475\n",
            "    0.04973856 0.03649454 0.03402241 0.01931185]\n",
            "   [0.29404283 0.15865861 0.14177158 0.12433877 0.10597337 0.05240076\n",
            "    0.04108367 0.03772043 0.02345941 0.02055062]\n",
            "   [0.24240194 0.24221043 0.13009368 0.06802855 0.0659058  0.06170589\n",
            "    0.06169973 0.05989478 0.04765695 0.02040222]\n",
            "   [0.40604967 0.27261236 0.06234813 0.04973195 0.03981537 0.03887432\n",
            "    0.03718225 0.03298335 0.03127662 0.02912592]]\n",
            "\n",
            "  [[0.48960426 0.20841889 0.04667228 0.04493827 0.04335542 0.04207087\n",
            "    0.03466055 0.0334998  0.02939372 0.02738602]\n",
            "   [0.65346533 0.17757389 0.10371896 0.02235911 0.01064532 0.01050549\n",
            "    0.00750092 0.00581406 0.00489807 0.00351891]\n",
            "   [0.43387496 0.24637778 0.10714414 0.0872578  0.05059041 0.02122211\n",
            "    0.01898009 0.01453593 0.01080181 0.00921498]\n",
            "   [0.5683163  0.12417884 0.08492316 0.05338537 0.05010207 0.03028057\n",
            "    0.02523821 0.02260076 0.02176566 0.01920915]\n",
            "   [0.7145239  0.06348012 0.05062731 0.04290464 0.03756461 0.02819284\n",
            "    0.02383985 0.01626832 0.01608031 0.0065181 ]\n",
            "   [0.45027953 0.34999585 0.04690137 0.03566573 0.03001613 0.02059476\n",
            "    0.02055438 0.01676671 0.01519714 0.01402829]\n",
            "   [0.31552538 0.2579293  0.12403753 0.10212865 0.05342733 0.04491894\n",
            "    0.03463863 0.03080445 0.01961542 0.01697443]\n",
            "   [0.6826026  0.13022482 0.04258374 0.03826763 0.03532741 0.0195627\n",
            "    0.01752435 0.01212188 0.01199692 0.00978798]\n",
            "   [0.4284722  0.1861072  0.1096639  0.07639468 0.05017954 0.04234973\n",
            "    0.04047512 0.03224343 0.02019598 0.01391816]\n",
            "   [0.5374471  0.19304998 0.04228677 0.03921919 0.03779282 0.03523285\n",
            "    0.03256983 0.03116389 0.02958855 0.02164906]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0\n",
            "Sum of softmax values in [0, 0, 1]: 1.0\n",
            "Sum of softmax values in [0, 0, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 5]: 1.0\n",
            "Sum of softmax values in [0, 1, 6]: 1.0\n",
            "Sum of softmax values in [0, 1, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 5]: 1.0\n",
            "Sum of softmax values in [0, 2, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 8]: 1.0\n",
            "Sum of softmax values in [0, 2, 9]: 1.0\n",
            "Sum of softmax values in [0, 3, 0]: 1.0\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 1.0\n",
            "Sum of softmax values in [0, 3, 5]: 1.0\n",
            "Sum of softmax values in [0, 3, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 0]: 1.0\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 4]: 1.0\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 5, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 1.0\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 5, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0\n",
            "Sum of softmax values in [0, 6, 3]: 1.0\n",
            "Sum of softmax values in [0, 6, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 1.0\n",
            "Sum of softmax values in [0, 6, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 1.0\n",
            "Sum of softmax values in [0, 7, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 1.0\n",
            "Sum of softmax values in [0, 8, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 5]: 1.0\n",
            "Sum of softmax values in [0, 8, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 7]: 1.0\n",
            "Sum of softmax values in [0, 8, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 7]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 9, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 1.0\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 1]: 1.0\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax sorted_attention_scores가 ./model/softmax_sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1Pr9O46V_Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "hhRL4CRO_QSf"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_SM_bert_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "6xc2_wJsIB-b"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_bert_layer1.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_bert_layer1.pkl_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1jdq5E2fjNWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/restored_softmax.pkl\"\n",
        "text_file_path = \"/./content/model/restored_softmax_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "V-oYzGDQCZvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_bert_layer1.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_bert_layer1.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "KSt61FVn6gBD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/softmax_sorted_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "THbCGtMz_twq",
        "outputId": "112c2397-825f-4837-ce06-6a4df446ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.10749399 0.09632882 0.0954031  0.09513693 0.09258841\n",
            "  0.09229334 0.09164356 0.0910974  0.0900939 ]\n",
            " [0.12004588 0.10565753 0.10268969 0.10120098 0.09709173 0.0958351\n",
            "  0.09575053 0.09450836 0.0938547  0.09336555]\n",
            " [0.13786007 0.11296417 0.10104739 0.09357624 0.09350549 0.09287033\n",
            "  0.09284727 0.09269542 0.09188308 0.09075052]\n",
            " [0.11074849 0.10814226 0.10393477 0.10047178 0.10030901 0.09913348\n",
            "  0.09670201 0.09443171 0.09372903 0.09239744]\n",
            " [0.1193184  0.10324923 0.10189565 0.09932904 0.09908514 0.09784093\n",
            "  0.09755905 0.0950703  0.09426644 0.09238588]\n",
            " [0.1328674  0.10326969 0.09898279 0.09854479 0.09625035 0.09615592\n",
            "  0.0958468  0.09484941 0.09185758 0.0913753 ]\n",
            " [0.11864013 0.1089671  0.10785589 0.10248473 0.09685351 0.09558748\n",
            "  0.09497281 0.09192704 0.0917357  0.0909756 ]\n",
            " [0.12209511 0.1143846  0.10398746 0.09853819 0.09724706 0.09612775\n",
            "  0.09440193 0.09189809 0.09072162 0.09059814]\n",
            " [0.13755944 0.11774409 0.09577599 0.0939422  0.09348241 0.09323013\n",
            "  0.09304722 0.09287393 0.09189644 0.09044815]\n",
            " [0.12786184 0.10347308 0.10287845 0.10249271 0.09869479 0.0964129\n",
            "  0.0952139  0.09130668 0.09093261 0.09073301]] [[0.11400125 0.1034065  0.1010711  0.1006773  0.09990909 0.09957507\n",
            "  0.09785708 0.09670063 0.09466569 0.09213626]\n",
            " [0.12259456 0.10524756 0.10206269 0.09920018 0.09916254 0.09589188\n",
            "  0.09563524 0.09519612 0.09302149 0.09198767]\n",
            " [0.12747219 0.10719077 0.10062093 0.09860631 0.09690202 0.0963392\n",
            "  0.09631989 0.09255879 0.0925522  0.09143765]\n",
            " [0.10658482 0.10630877 0.10104766 0.1003748  0.10008461 0.09871509\n",
            "  0.0979219  0.09733845 0.09657256 0.09505137]\n",
            " [0.11034425 0.10167924 0.10102019 0.10027704 0.10000083 0.09928491\n",
            "  0.09772887 0.09770507 0.09617376 0.0957859 ]\n",
            " [0.10516495 0.10368128 0.10063306 0.1006038  0.10018845 0.09995812\n",
            "  0.09989405 0.09896458 0.09562299 0.09528879]\n",
            " [0.11380466 0.10230775 0.1017336  0.10014401 0.09873901 0.09837577\n",
            "  0.09824028 0.09637209 0.09522659 0.0950562 ]\n",
            " [0.12674263 0.10445353 0.09908456 0.09906299 0.0978529  0.09758332\n",
            "  0.09610719 0.09558626 0.09211903 0.09140754]\n",
            " [0.10645555 0.10579788 0.10304288 0.10144265 0.09954634 0.09866013\n",
            "  0.09808288 0.097651   0.09623402 0.09308667]\n",
            " [0.11155472 0.10681042 0.1043413  0.10225179 0.0984853  0.09746661\n",
            "  0.09710175 0.09461471 0.09410094 0.09327243]] [[0.11106927 0.109332   0.10838971 0.10667203 0.10396456 0.09332467\n",
            "  0.09290537 0.09214137 0.09158181 0.09061927]\n",
            " [0.11498808 0.10829917 0.10712849 0.10341936 0.09627965 0.0959329\n",
            "  0.09385677 0.09360978 0.09335104 0.09313468]\n",
            " [0.10907564 0.1086611  0.10594706 0.10251999 0.09717342 0.09607369\n",
            "  0.09553417 0.09523229 0.09514245 0.0946402 ]\n",
            " [0.12777801 0.11388236 0.09597065 0.09547208 0.09541373 0.09527735\n",
            "  0.09474532 0.09463353 0.09392282 0.09290416]\n",
            " [0.11447315 0.10678963 0.10269815 0.10112287 0.10047487 0.09732886\n",
            "  0.0970234  0.09365991 0.09344386 0.09298529]\n",
            " [0.11844434 0.10639787 0.10390373 0.10112502 0.09893835 0.09716936\n",
            "  0.0958861  0.09353664 0.0925469  0.09205168]\n",
            " [0.11324795 0.10864487 0.10467929 0.10341784 0.10152826 0.09656344\n",
            "  0.09464015 0.0934985  0.09244199 0.09133781]\n",
            " [0.11619101 0.10672598 0.10503597 0.10199555 0.09804323 0.09668372\n",
            "  0.09610645 0.09338766 0.0933179  0.09251253]\n",
            " [0.11661826 0.11136508 0.10871449 0.09768787 0.09678789 0.09655615\n",
            "  0.09494792 0.09265881 0.09243154 0.09223206]\n",
            " [0.13535918 0.10957498 0.10064787 0.09704289 0.09668809 0.0939795\n",
            "  0.0930492  0.09208082 0.09086873 0.09070873]] [[0.1255899  0.10366833 0.10065787 0.09996307 0.09845075 0.09556752\n",
            "  0.09483397 0.09431619 0.09430879 0.09264354]\n",
            " [0.13242505 0.1023296  0.1009952  0.09722893 0.0965215  0.09473015\n",
            "  0.09469819 0.09453561 0.09363452 0.09290122]\n",
            " [0.10879505 0.10861369 0.10704175 0.0996678  0.09955349 0.0962432\n",
            "  0.09612511 0.09592903 0.09408776 0.09394309]\n",
            " [0.12335853 0.109509   0.10271551 0.09744254 0.09695764 0.09671901\n",
            "  0.09527482 0.09343539 0.09332724 0.09126032]\n",
            " [0.1051129  0.1042406  0.1015951  0.10096215 0.10058594 0.09961344\n",
            "  0.09938804 0.09867377 0.09613637 0.09369161]\n",
            " [0.11151089 0.10542171 0.10479862 0.10213321 0.0991762  0.09746461\n",
            "  0.09690585 0.09604911 0.09489696 0.09164282]\n",
            " [0.10953204 0.10539693 0.10379548 0.10073565 0.100105   0.09728067\n",
            "  0.09637927 0.09632144 0.09549578 0.09495777]\n",
            " [0.11535057 0.11265247 0.10442845 0.10190308 0.0975237  0.09578036\n",
            "  0.094757   0.0945795  0.09181842 0.09120651]\n",
            " [0.11083733 0.10423398 0.10382918 0.10361786 0.09832249 0.09829199\n",
            "  0.0961586  0.09549905 0.0948538  0.09435575]\n",
            " [0.12480727 0.10181123 0.1017132  0.09872679 0.09662166 0.09624251\n",
            "  0.09611325 0.09551828 0.094544   0.0939018 ]] [[0.13122697 0.11838867 0.09999187 0.09693875 0.09442222 0.0934737\n",
            "  0.09302619 0.09113406 0.09096654 0.090431  ]\n",
            " [0.11642858 0.11028487 0.10202178 0.09834425 0.09758889 0.09684826\n",
            "  0.09614606 0.0955855  0.09482107 0.09193079]\n",
            " [0.13121082 0.11401134 0.10236181 0.09529249 0.09509484 0.09347839\n",
            "  0.09292267 0.09219655 0.09185337 0.09157771]\n",
            " [0.11182034 0.11131455 0.10122852 0.09885452 0.09775028 0.09756619\n",
            "  0.0970481  0.09618475 0.09485637 0.09337639]\n",
            " [0.1190371  0.11268517 0.10337377 0.09892204 0.09817803 0.09598743\n",
            "  0.09449787 0.0939927  0.09308489 0.09024091]\n",
            " [0.1231669  0.11651503 0.10195184 0.09985358 0.09462189 0.09450209\n",
            "  0.0933025  0.09328135 0.09239239 0.09041242]\n",
            " [0.13613823 0.11589173 0.09990533 0.09561177 0.09451851 0.09313484\n",
            "  0.09205063 0.09152158 0.09145974 0.08976758]\n",
            " [0.1390204  0.11394679 0.10029403 0.09454747 0.09414111 0.09320738\n",
            "  0.09201896 0.09160782 0.0911697  0.09004641]\n",
            " [0.12268637 0.11812288 0.09949172 0.09598787 0.09570937 0.09495543\n",
            "  0.09386134 0.09341761 0.09317895 0.0925884 ]\n",
            " [0.11522201 0.10869771 0.10425299 0.10174679 0.09862161 0.09762945\n",
            "  0.09581748 0.09348565 0.0927586  0.09176765]] [[0.19221878 0.09784383 0.08963636 0.08957554 0.08923525 0.08854745\n",
            "  0.08842815 0.08823875 0.08822448 0.08805135]\n",
            " [0.11539409 0.10904791 0.10234714 0.10070689 0.09962562 0.09711855\n",
            "  0.09595603 0.09456613 0.09366652 0.09157109]\n",
            " [0.11589902 0.11491495 0.10738936 0.10107232 0.09720412 0.09633563\n",
            "  0.09241604 0.09182198 0.09179646 0.09115013]\n",
            " [0.11951818 0.10833368 0.10711588 0.09994849 0.09823545 0.09602655\n",
            "  0.09344209 0.09324856 0.09276845 0.09136264]\n",
            " [0.11600425 0.10421543 0.10398513 0.09926617 0.09877275 0.09778262\n",
            "  0.09739378 0.09617388 0.09505376 0.09135223]\n",
            " [0.11857469 0.10661126 0.1019878  0.09983031 0.09922573 0.09874775\n",
            "  0.09660321 0.09393042 0.09363413 0.09085469]\n",
            " [0.13629879 0.09932628 0.09855013 0.09824003 0.09734751 0.0959255\n",
            "  0.09526379 0.09510257 0.09359585 0.09034953]\n",
            " [0.1166717  0.10794695 0.10213608 0.10188431 0.10099822 0.09603059\n",
            "  0.09559518 0.09504844 0.09319708 0.09049152]\n",
            " [0.10728315 0.1037925  0.10343576 0.10218531 0.10196406 0.10056645\n",
            "  0.09859848 0.09630246 0.0945216  0.09135017]\n",
            " [0.18254873 0.09307522 0.09207456 0.09193303 0.09161045 0.09072111\n",
            "  0.0906655  0.08960212 0.08930827 0.08846102]] [[0.11651556 0.11437199 0.11160105 0.09936865 0.09705305 0.09333326\n",
            "  0.09255443 0.09213877 0.09158062 0.09148257]\n",
            " [0.11088444 0.10870033 0.10675944 0.10344209 0.10087191 0.09622392\n",
            "  0.09453411 0.09344795 0.09310738 0.09202842]\n",
            " [0.10944903 0.10575333 0.10088027 0.10072865 0.09912886 0.09830763\n",
            "  0.0975268  0.09695422 0.09693255 0.09433866]\n",
            " [0.10834975 0.10484561 0.10161021 0.10110388 0.10089392 0.0985859\n",
            "  0.09677326 0.09623311 0.09595081 0.0956535 ]\n",
            " [0.11836878 0.10995642 0.10637329 0.10316958 0.10050903 0.09407511\n",
            "  0.09224288 0.09195571 0.09188712 0.09146208]\n",
            " [0.11637533 0.107494   0.10246739 0.10176704 0.10082836 0.09627321\n",
            "  0.0941247  0.09410713 0.09370921 0.0928537 ]\n",
            " [0.17207588 0.10849798 0.09107385 0.09054288 0.09051681 0.08970771\n",
            "  0.08961482 0.0895204  0.08928338 0.08916631]\n",
            " [0.11313932 0.10984481 0.10417305 0.1018426  0.10149228 0.09582976\n",
            "  0.09468491 0.09335858 0.09303081 0.09260397]\n",
            " [0.12644607 0.10036467 0.10026442 0.09970112 0.09940325 0.0972826\n",
            "  0.09482437 0.09429312 0.09427355 0.09314673]\n",
            " [0.1405463  0.1159537  0.10057663 0.09612732 0.09178676 0.09127815\n",
            "  0.09113301 0.09111058 0.0908433  0.09064425]] [[0.10564238 0.10292613 0.10179431 0.10042136 0.09872103 0.09872036\n",
            "  0.09871954 0.09819727 0.09806671 0.09679093]\n",
            " [0.12064464 0.10207136 0.10152597 0.10133596 0.09803465 0.09705557\n",
            "  0.09630508 0.09615217 0.09468193 0.09219266]\n",
            " [0.10665165 0.10452332 0.10275489 0.10125034 0.10006174 0.09947256\n",
            "  0.09891605 0.097019   0.09581892 0.0935316 ]\n",
            " [0.11108197 0.1069545  0.10360119 0.10301835 0.09847432 0.09757042\n",
            "  0.09722493 0.0958219  0.09537969 0.09087261]\n",
            " [0.10333292 0.10259257 0.10245122 0.10149055 0.1004594  0.09958882\n",
            "  0.09949169 0.09887893 0.09800059 0.09371338]\n",
            " [0.10969684 0.10169461 0.10050323 0.09977714 0.09924264 0.0991381\n",
            "  0.09875637 0.09777958 0.09685702 0.09655443]\n",
            " [0.10171361 0.10146581 0.10124384 0.10099129 0.09960892 0.09923731\n",
            "  0.09916671 0.09902416 0.09887232 0.098676  ]\n",
            " [0.10602034 0.10511005 0.10080007 0.10076638 0.09995149 0.09937529\n",
            "  0.09768594 0.09724063 0.09691003 0.09613974]\n",
            " [0.10654233 0.10577352 0.10148946 0.10047438 0.10002071 0.0985586\n",
            "  0.09784236 0.09719845 0.0961601  0.09594019]\n",
            " [0.10370079 0.10097425 0.10082368 0.10058665 0.10050481 0.09954733\n",
            "  0.09918906 0.09886386 0.09817427 0.0976353 ]] [[0.13101614 0.10155541 0.09949803 0.09879939 0.09736524 0.09523892\n",
            "  0.09497467 0.09472965 0.0946505  0.09217209]\n",
            " [0.16043125 0.09743757 0.09690606 0.09600316 0.09286897 0.09224714\n",
            "  0.09165689 0.09157068 0.09061959 0.09025875]\n",
            " [0.12229677 0.10795741 0.09818567 0.09794795 0.09757593 0.09644455\n",
            "  0.0955545  0.09544124 0.09520435 0.09339152]\n",
            " [0.14856924 0.10204253 0.10037015 0.09949326 0.09272838 0.09220155\n",
            "  0.09164988 0.09154554 0.09090395 0.0904955 ]\n",
            " [0.13742623 0.10216511 0.10204151 0.09627024 0.0957383  0.09423456\n",
            "  0.09366982 0.09324936 0.09266366 0.09254126]\n",
            " [0.10827874 0.10729821 0.10317886 0.10045856 0.09872456 0.09777663\n",
            "  0.09749199 0.09618194 0.09610833 0.09450217]\n",
            " [0.13456634 0.10423085 0.10157086 0.09865664 0.09621219 0.09613518\n",
            "  0.09293942 0.09284518 0.09169888 0.0911445 ]\n",
            " [0.15805185 0.09799827 0.09751602 0.09492274 0.09333222 0.09234674\n",
            "  0.0920763  0.0920596  0.09175216 0.0899441 ]\n",
            " [0.15166666 0.10440575 0.09550705 0.09392787 0.0938193  0.09349321\n",
            "  0.09203372 0.0918356  0.09167873 0.09163215]\n",
            " [0.10974686 0.10353356 0.10199118 0.10157139 0.10014214 0.09902046\n",
            "  0.09866758 0.09735171 0.09568052 0.09229465]] [[0.11696494 0.10561763 0.1026743  0.10018165 0.10010299 0.09984183\n",
            "  0.09757758 0.09490325 0.09146243 0.09067347]\n",
            " [0.12616728 0.10725618 0.10489378 0.10077072 0.09898864 0.09442478\n",
            "  0.09362216 0.09245644 0.09102614 0.09039382]\n",
            " [0.12389978 0.10335313 0.1023483  0.10156903 0.10070038 0.09829431\n",
            "  0.09435275 0.09222058 0.09215761 0.09110405]\n",
            " [0.13135895 0.11509195 0.09834989 0.09702215 0.09552077 0.09462588\n",
            "  0.09443802 0.09247658 0.09081339 0.09030242]\n",
            " [0.11786105 0.10425267 0.10283441 0.10009396 0.0991247  0.098704\n",
            "  0.09789151 0.09510923 0.09314692 0.09098157]\n",
            " [0.11120586 0.11066937 0.10239101 0.1016436  0.09920651 0.09874985\n",
            "  0.09706905 0.09613745 0.0918766  0.09105068]\n",
            " [0.11243922 0.11034236 0.1020238  0.10166942 0.09871032 0.09781794\n",
            "  0.0956016  0.09512395 0.09494527 0.09132624]\n",
            " [0.11789278 0.10887911 0.1030987  0.10161806 0.09805292 0.09680559\n",
            "  0.09550236 0.09425528 0.09290124 0.09099401]\n",
            " [0.10826562 0.10599791 0.10526626 0.10162396 0.10086945 0.09868338\n",
            "  0.09792026 0.09593145 0.09358449 0.09185722]\n",
            " [0.11110785 0.10693549 0.10325618 0.10216829 0.0989797  0.09897416\n",
            "  0.09823224 0.09677328 0.09239224 0.09118057]] [[0.13062459 0.12001117 0.10074113 0.09474252 0.09386603 0.09363971\n",
            "  0.09245858 0.09179718 0.0914835  0.09063558]\n",
            " [0.10933135 0.10389441 0.10218149 0.10083347 0.0987934  0.09805172\n",
            "  0.09762    0.09760492 0.09685692 0.09483222]\n",
            " [0.11850341 0.10194103 0.10119431 0.09937377 0.09878195 0.09761009\n",
            "  0.09628828 0.09560166 0.09553706 0.09516849]\n",
            " [0.1064885  0.10433034 0.10290188 0.10156679 0.1006103  0.09858835\n",
            "  0.09808301 0.09728806 0.09667599 0.09346682]\n",
            " [0.11237273 0.10942037 0.10832172 0.0995042  0.09650969 0.0957105\n",
            "  0.09499046 0.09493661 0.09430388 0.09392986]\n",
            " [0.10560665 0.10434524 0.10314914 0.10254232 0.1011281  0.09828933\n",
            "  0.09727395 0.09697267 0.09606361 0.094629  ]\n",
            " [0.12966645 0.11357925 0.11246008 0.09314593 0.09302556 0.09259983\n",
            "  0.09171455 0.09159797 0.091246   0.09096438]\n",
            " [0.11097045 0.10328139 0.10222587 0.10110361 0.10058366 0.09976029\n",
            "  0.09791066 0.09548536 0.09508933 0.09358936]\n",
            " [0.10964395 0.10826695 0.1075901  0.10601512 0.09815793 0.0960831\n",
            "  0.09551324 0.09348555 0.09266593 0.09257816]\n",
            " [0.12031083 0.11849108 0.11690799 0.09304062 0.09284412 0.09219547\n",
            "  0.09208853 0.0916934  0.09121756 0.09121044]] [[0.13884439 0.10810776 0.09679952 0.09505253 0.0942751  0.09378396\n",
            "  0.09362106 0.0932615  0.09313487 0.09311935]\n",
            " [0.12123885 0.11415909 0.097437   0.09722511 0.09567007 0.09557963\n",
            "  0.09503611 0.09490646 0.09468962 0.09405799]\n",
            " [0.132849   0.12850621 0.09917664 0.09285689 0.0927122  0.0919118\n",
            "  0.09117553 0.0905907  0.09016381 0.09005725]\n",
            " [0.1297989  0.12024375 0.1006963  0.09401721 0.09367883 0.09252627\n",
            "  0.09244621 0.09233411 0.09221454 0.09204385]\n",
            " [0.12638246 0.12465423 0.099479   0.09614468 0.09545842 0.09220749\n",
            "  0.09193899 0.09154938 0.0913196  0.09086577]\n",
            " [0.13141826 0.12846188 0.09653927 0.09354375 0.09281931 0.09193935\n",
            "  0.09180678 0.09180298 0.09110983 0.09055864]\n",
            " [0.1273724  0.11926056 0.09824953 0.09632255 0.09553046 0.09303466\n",
            "  0.09287931 0.09279443 0.09237044 0.09218565]\n",
            " [0.12697604 0.1178524  0.10446963 0.09399208 0.09357508 0.09352376\n",
            "  0.09327863 0.09295432 0.09214232 0.0912357 ]\n",
            " [0.11518867 0.11475074 0.1059187  0.10441453 0.09405647 0.09398486\n",
            "  0.09382902 0.09279858 0.09260277 0.09245568]\n",
            " [0.15028572 0.10757346 0.09661791 0.0938767  0.09353498 0.09265015\n",
            "  0.09182073 0.09176069 0.09112944 0.09075014]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open( \"/./content/model/softmax_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "xhGzU2ZG_t3b",
        "outputId": "54c8137e-eff2-4565-b7b1-e1c1542b0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792055 0.09109741 0.09164357 0.09009392 0.09632883 0.09540311\n",
            "  0.107494   0.09258842 0.09229336 0.09513694]\n",
            " [0.12004586 0.10268968 0.10120098 0.09575053 0.09583508 0.09709172\n",
            "  0.10565752 0.09385469 0.09336554 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185757 0.09137529 0.09854478 0.09584679 0.0948494\n",
            "  0.09615591 0.13286738 0.09898278 0.10326968]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519613 0.09198768 0.10206269 0.10524758 0.0930215  0.09916256\n",
            "  0.09589189 0.09563526 0.09920019 0.12259457]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.09578589 0.0992849  0.10167923 0.10000082 0.09617375 0.10027704\n",
            "  0.09772886 0.09770505 0.10102018 0.11034424]\n",
            " [0.09562298 0.09995811 0.10516494 0.10018844 0.09989404 0.10063305\n",
            "  0.10060379 0.09528878 0.10368127 0.09896457]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908457 0.09758333 0.09906299 0.10445354 0.09140754 0.09558626\n",
            "  0.09211904 0.0961072  0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.10933199 0.09290536 0.09061925 0.0915818  0.1083897  0.10396454\n",
            "  0.11106926 0.09214136 0.09332465 0.10667202]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639788 0.09716938 0.10112503 0.09205169 0.09254691\n",
            "  0.09353665 0.11844435 0.09588612 0.09893835]\n",
            " [0.11324794 0.09464014 0.0913378  0.09244198 0.10467927 0.10152824\n",
            "  0.10341783 0.09349848 0.09656344 0.10864485]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.0949479  0.11661825 0.09678788 0.11136506 0.0926588  0.09223205\n",
            "  0.09243153 0.09768786 0.09655614 0.10871448]\n",
            " [0.1353592  0.0939795  0.09070874 0.09086874 0.0966881  0.0970429\n",
            "  0.10957499 0.09208083 0.09304921 0.10064787]] [[0.09431619 0.09845076 0.10366833 0.09264354 0.10065788 0.09556752\n",
            "  0.0943088  0.09483398 0.09996308 0.12558992]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113407 0.09302621 0.09096655 0.09999189 0.09347371\n",
            "  0.11838868 0.09693877 0.09442223 0.13122699]\n",
            " [0.11642858 0.09614605 0.11028486 0.09684824 0.09834424 0.09758888\n",
            "  0.10202176 0.09558548 0.09193078 0.09482107]\n",
            " [0.09292267 0.1023618  0.13121082 0.11401133 0.0915777  0.09347839\n",
            "  0.09219654 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024093 0.0939927  0.09598744 0.09817804 0.09449788 0.09892205\n",
            "  0.10337377 0.11268519 0.0930849  0.11903711]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152159 0.09205063 0.09145974 0.09561178 0.09990533\n",
            "  0.09451851 0.11589174 0.09313484 0.13613825]\n",
            " [0.09160781 0.09116969 0.09004641 0.09201896 0.09454746 0.0941411\n",
            "  0.10029402 0.11394678 0.09320737 0.13902038]\n",
            " [0.09258841 0.09495544 0.09341762 0.09949172 0.09386135 0.09570938\n",
            "  0.09598789 0.11812289 0.09317896 0.12268639]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.0904915  0.10794695 0.10099821 0.09559517 0.1166717  0.10213607\n",
            "  0.1018843  0.09319707 0.09603058 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912887 0.10944904 0.09433867 0.10088028 0.09830764 0.0975268\n",
            "  0.10072865 0.09693256 0.09695423 0.10575334]\n",
            " [0.10161023 0.09677327 0.10834976 0.10484561 0.10110389 0.09623312\n",
            "  0.0985859  0.0956535  0.09595082 0.10089393]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246737 0.10176703 0.09412469 0.10082835 0.0937092  0.09410712\n",
            "  0.0928537  0.11637531 0.0962732  0.10749398]\n",
            " [0.17207587 0.08952039 0.08916631 0.0897077  0.09107384 0.08961482\n",
            "  0.0905168  0.09054288 0.08928337 0.10849796]\n",
            " [0.1098448  0.10417304 0.0930308  0.0946849  0.09335857 0.09582975\n",
            "  0.09260397 0.10184258 0.10149226 0.11313931]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.14054629 0.09064424 0.09111057 0.0908433  0.09612731 0.09127814\n",
            "  0.10057662 0.09178675 0.091133   0.11595369]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665164 0.10275488 0.09353159 0.10125034 0.09947255 0.10006173\n",
            "  0.09701899 0.09581891 0.09891603 0.10452331]\n",
            " [0.11108198 0.09722494 0.09757043 0.09087262 0.09847433 0.10360121\n",
            "  0.09582192 0.10695451 0.0953797  0.10301836]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654232 0.1000207  0.09855858 0.09616009 0.10047437 0.09784234\n",
            "  0.09719844 0.10148945 0.09594018 0.1057735 ]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743756 0.16043124 0.09025874 0.09600315 0.09286896 0.09061958\n",
            "  0.09224714 0.09157067 0.09165689 0.09690605]\n",
            " [0.12229678 0.09520435 0.10795742 0.09818569 0.09339153 0.09644455\n",
            "  0.09794796 0.09544125 0.09757594 0.09555452]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872455 0.09450217 0.09777661 0.10317885 0.09749197 0.09618193\n",
            "  0.09610832 0.10827873 0.10045855 0.1072982 ]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.08994411 0.09333223 0.09175216 0.09207631\n",
            "  0.09234674 0.15805186 0.09799828 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077073 0.1048938  0.1072562  0.09898866 0.09102615 0.09362218\n",
            "  0.09039383 0.09442478 0.09245645 0.1261673 ]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135894 0.09834988 0.09081338 0.09247658\n",
            "  0.09030242 0.09443802 0.09552076 0.11509194]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290123 0.09680557 0.11789276 0.10161805 0.09425527 0.0980529\n",
            "  0.090994   0.10309868 0.09550235 0.1088791 ]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062458 0.09245858 0.0914835  0.09386603 0.10074112 0.09363971\n",
            "  0.12001116 0.09063558 0.09179717 0.09474251]\n",
            " [0.09483223 0.09760492 0.10083348 0.10933136 0.1021815  0.09805173\n",
            "  0.09762    0.09685693 0.10389443 0.09879342]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123886 0.11415911 0.09557965 0.09490647 0.09503613 0.09567008\n",
            "  0.09722512 0.09468964 0.09405801 0.09743701]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024376 0.09221455 0.09204386 0.12979892 0.09252628 0.09244622\n",
            "  0.09233411 0.09401721 0.09367883 0.10069631]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.0928193  0.09193934 0.09055864 0.09180677 0.09110983\n",
            "  0.09180297 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697606 0.0912357  0.09214232 0.09352377 0.09357508 0.09295433\n",
            "  0.09327864 0.1178524  0.09399209 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 정렬된 데이터와 원래 인덱스 로드\n",
        "sorted_file_path3 = \"./model/sorted_attention_scores.pkl\"\n",
        "indices_file_path3 = \"./model/original_indices.pkl\"\n",
        "restored_file_path3 = \"./model/restored_softmax.pkl\"\n",
        "\n",
        "with open(sorted_file_path3, \"rb\") as f:\n",
        "    sorted_attention_scores = pickle.load(f)\n",
        "\n",
        "with open(indices_file_path3, \"rb\") as f:\n",
        "    original_indices = pickle.load(f)\n",
        "\n",
        "# 2. 원래 순서로 복원\n",
        "restored_attention_scores = np.zeros_like(sorted_attention_scores)\n",
        "for i in range(sorted_attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(sorted_attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(sorted_attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 순서로 복원\n",
        "            inverse_indices = np.argsort(original_indices[i, j, k])  # 원래 순서 찾기\n",
        "            restored_attention_scores[i, j, k] = sorted_attention_scores[i, j, k][inverse_indices]\n",
        "\n",
        "# 3. 복원된 결과를 새로운 파일에 저장\n",
        "with open(restored_file_path3, \"wb\") as f:\n",
        "    pickle.dump(restored_attention_scores, f)\n",
        "\n",
        "print(f\"복원된 softmax attention_scores가 {restored_file_path3}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "MIofHJFRCG0b",
        "outputId": "ea3b115a-5c7c-49f1-89e6-6715fa22bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복원된 softmax attention_scores가 ./model/restored_softmax.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/restored_softmax_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "BIQ4u34qCk1E",
        "outputId": "b31e641a-a68a-4c58-f0ea-68cecc2a221f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.0910974  0.09164356 0.0900939  0.09632882 0.0954031\n",
            "  0.10749399 0.09258841 0.09229334 0.09513693]\n",
            " [0.12004588 0.10268969 0.10120098 0.09575053 0.0958351  0.09709173\n",
            "  0.10565753 0.0938547  0.09336555 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185758 0.0913753  0.09854479 0.0958468  0.09484941\n",
            "  0.09615592 0.1328674  0.09898279 0.10326969]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519612 0.09198767 0.10206269 0.10524756 0.09302149 0.09916254\n",
            "  0.09589188 0.09563524 0.09920018 0.12259456]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.0957859  0.09928491 0.10167924 0.10000083 0.09617376 0.10027704\n",
            "  0.09772887 0.09770507 0.10102019 0.11034425]\n",
            " [0.09562299 0.09995812 0.10516495 0.10018845 0.09989405 0.10063306\n",
            "  0.1006038  0.09528879 0.10368128 0.09896458]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908456 0.09758332 0.09906299 0.10445353 0.09140754 0.09558626\n",
            "  0.09211903 0.09610719 0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.109332   0.09290537 0.09061927 0.09158181 0.10838971 0.10396456\n",
            "  0.11106927 0.09214137 0.09332467 0.10667203]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639787 0.09716936 0.10112502 0.09205168 0.0925469\n",
            "  0.09353664 0.11844434 0.0958861  0.09893835]\n",
            " [0.11324795 0.09464015 0.09133781 0.09244199 0.10467929 0.10152826\n",
            "  0.10341784 0.0934985  0.09656344 0.10864487]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.09494792 0.11661826 0.09678789 0.11136508 0.09265881 0.09223206\n",
            "  0.09243154 0.09768787 0.09655615 0.10871449]\n",
            " [0.13535918 0.0939795  0.09070873 0.09086873 0.09668809 0.09704289\n",
            "  0.10957498 0.09208082 0.0930492  0.10064787]] [[0.09431619 0.09845075 0.10366833 0.09264354 0.10065787 0.09556752\n",
            "  0.09430879 0.09483397 0.09996307 0.1255899 ]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113406 0.09302619 0.09096654 0.09999187 0.0934737\n",
            "  0.11838867 0.09693875 0.09442222 0.13122697]\n",
            " [0.11642858 0.09614606 0.11028487 0.09684826 0.09834425 0.09758889\n",
            "  0.10202178 0.0955855  0.09193079 0.09482107]\n",
            " [0.09292267 0.10236181 0.13121082 0.11401134 0.09157771 0.09347839\n",
            "  0.09219655 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024091 0.0939927  0.09598743 0.09817803 0.09449787 0.09892204\n",
            "  0.10337377 0.11268517 0.09308489 0.1190371 ]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152158 0.09205063 0.09145974 0.09561177 0.09990533\n",
            "  0.09451851 0.11589173 0.09313484 0.13613823]\n",
            " [0.09160782 0.0911697  0.09004641 0.09201896 0.09454747 0.09414111\n",
            "  0.10029403 0.11394679 0.09320738 0.1390204 ]\n",
            " [0.0925884  0.09495543 0.09341761 0.09949172 0.09386134 0.09570937\n",
            "  0.09598787 0.11812288 0.09317895 0.12268637]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.09049152 0.10794695 0.10099822 0.09559518 0.1166717  0.10213608\n",
            "  0.10188431 0.09319708 0.09603059 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912886 0.10944903 0.09433866 0.10088027 0.09830763 0.0975268\n",
            "  0.10072865 0.09693255 0.09695422 0.10575333]\n",
            " [0.10161021 0.09677326 0.10834975 0.10484561 0.10110388 0.09623311\n",
            "  0.0985859  0.0956535  0.09595081 0.10089392]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246739 0.10176704 0.0941247  0.10082836 0.09370921 0.09410713\n",
            "  0.0928537  0.11637533 0.09627321 0.107494  ]\n",
            " [0.17207588 0.0895204  0.08916631 0.08970771 0.09107385 0.08961482\n",
            "  0.09051681 0.09054288 0.08928338 0.10849798]\n",
            " [0.10984481 0.10417305 0.09303081 0.09468491 0.09335858 0.09582976\n",
            "  0.09260397 0.1018426  0.10149228 0.11313932]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.1405463  0.09064425 0.09111058 0.0908433  0.09612732 0.09127815\n",
            "  0.10057663 0.09178676 0.09113301 0.1159537 ]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665165 0.10275489 0.0935316  0.10125034 0.09947256 0.10006174\n",
            "  0.097019   0.09581892 0.09891605 0.10452332]\n",
            " [0.11108197 0.09722493 0.09757042 0.09087261 0.09847432 0.10360119\n",
            "  0.0958219  0.1069545  0.09537969 0.10301835]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654233 0.10002071 0.0985586  0.0961601  0.10047438 0.09784236\n",
            "  0.09719845 0.10148946 0.09594019 0.10577352]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743757 0.16043125 0.09025875 0.09600316 0.09286897 0.09061959\n",
            "  0.09224714 0.09157068 0.09165689 0.09690606]\n",
            " [0.12229677 0.09520435 0.10795741 0.09818567 0.09339152 0.09644455\n",
            "  0.09794795 0.09544124 0.09757593 0.0955545 ]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872456 0.09450217 0.09777663 0.10317886 0.09749199 0.09618194\n",
            "  0.09610833 0.10827874 0.10045856 0.10729821]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.0899441  0.09333222 0.09175216 0.0920763\n",
            "  0.09234674 0.15805185 0.09799827 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077072 0.10489378 0.10725618 0.09898864 0.09102614 0.09362216\n",
            "  0.09039382 0.09442478 0.09245644 0.12616728]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135895 0.09834989 0.09081339 0.09247658\n",
            "  0.09030242 0.09443802 0.09552077 0.11509195]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290124 0.09680559 0.11789278 0.10161806 0.09425528 0.09805292\n",
            "  0.09099401 0.1030987  0.09550236 0.10887911]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062459 0.09245858 0.0914835  0.09386603 0.10074113 0.09363971\n",
            "  0.12001117 0.09063558 0.09179718 0.09474252]\n",
            " [0.09483222 0.09760492 0.10083347 0.10933135 0.10218149 0.09805172\n",
            "  0.09762    0.09685692 0.10389441 0.0987934 ]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123885 0.11415909 0.09557963 0.09490646 0.09503611 0.09567007\n",
            "  0.09722511 0.09468962 0.09405799 0.097437  ]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024375 0.09221454 0.09204385 0.1297989  0.09252627 0.09244621\n",
            "  0.09233411 0.09401721 0.09367883 0.1006963 ]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.09281931 0.09193935 0.09055864 0.09180678 0.09110983\n",
            "  0.09180298 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697604 0.0912357  0.09214232 0.09352376 0.09357508 0.09295432\n",
            "  0.09327863 0.1178524  0.09399208 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_text_file(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    # 데이터 전처리: 불필요한 문자 제거 및 정리\n",
        "    data = data.replace(\"\\n\", \" \")  # 줄바꿈 제거\n",
        "    data = data.replace(\"[\", \"\").replace(\"]\", \"\")  # 대괄호 제거\n",
        "    data = data.split()  # 공백 기준으로 나눔\n",
        "\n",
        "    # 문자열을 float으로 변환\n",
        "    try:\n",
        "        data_list = [float(value) for value in data]\n",
        "        return np.array(data_list)  # numpy 배열로 변환\n",
        "    except ValueError as e:\n",
        "        print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "        raise\n",
        "\n",
        "# 두 파일의 데이터 읽기\n",
        "try:\n",
        "    restored_data = parse_text_file('./model/softmax_sorted_attention_scores_2.txt')\n",
        "    original_data = parse_text_file('./model/sorted_SM_bert_2.txt')\n",
        "\n",
        "    # 데이터 형태 확인\n",
        "    print(f\"Restored data shape: {restored_data.shape}\")\n",
        "    print(f\"Original data shape: {original_data.shape}\")\n",
        "\n",
        "    # 데이터 값 하나하나 비교\n",
        "    if np.array_equal(restored_data, original_data):\n",
        "        print(\"두 데이터는 형태와 값이 모두 동일합니다.\")\n",
        "    else:\n",
        "        print(\"데이터에 차이가 있습니다.\")\n",
        "\n",
        "        # 값이 다를 경우, 차이를 확인\n",
        "        differences = np.where(restored_data != original_data)\n",
        "        print(f\"값이 다른 위치: {differences}\")\n",
        "        print(f\"Restored data at differences: {restored_data[differences]}\")\n",
        "        print(f\"Original data at differences: {original_data[differences]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"파일 처리 중 오류 발생: {e}\")\n"
      ],
      "metadata": {
        "id": "NqnBhDHgkSWH",
        "outputId": "cd3e5a3e-916f-4b3b-eb9d-8fbade4e35ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored data shape: (1200,)\n",
            "Original data shape: (1200,)\n",
            "데이터에 차이가 있습니다.\n",
            "값이 다른 위치: (array([   0,    1,    2,   10,   12,   21,   22,   25,   27,   30,   31,\n",
            "         32,   36,   40,   41,   42,   43,   44,   45,   46,   50,   51,\n",
            "         56,   57,   60,   61,   62,   64,   65,   71,   72,   74,   76,\n",
            "         78,   84,   91,  100,  101,  102,  103,  105,  106,  107,  108,\n",
            "        113,  120,  121,  122,  123,  124,  125,  127,  132,  133,  137,\n",
            "        139,  140,  141,  142,  144,  145,  151,  154,  160,  162,  164,\n",
            "        165,  166,  168,  171,  174,  181,  182,  183,  184,  185,  188,\n",
            "        190,  192,  193,  194,  196,  197,  198,  202,  203,  212,  222,\n",
            "        231,  232,  235,  239,  240,  241,  242,  243,  251,  253,  256,\n",
            "        257,  260,  261,  264,  270,  271,  272,  273,  274,  275,  276,\n",
            "        277,  278,  279,  282,  300,  301,  302,  305,  306,  307,  310,\n",
            "        311,  312,  315,  316,  321,  322,  323,  330,  331,  332,  333,\n",
            "        338,  339,  341,  345,  351,  353,  356,  362,  364,  365,  367,\n",
            "        375,  381,  382,  386,  387,  388,  390,  391,  393,  394,  403,\n",
            "        410,  411,  412,  413,  414,  415,  420,  421,  422,  424,  425,\n",
            "        426,  428,  430,  431,  434,  441,  442,  451,  461,  463,  469,\n",
            "        470,  471,  472,  473,  484,  491,  494,  500,  507,  513,  514,\n",
            "        521,  523,  534,  542,  543,  552,  554,  560,  561,  562,  563,\n",
            "        565,  566,  567,  568,  571,  573,  578,  580,  581,  582,  583,\n",
            "        584,  585,  586,  588,  591,  593,  600,  602,  603,  605,  614,\n",
            "        616,  620,  621,  622,  623,  624,  625,  627,  630,  631,  632,\n",
            "        633,  634,  640,  642,  644,  645,  661,  662,  665,  670,  671,\n",
            "        675,  676,  679,  683,  689,  692,  694,  696,  701,  703,  704,\n",
            "        707,  708,  710,  711,  712,  713,  714,  715,  716,  717,  719,\n",
            "        722,  723,  725,  728,  729,  730,  731,  732,  733,  735,  739,\n",
            "        743,  744,  745,  748,  750,  751,  752,  753,  754,  755,  756,\n",
            "        757,  758,  759,  760,  762,  763,  764,  766,  767,  769,  770,\n",
            "        773,  775,  776,  777,  781,  782,  783,  786,  790,  791,  792,\n",
            "        793,  794,  796,  797,  800,  801,  802,  803,  804,  807,  810,\n",
            "        811,  812,  813,  815,  818,  826,  830,  831,  833,  837,  849,\n",
            "        851,  852,  855,  856,  863,  864,  868,  870,  871,  872,  873,\n",
            "        877,  880,  881,  882,  883,  884,  885,  887,  894,  896,  897,\n",
            "        899,  900,  901,  904,  905,  908,  912,  913,  920,  921,  922,\n",
            "        923,  925,  929,  930,  933,  935,  937,  938,  943,  944,  946,\n",
            "        951,  958,  960,  962,  963,  964,  965,  969,  970,  971,  972,\n",
            "        973,  974,  975,  976,  985,  991,  994,  996, 1000, 1001, 1012,\n",
            "       1013, 1016, 1017, 1018, 1020, 1023, 1024, 1025, 1026, 1027, 1028,\n",
            "       1029, 1035, 1041, 1042, 1043, 1045, 1053, 1054, 1062, 1067, 1071,\n",
            "       1072, 1073, 1074, 1076, 1082, 1090, 1091, 1092, 1093, 1094, 1097,\n",
            "       1099, 1100, 1101, 1105, 1109, 1112, 1123, 1130, 1132, 1133, 1134,\n",
            "       1136, 1143, 1150, 1152, 1156, 1160, 1161, 1165, 1167, 1180, 1181,\n",
            "       1184, 1186, 1189, 1191]),)\n",
            "Restored data at differences: [0.52837735 0.14622849 0.12802094 0.59860635 0.08261914 0.21865611\n",
            " 0.1090568  0.03270087 0.02435579 0.669667   0.15477407 0.07847571\n",
            " 0.01069175 0.39969283 0.26201427 0.08347073 0.07126267 0.06900645\n",
            " 0.04055686 0.0337236  0.2187059  0.21677174 0.05442105 0.05174557\n",
            " 0.35450202 0.24281408 0.1047144  0.05489547 0.05246472 0.21439777\n",
            " 0.15665188 0.09266932 0.02581641 0.01836554 0.04999033 0.20655645\n",
            " 0.27761808 0.14469248 0.10874643 0.10097665 0.09415241 0.06689177\n",
            " 0.05368271 0.0356874  0.10470253 0.33725736 0.13576876 0.10322648\n",
            " 0.08901375 0.07730427 0.07099047 0.05898388 0.09529836 0.08528562\n",
            " 0.06378165 0.04553427 0.19012696 0.18000863 0.1691627  0.10327026\n",
            " 0.09034337 0.13416518 0.11514391 0.16616797 0.11066904 0.10017121\n",
            " 0.09394464 0.08270625 0.06784825 0.13758077 0.09883608 0.14077887\n",
            " 0.11384703 0.10731426 0.10706155 0.10506248 0.05274922 0.20915571\n",
            " 0.12079702 0.11930476 0.10975596 0.06445802 0.05797385 0.05027522\n",
            " 0.15359116 0.09426141 0.1789386  0.17485866 0.20774248 0.07020905\n",
            " 0.02488566 0.0069332  0.4483548  0.25610855 0.11616845 0.05915995\n",
            " 0.2591846  0.11820098 0.02244379 0.01493835 0.2509315  0.16767997\n",
            " 0.07178206 0.18211861 0.17483069 0.13898772 0.10721941 0.09105612\n",
            " 0.08440003 0.06384121 0.0596569  0.05096523 0.04692417 0.13254707\n",
            " 0.17345521 0.14967586 0.14472926 0.09729832 0.06519037 0.06048183\n",
            " 0.48765132 0.10237034 0.08777373 0.06065432 0.04793502 0.15283686\n",
            " 0.1310454  0.11628375 0.2399773  0.21243756 0.15876156 0.12853605\n",
            " 0.02358991 0.01966718 0.21156263 0.06478479 0.15371567 0.10363796\n",
            " 0.07233742 0.144755   0.12787814 0.08832397 0.03546436 0.07520694\n",
            " 0.13114852 0.12287569 0.08313145 0.081628   0.08090257 0.17079811\n",
            " 0.14316145 0.12002222 0.11659815 0.027266   0.699621   0.09142186\n",
            " 0.08682219 0.04493132 0.02208557 0.02016141 0.2960213  0.1397882\n",
            " 0.10450712 0.09084274 0.08885835 0.0664221  0.04091182 0.8076041\n",
            " 0.07591385 0.01718501 0.17341247 0.16316602 0.21419172 0.23664407\n",
            " 0.09103498 0.01726804 0.2109127  0.20034795 0.15953279 0.15764718\n",
            " 0.04567051 0.17826031 0.08731563 0.817817   0.00705368 0.11426104\n",
            " 0.10335509 0.22360915 0.07233716 0.0977328  0.15294491 0.13393198\n",
            " 0.11204894 0.10486991 0.15772055 0.15036172 0.14518489 0.14235465\n",
            " 0.09850053 0.08108556 0.04620931 0.03903242 0.21086536 0.13009691\n",
            " 0.02615291 0.15756966 0.14028054 0.1342441  0.12262746 0.10083228\n",
            " 0.0910212  0.08960975 0.07078877 0.09616268 0.06904632 0.30353034\n",
            " 0.24933638 0.04134365 0.0325757  0.10259051 0.09312712 0.18272899\n",
            " 0.14566234 0.14417833 0.14060499 0.10294528 0.09367248 0.06561077\n",
            " 0.21080445 0.18121335 0.17259824 0.11862965 0.10591871 0.3420291\n",
            " 0.0890731  0.07372274 0.06479937 0.15421888 0.12289774 0.09839239\n",
            " 0.17928226 0.16688584 0.08407862 0.07109627 0.04287465 0.09967152\n",
            " 0.05051371 0.14647162 0.02706973 0.0218764  0.1119823  0.11100604\n",
            " 0.10854257 0.08193889 0.07433476 0.20656607 0.15580031 0.1333135\n",
            " 0.09872989 0.0941653  0.07796247 0.06559978 0.06036348 0.05117705\n",
            " 0.1381084  0.10463523 0.08193705 0.06104058 0.02470827 0.20669404\n",
            " 0.16135015 0.13124843 0.10263912 0.07436839 0.05080836 0.12196275\n",
            " 0.10419733 0.10145807 0.08069363 0.11766883 0.11731818 0.11080629\n",
            " 0.11068872 0.10513055 0.09576281 0.08985044 0.0892885  0.08720491\n",
            " 0.07628079 0.19142638 0.10405412 0.08892288 0.08604647 0.07399796\n",
            " 0.06978021 0.06591645 0.15916045 0.12638603 0.10259225 0.0866404\n",
            " 0.08371166 0.11653509 0.10817669 0.1060553  0.09148511 0.12899478\n",
            " 0.10935357 0.10360527 0.10059211 0.09944329 0.09684331 0.0946543\n",
            " 0.32052314 0.3106711  0.06992378 0.06803015 0.05989642 0.03790188\n",
            " 0.38911515 0.2318588  0.12281422 0.07941024 0.04010713 0.01522333\n",
            " 0.03470233 0.36820278 0.27255395 0.07846794 0.02008597 0.02551285\n",
            " 0.23727559 0.12425505 0.07217833 0.05358112 0.09863728 0.09045879\n",
            " 0.05536916 0.38324448 0.18126372 0.13421565 0.10852906 0.03013357\n",
            " 0.22098409 0.16911836 0.15667981 0.13899091 0.09136322 0.0678046\n",
            " 0.04678694 0.07392143 0.061044   0.04430872 0.03711633 0.32245672\n",
            " 0.11816898 0.10154389 0.09569555 0.04516599 0.12593834 0.11838617\n",
            " 0.21004221 0.19937786 0.13601878 0.106469   0.08533786 0.01391231\n",
            " 0.21574429 0.11304038 0.06052643 0.04372811 0.0424815  0.10304777\n",
            " 0.09521512 0.06009609 0.13113172 0.03579707 0.1880343  0.15221152\n",
            " 0.12106892 0.11783196 0.08506133 0.01689019 0.23940286 0.14780323\n",
            " 0.14295705 0.12018654 0.10741436 0.08862209 0.08015427 0.10289833\n",
            " 0.1478222  0.10129215 0.08277145 0.73495495 0.07021614 0.12961586\n",
            " 0.12555788 0.07522292 0.07171068 0.05584679 0.18773967 0.11383611\n",
            " 0.11279432 0.10771273 0.09650943 0.05880833 0.03815652 0.03798618\n",
            " 0.07842355 0.16973065 0.14031349 0.13712397 0.07271752 0.06155465\n",
            " 0.05334687 0.13864833 0.03649454 0.15865861 0.14177158 0.12433877\n",
            " 0.10597337 0.04108367 0.13009368 0.40604967 0.27261236 0.06234813\n",
            " 0.04973195 0.03981537 0.03298335 0.02912592 0.48960426 0.20841889\n",
            " 0.04207087 0.02738602 0.10371896 0.0872578  0.5683163  0.08492316\n",
            " 0.05338537 0.05010207 0.02523821 0.04290464 0.45027953 0.04690137\n",
            " 0.02055438 0.31552538 0.2579293  0.04491894 0.03080445 0.4284722\n",
            " 0.1861072  0.05017954 0.04047512 0.01391816 0.19304998]\n",
            "Original data at differences: [0.5283773  0.14622848 0.12802093 0.5986064  0.08261915 0.2186561\n",
            " 0.10905681 0.03270088 0.02435578 0.66966695 0.15477404 0.0784757\n",
            " 0.01069174 0.3996929  0.2620143  0.08347075 0.07126268 0.06900646\n",
            " 0.04055687 0.03372361 0.21870588 0.21677172 0.05442104 0.05174556\n",
            " 0.35450205 0.24281411 0.10471441 0.05489548 0.05246473 0.21439776\n",
            " 0.15665187 0.09266931 0.0258164  0.01836555 0.04999034 0.20655647\n",
            " 0.2776181  0.1446925  0.10874645 0.10097667 0.09415242 0.06689178\n",
            " 0.05368272 0.03568741 0.10470254 0.3372574  0.13576879 0.10322649\n",
            " 0.08901376 0.07730429 0.07099048 0.05898389 0.09529835 0.08528563\n",
            " 0.06378164 0.04553426 0.19012694 0.18000862 0.16916269 0.10327027\n",
            " 0.09034336 0.13416517 0.11514392 0.16616796 0.11066903 0.1001712\n",
            " 0.09394463 0.08270624 0.06784824 0.13758078 0.09883609 0.1407789\n",
            " 0.11384704 0.10731427 0.10706156 0.10506249 0.05274923 0.2091557\n",
            " 0.12079701 0.11930475 0.10975597 0.06445801 0.05797384 0.05027521\n",
            " 0.15359114 0.0942614  0.17893858 0.17485864 0.20774251 0.07020906\n",
            " 0.02488567 0.00693321 0.44835484 0.25610858 0.11616847 0.05915996\n",
            " 0.25918457 0.11820097 0.0224438  0.01493836 0.25093147 0.16767995\n",
            " 0.07178205 0.18211858 0.17483066 0.1389877  0.1072194  0.09105611\n",
            " 0.08440001 0.0638412  0.05965689 0.05096522 0.04692416 0.13254708\n",
            " 0.17345522 0.14967588 0.14472927 0.09729833 0.06519038 0.06048184\n",
            " 0.48765135 0.10237035 0.08777374 0.06065433 0.04793503 0.15283684\n",
            " 0.13104539 0.11628374 0.23997733 0.21243758 0.15876158 0.12853606\n",
            " 0.02358992 0.01966719 0.21156266 0.0647848  0.15371569 0.10363797\n",
            " 0.07233743 0.14475499 0.12787813 0.08832395 0.03546437 0.07520693\n",
            " 0.1311485  0.12287568 0.08313146 0.08162799 0.08090258 0.1707981\n",
            " 0.14316143 0.12002221 0.11659814 0.02726601 0.69962096 0.09142184\n",
            " 0.08682218 0.04493131 0.02208556 0.0201614  0.29602128 0.13978818\n",
            " 0.1045071  0.09084273 0.08885834 0.06642209 0.04091181 0.807604\n",
            " 0.07591384 0.017185   0.1734125  0.163166   0.2141917  0.23664406\n",
            " 0.09103497 0.01726803 0.21091267 0.20034792 0.15953277 0.15764716\n",
            " 0.04567052 0.17826033 0.08731562 0.8178169  0.00705367 0.11426105\n",
            " 0.1033551  0.22360913 0.07233715 0.09773281 0.15294492 0.133932\n",
            " 0.11204895 0.10486992 0.15772054 0.1503617  0.14518486 0.14235464\n",
            " 0.09850051 0.08108555 0.04620929 0.03903241 0.21086535 0.1300969\n",
            " 0.0261529  0.15756969 0.14028057 0.13424411 0.12262748 0.10083229\n",
            " 0.09102122 0.08960976 0.07078879 0.09616266 0.06904631 0.3035303\n",
            " 0.24933636 0.04134364 0.03257569 0.1025905  0.09312713 0.18272896\n",
            " 0.14566232 0.1441783  0.14060497 0.10294527 0.09367246 0.06561076\n",
            " 0.21080446 0.18121336 0.17259826 0.11862966 0.1059187  0.34202906\n",
            " 0.08907308 0.07372273 0.06479938 0.1542189  0.12289775 0.0983924\n",
            " 0.17928228 0.16688585 0.08407863 0.07109628 0.04287466 0.09967153\n",
            " 0.0505137  0.1464716  0.02706972 0.02187639 0.11198232 0.11100605\n",
            " 0.10854258 0.0819389  0.07433478 0.20656608 0.15580034 0.13331352\n",
            " 0.0987299  0.09416532 0.07796248 0.0655998  0.06036349 0.05117706\n",
            " 0.13810842 0.10463522 0.08193706 0.06104059 0.02470826 0.20669405\n",
            " 0.16135018 0.13124844 0.10263914 0.0743684  0.05080837 0.12196276\n",
            " 0.10419735 0.10145809 0.08069364 0.11766881 0.11731817 0.11080628\n",
            " 0.1106887  0.10513053 0.0957628  0.08985043 0.08928849 0.0872049\n",
            " 0.07628078 0.1914264  0.10405413 0.08892289 0.08604649 0.07399797\n",
            " 0.06978022 0.06591646 0.15916047 0.12638605 0.10259226 0.08664041\n",
            " 0.08371168 0.1165351  0.1081767  0.10605529 0.0914851  0.1289948\n",
            " 0.10935359 0.10360528 0.10059213 0.0994433  0.09684332 0.09465431\n",
            " 0.3205231  0.31067106 0.06992377 0.06803014 0.05989641 0.03790187\n",
            " 0.38911507 0.23185876 0.12281419 0.07941023 0.04010712 0.01522332\n",
            " 0.03470234 0.36820275 0.27255392 0.07846793 0.02008596 0.02551284\n",
            " 0.2372756  0.12425506 0.07217834 0.05358113 0.09863727 0.0904588\n",
            " 0.05536915 0.38324445 0.1812637  0.13421564 0.10852905 0.03013356\n",
            " 0.22098413 0.1691184  0.15667984 0.13899094 0.09136325 0.06780462\n",
            " 0.04678695 0.07392142 0.06104399 0.04430871 0.03711632 0.3224567\n",
            " 0.11816899 0.10154388 0.09569554 0.045166   0.12593833 0.11838616\n",
            " 0.2100422  0.19937783 0.13601877 0.10646899 0.08533785 0.0139123\n",
            " 0.2157443  0.1130404  0.06052644 0.04372812 0.04248151 0.10304776\n",
            " 0.09521511 0.0600961  0.13113174 0.03579708 0.18803431 0.15221153\n",
            " 0.12106893 0.11783197 0.08506135 0.0168902  0.23940288 0.14780325\n",
            " 0.14295706 0.12018657 0.10741437 0.0886221  0.08015428 0.10289832\n",
            " 0.14782219 0.10129216 0.08277144 0.7349549  0.07021615 0.12961587\n",
            " 0.12555787 0.07522293 0.07171067 0.0558468  0.18773969 0.1138361\n",
            " 0.11279433 0.10771274 0.09650944 0.05880834 0.03815653 0.03798619\n",
            " 0.07842356 0.16973063 0.1403135  0.13712396 0.07271751 0.06155464\n",
            " 0.05334686 0.13864832 0.03649453 0.1586586  0.1417716  0.12433876\n",
            " 0.10597336 0.04108366 0.1300937  0.40604973 0.2726124  0.06234814\n",
            " 0.04973197 0.03981538 0.03298336 0.02912593 0.4896042  0.20841888\n",
            " 0.04207086 0.02738601 0.10371897 0.08725781 0.5683162  0.08492315\n",
            " 0.05338536 0.05010206 0.0252382  0.04290465 0.4502796  0.04690138\n",
            " 0.02055439 0.31552535 0.25792927 0.04491893 0.03080444 0.42847222\n",
            " 0.18610723 0.05017955 0.04047513 0.01391817 0.19304997]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    음수의 경우 정수부를 내림하여 변환하고, 남은 값을 소수부로 변환.\n",
        "    \"\"\"\n",
        "    max_int_value = 2**(int_bits - 1) - 1  # 7비트 최대값 (63)\n",
        "    min_int_value = -2**(int_bits - 1)     # 7비트 최소값 (-64)\n",
        "    max_frac_value = 2**frac_bits           # 13비트 정밀도 (8192)\n",
        "\n",
        "    # ✅ 정수부 조정 (floor 적용하여 내림)\n",
        "    int_part = int(np.floor(value))\n",
        "    frac_part = abs(value - int_part)\n",
        "\n",
        "    # ✅ 정수부 범위 확인\n",
        "    if int_part < min_int_value or int_part > max_int_value:\n",
        "        raise ValueError(f\"정수부 {int_part}가 {min_int_value} ~ {max_int_value} 범위를 벗어남!\")\n",
        "\n",
        "    # ✅ 2의 보수 변환 (정수부 7비트)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 앞 12비트는 항상 0 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트, 항상 양수)\n",
        "    frac_binary = format(int(round(frac_part * max_frac_value)), f'0{frac_bits}b')\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "id": "gNlyfcx-D_Mi",
        "outputId": "27a8ec3b-924d-4dc5-bbf5-01d290e49526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output2.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjoyAYqcE8Rj",
        "outputId": "acc46891-cd75-4111-e2b4-252f19d78553"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output2.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/output.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "y9gvMWCUC7wz",
        "outputId": "03ce7d82-9770-4acd-afd6-5f56d6e16db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000000000000110111101010111 00000000000000000000001110111111 00000000000000000001001010111110 00000000000000000001010000101111 00000000000011111111011000011011 00000000000000000100011000111011\n",
            "00000000000011111111101101000000 00000000000000000000111111101101 00000000000000000100000111111001 00000000000000000010110011111000\n",
            "00000000000000000011010101110011 00000000000000000110101100010111 00000000000000001011100101100001 00000000000000001001001111011111 00000000000000000111101000000010 00000000000000000100101011110001\n",
            "00000000000000000011110001101001 00000000000000000100110001101111 00000000000000000011000110001100 00000000000000000011110100011101\n",
            "00000000000000000110101000100011 00000000000000001001000000011000 00000000000000000111100111010101 00000000000000001010011011001011 00000000000000000100100111011101 00000000000000000110000100011111\n",
            "00000000000000000100111101011010 00000000000000000011010111111111 00000000000000000101001101001010 00000000000000000011001000011001\n",
            "00000000000000000101001001001100 00000000000000001001010011100101 00000000000000001101100110000000 00000000000000000111100110100110 00000000000000001010101010100000 00000000000000000101010100011011\n",
            "00000000000000000101011100001010 00000000000000000100110101010101 00000000000000000100010110110110 00000000000000000110001101111010\n",
            "00000000000000000001010000000001 00000000000000001001010010001010 00000000000000000110100111011000 00000000000000001010001000001110 00000000000000000110101011100000 00000000000000000101100011010110\n",
            "00000000000000000011101111110011 00000000000000000110111111101111 00000000000000000100000011000001 00000000000000000101001011101111\n",
            "00000000000000000111111101011000 00000000000000000101001110100111 00000000000000000100100011010011 00000000000000000101110101111101 00000000000000000111000001100001 00000000000000000110011100001110\n",
            "00000000000000000110000101100010 00000000000000000101101111100000 00000000000000001000101000000000 00000000000000001000100110110111\n",
            "00000000000000000011100101111000 00000000000000000101010111101101 00000000000000000011010110011001 00000000000000000010101000110110 00000000000000001000010110000010 00000000000000000110101010011000\n",
            "00000000000000000100111100101100 00000000000000001001000110011110 00000000000000000101010001111010 00000000000000000110010110011100\n",
            "00000000000000000011010001110000 00000000000000000011100010001000 00000000000000000100001101000001 00000000000000000100001101101110 00000000000000000110110110001001 00000000000000000110110001010011\n",
            "00000000000000001000011100101011 00000000000000000101111011000000 00000000000000000111110100100000 00000000000000001001000100110100\n",
            "00000000000000000110100111010101 00000000000000000010100001100000 00000000000000000100101110110001 00000000000000000010010000011010 00000000000000000100011101110111 00000000000000000101111111100111\n",
            "00000000000000000111101001010101 00000000000000001000101110011111 00000000000000000111000011101111 00000000000000001011011111111100\n",
            "00000000000000001001001001000000 00000000000000000110001110111000 00000000000000000100111110010000 00000000000000000110110110100111 00000000000000000100010111000001 00000000000000001011011111100001\n",
            "00000000000000000110010110010001 00000000000000001000111011101001 00000000000000001101001111001000 00000000000000001010010010111111 00000000000011111101110100101001 00000000000000000000000011010001 00000000000000000000100111110100 00000000000011111111110000110100\n",
            "00000000000011111111110110001000 00000000000011111100100110101100 00000000000011111111111001110010 00000000000011111111000101000100\n",
            "00000000000011111110101000111010 00000000000000000001111011001111\n",
            "00000000000011111100100000111000 00000000000011111110110101111000 00000000000000000001011101011101 00000000000000000000110111101101\n",
            "00000000000000000000000111110101 00000000000011111101101001001001 00000000000011111111100011110101 00000000000011111110100001100110\n",
            "00000000000011111110100111101100 00000000000000000001111100011101\n",
            "00000000000011111111001000100101 00000000000011111111010011011111 00000000000011111110110000110111 00000000000011111110111000110000\n",
            "00000000000011111111100101100010 00000000000011111101101111001111 00000000000000000000011011100100 00000000000011111111111000100000\n",
            "00000000000011111101010111101110 00000000000000000010010000000010\n",
            "00000000000011111110110100011000 00000000000011111111011111100000 00000000000000000000000000000010 00000000000000000000000010001001\n",
            "00000000000000000000111010010101 00000000000011111111011111111110 00000000000000000000000100101100 00000000000000000000010010111010\n",
            "00000000000011111111010101000100 00000000000000000010100010001001\n",
            "00000000000011111100100011000100 00000000000011111111111011010000 00000000000000000000101001010111 00000000000000000000001100011000\n",
            "00000000000011111111011111011001 00000000000011111100111011010011 00000000000000000001011010100000 00000000000000000001010011100000\n",
            "00000000000011111101100101100100 00000000000000000001001011100011\n",
            "00000000000011111101100101001110 00000000000000000000010011100100 00000000000000000000110000111011 00000000000000000000100100011101\n",
            "00000000000000000000110000010000 00000000000011111110010010111110 00000000000000000000000010010110 00000000000000000000111000000010\n",
            "00000000000011111111000000111100 00000000000000000001100110011000\n",
            "00000000000011111111011010111111 00000000000000000000001100110110 00000000000011111111110100010101 00000000000000000000000100101001\n",
            "00000000000000000000001101101010 00000000000011111110010100111101 00000000000000000000011001100111 00000000000000000001001010101011\n",
            "00000000000011111111101001100111 00000000000000000001001101101000\n",
            "00000000000011111111010001111100 00000000000000000000001011101110 00000000000000000000110110000100 00000000000000000000001110011010\n",
            "00000000000011111111110111101110 00000000000011111101001110001000 00000000000000000000110001110101 00000000000011111111010100111100\n",
            "00000000000011111110110111001001 00000000000000000001111111011111\n",
            "00000000000011111110000100111000 00000000000000000000011101010111 00000000000000000000010011000101 00000000000000000000010101011111\n",
            "00000000000000000000010101110011 00000000000011111110111010111001 00000000000000000000000100011100 00000000000000000001011000000100\n",
            "00000000000011111111010101001101 00000000000000000000111000100010\n",
            "00000000000011111110110010010111 00000000000011111111010010001011 00000000000000000000111100101001 00000000000000000000100010100101\n",
            "00000000000000000000100000111111 00000000000011111110001011100100 00000000000000000000010110010011 00000000000011111111110010101000\n",
            "00000000000011111111000100100111 00000000000000000001101000110110 00000000000000000101110011001001 00000000000000000000000010110100 00000000000011111110100000001100 00000000000000000001010000110100 00000000000011111101101111101011 00000000000000000110001011011101\n",
            "00000000000000000001110110110010 00000000000011111111101101000111 00000000000000001000001011111000 00000000000000000100110100101010\n",
            "00000000000000000001001011001111 00000000000000000110000001011110 00000000000000000111110100000010 00000000000000000110011110001100 00000000000000000001000000100011 00000000000000000000101100100101\n",
            "00000000000000000000010110011110 00000000000000000100010000110001 00000000000011111111110011111100 00000000000000000001111110001000\n",
            "00000000000000000001001101011011 00000000000000000100011101111111 00000000000000000101010000111011 00000000000000000100110111000110 00000000000000000000111110010101 00000000000000000001101101101101\n",
            "00000000000000000010000000000000 00000000000000000011000001010010 00000000000000000001001000101111 00000000000000000010110000110010\n",
            "00000000000000000010110111001000 00000000000000000100000001010001 00000000000000001000001011001000 00000000000000000110001100000111 00000000000000000001001000101110 00000000000000000001100000110101\n",
            "00000000000000000000101010100101 00000000000000000010111011100111 00000000000011111111011000111011 00000000000000000001111100100000\n",
            "00000000000011111111010111011111 00000000000000000011000110101010 00000000000000000110000010001111 00000000000000000010111101111000 00000000000000000100011101000010 00000000000011111101011001011111\n",
            "00000000000000000010010001000000 00000000000000000111001001111010 00000000000011111101001000111111 00000000000011111111101001101111\n",
            "00000000000000000110110101100110 00000000000000000001010000011100 00000000000000000000001001010100 00000000000000000001011011110100 00000000000011111111010110000101 00000000000000000100100101000110\n",
            "00000000000000000010000111011000 00000000000000000000011100010101 00000000000000000110001001100110 00000000000000000100111010000001\n",
            "00000000000000000011110100000010 00000000000000000001110001001011 00000000000000000010011010101000 00000000000000000000010010010011 00000000000000000001001011111100 00000000000000000000111110110010\n",
            "00000000000000000001001001000100 00000000000000000011000000011011 00000000000000000000110110100110 00000000000000000001010011110101\n",
            "00000000000000000100001111110001 00000000000000000001101100110000 00000000000000000010110111000010 00000000000000000010101101010100 00000000000000000010001001100101 00000000000000000011101101001011\n",
            "00000000000000000001100010001011 00000000000000000011001011111101 00000000000000000010000000111010 00000000000000000100001010100010\n",
            "00000000000000000110011100000110 00000000000000000000000001001111 00000000000000000001001000111001 00000000000000000000011101101011 00000000000011111111010110101110 00000000000000000100001111100111\n",
            "00000000000000000010010111000010 00000000000000000000100000111100 00000000000000000011100100000100 00000000000000000100000000101011\n",
            "00000000000000000111110100110101 00000000000000000001101100110001 00000000000000000000110001011111 00000000000000000001101010000110 00000000000000000000011110101011 00000000000000000111000100000110\n",
            "00000000000000000010101000100100 00000000000000000001110011111111 00000000000000001000010100010100 00000000000000000101110101110110 00000000000011111110001010011110 00000000000011111110100001101001 00000000000011111101011011101100 00000000000011111101010111101001 00000000000011111100011010110010 00000000000011111011010001111010\n",
            "00000000000011111100100100011000 00000000000011111011111000100000 00000000000011111110001110110001 00000000000011111101111010111111\n",
            "00000000000000000001100010010100 00000000000000000101101101001000 00000000000000000001111101100100 00000000000000000010001011011100 00000000000000000010100101010100 00000000000011111111010010000010\n",
            "00000000000011111111111001000110 00000000000000000010010001101000 00000000000011111101101000110011 00000000000000000001000100001100\n",
            "00000000000000000000111000011010 00000000000000000011110001110100 00000000000000000010110010011101 00000000000000000010011110110001 00000000000000000001110111100011 00000000000011111110110010000001\n",
            "00000000000000000000101111101000 00000000000000000010001111011110 00000000000011111111000010011110 00000000000000000001110101001001\n",
            "00000000000011111111001011110010 00000000000000000011110100101101 00000000000000000001001110010001 00000000000000000010111111110100 00000000000000000010100100110010 00000000000011111111011111011110\n",
            "00000000000000000000010110110100 00000000000000000001101010110110 00000000000011111110110100100000 00000000000000000011100101000110\n",
            "00000000000000000001000000110000 00000000000000000011011000001110 00000000000000000001101010010010 00000000000000000000101101100001 00000000000000000011111000001111 00000000000011111111010110001110\n",
            "00000000000011111111101011100111 00000000000000000010100001010110 00000000000011111101000010100001 00000000000000000001110110010001\n",
            "00000000000000000000111100011110 00000000000000000010000110010101 00000000000000000001011000010100 00000000000000000001001001101011 00000000000000000000100100001100 00000000000000000011010110001001\n",
            "00000000000000000010011111110001 00000000000000000010111000110011 00000000000000000010000001010100 00000000000000000001100101010010\n",
            "00000000000000000010011110100010 00000000000000000010010001000101 00000000000000000001010010100000 00000000000000000000110111111111 00000000000000000010000001110111 00000000000011111110111100011111\n",
            "00000000000000000010010001101111 00000000000000000010100011111111 00000000000011111111011101101101 00000000000011111111010110010111\n",
            "00000000000011111110110001000010 00000000000000000001111000100000 00000000000000000001010011110001 00000000000000000000111000100101 00000000000000000010000100000000 00000000000000000000100011110110\n",
            "00000000000000000001010011111011 00000000000000000010111001111101 00000000000000000000001101110000 00000000000000000100000010111010\n",
            "00000000000000000001010100100111 00000000000000000010010010011100 00000000000000000001101010001111 00000000000000000001010101110000 00000000000000000001011000000110 00000000000000000001110001001010\n",
            "00000000000000000010011101100000 00000000000000000010001010000111 00000000000000000001111100001000 00000000000000000000010111101001\n",
            "00000000000000000000111101100010 00000000000000000001001010011011 00000000000000000001010100000111 00000000000000000000101011110010 00000000000011111111001010001100 00000000000011111101111101001000\n",
            "00000000000011111111101110000110 00000000000000000001101010101100 00000000000000000000111001110101 00000000000011111111111100100011 00000000000011111111001010001010 00000000000011111111011110001010 00000000000011111110010111001011 00000000000000000001000101110011 00000000000011111110010111001100 00000000000000000110100010000001\n",
            "00000000000000000010001111101111 00000000000011111111000101001001 00000000000000000110000001001000 00000000000000001000001000111011\n",
            "00000000000000000011011011000101 00000000000000001000000001010101 00000000000000001100001100011100 00000000000000001000000111111100 00000000000000000110101101000001 00000000000000000001010111000000\n",
            "00000000000000000100111100101101 00000000000000000101000110011100 00000000000000000010000101001011 00000000000000000101010010000111\n",
            "00000000000000000011010011111010 00000000000000000101110001001011 00000000000000000111010001001110 00000000000000000100110111001100 00000000000000000100111010000001 00000000000000000011101100011001\n",
            "00000000000000000010010111111101 00000000000000000100010001111100 00000000000000000101001011111101 00000000000000000101000011000100\n",
            "00000000000000000101110010111001 00000000000000001000100110011011 00000000000000001101010101000101 00000000000000000101101000010001 00000000000000001000000000111100 00000000000000000001110110100000\n",
            "00000000000000000001110111101111 00000000000000000011111000100010 00000000000000000010010011010100 00000000000000000100001011100000\n",
            "00000000000000000010111000000111 00000000000000001001000111110010 00000000000000000111011011001111 00000000000000000110100111000110 00000000000000000101000100011010 00000000000000000000101000001111\n",
            "00000000000000000101100000000010 00000000000000000111100011000010 00000000000000000010110101111010 00000000000000000011011101111100\n",
            "00000000000011111100010000011011 00000000000000000100001101011100 00000000000000000100100100010010 00000000000000000100001110010110 00000000000000000010111110001000 00000000000000000100110110101111\n",
            "00000000000000000110001001100101 00000000000000000011110010001010 00000000000000000111111001011011 00000000000000001001100100100110\n",
            "00000000000000000001010001100001 00000000000000000011100111101110 00000000000000000001101100100010 00000000000000000010010100010001 00000000000000000100100110010011 00000000000000000011110111100010\n",
            "00000000000000000100010111111010 00000000000000000110100000100101 00000000000000000100101110001100 00000000000000000111000010000110\n",
            "00000000000000000000110011001011 00000000000000000011001101100101 00000000000000000011011101110001 00000000000000000000101101111000 00000000000000000100111101001001 00000000000000000010000100101111\n",
            "00000000000000000101011010010011 00000000000000000100111011100111 00000000000000000010101110000110 00000000000000000101100000111000\n",
            "00000000000011111100111101011110 00000000000000000000111101010000 00000000000000000010011010101110 00000000000000000001101101001001 00000000000000000010000101000111 00000000000000000100100010000101\n",
            "00000000000000000110001001011101 00000000000000000100000110011010 00000000000000000100111111011110 00000000000000001001010111111111\n",
            "00000000000000000110000000000001 00000000000011111110100010101000 00000000000011111110100000101111 00000000000000000011100101010101 00000000000000000000111100111110 00000000000000000101110111110101\n",
            "00000000000000000100100100101010 00000000000000000100001011110011 00000000000000000100101010101101 00000000000000000111001101111110 00000000000000000100101101000010 00000000000011111011001100101001 00000000000011111010110101001001 00000000000011111010110101001110 00000000000011111101000111110011 00000000000011111101001101001011\n",
            "00000000000011111101000001101011 00000000000011111101010111101110 00000000000011111100111101010001 00000000000011111111110010101011\n",
            "00000000000011111111110101101110 00000000000000000001111010001110 00000000000000000110001011000001 00000000000000000010001010010010 00000000000000000101100110100111 00000000000000000010100111010111\n",
            "00000000000000000101000000000011 00000000000000000110110100101011 00000000000000000011000011101000 00000000000000000100110011001101\n",
            "00000000000011111110000001111101 00000000000000000010111010010100 00000000000000000011000101011011 00000000000000000000100111100100 00000000000000000110010100011010 00000000000000000010101001011001\n",
            "00000000000000000100000011111101 00000000000000000111110000101011 00000000000000000001100011010110 00000000000000000100011010110101\n",
            "00000000000011111101010001010001 00000000000000000011111111110100 00000000000000000110010000010110 00000000000000000001111100111001 00000000000000000110010011101100 00000000000000000101000111001001\n",
            "00000000000000000101100110010100 00000000000000000111001101110001 00000000000000000100111101111100 00000000000000000111000001001111\n",
            "00000000000011111110111011111010 00000000000000000101100100101011 00000000000000000101110111011011 00000000000000000011111111010100 00000000000000000101010011101100 00000000000000000000010101111001\n",
            "00000000000000000010110100100010 00000000000000000111000100010111 00000000000000000000001100000011 00000000000000000100001110100101\n",
            "00000000000011111111111001011010 00000000000000000101111010111011 00000000000000000101101011100010 00000000000000000101111110011101 00000000000000000100011011011110 00000000000000000110000011011001\n",
            "00000000000000000101001100110110 00000000000000000100111000001001 00000000000000000110010010000111 00000000000000000111110010001100\n",
            "00000000000011111110000000100001 00000000000000000101010111110010 00000000000000000101001010101010 00000000000000000101001101001011 00000000000000000101000100011010 00000000000000000010100101000010\n",
            "00000000000000000010111010101001 00000000000000000101010001101010 00000000000000000100000010100111 00000000000000000100011011100001\n",
            "00000000000000000000000101110010 00000000000000000101110111011011 00000000000000000110100011100011 00000000000000000101011100010001 00000000000000000110011010000101 00000000000000000010011010111110\n",
            "00000000000000000011111101100101 00000000000000000100111111100111 00000000000000000010001110111011 00000000000000000011001001001001\n",
            "00000000000011111111100010011001 00000000000000000100011100101000 00000000000000000101010100000000 00000000000000000101001110011000 00000000000000000100010100001100 00000000000000000100011010101000\n",
            "00000000000000000101000010110010 00000000000000000100101001101111 00000000000000000011111100011101 00000000000000000101100010111000\n",
            "00000000000000000000011111111010 00000000000000000110011000000111 00000000000000000110001101110010 00000000000000000110101111010011 00000000000000000101010100011001 00000000000000000110111111010101\n",
            "00000000000000000101101111110011 00000000000000000101111010101111 00000000000000000111011001101100 00000000000000001010110001111110 00000000000000000011101101110010 00000000000011111111101001001011 00000000000011111110010100100101 00000000000011111111100110001100 00000000000000000000000100101101 00000000000000000011101010101101\n",
            "00000000000011111110111110000001 00000000000011111110001000001100 00000000000011111111010001111001 00000000000000000100000011111000\n",
            "00000000000000000000001001101110 00000000000000000011010010001000 00000000000000000100111100001100 00000000000000000011011001110010 00000000000000000011011111001010 00000000000000000000000001010001\n",
            "00000000000000000010100110100000 00000000000000000011110010101110 00000000000000000011000101101111 00000000000000000011001110111100\n",
            "00000000000000000001011001000000 00000000000000000100010101101010 00000000000000000100010010011100 00000000000000000011011110011101 00000000000000000100010110111110 00000000000000000000000001001101\n",
            "00000000000000000010110000111000 00000000000000000100110011111111 00000000000000000011000001111010 00000000000000000011101010100010\n",
            "00000000000000000011000000000011 00000000000000000100011000100001 00000000000000000101100010000111 00000000000000000001110111010101 00000000000000000100001010000001 00000000000011111111010110001011\n",
            "00000000000000000011000011011101 00000000000000000101001110110000 00000000000000000010100010011001 00000000000000000101001000100001\n",
            "00000000000011111110111101001000 00000000000000000100111111000010 00000000000000000010111101111101 00000000000000000010101110011101 00000000000000000011000110101010 00000000000011111110011111110111\n",
            "00000000000000000010001110010011 00000000000000000101110010111000 00000000000000000010011101111100 00000000000000000001100101010010\n",
            "00000000000000001001001101111000 00000000000000000101001110100110 00000000000000000011010110010111 00000000000000000011001000000101 00000000000000000010010000000101 00000000000000000100010100000000\n",
            "00000000000000000011100111010001 00000000000000000010000111011101 00000000000000000011111000100110 00000000000000001000011010111101\n",
            "00000000000000000100111000110011 00000000000000000100001010100000 00000000000000000011100101001000 00000000000000000011000111011100 00000000000000000100011000001100 00000000000000000011111011101110\n",
            "00000000000000000010110011101101 00000000000000000100001101111000 00000000000000000010000010100111 00000000000000000100110101010000\n",
            "00000000000000000011001110111110 00000000000000000100001110110100 00000000000000000011100100011100 00000000000000000010010001001001 00000000000000000100111100001100 00000000000000000010001110001111\n",
            "00000000000000000011111001001010 00000000000000000100100100000001 00000000000000000010110100100010 00000000000000000101000101010111\n",
            "00000000000000000101001001101111 00000000000000000011101100010101 00000000000000000010111001001111 00000000000000000010011110110111 00000000000000000010010101010101 00000000000000000010011101000000\n",
            "00000000000000000100010001101001 00000000000000000011011100001100 00000000000000000010101001100000 00000000000000000100111101010101\n",
            "00000000000000001010111010010111 00000000000000000101101101001110 00000000000000000011110011111101 00000000000000000101100110111011 00000000000000000100010111111110 00000000000000001001000101010101\n",
            "00000000000000000100101011110000 00000000000000000101010001111101 00000000000000000110101000011000 00000000000000001010101101001110 00000000000011111111100101010010 00000000000011111111111010000000 00000000000011111111110111001001 00000000000000000000011100111100\n",
            "00000000000011111110111100100000 00000000000011111111111011000010 00000000000011111111010011001001 00000000000011111111100001001001\n",
            "00000000000011111111111011001000 00000000000011111111000110101011\n",
            "00000000000000000000110010010100 00000000000011111110100011110100 00000000000011111111110001110111 00000000000011111111000011100110\n",
            "00000000000011111110110000000101 00000000000011111110111000111100 00000000000011111111110111111011 00000000000000000000011110010111\n",
            "00000000000011111111011001101100 00000000000000000001010110011011\n",
            "00000000000000000001110111100000 00000000000011111111011000101111 00000000000011111101100010110100 00000000000011111111100001011001\n",
            "00000000000000000000011011100011 00000000000011111111111100010000 00000000000000000000010111111111 00000000000000000000111111000101\n",
            "00000000000011111111010110100100 00000000000000000001000101000011\n",
            "00000000000000000000111001100101 00000000000011111111110101111101 00000000000011111110100101101011 00000000000011111110101000111111\n",
            "00000000000011111111010110011100 00000000000011111111111111101011 00000000000000000000011111001010 00000000000011111111001111001010\n",
            "00000000000011111110110000101010 00000000000000000001011001010010\n",
            "00000000000000000000001001100110 00000000000011111111010100011010 00000000000011111111100101100110 00000000000011111111111011100000\n",
            "00000000000011111011101111010111 00000000000011111111000100111000 00000000000000000000001101000111 00000000000011111111100010001011\n",
            "00000000000011111111000110100011 00000000000011111111111001101111\n",
            "00000000000000000000011111000001 00000000000000000000011110111000 00000000000011111111101111001110 00000000000000000000100110010101\n",
            "00000000000000000000000000010111 00000000000000000000011000010010 00000000000000000000100110101101 00000000000000000000000011011000\n",
            "00000000000000000000000100001100 00000000000000000000001100010110\n",
            "00000000000000000001000011000100 00000000000011111111000111110100 00000000000000000001001101100110 00000000000011111111101011011101\n",
            "00000000000011111111000101001000 00000000000011111111001100011011 00000000000011111111010011111100 00000000000011111111010111110001\n",
            "00000000000011111111111111100100 00000000000011111111100111010000\n",
            "00000000000011111110110111100010 00000000000011111111100111110111 00000000000011111111111100001010 00000000000011111101010111100110\n",
            "00000000000011111111001101001010 00000000000011111111101010110110 00000000000011111111011000010001 00000000000011111010110001100100\n",
            "00000000000011111110110011001000 00000000000000000000000101011000\n",
            "00000000000000000000011101110010 00000000000000000000101100011011 00000000000011111111111011000010 00000000000000000000001000010010\n",
            "00000000000011111111100111100110 00000000000000000000010001101110 00000000000000000000001000100110 00000000000011111111110100111001\n",
            "00000000000000000000010100010000 00000000000011111111111110110011\n",
            "00000000000000000000011100001100 00000000000011111111101100010000 00000000000011111111110100100100 00000000000011111111111010111000\n",
            "00000000000000000000000000001000 00000000000011111111111100010110 00000000000011111111110111011111 00000000000011111111111000000001\n",
            "00000000000000000000000111000010 00000000000011111111011111111100 00000000000000000001011101000111 00000000000000000000001110101110 00000000000000000000100100011000 00000000000011111111001100011101 00000000000011111111100010101000 00000000000000000001001001010011\n",
            "00000000000000000001011001100110 00000000000000000000010001011111 00000000000000000100100000000000 00000000000000000100011100000000\n",
            "00000000000000000010110011011100 00000000000000000110111100000001 00000000000000000100101000011010 00000000000000000101111001101111 00000000000000000010011001001010 00000000000000000010010100100001\n",
            "00000000000011111111101001010101 00000000000000000001010100001000 00000000000000000000011101001010 00000000000000000011110000100110\n",
            "00000000000000000010100101011001 00000000000000000001110001111111 00000000000000000111011010110110 00000000000000000100101100001110 00000000000000000010000001111101 00000000000000000010110110110100\n",
            "00000000000000000001000111110001 00000000000000000000111100010101 00000000000000000011010001110111 00000000000000000011110100001110\n",
            "00000000000000000011101110100011 00000000000000000110000000011111 00000000000000000111101010111011 00000000000000001000010001011011 00000000000000000010011101001000 00000000000000000100101001010111\n",
            "00000000000011111111100111011000 00000000000000000010000110110100 00000000000000000010101010010111 00000000000000000101001011100011\n",
            "00000000000000000001000101001000 00000000000000000001001110101000 00000000000000000011100000100110 00000000000000000011101011000000 00000000000000000110001100000100 00000000000000000001010110010110\n",
            "00000000000000000000100001001111 00000000000000000011000011001011 00000000000000000000111100001111 00000000000000000010100110100000\n",
            "00000000000011111110001000011101 00000000000000000001000000011110 00000000000000000001101111111100 00000000000000000000111001101101 00000000000000000001110011010111 00000000000011111111110001111101\n",
            "00000000000000000011111110111011 00000000000000000010101100001000 00000000000000000100001011111111 00000000000000000001100110100110\n",
            "00000000000000000001001001010100 00000000000011111111111010110111 00000000000000000000111001101101 00000000000011111111001000101110 00000000000000000001111101101101 00000000000000000000000101001110\n",
            "00000000000000000010111101100100 00000000000000000000110100000000 00000000000000000000001001011100 00000000000000000001000100110010\n",
            "00000000000000000100001100001111 00000000000000000001001101000010 00000000000000000001010110010110 00000000000000000001000011100001 00000000000000000011110001000011 00000000000000000001011010101000\n",
            "00000000000000000010001010011100 00000000000000000110010010100011 00000000000000000000011000110100 00000000000000000100110010101101\n",
            "00000000000011111111001111100110 00000000000000000000010111111111 00000000000000000011011111010111 00000000000000000000111010111000 00000000000000000001101010011000 00000000000000000001001001011011\n",
            "00000000000000000100000001100110 00000000000000000011010101100101 00000000000000000011000110010000 00000000000000000010010000100011\n",
            "00000000000000000001001111010100 00000000000000000000100100011100 00000000000000000001100111110100 00000000000000000000100110010011 00000000000000000000001111101000 00000000000000000001010001000110\n",
            "00000000000000000011011001110110 00000000000000000010011001010100 00000000000000000100001001001110 00000000000000000010101110010100 00000000000011111110011110001011 00000000000011111111111010101001 00000000000011111111111011000010 00000000000011111111111110101011 00000000000000000000001110000011 00000000000011111001001011100111\n",
            "00000000000011111110010010111100 00000000000011111111110011000011 00000000000011111110110001110111 00000000000000000010001110100011\n",
            "00000000000000000001010000110101 00000000000000000011001000011110 00000000000000000010000001110000 00000000000000000001100101010001 00000000000000000001000000010110 00000000000011111110010011101110\n",
            "00000000000011111110110011001011 00000000000000000010001001101010 00000000000000000000101110011111 00000000000000000011000100100111\n",
            "00000000000011111111100110110111 00000000000000000010110000100101 00000000000000000001111111101001 00000000000000000000110110010111 00000000000000000001100000010010 00000000000011111101011011110011\n",
            "00000000000011111111100000110011 00000000000000000001000011111110 00000000000000000001001100111101 00000000000000000010110111010000\n",
            "00000000000011111111111101110001 00000000000000000010011100111100 00000000000000000001001101101111 00000000000011111111010000011101 00000000000000000010000000110110 00000000000011111101110100000101\n",
            "00000000000011111111010100001010 00000000000000000010100000011110 00000000000011111111111101100010 00000000000000000000000110111100\n",
            "00000000000011111110110010000011 00000000000000000001100111111111 00000000000000000001011101110111 00000000000000000000100010111110 00000000000000000010001100100011 00000000000011111110100111000101\n",
            "00000000000000000000100110011101 00000000000000000011111000110110 00000000000011111110110100111111 00000000000000000010011000000110\n",
            "00000000000011111111001110100011 00000000000000000001110100101111 00000000000000000001001111011100 00000000000000000001011011011011 00000000000000000000111111001001 00000000000011111101111011100110\n",
            "00000000000011111111010111000101 00000000000000000000111010001111 00000000000000000001110000000001 00000000000000000011010011011100\n",
            "00000000000011111111110001001100 00000000000000000010001111000111 00000000000000000010010010100101 00000000000000000000111010001111 00000000000000000001100101011001 00000000000011111110010110011110\n",
            "00000000000000000000010000111101 00000000000000000010101111111000 00000000000000000011000101010001 00000000000000000011001010111011\n",
            "00000000000011111111001001110010 00000000000000000001100001110110 00000000000000000010010101101101 00000000000000000001101110101101 00000000000000000010000111010100 00000000000011111101001101110100\n",
            "00000000000000000000001000000101 00000000000000000011101101111010 00000000000000000010110000001011 00000000000000000010101011111010\n",
            "00000000000011111111111010000111 00000000000000000010000011111110 00000000000000000010010101000000 00000000000000000001101010010011 00000000000000000001000111000011 00000000000011111101001001001110\n",
            "00000000000011111111011000111010 00000000000000000001111001101100 00000000000000000010000000010110 00000000000000000011001110001111\n",
            "00000000000011111111110000100101 00000000000000000001110001101100 00000000000000000001101010111000 00000000000000000000111100001000 00000000000000000000100111011101 00000000000011111101101000000000\n",
            "00000000000000000000000111101101 00000000000000000001010110011001 00000000000000000001000001010011 00000000000000000010000110101011 00000000000000000111000001011100 00000000000000000000011101100110 00000000000000000000010011000000 00000000000000000000101000111100 00000000000011111111010011110110 00000000000000000010010100110111\n",
            "00000000000011111111100001100111 00000000000011111110101010010011 00000000000000000000000101001110 00000000000000000001011010101001\n",
            "00000000000000000011100101001011 00000000000000000100011100110000 00000000000000000101100111010010 00000000000000000101000101110100 00000000000000000101001100111000 00000000000000000100000101001011\n",
            "00000000000000000100001011010011 00000000000000000101010000111101 00000000000000000010000101010110 00000000000000000101101000111001\n",
            "00000000000000000101001010101000 00000000000000000101000101100101 00000000000000000101010110111001 00000000000000000101000110110001 00000000000000000011110010001110 00000000000000000100110001101000\n",
            "00000000000000000100111111101100 00000000000000000010111010110110 00000000000000000010111010010010 00000000000000000110000110110011\n",
            "00000000000000000100000011111001 00000000000000000110000011010100 00000000000000000110000110000101 00000000000000000101001000100001 00000000000000000100100111011110 00000000000000000101101101001111\n",
            "00000000000000000100110111010010 00000000000000000111000101011011 00000000000000000011000001101101 00000000000000000110100000010010\n",
            "00000000000000000001101101010001 00000000000000000100010000101001 00000000000000000101111101001000 00000000000000000101100001110101 00000000000000000011110011011110 00000000000000000100100001100001\n",
            "00000000000000000001100101000101 00000000000000000101100100110001 00000000000000000011000001110110 00000000000000000110110100000010\n",
            "00000000000000001001011110110111 00000000000000000100100100010000 00000000000000000101001100001000 00000000000000000101011110011100 00000000000000000011111011110011 00000000000000000111010001100111\n",
            "00000000000000000100100000001000 00000000000000000110101011111010 00000000000000000010111101000001 00000000000000000100101101000100\n",
            "00000000000000000010110010011010 00000000000000000101010001000100 00000000000000000101011101010001 00000000000000000011101111000100 00000000000000000101111001011010 00000000000000000010101001011100\n",
            "00000000000000000001100000111100 00000000000000000110110100100010 00000000000000000011011010000011 00000000000000000100100110001111\n",
            "00000000000000000011000011100110 00000000000000000111001001001101 00000000000000000110010101100011 00000000000000000100111011011010 00000000000000000110111010110011 00000000000000000100010001010101\n",
            "00000000000000000100011100010001 00000000000000000110101010000001 00000000000000000011010100100010 00000000000000001000011000001100\n",
            "00000000000000000111011100000101 00000000000000000100101100111011 00000000000000000100101001001000 00000000000000000100101100111100 00000000000000000100111001011011 00000000000000000111011011111110\n",
            "00000000000000000100110101011000 00000000000000000110001100011010 00000000000000000010011111010010 00000000000000000100001011111000\n",
            "00000000000000001010011111011110 00000000000000000101110110001110 00000000000000000101001110001101 00000000000000000101110011001010 00000000000000000101011110001000 00000000000000001001101100011110\n",
            "00000000000000000101010111010101 00000000000000000110101111101000 00000000000000000101101101011101 00000000000000000110010010101100 00000000000000000011011110110010 00000000000000000000011010011001 00000000000000000000010101110011 00000000000000000000010001111101 00000000000011111111110100110010 00000000000011111111011011000000\n",
            "00000000000011111111111001001010 00000000000011111111100100000011 00000000000000000000011111001111 00000000000000000101001100000110\n",
            "00000000000000000101000000011111 00000000000000000111100111010000 00000000000011111110001010110101 00000000000011111101110100111001 00000000000011111110101011011100 00000000000011111111010110100100\n",
            "00000000000011111111011000010000 00000000000011111101001010100100 00000000000000000000110111010000 00000000000000000011111011101010\n",
            "00000000000000000100101011011101 00000000000011111100111110011010 00000000000000000011100011000001 00000000000011111110101001001100 00000000000011111101111000110000 00000000000000000000011000011000\n",
            "00000000000011111110011010111001 00000000000011111101010010101111 00000000000000000001111000011100 00000000000000000001011110001010\n",
            "00000000000000000010100000100111 00000000000000000000101100011011 00000000000011111111000110100010 00000000000000000101100011010010 00000000000011111111010100101010 00000000000011111111101011111110\n",
            "00000000000011111110110001101110 00000000000011111111000001101101 00000000000000000000110100100011 00000000000000000001101111111110\n",
            "00000000000000000001010110010000 00000000000000000000111001010011 00000000000011111100110010111010 00000000000011111110100110011111 00000000000000000110001100001000 00000000000011111111011000111001\n",
            "00000000000011111110100111111111 00000000000011111111101110010111 00000000000000000000010011000110 00000000000000000000100100000111\n",
            "00000000000000000011000101111101 00000000000011111111000100101100 00000000000011111101011011010110 00000000000011111101000001000010 00000000000011111101011011000110 00000000000011111100101010001101\n",
            "00000000000011111110100001101001 00000000000011111100110100011100 00000000000011111110001011100100 00000000000000000011100110001101\n",
            "00000000000000000010110101100101 00000000000000000000100101001101 00000000000011111110001011110010 00000000000011111100111111100000 00000000000011111111010010010001 00000000000011111110011010110011\n",
            "00000000000000000010011011110010 00000000000011111101010010000000 00000000000011111110111100000100 00000000000000000000111110000101\n",
            "00000000000000000011000010110101 00000000000011111110010001100111 00000000000011111111010000001100 00000000000011111110010010111100 00000000000011111101110111100100 00000000000011111111000010000111\n",
            "00000000000000000000011011110110 00000000000000000110010110111001 00000000000000000000110011110001 00000000000000000000100110000101\n",
            "00000000000000000011100101101100 00000000000000000000110111010000 00000000000011111111010011001011 00000000000011111110011010100100 00000000000000000000001000111110 00000000000011111110110111101010\n",
            "00000000000011111110111101011101 00000000000011111100101111000001 00000000000011111101011110101011 00000000000000000001111010111100\n",
            "00000000000000000011111101011011 00000000000011111110111000000000 00000000000011111110100000101001 00000000000011111101100010010011 00000000000011111110101110010111 00000000000011111110101001100111\n",
            "00000000000011111110010000111011 00000000000011111110001010010010 00000000000011111110010110100101 00000000000000000001111010010111\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt(input_file, output_file):\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # txt 파일 읽기 및 값 분리\n",
        "    with open(input_file, 'r') as f:\n",
        "        content = f.read()  # 파일 전체 내용을 읽음\n",
        "        binary_values = content.split()  # 스페이스와 줄바꿈을 기준으로 값을 분리\n",
        "\n",
        "    # 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            # 줄 생성\n",
        "            line = template.format(index=i+1, binary_value=binary_value)  # index는 1부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "# 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output2.txt'  # 입력 파일 경로 (값들이 스페이스/줄바꿈으로 구별됨)\n",
        "output_code_file = './model/generated_code.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# 코드 생성 함수 호출\n",
        "generate_code_from_txt(input_txt_file, output_code_file)\n",
        "print(f\"코드가 성공적으로 생성되어 {output_code_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "bBrrgb7-GxN3",
        "outputId": "f1afb6e4-e5be-4d5e-c5b1-672cea34dbf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코드가 성공적으로 생성되어 ./model/generated_code.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt_with_msb(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일에서 1200개의 32비트 값을 읽고,\n",
        "    10개 단위의 첫 번째 값(총 120개)의 MSB(최상위 비트)를 1로 변경한 후\n",
        "    코드 파일을 생성하는 함수.\n",
        "\n",
        "    Args:\n",
        "    - input_file: 입력 TXT 파일 (각 줄에 32비트 바이너리 값 존재)\n",
        "    - output_file: 출력 코드가 저장될 TXT 파일\n",
        "    \"\"\"\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # TXT 파일 읽기\n",
        "    with open(input_file, 'r') as f:\n",
        "        binary_values = f.read().split()  # 스페이스와 줄바꿈을 기준으로 값 분리\n",
        "\n",
        "    # ✅ 10개 단위의 첫 번째 값(총 120개)의 MSB를 1로 변경\n",
        "    for i in range(0, len(binary_values), 10):  # 10개씩 건너뛰며 첫 번째 값 선택\n",
        "        if i < len(binary_values):  # 범위 초과 방지\n",
        "            original_value = binary_values[i]  # 원본 값\n",
        "            modified_value = '1' + original_value[1:]  # MSB(최상위 비트)만 1로 변경\n",
        "            binary_values[i] = modified_value  # 변경된 값 반영\n",
        "\n",
        "    # ✅ 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            line = template.format(index=i+1, binary_value=binary_value)  # index는 1부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "    print(f\"✅ 코드가 성공적으로 생성되어 {output_file}에 저장되었습니다.\")\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output2.txt'  # 입력 파일 (각 줄에 32비트 값이 존재)\n",
        "output_code_file = './model/generated_code2.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# ✅ 함수 실행\n",
        "generate_code_from_txt_with_msb(input_txt_file, output_code_file)\n"
      ],
      "metadata": {
        "id": "YBfF8wke255-",
        "outputId": "07b81d52-830e-4561-8d76-b62891cd16eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 코드가 성공적으로 생성되어 ./model/generated_code2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/generated_code.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "sEWA6mjj3Umy",
        "outputId": "c578518b-97c8-4d04-af42-7c39ab2866a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1), 0b10000000000000000110111101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 2), 0b00000000000000000000001110111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 3), 0b00000000000000000001001010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 4), 0b00000000000000000001010000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 5), 0b00000000000011111111011000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 6), 0b00000000000000000100011000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 7), 0b00000000000011111111101101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 8), 0b00000000000000000000111111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 9), 0b00000000000000000100000111111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 10), 0b00000000000000000010110011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 11), 0b10000000000000000011010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 12), 0b00000000000000000110101100010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 13), 0b00000000000000001011100101100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 14), 0b00000000000000001001001111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 15), 0b00000000000000000111101000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 16), 0b00000000000000000100101011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 17), 0b00000000000000000011110001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 18), 0b00000000000000000100110001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 19), 0b00000000000000000011000110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 20), 0b00000000000000000011110100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 21), 0b10000000000000000110101000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 22), 0b00000000000000001001000000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 23), 0b00000000000000000111100111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 24), 0b00000000000000001010011011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 25), 0b00000000000000000100100111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 26), 0b00000000000000000110000100011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 27), 0b00000000000000000100111101011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 28), 0b00000000000000000011010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 29), 0b00000000000000000101001101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 30), 0b00000000000000000011001000011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 31), 0b10000000000000000101001001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 32), 0b00000000000000001001010011100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 33), 0b00000000000000001101100110000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 34), 0b00000000000000000111100110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 35), 0b00000000000000001010101010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 36), 0b00000000000000000101010100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 37), 0b00000000000000000101011100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 38), 0b00000000000000000100110101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 39), 0b00000000000000000100010110110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 40), 0b00000000000000000110001101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 41), 0b10000000000000000001010000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 42), 0b00000000000000001001010010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 43), 0b00000000000000000110100111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 44), 0b00000000000000001010001000001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 45), 0b00000000000000000110101011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 46), 0b00000000000000000101100011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 47), 0b00000000000000000011101111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 48), 0b00000000000000000110111111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 49), 0b00000000000000000100000011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 50), 0b00000000000000000101001011101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 51), 0b10000000000000000111111101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 52), 0b00000000000000000101001110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 53), 0b00000000000000000100100011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 54), 0b00000000000000000101110101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 55), 0b00000000000000000111000001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 56), 0b00000000000000000110011100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 57), 0b00000000000000000110000101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 58), 0b00000000000000000101101111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 59), 0b00000000000000001000101000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 60), 0b00000000000000001000100110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 61), 0b10000000000000000011100101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 62), 0b00000000000000000101010111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 63), 0b00000000000000000011010110011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 64), 0b00000000000000000010101000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 65), 0b00000000000000001000010110000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 66), 0b00000000000000000110101010011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 67), 0b00000000000000000100111100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 68), 0b00000000000000001001000110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 69), 0b00000000000000000101010001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 70), 0b00000000000000000110010110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 71), 0b10000000000000000011010001110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 72), 0b00000000000000000011100010001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 73), 0b00000000000000000100001101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 74), 0b00000000000000000100001101101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 75), 0b00000000000000000110110110001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 76), 0b00000000000000000110110001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 77), 0b00000000000000001000011100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 78), 0b00000000000000000101111011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 79), 0b00000000000000000111110100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 80), 0b00000000000000001001000100110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 81), 0b10000000000000000110100111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 82), 0b00000000000000000010100001100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 83), 0b00000000000000000100101110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 84), 0b00000000000000000010010000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 85), 0b00000000000000000100011101110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 86), 0b00000000000000000101111111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 87), 0b00000000000000000111101001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 88), 0b00000000000000001000101110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 89), 0b00000000000000000111000011101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 90), 0b00000000000000001011011111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 91), 0b10000000000000001001001001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 92), 0b00000000000000000110001110111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 93), 0b00000000000000000100111110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 94), 0b00000000000000000110110110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 95), 0b00000000000000000100010111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 96), 0b00000000000000001011011111100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 97), 0b00000000000000000110010110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 98), 0b00000000000000001000111011101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 99), 0b00000000000000001101001111001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 100), 0b00000000000000001010010010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 101), 0b10000000000011111101110100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 102), 0b00000000000000000000000011010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 103), 0b00000000000000000000100111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 104), 0b00000000000011111111110000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 105), 0b00000000000011111111110110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 106), 0b00000000000011111100100110101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 107), 0b00000000000011111111111001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 108), 0b00000000000011111111000101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 109), 0b00000000000011111110101000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 110), 0b00000000000000000001111011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 111), 0b10000000000011111100100000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 112), 0b00000000000011111110110101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 113), 0b00000000000000000001011101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 114), 0b00000000000000000000110111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 115), 0b00000000000000000000000111110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 116), 0b00000000000011111101101001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 117), 0b00000000000011111111100011110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 118), 0b00000000000011111110100001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 119), 0b00000000000011111110100111101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 120), 0b00000000000000000001111100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 121), 0b10000000000011111111001000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 122), 0b00000000000011111111010011011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 123), 0b00000000000011111110110000110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 124), 0b00000000000011111110111000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 125), 0b00000000000011111111100101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 126), 0b00000000000011111101101111001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 127), 0b00000000000000000000011011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 128), 0b00000000000011111111111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 129), 0b00000000000011111101010111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 130), 0b00000000000000000010010000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 131), 0b10000000000011111110110100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 132), 0b00000000000011111111011111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 133), 0b00000000000000000000000000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 134), 0b00000000000000000000000010001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 135), 0b00000000000000000000111010010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 136), 0b00000000000011111111011111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 137), 0b00000000000000000000000100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 138), 0b00000000000000000000010010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 139), 0b00000000000011111111010101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 140), 0b00000000000000000010100010001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 141), 0b10000000000011111100100011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 142), 0b00000000000011111111111011010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 143), 0b00000000000000000000101001010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 144), 0b00000000000000000000001100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 145), 0b00000000000011111111011111011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 146), 0b00000000000011111100111011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 147), 0b00000000000000000001011010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 148), 0b00000000000000000001010011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 149), 0b00000000000011111101100101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 150), 0b00000000000000000001001011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 151), 0b10000000000011111101100101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 152), 0b00000000000000000000010011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 153), 0b00000000000000000000110000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 154), 0b00000000000000000000100100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 155), 0b00000000000000000000110000010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 156), 0b00000000000011111110010010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 157), 0b00000000000000000000000010010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 158), 0b00000000000000000000111000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 159), 0b00000000000011111111000000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 160), 0b00000000000000000001100110011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 161), 0b10000000000011111111011010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 162), 0b00000000000000000000001100110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 163), 0b00000000000011111111110100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 164), 0b00000000000000000000000100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 165), 0b00000000000000000000001101101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 166), 0b00000000000011111110010100111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 167), 0b00000000000000000000011001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 168), 0b00000000000000000001001010101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 169), 0b00000000000011111111101001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 170), 0b00000000000000000001001101101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 171), 0b10000000000011111111010001111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 172), 0b00000000000000000000001011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 173), 0b00000000000000000000110110000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 174), 0b00000000000000000000001110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 175), 0b00000000000011111111110111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 176), 0b00000000000011111101001110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 177), 0b00000000000000000000110001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 178), 0b00000000000011111111010100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 179), 0b00000000000011111110110111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 180), 0b00000000000000000001111111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 181), 0b10000000000011111110000100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 182), 0b00000000000000000000011101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 183), 0b00000000000000000000010011000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 184), 0b00000000000000000000010101011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 185), 0b00000000000000000000010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 186), 0b00000000000011111110111010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 187), 0b00000000000000000000000100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 188), 0b00000000000000000001011000000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 189), 0b00000000000011111111010101001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 190), 0b00000000000000000000111000100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 191), 0b10000000000011111110110010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 192), 0b00000000000011111111010010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 193), 0b00000000000000000000111100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 194), 0b00000000000000000000100010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 195), 0b00000000000000000000100000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 196), 0b00000000000011111110001011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 197), 0b00000000000000000000010110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 198), 0b00000000000011111111110010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 199), 0b00000000000011111111000100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 200), 0b00000000000000000001101000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 201), 0b10000000000000000101110011001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 202), 0b00000000000000000000000010110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 203), 0b00000000000011111110100000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 204), 0b00000000000000000001010000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 205), 0b00000000000011111101101111101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 206), 0b00000000000000000110001011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 207), 0b00000000000000000001110110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 208), 0b00000000000011111111101101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 209), 0b00000000000000001000001011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 210), 0b00000000000000000100110100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 211), 0b10000000000000000001001011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 212), 0b00000000000000000110000001011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 213), 0b00000000000000000111110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 214), 0b00000000000000000110011110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 215), 0b00000000000000000001000000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 216), 0b00000000000000000000101100100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 217), 0b00000000000000000000010110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 218), 0b00000000000000000100010000110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 219), 0b00000000000011111111110011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 220), 0b00000000000000000001111110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 221), 0b10000000000000000001001101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 222), 0b00000000000000000100011101111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 223), 0b00000000000000000101010000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 224), 0b00000000000000000100110111000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 225), 0b00000000000000000000111110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 226), 0b00000000000000000001101101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 227), 0b00000000000000000010000000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 228), 0b00000000000000000011000001010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 229), 0b00000000000000000001001000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 230), 0b00000000000000000010110000110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 231), 0b10000000000000000010110111001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 232), 0b00000000000000000100000001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 233), 0b00000000000000001000001011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 234), 0b00000000000000000110001100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 235), 0b00000000000000000001001000101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 236), 0b00000000000000000001100000110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 237), 0b00000000000000000000101010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 238), 0b00000000000000000010111011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 239), 0b00000000000011111111011000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 240), 0b00000000000000000001111100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 241), 0b10000000000011111111010111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 242), 0b00000000000000000011000110101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 243), 0b00000000000000000110000010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 244), 0b00000000000000000010111101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 245), 0b00000000000000000100011101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 246), 0b00000000000011111101011001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 247), 0b00000000000000000010010001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 248), 0b00000000000000000111001001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 249), 0b00000000000011111101001000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 250), 0b00000000000011111111101001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 251), 0b10000000000000000110110101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 252), 0b00000000000000000001010000011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 253), 0b00000000000000000000001001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 254), 0b00000000000000000001011011110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 255), 0b00000000000011111111010110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 256), 0b00000000000000000100100101000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 257), 0b00000000000000000010000111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 258), 0b00000000000000000000011100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 259), 0b00000000000000000110001001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 260), 0b00000000000000000100111010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 261), 0b10000000000000000011110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 262), 0b00000000000000000001110001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 263), 0b00000000000000000010011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 264), 0b00000000000000000000010010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 265), 0b00000000000000000001001011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 266), 0b00000000000000000000111110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 267), 0b00000000000000000001001001000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 268), 0b00000000000000000011000000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 269), 0b00000000000000000000110110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 270), 0b00000000000000000001010011110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 271), 0b10000000000000000100001111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 272), 0b00000000000000000001101100110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 273), 0b00000000000000000010110111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 274), 0b00000000000000000010101101010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 275), 0b00000000000000000010001001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 276), 0b00000000000000000011101101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 277), 0b00000000000000000001100010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 278), 0b00000000000000000011001011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 279), 0b00000000000000000010000000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 280), 0b00000000000000000100001010100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 281), 0b10000000000000000110011100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 282), 0b00000000000000000000000001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 283), 0b00000000000000000001001000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 284), 0b00000000000000000000011101101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 285), 0b00000000000011111111010110101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 286), 0b00000000000000000100001111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 287), 0b00000000000000000010010111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 288), 0b00000000000000000000100000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 289), 0b00000000000000000011100100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 290), 0b00000000000000000100000000101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 291), 0b10000000000000000111110100110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 292), 0b00000000000000000001101100110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 293), 0b00000000000000000000110001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 294), 0b00000000000000000001101010000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 295), 0b00000000000000000000011110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 296), 0b00000000000000000111000100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 297), 0b00000000000000000010101000100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 298), 0b00000000000000000001110011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 299), 0b00000000000000001000010100010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 300), 0b00000000000000000101110101110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 301), 0b10000000000011111110001010011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 302), 0b00000000000011111110100001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 303), 0b00000000000011111101011011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 304), 0b00000000000011111101010111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 305), 0b00000000000011111100011010110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 306), 0b00000000000011111011010001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 307), 0b00000000000011111100100100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 308), 0b00000000000011111011111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 309), 0b00000000000011111110001110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 310), 0b00000000000011111101111010111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 311), 0b10000000000000000001100010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 312), 0b00000000000000000101101101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 313), 0b00000000000000000001111101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 314), 0b00000000000000000010001011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 315), 0b00000000000000000010100101010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 316), 0b00000000000011111111010010000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 317), 0b00000000000011111111111001000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 318), 0b00000000000000000010010001101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 319), 0b00000000000011111101101000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 320), 0b00000000000000000001000100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 321), 0b10000000000000000000111000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 322), 0b00000000000000000011110001110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 323), 0b00000000000000000010110010011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 324), 0b00000000000000000010011110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 325), 0b00000000000000000001110111100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 326), 0b00000000000011111110110010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 327), 0b00000000000000000000101111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 328), 0b00000000000000000010001111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 329), 0b00000000000011111111000010011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 330), 0b00000000000000000001110101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 331), 0b10000000000011111111001011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 332), 0b00000000000000000011110100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 333), 0b00000000000000000001001110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 334), 0b00000000000000000010111111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 335), 0b00000000000000000010100100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 336), 0b00000000000011111111011111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 337), 0b00000000000000000000010110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 338), 0b00000000000000000001101010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 339), 0b00000000000011111110110100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 340), 0b00000000000000000011100101000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 341), 0b10000000000000000001000000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 342), 0b00000000000000000011011000001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 343), 0b00000000000000000001101010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 344), 0b00000000000000000000101101100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 345), 0b00000000000000000011111000001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 346), 0b00000000000011111111010110001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 347), 0b00000000000011111111101011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 348), 0b00000000000000000010100001010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 349), 0b00000000000011111101000010100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 350), 0b00000000000000000001110110010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 351), 0b10000000000000000000111100011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 352), 0b00000000000000000010000110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 353), 0b00000000000000000001011000010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 354), 0b00000000000000000001001001101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 355), 0b00000000000000000000100100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 356), 0b00000000000000000011010110001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 357), 0b00000000000000000010011111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 358), 0b00000000000000000010111000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 359), 0b00000000000000000010000001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 360), 0b00000000000000000001100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 361), 0b10000000000000000010011110100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 362), 0b00000000000000000010010001000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 363), 0b00000000000000000001010010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 364), 0b00000000000000000000110111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 365), 0b00000000000000000010000001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 366), 0b00000000000011111110111100011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 367), 0b00000000000000000010010001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 368), 0b00000000000000000010100011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 369), 0b00000000000011111111011101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 370), 0b00000000000011111111010110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 371), 0b10000000000011111110110001000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 372), 0b00000000000000000001111000100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 373), 0b00000000000000000001010011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 374), 0b00000000000000000000111000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 375), 0b00000000000000000010000100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 376), 0b00000000000000000000100011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 377), 0b00000000000000000001010011111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 378), 0b00000000000000000010111001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 379), 0b00000000000000000000001101110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 380), 0b00000000000000000100000010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 381), 0b10000000000000000001010100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 382), 0b00000000000000000010010010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 383), 0b00000000000000000001101010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 384), 0b00000000000000000001010101110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 385), 0b00000000000000000001011000000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 386), 0b00000000000000000001110001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 387), 0b00000000000000000010011101100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 388), 0b00000000000000000010001010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 389), 0b00000000000000000001111100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 390), 0b00000000000000000000010111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 391), 0b10000000000000000000111101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 392), 0b00000000000000000001001010011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 393), 0b00000000000000000001010100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 394), 0b00000000000000000000101011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 395), 0b00000000000011111111001010001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 396), 0b00000000000011111101111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 397), 0b00000000000011111111101110000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 398), 0b00000000000000000001101010101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 399), 0b00000000000000000000111001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 400), 0b00000000000011111111111100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 401), 0b10000000000011111111001010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 402), 0b00000000000011111111011110001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 403), 0b00000000000011111110010111001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 404), 0b00000000000000000001000101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 405), 0b00000000000011111110010111001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 406), 0b00000000000000000110100010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 407), 0b00000000000000000010001111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 408), 0b00000000000011111111000101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 409), 0b00000000000000000110000001001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 410), 0b00000000000000001000001000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 411), 0b10000000000000000011011011000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 412), 0b00000000000000001000000001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 413), 0b00000000000000001100001100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 414), 0b00000000000000001000000111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 415), 0b00000000000000000110101101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 416), 0b00000000000000000001010111000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 417), 0b00000000000000000100111100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 418), 0b00000000000000000101000110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 419), 0b00000000000000000010000101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 420), 0b00000000000000000101010010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 421), 0b10000000000000000011010011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 422), 0b00000000000000000101110001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 423), 0b00000000000000000111010001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 424), 0b00000000000000000100110111001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 425), 0b00000000000000000100111010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 426), 0b00000000000000000011101100011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 427), 0b00000000000000000010010111111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 428), 0b00000000000000000100010001111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 429), 0b00000000000000000101001011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 430), 0b00000000000000000101000011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 431), 0b10000000000000000101110010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 432), 0b00000000000000001000100110011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 433), 0b00000000000000001101010101000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 434), 0b00000000000000000101101000010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 435), 0b00000000000000001000000000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 436), 0b00000000000000000001110110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 437), 0b00000000000000000001110111101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 438), 0b00000000000000000011111000100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 439), 0b00000000000000000010010011010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 440), 0b00000000000000000100001011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 441), 0b10000000000000000010111000000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 442), 0b00000000000000001001000111110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 443), 0b00000000000000000111011011001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 444), 0b00000000000000000110100111000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 445), 0b00000000000000000101000100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 446), 0b00000000000000000000101000001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 447), 0b00000000000000000101100000000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 448), 0b00000000000000000111100011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 449), 0b00000000000000000010110101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 450), 0b00000000000000000011011101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 451), 0b10000000000011111100010000011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 452), 0b00000000000000000100001101011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 453), 0b00000000000000000100100100010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 454), 0b00000000000000000100001110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 455), 0b00000000000000000010111110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 456), 0b00000000000000000100110110101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 457), 0b00000000000000000110001001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 458), 0b00000000000000000011110010001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 459), 0b00000000000000000111111001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 460), 0b00000000000000001001100100100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 461), 0b10000000000000000001010001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 462), 0b00000000000000000011100111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 463), 0b00000000000000000001101100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 464), 0b00000000000000000010010100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 465), 0b00000000000000000100100110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 466), 0b00000000000000000011110111100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 467), 0b00000000000000000100010111111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 468), 0b00000000000000000110100000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 469), 0b00000000000000000100101110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 470), 0b00000000000000000111000010000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 471), 0b10000000000000000000110011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 472), 0b00000000000000000011001101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 473), 0b00000000000000000011011101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 474), 0b00000000000000000000101101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 475), 0b00000000000000000100111101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 476), 0b00000000000000000010000100101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 477), 0b00000000000000000101011010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 478), 0b00000000000000000100111011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 479), 0b00000000000000000010101110000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 480), 0b00000000000000000101100000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 481), 0b10000000000011111100111101011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 482), 0b00000000000000000000111101010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 483), 0b00000000000000000010011010101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 484), 0b00000000000000000001101101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 485), 0b00000000000000000010000101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 486), 0b00000000000000000100100010000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 487), 0b00000000000000000110001001011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 488), 0b00000000000000000100000110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 489), 0b00000000000000000100111111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 490), 0b00000000000000001001010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 491), 0b10000000000000000110000000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 492), 0b00000000000011111110100010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 493), 0b00000000000011111110100000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 494), 0b00000000000000000011100101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 495), 0b00000000000000000000111100111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 496), 0b00000000000000000101110111110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 497), 0b00000000000000000100100100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 498), 0b00000000000000000100001011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 499), 0b00000000000000000100101010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 500), 0b00000000000000000111001101111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 501), 0b10000000000000000100101101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 502), 0b00000000000011111011001100101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 503), 0b00000000000011111010110101001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 504), 0b00000000000011111010110101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 505), 0b00000000000011111101000111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 506), 0b00000000000011111101001101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 507), 0b00000000000011111101000001101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 508), 0b00000000000011111101010111101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 509), 0b00000000000011111100111101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 510), 0b00000000000011111111110010101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 511), 0b10000000000011111111110101101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 512), 0b00000000000000000001111010001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 513), 0b00000000000000000110001011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 514), 0b00000000000000000010001010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 515), 0b00000000000000000101100110100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 516), 0b00000000000000000010100111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 517), 0b00000000000000000101000000000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 518), 0b00000000000000000110110100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 519), 0b00000000000000000011000011101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 520), 0b00000000000000000100110011001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 521), 0b10000000000011111110000001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 522), 0b00000000000000000010111010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 523), 0b00000000000000000011000101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 524), 0b00000000000000000000100111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 525), 0b00000000000000000110010100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 526), 0b00000000000000000010101001011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 527), 0b00000000000000000100000011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 528), 0b00000000000000000111110000101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 529), 0b00000000000000000001100011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 530), 0b00000000000000000100011010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 531), 0b10000000000011111101010001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 532), 0b00000000000000000011111111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 533), 0b00000000000000000110010000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 534), 0b00000000000000000001111100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 535), 0b00000000000000000110010011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 536), 0b00000000000000000101000111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 537), 0b00000000000000000101100110010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 538), 0b00000000000000000111001101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 539), 0b00000000000000000100111101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 540), 0b00000000000000000111000001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 541), 0b10000000000011111110111011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 542), 0b00000000000000000101100100101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 543), 0b00000000000000000101110111011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 544), 0b00000000000000000011111111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 545), 0b00000000000000000101010011101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 546), 0b00000000000000000000010101111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 547), 0b00000000000000000010110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 548), 0b00000000000000000111000100010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 549), 0b00000000000000000000001100000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 550), 0b00000000000000000100001110100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 551), 0b10000000000011111111111001011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 552), 0b00000000000000000101111010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 553), 0b00000000000000000101101011100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 554), 0b00000000000000000101111110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 555), 0b00000000000000000100011011011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 556), 0b00000000000000000110000011011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 557), 0b00000000000000000101001100110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 558), 0b00000000000000000100111000001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 559), 0b00000000000000000110010010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 560), 0b00000000000000000111110010001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 561), 0b10000000000011111110000000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 562), 0b00000000000000000101010111110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 563), 0b00000000000000000101001010101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 564), 0b00000000000000000101001101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 565), 0b00000000000000000101000100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 566), 0b00000000000000000010100101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 567), 0b00000000000000000010111010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 568), 0b00000000000000000101010001101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 569), 0b00000000000000000100000010100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 570), 0b00000000000000000100011011100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 571), 0b10000000000000000000000101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 572), 0b00000000000000000101110111011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 573), 0b00000000000000000110100011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 574), 0b00000000000000000101011100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 575), 0b00000000000000000110011010000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 576), 0b00000000000000000010011010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 577), 0b00000000000000000011111101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 578), 0b00000000000000000100111111100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 579), 0b00000000000000000010001110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 580), 0b00000000000000000011001001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 581), 0b10000000000011111111100010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 582), 0b00000000000000000100011100101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 583), 0b00000000000000000101010100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 584), 0b00000000000000000101001110011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 585), 0b00000000000000000100010100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 586), 0b00000000000000000100011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 587), 0b00000000000000000101000010110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 588), 0b00000000000000000100101001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 589), 0b00000000000000000011111100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 590), 0b00000000000000000101100010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 591), 0b10000000000000000000011111111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 592), 0b00000000000000000110011000000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 593), 0b00000000000000000110001101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 594), 0b00000000000000000110101111010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 595), 0b00000000000000000101010100011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 596), 0b00000000000000000110111111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 597), 0b00000000000000000101101111110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 598), 0b00000000000000000101111010101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 599), 0b00000000000000000111011001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 600), 0b00000000000000001010110001111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 601), 0b10000000000000000011101101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 602), 0b00000000000011111111101001001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 603), 0b00000000000011111110010100100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 604), 0b00000000000011111111100110001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 605), 0b00000000000000000000000100101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 606), 0b00000000000000000011101010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 607), 0b00000000000011111110111110000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 608), 0b00000000000011111110001000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 609), 0b00000000000011111111010001111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 610), 0b00000000000000000100000011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 611), 0b10000000000000000000001001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 612), 0b00000000000000000011010010001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 613), 0b00000000000000000100111100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 614), 0b00000000000000000011011001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 615), 0b00000000000000000011011111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 616), 0b00000000000000000000000001010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 617), 0b00000000000000000010100110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 618), 0b00000000000000000011110010101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 619), 0b00000000000000000011000101101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 620), 0b00000000000000000011001110111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 621), 0b10000000000000000001011001000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 622), 0b00000000000000000100010101101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 623), 0b00000000000000000100010010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 624), 0b00000000000000000011011110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 625), 0b00000000000000000100010110111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 626), 0b00000000000000000000000001001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 627), 0b00000000000000000010110000111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 628), 0b00000000000000000100110011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 629), 0b00000000000000000011000001111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 630), 0b00000000000000000011101010100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 631), 0b10000000000000000011000000000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 632), 0b00000000000000000100011000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 633), 0b00000000000000000101100010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 634), 0b00000000000000000001110111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 635), 0b00000000000000000100001010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 636), 0b00000000000011111111010110001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 637), 0b00000000000000000011000011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 638), 0b00000000000000000101001110110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 639), 0b00000000000000000010100010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 640), 0b00000000000000000101001000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 641), 0b10000000000011111110111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 642), 0b00000000000000000100111111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 643), 0b00000000000000000010111101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 644), 0b00000000000000000010101110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 645), 0b00000000000000000011000110101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 646), 0b00000000000011111110011111110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 647), 0b00000000000000000010001110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 648), 0b00000000000000000101110010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 649), 0b00000000000000000010011101111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 650), 0b00000000000000000001100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 651), 0b10000000000000001001001101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 652), 0b00000000000000000101001110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 653), 0b00000000000000000011010110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 654), 0b00000000000000000011001000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 655), 0b00000000000000000010010000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 656), 0b00000000000000000100010100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 657), 0b00000000000000000011100111010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 658), 0b00000000000000000010000111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 659), 0b00000000000000000011111000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 660), 0b00000000000000001000011010111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 661), 0b10000000000000000100111000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 662), 0b00000000000000000100001010100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 663), 0b00000000000000000011100101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 664), 0b00000000000000000011000111011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 665), 0b00000000000000000100011000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 666), 0b00000000000000000011111011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 667), 0b00000000000000000010110011101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 668), 0b00000000000000000100001101111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 669), 0b00000000000000000010000010100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 670), 0b00000000000000000100110101010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 671), 0b10000000000000000011001110111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 672), 0b00000000000000000100001110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 673), 0b00000000000000000011100100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 674), 0b00000000000000000010010001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 675), 0b00000000000000000100111100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 676), 0b00000000000000000010001110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 677), 0b00000000000000000011111001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 678), 0b00000000000000000100100100000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 679), 0b00000000000000000010110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 680), 0b00000000000000000101000101010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 681), 0b10000000000000000101001001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 682), 0b00000000000000000011101100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 683), 0b00000000000000000010111001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 684), 0b00000000000000000010011110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 685), 0b00000000000000000010010101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 686), 0b00000000000000000010011101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 687), 0b00000000000000000100010001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 688), 0b00000000000000000011011100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 689), 0b00000000000000000010101001100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 690), 0b00000000000000000100111101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 691), 0b10000000000000001010111010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 692), 0b00000000000000000101101101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 693), 0b00000000000000000011110011111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 694), 0b00000000000000000101100110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 695), 0b00000000000000000100010111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 696), 0b00000000000000001001000101010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 697), 0b00000000000000000100101011110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 698), 0b00000000000000000101010001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 699), 0b00000000000000000110101000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 700), 0b00000000000000001010101101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 701), 0b10000000000011111111100101010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 702), 0b00000000000011111111111010000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 703), 0b00000000000011111111110111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 704), 0b00000000000000000000011100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 705), 0b00000000000011111110111100100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 706), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 707), 0b00000000000011111111010011001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 708), 0b00000000000011111111100001001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 709), 0b00000000000011111111111011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 710), 0b00000000000011111111000110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 711), 0b10000000000000000000110010010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 712), 0b00000000000011111110100011110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 713), 0b00000000000011111111110001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 714), 0b00000000000011111111000011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 715), 0b00000000000011111110110000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 716), 0b00000000000011111110111000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 717), 0b00000000000011111111110111111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 718), 0b00000000000000000000011110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 719), 0b00000000000011111111011001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 720), 0b00000000000000000001010110011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 721), 0b10000000000000000001110111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 722), 0b00000000000011111111011000101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 723), 0b00000000000011111101100010110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 724), 0b00000000000011111111100001011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 725), 0b00000000000000000000011011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 726), 0b00000000000011111111111100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 727), 0b00000000000000000000010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 728), 0b00000000000000000000111111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 729), 0b00000000000011111111010110100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 730), 0b00000000000000000001000101000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 731), 0b10000000000000000000111001100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 732), 0b00000000000011111111110101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 733), 0b00000000000011111110100101101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 734), 0b00000000000011111110101000111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 735), 0b00000000000011111111010110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 736), 0b00000000000011111111111111101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 737), 0b00000000000000000000011111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 738), 0b00000000000011111111001111001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 739), 0b00000000000011111110110000101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 740), 0b00000000000000000001011001010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 741), 0b10000000000000000000001001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 742), 0b00000000000011111111010100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 743), 0b00000000000011111111100101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 744), 0b00000000000011111111111011100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 745), 0b00000000000011111011101111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 746), 0b00000000000011111111000100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 747), 0b00000000000000000000001101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 748), 0b00000000000011111111100010001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 749), 0b00000000000011111111000110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 750), 0b00000000000011111111111001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 751), 0b10000000000000000000011111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 752), 0b00000000000000000000011110111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 753), 0b00000000000011111111101111001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 754), 0b00000000000000000000100110010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 755), 0b00000000000000000000000000010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 756), 0b00000000000000000000011000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 757), 0b00000000000000000000100110101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 758), 0b00000000000000000000000011011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 759), 0b00000000000000000000000100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 760), 0b00000000000000000000001100010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 761), 0b10000000000000000001000011000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 762), 0b00000000000011111111000111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 763), 0b00000000000000000001001101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 764), 0b00000000000011111111101011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 765), 0b00000000000011111111000101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 766), 0b00000000000011111111001100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 767), 0b00000000000011111111010011111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 768), 0b00000000000011111111010111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 769), 0b00000000000011111111111111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 770), 0b00000000000011111111100111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 771), 0b10000000000011111110110111100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 772), 0b00000000000011111111100111110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 773), 0b00000000000011111111111100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 774), 0b00000000000011111101010111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 775), 0b00000000000011111111001101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 776), 0b00000000000011111111101010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 777), 0b00000000000011111111011000010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 778), 0b00000000000011111010110001100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 779), 0b00000000000011111110110011001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 780), 0b00000000000000000000000101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 781), 0b10000000000000000000011101110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 782), 0b00000000000000000000101100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 783), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 784), 0b00000000000000000000001000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 785), 0b00000000000011111111100111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 786), 0b00000000000000000000010001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 787), 0b00000000000000000000001000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 788), 0b00000000000011111111110100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 789), 0b00000000000000000000010100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 790), 0b00000000000011111111111110110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 791), 0b10000000000000000000011100001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 792), 0b00000000000011111111101100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 793), 0b00000000000011111111110100100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 794), 0b00000000000011111111111010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 795), 0b00000000000000000000000000001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 796), 0b00000000000011111111111100010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 797), 0b00000000000011111111110111011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 798), 0b00000000000011111111111000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 799), 0b00000000000000000000000111000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 800), 0b00000000000011111111011111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 801), 0b10000000000000000001011101000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 802), 0b00000000000000000000001110101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 803), 0b00000000000000000000100100011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 804), 0b00000000000011111111001100011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 805), 0b00000000000011111111100010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 806), 0b00000000000000000001001001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 807), 0b00000000000000000001011001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 808), 0b00000000000000000000010001011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 809), 0b00000000000000000100100000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 810), 0b00000000000000000100011100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 811), 0b10000000000000000010110011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 812), 0b00000000000000000110111100000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 813), 0b00000000000000000100101000011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 814), 0b00000000000000000101111001101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 815), 0b00000000000000000010011001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 816), 0b00000000000000000010010100100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 817), 0b00000000000011111111101001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 818), 0b00000000000000000001010100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 819), 0b00000000000000000000011101001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 820), 0b00000000000000000011110000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 821), 0b10000000000000000010100101011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 822), 0b00000000000000000001110001111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 823), 0b00000000000000000111011010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 824), 0b00000000000000000100101100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 825), 0b00000000000000000010000001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 826), 0b00000000000000000010110110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 827), 0b00000000000000000001000111110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 828), 0b00000000000000000000111100010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 829), 0b00000000000000000011010001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 830), 0b00000000000000000011110100001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 831), 0b10000000000000000011101110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 832), 0b00000000000000000110000000011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 833), 0b00000000000000000111101010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 834), 0b00000000000000001000010001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 835), 0b00000000000000000010011101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 836), 0b00000000000000000100101001010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 837), 0b00000000000011111111100111011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 838), 0b00000000000000000010000110110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 839), 0b00000000000000000010101010010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 840), 0b00000000000000000101001011100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 841), 0b10000000000000000001000101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 842), 0b00000000000000000001001110101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 843), 0b00000000000000000011100000100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 844), 0b00000000000000000011101011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 845), 0b00000000000000000110001100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 846), 0b00000000000000000001010110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 847), 0b00000000000000000000100001001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 848), 0b00000000000000000011000011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 849), 0b00000000000000000000111100001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 850), 0b00000000000000000010100110100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 851), 0b10000000000011111110001000011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 852), 0b00000000000000000001000000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 853), 0b00000000000000000001101111111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 854), 0b00000000000000000000111001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 855), 0b00000000000000000001110011010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 856), 0b00000000000011111111110001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 857), 0b00000000000000000011111110111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 858), 0b00000000000000000010101100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 859), 0b00000000000000000100001011111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 860), 0b00000000000000000001100110100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 861), 0b10000000000000000001001001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 862), 0b00000000000011111111111010110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 863), 0b00000000000000000000111001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 864), 0b00000000000011111111001000101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 865), 0b00000000000000000001111101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 866), 0b00000000000000000000000101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 867), 0b00000000000000000010111101100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 868), 0b00000000000000000000110100000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 869), 0b00000000000000000000001001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 870), 0b00000000000000000001000100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 871), 0b10000000000000000100001100001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 872), 0b00000000000000000001001101000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 873), 0b00000000000000000001010110010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 874), 0b00000000000000000001000011100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 875), 0b00000000000000000011110001000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 876), 0b00000000000000000001011010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 877), 0b00000000000000000010001010011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 878), 0b00000000000000000110010010100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 879), 0b00000000000000000000011000110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 880), 0b00000000000000000100110010101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 881), 0b10000000000011111111001111100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 882), 0b00000000000000000000010111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 883), 0b00000000000000000011011111010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 884), 0b00000000000000000000111010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 885), 0b00000000000000000001101010011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 886), 0b00000000000000000001001001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 887), 0b00000000000000000100000001100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 888), 0b00000000000000000011010101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 889), 0b00000000000000000011000110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 890), 0b00000000000000000010010000100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 891), 0b10000000000000000001001111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 892), 0b00000000000000000000100100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 893), 0b00000000000000000001100111110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 894), 0b00000000000000000000100110010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 895), 0b00000000000000000000001111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 896), 0b00000000000000000001010001000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 897), 0b00000000000000000011011001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 898), 0b00000000000000000010011001010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 899), 0b00000000000000000100001001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 900), 0b00000000000000000010101110010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 901), 0b10000000000011111110011110001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 902), 0b00000000000011111111111010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 903), 0b00000000000011111111111011000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 904), 0b00000000000011111111111110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 905), 0b00000000000000000000001110000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 906), 0b00000000000011111001001011100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 907), 0b00000000000011111110010010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 908), 0b00000000000011111111110011000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 909), 0b00000000000011111110110001110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 910), 0b00000000000000000010001110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 911), 0b10000000000000000001010000110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 912), 0b00000000000000000011001000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 913), 0b00000000000000000010000001110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 914), 0b00000000000000000001100101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 915), 0b00000000000000000001000000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 916), 0b00000000000011111110010011101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 917), 0b00000000000011111110110011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 918), 0b00000000000000000010001001101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 919), 0b00000000000000000000101110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 920), 0b00000000000000000011000100100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 921), 0b10000000000011111111100110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 922), 0b00000000000000000010110000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 923), 0b00000000000000000001111111101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 924), 0b00000000000000000000110110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 925), 0b00000000000000000001100000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 926), 0b00000000000011111101011011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 927), 0b00000000000011111111100000110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 928), 0b00000000000000000001000011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 929), 0b00000000000000000001001100111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 930), 0b00000000000000000010110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 931), 0b10000000000011111111111101110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 932), 0b00000000000000000010011100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 933), 0b00000000000000000001001101101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 934), 0b00000000000011111111010000011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 935), 0b00000000000000000010000000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 936), 0b00000000000011111101110100000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 937), 0b00000000000011111111010100001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 938), 0b00000000000000000010100000011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 939), 0b00000000000011111111111101100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 940), 0b00000000000000000000000110111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 941), 0b10000000000011111110110010000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 942), 0b00000000000000000001100111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 943), 0b00000000000000000001011101110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 944), 0b00000000000000000000100010111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 945), 0b00000000000000000010001100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 946), 0b00000000000011111110100111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 947), 0b00000000000000000000100110011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 948), 0b00000000000000000011111000110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 949), 0b00000000000011111110110100111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 950), 0b00000000000000000010011000000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 951), 0b10000000000011111111001110100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 952), 0b00000000000000000001110100101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 953), 0b00000000000000000001001111011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 954), 0b00000000000000000001011011011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 955), 0b00000000000000000000111111001001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 956), 0b00000000000011111101111011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 957), 0b00000000000011111111010111000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 958), 0b00000000000000000000111010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 959), 0b00000000000000000001110000000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 960), 0b00000000000000000011010011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 961), 0b10000000000011111111110001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 962), 0b00000000000000000010001111000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 963), 0b00000000000000000010010010100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 964), 0b00000000000000000000111010001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 965), 0b00000000000000000001100101011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 966), 0b00000000000011111110010110011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 967), 0b00000000000000000000010000111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 968), 0b00000000000000000010101111111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 969), 0b00000000000000000011000101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 970), 0b00000000000000000011001010111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 971), 0b10000000000011111111001001110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 972), 0b00000000000000000001100001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 973), 0b00000000000000000010010101101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 974), 0b00000000000000000001101110101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 975), 0b00000000000000000010000111010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 976), 0b00000000000011111101001101110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 977), 0b00000000000000000000001000000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 978), 0b00000000000000000011101101111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 979), 0b00000000000000000010110000001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 980), 0b00000000000000000010101011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 981), 0b10000000000011111111111010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 982), 0b00000000000000000010000011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 983), 0b00000000000000000010010101000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 984), 0b00000000000000000001101010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 985), 0b00000000000000000001000111000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 986), 0b00000000000011111101001001001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 987), 0b00000000000011111111011000111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 988), 0b00000000000000000001111001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 989), 0b00000000000000000010000000010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 990), 0b00000000000000000011001110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 991), 0b10000000000011111111110000100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 992), 0b00000000000000000001110001101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 993), 0b00000000000000000001101010111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 994), 0b00000000000000000000111100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 995), 0b00000000000000000000100111011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 996), 0b00000000000011111101101000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 997), 0b00000000000000000000000111101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 998), 0b00000000000000000001010110011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 999), 0b00000000000000000001000001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1000), 0b00000000000000000010000110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1001), 0b10000000000000000111000001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1002), 0b00000000000000000000011101100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1003), 0b00000000000000000000010011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1004), 0b00000000000000000000101000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1005), 0b00000000000011111111010011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1006), 0b00000000000000000010010100110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1007), 0b00000000000011111111100001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1008), 0b00000000000011111110101010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1009), 0b00000000000000000000000101001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1010), 0b00000000000000000001011010101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1011), 0b10000000000000000011100101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1012), 0b00000000000000000100011100110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1013), 0b00000000000000000101100111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1014), 0b00000000000000000101000101110100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1015), 0b00000000000000000101001100111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1016), 0b00000000000000000100000101001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1017), 0b00000000000000000100001011010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1018), 0b00000000000000000101010000111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1019), 0b00000000000000000010000101010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1020), 0b00000000000000000101101000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1021), 0b10000000000000000101001010101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1022), 0b00000000000000000101000101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1023), 0b00000000000000000101010110111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1024), 0b00000000000000000101000110110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1025), 0b00000000000000000011110010001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1026), 0b00000000000000000100110001101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1027), 0b00000000000000000100111111101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1028), 0b00000000000000000010111010110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1029), 0b00000000000000000010111010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1030), 0b00000000000000000110000110110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1031), 0b10000000000000000100000011111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1032), 0b00000000000000000110000011010100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1033), 0b00000000000000000110000110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1034), 0b00000000000000000101001000100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1035), 0b00000000000000000100100111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1036), 0b00000000000000000101101101001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1037), 0b00000000000000000100110111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1038), 0b00000000000000000111000101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1039), 0b00000000000000000011000001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1040), 0b00000000000000000110100000010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1041), 0b10000000000000000001101101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1042), 0b00000000000000000100010000101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1043), 0b00000000000000000101111101001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1044), 0b00000000000000000101100001110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1045), 0b00000000000000000011110011011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1046), 0b00000000000000000100100001100001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1047), 0b00000000000000000001100101000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1048), 0b00000000000000000101100100110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1049), 0b00000000000000000011000001110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1050), 0b00000000000000000110110100000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1051), 0b10000000000000001001011110110111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1052), 0b00000000000000000100100100010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1053), 0b00000000000000000101001100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1054), 0b00000000000000000101011110011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1055), 0b00000000000000000011111011110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1056), 0b00000000000000000111010001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1057), 0b00000000000000000100100000001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1058), 0b00000000000000000110101011111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1059), 0b00000000000000000010111101000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1060), 0b00000000000000000100101101000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1061), 0b10000000000000000010110010011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1062), 0b00000000000000000101010001000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1063), 0b00000000000000000101011101010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1064), 0b00000000000000000011101111000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1065), 0b00000000000000000101111001011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1066), 0b00000000000000000010101001011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1067), 0b00000000000000000001100000111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1068), 0b00000000000000000110110100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1069), 0b00000000000000000011011010000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1070), 0b00000000000000000100100110001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1071), 0b10000000000000000011000011100110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1072), 0b00000000000000000111001001001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1073), 0b00000000000000000110010101100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1074), 0b00000000000000000100111011011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1075), 0b00000000000000000110111010110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1076), 0b00000000000000000100010001010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1077), 0b00000000000000000100011100010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1078), 0b00000000000000000110101010000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1079), 0b00000000000000000011010100100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1080), 0b00000000000000001000011000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1081), 0b10000000000000000111011100000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1082), 0b00000000000000000100101100111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1083), 0b00000000000000000100101001001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1084), 0b00000000000000000100101100111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1085), 0b00000000000000000100111001011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1086), 0b00000000000000000111011011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1087), 0b00000000000000000100110101011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1088), 0b00000000000000000110001100011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1089), 0b00000000000000000010011111010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1090), 0b00000000000000000100001011111000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1091), 0b10000000000000001010011111011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1092), 0b00000000000000000101110110001110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1093), 0b00000000000000000101001110001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1094), 0b00000000000000000101110011001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1095), 0b00000000000000000101011110001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1096), 0b00000000000000001001101100011110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1097), 0b00000000000000000101010111010101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1098), 0b00000000000000000110101111101000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1099), 0b00000000000000000101101101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1100), 0b00000000000000000110010010101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1101), 0b10000000000000000011011110110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1102), 0b00000000000000000000011010011001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1103), 0b00000000000000000000010101110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1104), 0b00000000000000000000010001111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1105), 0b00000000000011111111110100110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1106), 0b00000000000011111111011011000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1107), 0b00000000000011111111111001001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1108), 0b00000000000011111111100100000011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1109), 0b00000000000000000000011111001111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1110), 0b00000000000000000101001100000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1111), 0b10000000000000000101000000011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1112), 0b00000000000000000111100111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1113), 0b00000000000011111110001010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1114), 0b00000000000011111101110100111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1115), 0b00000000000011111110101011011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1116), 0b00000000000011111111010110100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1117), 0b00000000000011111111011000010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1118), 0b00000000000011111101001010100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1119), 0b00000000000000000000110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1120), 0b00000000000000000011111011101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1121), 0b10000000000000000100101011011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1122), 0b00000000000011111100111110011010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1123), 0b00000000000000000011100011000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1124), 0b00000000000011111110101001001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1125), 0b00000000000011111101111000110000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1126), 0b00000000000000000000011000011000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1127), 0b00000000000011111110011010111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1128), 0b00000000000011111101010010101111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1129), 0b00000000000000000001111000011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1130), 0b00000000000000000001011110001010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1131), 0b10000000000000000010100000100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1132), 0b00000000000000000000101100011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1133), 0b00000000000011111111000110100010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1134), 0b00000000000000000101100011010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1135), 0b00000000000011111111010100101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1136), 0b00000000000011111111101011111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1137), 0b00000000000011111110110001101110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1138), 0b00000000000011111111000001101101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1139), 0b00000000000000000000110100100011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1140), 0b00000000000000000001101111111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1141), 0b10000000000000000001010110010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1142), 0b00000000000000000000111001010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1143), 0b00000000000011111100110010111010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1144), 0b00000000000011111110100110011111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1145), 0b00000000000000000110001100001000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1146), 0b00000000000011111111011000111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1147), 0b00000000000011111110100111111111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1148), 0b00000000000011111111101110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1149), 0b00000000000000000000010011000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1150), 0b00000000000000000000100100000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1151), 0b10000000000000000011000101111101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1152), 0b00000000000011111111000100101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1153), 0b00000000000011111101011011010110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1154), 0b00000000000011111101000001000010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1155), 0b00000000000011111101011011000110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1156), 0b00000000000011111100101010001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1157), 0b00000000000011111110100001101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1158), 0b00000000000011111100110100011100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1159), 0b00000000000011111110001011100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1160), 0b00000000000000000011100110001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1161), 0b10000000000000000010110101100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1162), 0b00000000000000000000100101001101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1163), 0b00000000000011111110001011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1164), 0b00000000000011111100111111100000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1165), 0b00000000000011111111010010010001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1166), 0b00000000000011111110011010110011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1167), 0b00000000000000000010011011110010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1168), 0b00000000000011111101010010000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1169), 0b00000000000011111110111100000100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1170), 0b00000000000000000000111110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1171), 0b10000000000000000011000010110101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1172), 0b00000000000011111110010001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1173), 0b00000000000011111111010000001100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1174), 0b00000000000011111110010010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1175), 0b00000000000011111101110111100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1176), 0b00000000000011111111000010000111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1177), 0b00000000000000000000011011110110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1178), 0b00000000000000000110010110111001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1179), 0b00000000000000000000110011110001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1180), 0b00000000000000000000100110000101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1181), 0b10000000000000000011100101101100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1182), 0b00000000000000000000110111010000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1183), 0b00000000000011111111010011001011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1184), 0b00000000000011111110011010100100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1185), 0b00000000000000000000001000111110);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1186), 0b00000000000011111110110111101010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1187), 0b00000000000011111110111101011101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1188), 0b00000000000011111100101111000001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1189), 0b00000000000011111101011110101011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1190), 0b00000000000000000001111010111100);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1191), 0b10000000000000000011111101011011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1192), 0b00000000000011111110111000000000);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1193), 0b00000000000011111110100000101001);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1194), 0b00000000000011111101100010010011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1195), 0b00000000000011111110101110010111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1196), 0b00000000000011111110101001100111);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1197), 0b00000000000011111110010000111011);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1198), 0b00000000000011111110001010010010);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1199), 0b00000000000011111110010110100101);\n",
            "Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * 1200), 0b00000000000000000001111010010111);\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hex_to_16bit_binary(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일 내용 읽기 및 분리 (스페이스 및 줄바꿈 기준)\n",
        "        hex_values = f.read().split()\n",
        "\n",
        "    # 16진수 -> 16비트 2진수 변환\n",
        "    binary_values = [format(int(hex_value, 16), '016b') for hex_value in hex_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for binary_value in binary_values:\n",
        "            f.write(binary_value + \"\\n\")  # 각 값을 줄바꿈으로 저장\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/RESULT_0212_Nrtl_sort2.txt'  # 16진수 값이 저장된 입력 파일\n",
        "output_txt_file = './model/binary_values_sorted2.txt'  # 변환된 16비트 2진수를 저장할 출력 파일https://github.com/MMujtabaRoohani/RISC-V-Processor/blob/master/PipelinedProcessor/Control_Unit.v\n",
        "# 함수 호출\n",
        "convert_hex_to_16bit_binary(input_txt_file, output_txt_file)\n",
        "print(f\"16진수 값이 16비트 2진수로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "cCw_Fb3iL9zA",
        "outputId": "bfeef1db-3315-4e64-e5fe-39bd82a9f8f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16진수 값이 16비트 2진수로 변환되어 ./model/binary_values_sorted2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary_to_decimal(input_file, output_file):\n",
        "    def binary_to_decimal(binary_str):\n",
        "        # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "        int_part = int(binary_str[:3], 2)  # 정수부\n",
        "        frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "        return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 16비트 바이너리 값 읽기\n",
        "        binary_values = f.read().splitlines()\n",
        "\n",
        "    # 16비트 이진수를 10진수로 변환\n",
        "    decimal_values = [binary_to_decimal(binary) for binary in binary_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for decimal in decimal_values:\n",
        "            f.write(f\"{decimal:.10f}\\n\")  # 소수점 10자리까지 출력\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/binary_values_sorted2.txt'  # 16비트 바이너리 입력 파일\n",
        "output_txt_file = './model/cordic_dec_val_sorted2.txt'  # 변환된 10진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_binary_to_decimal(input_txt_file, output_txt_file)\n",
        "print(f\"16비트 바이너리 값이 10진수 소수점 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "6YmJ4ZPhM_Nb",
        "outputId": "6bffc754-4ecf-4a6d-b620-56d5223ade98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16비트 바이너리 값이 10진수 소수점 값으로 변환되어 ./model/cordic_dec_val_sorted2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_fixed_point_hex(input_file, output_file):\n",
        "    def float_to_fixed_point(value):\n",
        "        \"\"\"\n",
        "        10진수 소수를 16비트 고정소수점 표현으로 변환:\n",
        "        - 앞 3비트: 정수부 (0~7)\n",
        "        - 뒤 13비트: 소수부\n",
        "        \"\"\"\n",
        "        # 정수부: value의 정수 부분 (0~7 사이 값)\n",
        "        int_part = int(value)\n",
        "        if int_part > 7:\n",
        "            raise ValueError(f\"정수부가 3비트를 초과했습니다: {value}\")\n",
        "\n",
        "        # 소수부: value의 소수 부분을 13비트로 표현\n",
        "        frac_part = value - int_part\n",
        "        frac_binary = int(round(frac_part * (2 ** 13)))  # 소수부를 2^13로 스케일링\n",
        "\n",
        "        # 16비트 바이너리 표현\n",
        "        binary_value = f\"{int_part:03b}{frac_binary:013b}\"\n",
        "        return binary_value\n",
        "\n",
        "    def binary_to_hex(binary_str):\n",
        "        \"\"\"\n",
        "        16비트 바이너리를 16진수(hex)로 변환.\n",
        "        \"\"\"\n",
        "        return f\"0x{int(binary_str, 2):04X}\"\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 10진수 소수점 값 읽기 (불필요한 문자 제거)\n",
        "        raw_data = f.read()\n",
        "        cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "        decimal_values = [float(value) for value in cleaned_data.split()]\n",
        "\n",
        "    # 10진수를 16비트 고정소수점 -> 16진수로 변환\n",
        "    hex_values = []\n",
        "    for value in decimal_values:\n",
        "        binary_value = float_to_fixed_point(value)  # 16비트 바이너리 변환\n",
        "        hex_value = binary_to_hex(binary_value)  # 16진수 변환\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for hex_value in hex_values:\n",
        "            f.write(f\"{hex_value}\\n\")\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/softmax_sorted_attention_scores_2.txt'  # 입력 파일\n",
        "output_txt_file = './model/converted_fixed_point_hex.txt'  # 변환된 16진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "decimal_to_fixed_point_hex(input_txt_file, output_txt_file)\n",
        "print(f\"소수점 값이 16비트 16진수 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jaDSmkz7Rmej",
        "outputId": "1be6d348-7a2d-4fe4-b519-52be78856cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소수점 값이 16비트 16진수 값으로 변환되어 ./model/converted_fixed_point_hex.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_sorted2.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"각 값의 오차율 (퍼센트):\\n{error_rates}\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "ubtP_IPwR_KR",
        "outputId": "d9162427-bc30-4699-ddaa-ba1df79b1401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "[   95.31011771    83.05372975   802.12375945   539.53063006\n",
            "   410.1153017    247.55210415    48.9803008     99.31327041\n",
            "    45.17360522    70.50694549    96.59446638    89.26835239\n",
            "   864.66384646   911.85463322   980.90106322   599.05170616\n",
            "   509.25342046   549.15449377   593.61922931   447.48531658\n",
            "    93.6009912     86.99218416  1109.43362143   362.32557209\n",
            "   254.47711505    98.21893448     8.37888761     2.26668618\n",
            "    81.81958442   105.37897644    97.39332295    93.13830847\n",
            "   709.02457105  1775.07914033  1123.4056931   1208.13306348\n",
            "  1207.27559593   768.81808769   914.60207135   341.47860687\n",
            "    92.21203837    95.85356303   439.1987519    520.606385\n",
            "   292.53429809   508.89373909   307.21945723   405.32375693\n",
            "   504.97287126  2007.98731868    54.51091452    73.92715494\n",
            "   430.87687272   297.62822874   168.6450454    134.95054345\n",
            "   110.1758489    121.04289296   140.66853161    46.75913553\n",
            "    88.18903383    89.39236443   572.51835999   319.41586251\n",
            "   391.65698323   292.98164272   329.81605051   341.05043113\n",
            "    99.69559236   181.57994797    87.64297865    83.08989665\n",
            "   642.07577982   200.23877509    69.26893229   144.62492196\n",
            "   267.39682063   124.86385047   112.02974972    85.06935701\n",
            "    98.06753799    94.47868036  1168.45682809   526.10832869\n",
            "   244.06061311   291.97159724   511.87718457   135.14149545\n",
            "   268.21231246   282.00320893    96.71329378    95.80405678\n",
            "   356.60520675   395.8985895    211.05369686   839.55127288\n",
            "  1109.6422121   1181.62586199  2213.55282524  1922.37167562\n",
            "    74.71691158    71.06269005   314.99648522   346.92892457\n",
            "   258.83933284    76.97471462   148.00290066   134.44134761\n",
            "   182.87888754   372.31219246    76.51569112    83.81593082\n",
            "   280.91287512   143.31858826   136.47365779   238.58016434\n",
            "   278.29102251   296.7309773    387.71821926   657.19189582\n",
            "    79.91177558    50.09970745   467.97795886   253.4006375\n",
            "   119.96702292    91.03986506   108.00722166   117.09615592\n",
            "   301.90197537   382.94715461    51.34599194    18.5729311\n",
            "   313.09923813   361.59799464   370.88149963   198.82907774\n",
            "   143.88594631   126.79460782   146.07964955    16.61677581\n",
            "    76.95053515    83.25004258   128.53542924   134.40777299\n",
            "   163.00545675   197.3951354    207.57324839   512.19838275\n",
            "   549.56004818   667.41206076    67.62863881    61.14936283\n",
            "   220.36930261   222.04872713    72.48709129    62.95998515\n",
            "    84.19724912   170.14847113   304.72598363   478.55802773\n",
            "    10.00904579    58.27322226   276.46121648   214.48013066\n",
            "   196.48948031    81.78406493    97.92495596   101.41597873\n",
            "   125.79545497   290.19439953    51.35331064    58.91973087\n",
            "   211.91281371   225.24451055   117.49729304   125.70165196\n",
            "   194.63820221   190.77564592   184.83294536   579.61558118\n",
            "    30.52630434    61.76059921   257.58900029   220.20711663\n",
            "   113.55722381   112.0436326    101.00682671   131.18406744\n",
            "   183.94779109   313.2200262     48.58187212    60.35204629\n",
            "   686.50393929   190.68562467   197.95770308   192.61307596\n",
            "    32.0127286     24.40859153    70.62069398    57.58641376\n",
            "    98.43341034    96.91052794   483.12600766   397.93484035\n",
            "  1301.38864393   779.22956068   415.55450761   510.80004085\n",
            "   898.07701174   965.68789655    95.34495819    92.96810844\n",
            "   196.13917055   452.73930903  1074.0266407   1015.80301093\n",
            "   836.71775788  1443.04986129   580.34771209   791.02751398\n",
            "    72.56933315    70.7944469    507.56387543   367.65042036\n",
            "    66.63426181   122.82436806   139.36174694    45.64368684\n",
            "    51.06591991    63.87169913    94.40152898    91.47974322\n",
            "  1410.72944902   781.73124143   411.03915471   466.55581666\n",
            "   515.61565463   268.28036464    46.04883348   176.42375033\n",
            "    98.44810244    97.28318052   599.52033482   590.20532688\n",
            "   479.68966974   494.02054762   406.58027456   484.20856391\n",
            "  1463.53157415   815.7562824     94.55661131    92.51144476\n",
            "   210.72549381   227.27381197   522.13386445   548.41311375\n",
            "   608.69290049   964.75956665  1135.32892659  1508.5449601\n",
            "    51.30448054    58.72263368   157.52553677   228.45970711\n",
            "   293.68167028   318.70893503   231.2953991    208.09815335\n",
            "    87.83181075   117.63374311    43.09328829    40.72109818\n",
            "   551.94828729   155.1399936    141.44303199   185.93954882\n",
            "    76.10376653    47.53148429     6.34889401     1.92577171\n",
            "    93.46393131    78.9396669    380.46386258   391.86510516\n",
            "   754.13543935   507.33039374    85.6450776      9.04598964\n",
            "    36.1821732     89.82102487    95.28634151    95.46818248\n",
            "    87.17380437   156.40499437  1094.56313403  1619.52820554\n",
            "  1719.37417382  1757.70891852  1567.49850718  1564.72587905\n",
            "    49.96288252    42.01337437   579.89618762    65.3442288\n",
            "    55.45614153    44.65517579   103.54296094   119.38887722\n",
            "   171.46334477    42.30618       90.01211527    82.9481342\n",
            "   447.25556835   312.92674592   238.18785268   229.45562436\n",
            "   267.98058038   561.68007821   610.10771851  1303.8366562\n",
            "    76.09641774    69.56964754   221.65098604   262.48299986\n",
            "   287.35984884   158.52339693   162.9789535    181.66855395\n",
            "   208.81898595   175.35124438    76.3466427     80.06077908\n",
            "   201.48206846   272.37619957   222.41896084   169.04694069\n",
            "   314.90135323   474.58048853   397.28685091   228.3397135\n",
            "    76.23144824    89.78721231   212.0975159    247.17234827\n",
            "   157.83960368   139.86414684   157.29102092   373.80943177\n",
            "   459.94741734  1675.54521238    31.23690418    40.67845423\n",
            "   171.99551475   204.47504694   159.09019019   219.46808977\n",
            "   178.94580524   241.4893946    196.79805319    68.11364888\n",
            "    51.51871435    57.34603025   226.77454567   185.38587689\n",
            "    38.12818674   111.59566392   160.29677482   426.97862221\n",
            "   340.70323491   289.53056631    74.67258719    71.43441222\n",
            "   154.22555102   134.02926919   173.49302477   162.78407575\n",
            "   224.9873642    282.11612584   354.1552554    837.05278892\n",
            "    38.21590189    28.60922565  1527.56204458  1715.37320061\n",
            "  1877.69022309  1987.61626613  2261.33552244  1831.07039056\n",
            "  1004.63319934  1678.69624524   423.23577241   129.28457078\n",
            "   638.55416445   343.54176848   173.77269243    48.47671413\n",
            "    35.27841729    74.46090438    66.18851999    41.01290765\n",
            "    98.51900522    96.69057964   651.9613506    522.75266788\n",
            "   896.4031279   1533.13519479   971.05881232   983.23861839\n",
            "  1201.48242474   446.27086844    99.14504487    91.58797318\n",
            "   629.56340373   419.1844333    956.23931293   979.54490859\n",
            "   909.45951133  1971.87792649  2166.41795495  2663.43485681\n",
            "    71.0103849     70.92070724  1516.47491386    38.35129223\n",
            "    17.35910821    66.06805034    54.60641603    78.06971702\n",
            "    75.83168454    85.224945      99.65235224    96.30157399\n",
            "  1396.66484884  1570.50240675  1714.89466628  2153.62652216\n",
            "  1496.88190427  3256.31014546  1495.3924342   1144.51803377\n",
            "    91.76619081    94.86130884   547.5114636    257.84887607\n",
            "   137.22322698   118.51888463   264.22953957   248.38040653\n",
            "   249.98113569   864.69783599    90.84724173    99.82902657\n",
            "   710.67000507   817.87975299   381.78572985   405.28944295\n",
            "   305.89788208   289.0916668    484.27566734  7410.89621855\n",
            "    87.33504033    83.54472548   314.66421814   341.02750602\n",
            "   319.40305402   427.35256792   164.33683363   407.37308213\n",
            "   365.39634382   200.43891978    81.42142418    81.90403833\n",
            "   758.29556855    20.8723061    115.19833497    54.56404689\n",
            "    27.48395976    11.77541687    19.17228675    29.30994961\n",
            "    96.69146496    98.17571603  1026.34972747   370.0711709\n",
            "   547.63082881   852.87999137   932.70153541   743.44814991\n",
            "  1051.60065247  2491.12183838    97.57914539    95.68584345\n",
            "   871.18286385    33.49538352    49.53092837    38.71233349\n",
            "    17.22496742   179.36427381   787.25085888   267.72439877\n",
            "    98.67155377    84.5137391   2838.46799026  1562.9649427\n",
            "  1542.95338448  1432.06281522  1198.66845978  1390.04049098\n",
            "  1045.02546232   629.85055556    85.69619149    92.80362574\n",
            "   496.39435372   262.48972883    62.63427765   172.51436938\n",
            "   247.61531426   265.53635262   218.18477829   426.2703508\n",
            "    94.02576419    97.65258986   476.24133554   524.21326511\n",
            "   399.24505656   416.90831014   413.93600411   782.39150095\n",
            "  1116.89948795  1790.21426335    88.81164662    98.58806231\n",
            "   446.52334078   116.83635066   201.13891476   284.1582166\n",
            "    70.03000708   147.87205918   408.27140169  1097.65036742\n",
            "    95.20040715    93.31288504   249.18297201    73.08150659\n",
            "   136.29558047   183.48573119   408.49514886  1655.97868627\n",
            "  1796.41683274  2688.35724333    63.00252224    92.52225317\n",
            "  1684.82523013  1755.0263427   1807.00815801  2050.57310325\n",
            "  2633.4318017   2589.34317715  2177.21742592 19283.60057407\n",
            "   353.31180092    63.54818395   209.83196292   172.43044751\n",
            "   114.01640668   194.57830503   215.9941394    131.14729397\n",
            "   173.64829228  1230.89710159    80.69893227    93.45841064\n",
            "  1143.41164841  1437.22181674  1822.8719092   3121.35944786\n",
            "  4236.41634033  4970.81276646  5298.97030425 14156.48830769\n",
            "   564.46603424     0.33254805   697.37917016    65.54440302\n",
            "    77.35688419    52.48526146     6.93611421     3.8751464\n",
            "     4.67290047   848.14258989    85.77671527    95.81093087\n",
            "   548.98380104   680.54921356   835.55489346    30.70967037\n",
            "    57.54100243    71.59407585   112.55652387  1946.31188101\n",
            "    89.66427065    89.72485191   100.48336701   430.57822582\n",
            "   557.86856325   573.38666226   689.13697851   821.6488463\n",
            "  1139.90787323   736.49175968    86.85504335    79.61367095\n",
            "   259.28570817   137.74303938   147.37590683   141.43103434\n",
            "   118.77121264   179.25263688   770.77876882   611.16090155\n",
            "    59.0491285     82.98786302   181.68450433   188.84322489\n",
            "   294.50858665   108.11483877   107.3490522    113.77406556\n",
            "   302.55853538   402.79945606    73.99980517    89.01987089\n",
            "   245.77507201   340.5163159    104.56709221   209.42137447\n",
            "   149.55097226   143.68365995   166.45584925   743.91314297\n",
            "    92.61216146    93.09654159  1061.73151203   519.49226402\n",
            "    90.58291751     3.36007798    10.80425786    22.88038448\n",
            "   357.10760213   474.57565678    95.33351813    94.00646339\n",
            "   491.53956577   784.13123959   595.50312675   576.8865207\n",
            "   633.33807145   682.89033756  1112.59772971  1195.1545502\n",
            "    21.08858719    62.24357773   251.51728644   230.21005292\n",
            "   132.23916902    87.21374984    99.08145986   151.05637892\n",
            "   192.90209461   219.91563021    60.84920958    59.84284971\n",
            "   253.4745796    255.67622681   113.01208811   113.56845336\n",
            "   152.56656143   148.44336002   155.78849261   121.2230553\n",
            "    55.19471432    56.35854545   470.70482549   522.03832649\n",
            "   277.99478961    16.27628534    20.94294078    14.08393171\n",
            "    12.82958198    40.31051537    94.08755813    95.15068407\n",
            "    86.59960682   354.77905999   621.96746143   658.33691404\n",
            "   793.35841197  1104.10141682  1305.30044165  1761.79937945\n",
            "    32.33729246    46.8345279    301.57011923   190.42353574\n",
            "   117.61603115    74.94476112    80.68570257   101.56620702\n",
            "   109.04818417    91.50842088    44.50975523    39.4350798\n",
            "   176.80504926   259.42343545   243.14131487   137.83851501\n",
            "   167.40178949   124.67242567   140.79408572   165.00177462\n",
            "    36.80334464    65.66548458   221.11108454   240.77185751\n",
            "   131.89077017    98.88908291   145.3174505    162.49244515\n",
            "   166.97623204   361.93354854    51.04054079    40.45910832\n",
            "    80.52669929   118.71510683   128.53058729   192.33817939\n",
            "   209.4495207    292.70685354   316.9568581    321.64981557\n",
            "    47.02592942    78.68977142   113.92366541   115.69003801\n",
            "   125.0508965    130.88639822   131.65441199   114.25012035\n",
            "    91.06190364   900.07213488    25.42236792    38.49140836\n",
            "   271.14763062   246.39746569    43.8641251     57.93723366\n",
            "    68.32987577    69.38926529    73.43648946    98.27421429\n",
            "    20.99046046    17.3942679    134.27653866   183.20160838\n",
            "   192.66859659   230.28162768   240.32157193   260.89174654\n",
            "   191.42533822   178.33970407    41.63405788    83.59777826\n",
            "   136.9258324     92.88079191    87.74813316    96.92164614\n",
            "   101.89973455   107.79680362   320.05265474  1436.87234271\n",
            "    31.63971639    47.59250243   148.36841741    81.97410436\n",
            "    78.10655178    97.37747728   112.55702601   118.91063185\n",
            "   129.67908946   154.82123385    50.7487184     77.82498755\n",
            "   497.71345177   477.75569301    56.51094483    60.04878435\n",
            "    60.71283843     5.21120517    25.2722917     21.97055294\n",
            "    82.21443762    81.65041961  1168.2966326    474.01459074\n",
            "   301.28689733   219.54475717   170.13254522    83.25746935\n",
            "   139.55329312   132.947472      93.12969338    91.83947227\n",
            "   765.42622713   221.43090808   191.71950642   258.23254774\n",
            "   185.62993537   259.61751472   216.73625333   418.11557085\n",
            "    89.75443768    66.23781809   697.35670338   792.58579719\n",
            "   268.43240103   364.85744857   282.36738416   154.65479965\n",
            "   122.24873643    94.53397618    92.54057166    96.46178096\n",
            "   511.34748387   217.51252747   314.71727357   512.845732\n",
            "   565.84703587   352.76592605   439.01141235  1707.68178963\n",
            "    82.49101959    59.54213126   306.0885784    376.4775153\n",
            "   289.01539855   309.80718651   335.28842493   368.84635747\n",
            "   349.06226714   399.0402319     77.83914793    90.89394556\n",
            "   351.2242361    202.31026265   210.50463029   219.81195591\n",
            "   262.46691177   249.4621876    214.25672779   570.479892\n",
            "    65.08066923    42.48467454   581.19427394   329.55979489\n",
            "   156.80177573   149.30422772    33.59566354    31.55423416\n",
            "    42.64169163   111.05728192    80.60224478    78.92131309\n",
            "   139.65558217   225.17125452   624.8747528    931.99394367\n",
            "   359.94147226   328.99830256   362.11812046   429.37830758\n",
            "    71.99362307    72.21055172   168.86972083   195.18349923\n",
            "   202.62633805   193.99297614   187.6335139    222.219841\n",
            "   323.20143587   343.37151584    66.63288167    65.2424168\n",
            "   379.7575044    106.29063473   174.61990002   227.97719784\n",
            "   232.55186907   358.15581113   230.69870477   184.4862322\n",
            "    72.40272638    92.45899216   360.70229433   352.88952176\n",
            "    80.68216391    69.5287422    208.85003535   260.20567759\n",
            "   251.08120245  3327.52117866    77.03542249    85.50624062\n",
            "   248.84618106   234.59837206   120.13900695   158.2400801\n",
            "   193.74346277   219.15413973   575.74389462   315.11709372\n",
            "    63.56061501    85.97933301   221.73652967   289.01897191\n",
            "   191.08404019   247.73893378    41.10067326   164.96799782\n",
            "   177.81814398   685.29739655    49.3599925     81.21408218\n",
            "   257.90708037   154.09627469   269.28827094   266.45432608\n",
            "   267.15744391   202.88585263   194.53301048   196.26362749\n",
            "    81.7012373     67.3804824    327.22579631   108.84487048\n",
            "   126.02500895   248.46324765   258.1096958    641.96876343\n",
            "   604.23264443   245.91820983    71.26159352    77.9377105\n",
            "   249.37268109   296.03457589   211.33228686   123.71521378\n",
            "   120.3842337    323.98286129   267.94584139   269.64551155\n",
            "    68.2545261     84.73247962   210.92690652   171.12411938\n",
            "   160.75349211   155.30171564   185.70520295   295.51960645\n",
            "   406.98349763   280.87799256    73.43447464    84.22536061\n",
            "   293.38940637   112.37732585    81.94452968   111.71025094\n",
            "   158.13865423   420.5289882    739.81967345   722.50351236\n",
            "    66.03815864    80.54070958   117.5444259    126.97015781\n",
            "   139.09656064   169.65048632   221.7098965    442.37081081\n",
            "   408.67709587   850.01386905    41.61904655    74.81335833\n",
            "  1013.94550047    11.79962344    15.27929733    45.66812929\n",
            "    46.7601593     42.35523481    43.61865927    67.81903075\n",
            "    95.76464764    72.01025647  4381.8970928   6508.88155498\n",
            "  7121.32186595  7743.97217026  8402.10376165  5806.64622481\n",
            "  4908.29233092  6194.3004009    369.98481985    68.40604542\n",
            "   103.14307507   111.65305711   123.66089008   205.13758591\n",
            "   242.89354363   228.36624285   237.70714311   270.16154547\n",
            "    57.28117198    38.45901183   344.78371262   156.3950427\n",
            "    71.75117393    72.60083245   105.28573909   236.89119128\n",
            "   303.41892751   216.53413464    66.97307991    57.26234389\n",
            "   354.27850844   131.37456997   174.92876784   266.25657557\n",
            "   131.35973606   101.71984781   130.68526179   253.89775027\n",
            "    85.05899992    77.05751184   545.09214523   142.76263769\n",
            "   160.57569774    69.04429855   112.30719557   105.34789196\n",
            "   247.10545891   245.63331482    90.12863962    74.91789374\n",
            "   413.28927516   365.04192503   436.59181215   583.89964705\n",
            "   335.85136173   179.13277407   270.70091841   334.62438531\n",
            "    76.09006142    77.60076363   265.81918079   209.98638057\n",
            "   255.25578295   320.89081946   260.52770547   226.12710645\n",
            "   114.1999247    219.21078405    82.02423596    68.83971206\n",
            "   261.54860508   312.23930671    91.79072014   188.63153359\n",
            "   244.96350325   231.06178721   431.27418422   470.83226832\n",
            "    69.43230747    84.83006529   507.19081108   698.32779076\n",
            "   108.74223847    42.23691563    18.90531417    22.48856712\n",
            "    53.94241092   259.5895829     81.93219885    73.08843699\n",
            "  1656.02453064   709.76072514    97.13791731    86.83757272\n",
            "    81.55136604    92.8203579     74.46076238    87.34313273\n",
            "    88.85519575    73.81934415  2625.06632609   833.08336836\n",
            "   296.71411394    15.19116581    33.43645989    31.13006913\n",
            "    48.91885614    69.24396215    98.78577027    95.53167963\n",
            "   753.8651292   2157.51714715  1646.4302238   1669.6755306\n",
            "  1083.12309957   624.35196403   580.37401058   604.20310267\n",
            "    94.28861407    91.32945158   964.45665596   161.74568752\n",
            "   205.23363084   440.11605538   433.17075472   287.14010111\n",
            "   420.97207875   500.08650697    90.95721685    68.05184233\n",
            "  1454.57072624   210.74728109   164.84026745   210.00760653\n",
            "   186.81797949   175.9992571    186.58873519    92.55044966\n",
            "    95.06268156    75.57829175  1514.75077937  1759.30777247\n",
            "   181.09121937   117.79064188    80.75122243   146.86711842\n",
            "   149.75347366   456.2185729     93.30385671    92.71057205\n",
            "  1328.62309233  1154.39096662   836.58952603   825.24388631\n",
            "   483.79313227   499.18652616   291.18046027   235.01638689\n",
            "    86.11102335    84.9026713    915.53421348   231.68471061\n",
            "    82.55484543    74.19620258    91.35912621    55.73609778\n",
            "   124.65684038    21.53505479    97.01352702    87.15787605\n",
            "  1943.59517929   736.71350878   604.55594452   517.13127073\n",
            "   573.58841954   730.79528753   668.22289304   497.38250078\n",
            "    89.88616791    84.06129311   836.69993471   393.90786885\n",
            "   117.72401247   121.08270749   113.82970629   133.58985939\n",
            "   216.11624393   321.86451452    90.16527481    73.7585146\n",
            "   784.20413098]\n",
            "전체 평균 오차율 (퍼센트): 442.353855\n",
            "최대 오차율 (퍼센트): 19283.600574 (위치: 559)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_bert_layer1.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# numpy 배열 전체 출력 설정 (생략 없이)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# ✅ 결과 출력 (10개 단위 줄바꿈)\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "tVsIMaMrF_jQ",
        "outputId": "379ff2c7-0fa8-4f0f-c8de-4eb5c2763690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "120.101028, 52.651301, 129.893409, 119.760384, 107.262933, 65.873099, 76.468514, 125.520639, 45.220852, 103.863026\n",
            "110.225792, 96.154273, 92.932656, 129.051547, 88.973052, 92.287452, 69.124494, 100.712463, 131.792484, 65.439547\n",
            "98.714075, 139.890921, 97.113615, 79.309564, 92.960645, 49.011227, 132.641627, 117.251093, 139.281237, 145.401546\n",
            "143.069622, 127.572188, 96.959060, 93.521287, 99.462274, 122.636455, 109.602257, 108.160827, 60.705602, 58.117353\n",
            "130.197388, 139.701328, 102.546990, 58.843876, 108.467560, 109.786918, 89.285990, 145.542366, 52.683158, 152.295077\n",
            "72.805601, 148.599307, 98.103439, 82.810370, 151.454175, 87.136642, 57.097109, 92.262495, 105.789274, 104.021420\n",
            "85.619997, 108.359382, 109.466631, 83.942319, 60.823821, 88.267837, 116.693204, 134.738648, 118.012907, 61.146140\n",
            "124.349383, 97.407008, 53.553961, 54.618739, 114.238822, 106.152435, 75.307098, 64.089968, 72.291247, 140.025778\n",
            "89.733922, 71.832412, 99.783851, 40.283664, 75.105369, 57.521296, 87.374069, 101.060979, 137.651240, 102.228964\n",
            "125.443275, 45.136134, 104.725566, 97.768630, 48.488510, 89.172031, 50.915055, 107.723487, 114.970356, 51.413682\n",
            "96.681210, 64.225009, 118.421853, 102.645772, 94.407583, 115.716487, 88.950476, 174.281354, 119.888247, 86.831031\n",
            "91.954166, 128.005323, 120.784147, 131.403168, 59.142249, 101.772773, 109.907055, 94.608076, 104.341395, 73.296387\n",
            "163.260156, 141.758444, 121.235263, 135.637741, 109.955908, 91.793290, 87.643082, 81.048148, 130.469192, 71.890050\n",
            "131.893129, 122.584075, 55.723648, 56.084441, 142.586771, 121.766502, 59.018720, 78.433252, 141.511082, 100.933105\n",
            "80.696644, 60.115055, 89.731744, 51.183811, 99.057509, 117.327174, 107.059956, 118.698837, 89.272421, 132.720795\n",
            "101.668798, 70.218782, 113.996307, 94.114237, 112.797733, 68.828553, 48.492598, 126.279941, 142.003199, 100.626420\n",
            "120.397954, 62.197903, 80.803931, 52.158070, 63.113106, 72.556089, 79.461588, 150.435850, 96.601254, 144.701933\n",
            "143.444587, 65.624003, 130.422158, 69.214232, 81.225575, 151.528389, 123.135512, 137.794819, 132.697276, 70.638387\n",
            "55.619156, 88.819859, 74.166249, 77.299243, 77.791731, 137.201700, 55.151737, 130.517111, 135.706005, 133.164963\n",
            "113.910485, 132.368752, 132.035322, 89.274300, 86.730470, 58.146783, 71.612070, 80.329605, 146.566962, 94.641835\n",
            "112.920073, 70.909850, 98.394513, 175.671103, 109.570424, 86.748725, 104.928115, 115.871795, 87.581036, 157.838301\n",
            "181.068392, 67.477923, 104.515220, 109.593977, 173.732535, 133.854735, 94.218920, 88.415156, 96.482990, 88.858406\n",
            "108.316765, 58.400831, 103.549615, 92.733699, 103.938129, 61.880488, 278.249762, 108.692781, 116.072282, 83.346843\n",
            "168.396399, 76.822632, 89.585577, 90.794992, 200.652034, 149.047283, 139.073568, 178.331065, 155.295820, 100.624527\n",
            "109.887288, 138.322019, 40.273680, 123.433571, 73.067447, 103.938900, 57.213045, 136.569086, 131.991591, 81.997948\n",
            "122.310666, 137.681349, 54.534624, 117.464721, 124.941644, 95.496790, 54.736767, 83.861015, 57.542247, 130.040353\n",
            "72.355870, 76.197200, 71.846703, 60.884397, 135.670731, 127.916461, 141.026189, 130.701894, 113.901755, 121.584111\n",
            "76.484537, 103.349844, 140.102427, 122.301005, 68.072976, 103.322145, 120.862122, 163.564964, 56.944034, 69.597706\n",
            "103.000995, 61.928057, 179.085541, 104.529045, 142.706485, 83.642827, 93.615245, 106.801212, 127.679071, 65.864561\n",
            "87.916433, 89.184795, 104.885467, 93.170974, 78.425355, 161.605493, 107.057610, 78.802467, 79.497492, 86.163552\n",
            "70.796400, 104.582138, 134.946616, 142.513838, 93.958336, 153.583193, 108.786018, 87.570883, 76.243457, 84.001378\n",
            "118.764975, 101.785310, 76.820681, 68.294287, 107.126510, 147.885372, 82.706125, 77.875444, 102.163789, 162.042919\n",
            "136.867568, 91.569442, 125.951357, 93.661280, 82.860170, 125.610375, 120.407308, 71.846125, 155.700037, 86.317361\n",
            "140.622670, 75.645253, 136.933080, 135.357463, 90.414252, 106.316546, 70.740113, 89.508875, 115.375956, 98.415360\n",
            "144.009482, 126.239212, 96.274099, 110.431209, 76.174842, 129.089082, 93.847788, 91.262713, 143.056073, 78.733603\n",
            "128.419138, 49.940710, 118.195358, 144.623705, 89.413116, 122.453982, 82.778669, 122.277117, 43.938995, 97.170520\n",
            "97.245996, 77.571551, 149.464516, 140.574746, 57.792600, 149.424498, 78.355655, 105.990621, 128.208247, 141.675968\n",
            "126.304905, 86.516820, 148.500568, 142.686673, 61.132007, 106.045323, 148.202621, 145.985509, 71.956252, 60.103955\n",
            "144.283725, 78.802709, 106.302309, 142.112829, 137.734109, 95.439203, 94.902350, 67.594285, 79.398719, 86.348862\n",
            "1566.256545, 1406.628424, 1296.939057, 1408.662564, 1733.584037, 1129.583655, 1284.975696, 1070.901743, 1583.571192, 1137.145449\n",
            "182.960617, 142.012205, 96.657397, 205.542312, 96.626656, 129.085431, 97.436360, 181.162739, 77.615295, 88.791576\n",
            "145.151211, 75.606990, 93.167516, 85.732205, 147.502337, 147.648037, 172.456062, 200.916287, 34.286081, 182.437593\n",
            "109.757098, 66.878464, 113.978823, 103.179578, 107.610043, 73.224609, 58.712712, 51.985805, 123.215808, 123.240146\n",
            "61.492814, 77.685251, 109.178141, 75.451616, 32.534046, 8.014711, 6.979603, 37.750259, 16.251973, 30.496277\n",
            "92.736539, 122.505077, 91.148676, 72.797274, 117.546622, 63.394246, 83.941055, 79.854191, 90.158860, 85.632556\n",
            "42.371364, 70.354642, 102.777854, 71.290623, 148.300481, 134.491045, 65.356472, 92.094532, 81.402830, 113.523247\n",
            "125.505867, 90.873478, 82.609381, 64.088422, 89.471529, 68.698717, 69.111725, 81.523859, 101.595650, 135.711177\n",
            "96.175918, 121.145492, 94.887478, 89.187493, 113.866106, 37.345963, 100.396020, 111.313596, 90.173320, 90.358056\n",
            "80.334821, 122.599999, 69.249333, 79.664178, 43.124912, 81.956075, 49.879333, 45.670171, 128.487595, 114.519292\n",
            "49.488948, 85.438403, 82.414604, 105.217886, 133.230708, 76.890632, 96.703559, 61.792653, 104.977423, 145.102218\n",
            "98.565396, 119.785299, 85.061822, 84.949666, 138.674516, 128.871652, 126.792458, 110.766331, 123.264727, 74.176935\n",
            "70.720408, 66.859104, 56.000741, 55.142999, 96.426769, 94.058803, 135.997586, 116.189394, 143.144945, 113.656796\n",
            "48.049568, 148.103989, 171.490287, 112.414573, 85.227039, 117.421294, 62.845580, 100.336041, 120.745828, 94.338555\n",
            "84.872205, 52.729249, 54.960196, 55.498557, 59.041184, 137.569432, 87.478022, 127.273865, 120.713675, 127.076413\n",
            "113.810792, 92.429748, 66.212724, 56.983087, 119.746979, 62.610830, 107.632885, 135.709139, 49.686102, 55.288889\n",
            "82.172251, 87.290248, 111.211141, 82.185032, 98.008239, 64.613985, 168.454603, 148.087152, 84.418716, 100.574926\n",
            "1280.075747, 1167.988259, 1304.856160, 1277.470027, 1375.065541, 1731.723484, 2064.331177, 1230.044772, 1297.208961, 1599.433024\n",
            "53.969529, 80.405877, 98.118202, 123.034625, 83.917074, 83.937499, 72.049656, 146.359527, 67.565517, 159.160187\n",
            "1701.002316, 1500.894078, 1325.627177, 1389.732346, 1398.888738, 1475.707049, 1530.856256, 1672.479278, 1379.043603, 1169.202173\n",
            "32.149299, 66.344415, 54.140929, 101.015732, 118.311015, 128.493456, 76.239601, 61.806072, 111.103696, 105.476085\n",
            "110.998971, 116.360780, 82.193438, 121.464395, 68.001675, 116.149955, 162.082671, 67.923182, 159.532529, 67.342295\n",
            "44.085696, 113.821311, 112.761255, 101.425857, 93.130846, 34.445303, 79.196869, 65.765761, 129.257550, 119.227675\n",
            "126.600902, 76.021065, 71.812667, 117.497599, 77.747500, 49.004802, 117.495111, 123.325878, 149.046898, 97.906472\n",
            "123.671612, 64.331828, 92.656232, 62.773709, 46.712061, 108.105661, 129.815876, 124.115887, 77.389274, 135.302447\n",
            "125.826429, 129.098492, 126.936901, 101.180056, 143.255094, 76.897995, 56.465085, 74.488612, 77.267381, 93.851872\n",
            "126.044382, 125.525684, 110.026419, 134.811060, 51.900217, 58.864913, 84.046367, 40.192356, 60.736795, 67.620564\n",
            "132.422981, 61.716280, 106.778290, 160.389330, 80.079356, 73.318495, 123.215351, 65.912518, 52.447308, 125.984456\n",
            "130.932716, 57.348410, 95.275030, 60.041766, 124.338761, 56.308182, 66.087686, 85.616119, 111.292951, 140.964604\n",
            "136.187020, 80.157192, 114.846449, 74.299700, 62.152406, 72.747643, 57.842845, 104.347790, 89.695659, 121.849481\n",
            "108.338418, 72.713016, 52.339612, 81.413515, 55.364259, 126.769777, 85.767052, 113.714099, 80.945822, 88.012791\n",
            "107.011502, 76.057585, 80.053367, 87.415052, 139.518888, 74.657365, 138.512563, 113.804737, 74.522702, 159.627006\n",
            "106.923615, 84.380173, 75.394862, 136.884118, 103.515433, 117.796762, 67.285830, 77.180870, 111.846946, 117.528851\n",
            "71.956336, 118.448769, 101.076956, 104.155571, 77.210699, 65.517432, 72.388534, 133.961200, 122.180220, 145.234487\n",
            "120.989764, 71.301704, 89.081712, 94.080424, 119.130527, 58.773609, 79.782643, 131.956828, 106.165586, 114.559367\n",
            "62.612076, 138.621462, 108.649478, 75.818204, 93.277774, 158.531111, 66.984979, 114.282791, 162.027151, 78.257057\n",
            "111.627960, 111.632199, 112.996755, 124.229140, 69.237059, 100.759542, 124.805849, 70.482981, 71.590503, 82.921655\n",
            "117.489191, 124.689480, 114.837077, 70.085697, 120.930983, 116.744970, 104.390900, 98.361094, 45.352344, 75.771397\n",
            "126.415125, 99.255420, 70.039113, 126.870171, 145.467889, 94.654716, 125.057756, 117.060040, 119.170944, 53.162663\n",
            "109.185399, 134.597110, 93.625286, 76.561773, 125.388022, 90.491551, 77.117758, 103.149929, 94.203565, 88.005555\n",
            "108.284952, 119.228802, 105.440204, 95.546616, 69.782197, 93.313342, 100.796511, 99.966834, 76.485440, 141.360989\n",
            "122.584750, 65.865724, 99.885444, 152.404801, 112.279673, 159.848042, 128.780432, 71.157494, 93.203765, 87.071418\n",
            "112.407491, 127.912227, 95.707390, 68.422763, 73.181240, 66.328150, 86.329265, 124.956675, 75.608201, 80.622342\n",
            "83.756042, 71.762471, 106.979376, 94.481329, 38.946749, 110.632548, 138.875824, 119.987020, 121.780343, 69.555346\n",
            "105.568726, 62.840832, 112.158780, 83.501937, 95.084379, 120.870983, 98.618723, 62.788682, 119.756923, 171.153521\n",
            "159.907888, 150.030745, 118.976694, 101.893668, 67.023869, 135.394259, 95.692670, 157.208747, 141.385498, 105.233916\n",
            "69.778170, 164.047235, 103.911142, 150.507946, 98.529828, 100.669959, 81.555176, 126.250689, 75.846593, 119.352780\n",
            "135.903681, 59.838063, 114.698700, 136.501591, 56.679680, 42.127372, 121.219981, 105.284466, 46.974905, 134.024077\n",
            "73.079534, 162.098113, 143.720010, 165.750647, 98.747010, 135.686580, 70.249034, 81.650900, 90.673660, 133.751189\n",
            "132.242222, 73.735326, 108.673493, 126.727969, 90.654355, 146.642827, 45.555825, 125.239746, 148.811322, 63.137642\n",
            "146.964256, 99.313759, 103.942018, 102.492196, 68.718424, 143.566951, 127.719761, 83.182494, 61.500597, 115.648094\n",
            "114.142894, 99.916459, 99.300152, 93.716287, 89.971417, 154.536160, 97.027095, 112.134160, 151.113122, 90.758109\n",
            "119.859167, 134.689675, 37.035820, 87.420863, 123.272532, 56.910289, 100.393017, 45.683748, 94.259145, 131.105134\n",
            "85.625625, 98.677137, 53.374541, 107.594564, 95.942653, 100.930842, 94.627906, 131.015376, 127.880268, 109.163232\n",
            "80.504470, 97.339378, 162.519356, 157.177604, 58.128143, 91.004294, 149.845934, 102.842935, 80.850805, 66.527044\n",
            "135.071385, 115.241707, 132.948067, 108.203312, 75.110052, 114.394439, 114.454126, 88.756131, 140.288527, 91.405798\n",
            "120.631102, 64.117368, 119.639384, 100.002566, 118.904134, 54.507912, 106.408511, 110.974900, 70.291412, 113.161689\n",
            "73.975390, 55.291810, 59.407673, 116.942937, 90.722867, 62.613944, 57.375170, 100.414325, 136.884061, 134.812636\n",
            "160.289143, 117.019223, 80.688313, 96.283089, 61.488555, 151.357074, 61.839986, 97.686261, 122.083797, 114.925361\n",
            "78.130193, 55.416611, 77.682866, 101.081203, 162.649022, 159.920163, 130.881035, 78.296819, 53.476961, 150.339525\n",
            "88.617096, 87.702415, 97.951538, 138.784180, 103.078284, 100.724723, 58.192356, 132.305279, 148.136453, 57.060884\n",
            "112.448596, 59.355535, 46.244362, 74.927912, 100.268864, 50.031979, 79.844154, 74.932222, 32.970532, 92.601850\n",
            "1215.199922, 1085.859528, 1194.013385, 1535.693629, 1490.460432, 886.120085, 934.847197, 1440.666465, 883.862585, 1177.793197\n",
            "126.501554, 128.676894, 105.798358, 131.087962, 66.266078, 95.419881, 118.612611, 110.187340, 109.201748, 40.250399\n",
            "49.799080, 49.759231, 52.709170, 152.628314, 98.495555, 89.634250, 124.591707, 150.781676, 143.221026, 87.496763\n",
            "91.900592, 68.037083, 69.227820, 109.468459, 82.790803, 91.128081, 104.558493, 104.706921, 146.355338, 121.117434\n",
            "98.363515, 80.276871, 130.425567, 99.700306, 58.137155, 119.932166, 73.933601, 91.739149, 117.662132, 92.775124\n",
            "107.717880, 127.090929, 106.461126, 80.143770, 65.697821, 92.672294, 100.375879, 111.093145, 112.291671, 88.793073\n",
            "140.569270, 146.281683, 69.213554, 127.131352, 126.021693, 63.427373, 77.384334, 98.412869, 125.310207, 72.492609\n",
            "111.455916, 102.000542, 95.859423, 102.376029, 122.325946, 111.623109, 115.039697, 56.231294, 80.093951, 55.479274\n",
            "94.537007, 84.261102, 151.886404, 88.721649, 122.428090, 99.217211, 134.565812, 120.653322, 97.309893, 76.483165\n",
            "93.221440, 61.625794, 55.701139, 51.170270, 62.882852, 99.245636, 57.428055, 85.636353, 68.175223, 123.619126\n",
            "136.133546, 94.631685, 44.870393, 61.993812, 100.170758, 119.611737, 116.727060, 125.483752, 116.743484, 65.829906\n",
            "104.118744, 131.821498, 104.872672, 98.445196, 70.476009, 75.418853, 75.579754, 129.408529, 73.516803, 113.061829\n",
            "83.923086, 101.980296, 144.672531, 100.681052, 122.973168, 85.843312, 106.531010, 136.113224, 114.710594, 81.833747\n",
            "161.331508, 162.092593, 137.844306, 119.388310, 84.765048, 161.654036, 127.357863, 121.254509, 92.701842, 118.792299\n",
            "127.925415, 125.133717, 95.006559, 116.231347, 95.389563, 81.866039, 72.157887, 98.401589, 43.558881, 81.554946\n",
            "112.358197, 86.580120, 52.565897, 129.406405, 124.595010, 71.624115, 73.453635, 123.412204, 123.655967, 126.647475\n",
            "160.123314, 69.924799, 145.230121, 70.187156, 70.858878, 151.463722, 87.628189, 84.535417, 129.040896, 104.473259\n",
            "103.102842, 126.967459, 135.239240, 81.344478, 58.031343, 127.703002, 137.800826, 113.124900, 114.572211, 72.046207\n",
            "91.129821, 158.361965, 113.770339, 134.001752, 138.729891, 129.006069, 88.409792, 78.638174, 96.018135, 95.451642\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 142.633776\n",
            "최대 오차율 (퍼센트): 2064.331177 (위치: 566)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2, output_file):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 오차율을 계산하고 저장.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "    output_file: 오차율 결과를 저장할 파일 경로\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 오차율 결과를 TXT 파일로 저장\n",
        "    np.savetxt(output_file, error_rates, fmt=\"%.6f\", delimiter=\"\\n\")\n",
        "\n",
        "    # ✅ 전체 평균 및 최대 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)\n",
        "\n",
        "    return mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'\n",
        "file2_path = './model/cordic_dec_val.txt'\n",
        "output_file = './model/error_rates_output.txt'  # 저장할 파일\n",
        "\n",
        "# ✅ 함수 실행 (오차율 계산 및 저장)\n",
        "mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path, output_file)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"오차율 결과가 '{output_file}'에 저장되었습니다!\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "FlxQvesTKOA6",
        "outputId": "8828c4cd-f177-4bd3-f458-f10e2eda2748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차율 결과가 './model/error_rates_output.txt'에 저장되었습니다!\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_values_from_files(file1, file2, section):\n",
        "    \"\"\"\n",
        "    두 파일에서 section 값(1부터 시작)을 기준으로 10개 단위의 값을 가져와 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "    section: 출력할 10개 단위의 번호 (1부터 시작)\n",
        "\n",
        "    출력:\n",
        "    - 두 파일에서 해당 범위의 10개 값을 한 줄씩 출력\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 시작 및 끝 인덱스 계산\n",
        "    start_idx = (section - 1) * 10\n",
        "    end_idx = start_idx + 10\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    if start_idx >= len(values1) or start_idx >= len(values2):\n",
        "        raise ValueError(f\"입력한 section={section}이 데이터 길이를 초과했습니다.\")\n",
        "\n",
        "    # 해당 구간의 데이터 추출\n",
        "    extracted_values1 = values1[start_idx:end_idx]\n",
        "    extracted_values2 = values2[start_idx:end_idx]\n",
        "\n",
        "    # 출력\n",
        "    print(f\"파일1 ({file1}) [{start_idx + 1}~{min(end_idx, len(values1))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values1))\n",
        "\n",
        "    print(f\"\\n파일2 ({file2}) [{start_idx + 1}~{min(end_idx, len(values2))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values2))\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_attention_scores_2.txt'\n",
        "file2_path = './model/cordic_dec_val.txt'\n",
        "\n",
        "# ✅ section 번호 입력\n",
        "section_number = 42  # 원하는 section 값 입력 (1부터 시작)\n",
        "\n",
        "# 함수 실행\n",
        "extract_values_from_files(file1_path, file2_path, section_number)\n"
      ],
      "metadata": {
        "id": "6iGJh7Z_Imbo",
        "outputId": "ea83fb4d-ca22-4a39-d9ef-9f1e452cd6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일1 (./model/sorted_attention_scores_2.txt) [411~420]:\n",
            "6.097168, 4.062114, 4.010491, 3.351764, 2.641553, 2.550399, 2.474250, 1.711552, 1.040489, 0.679768\n",
            "\n",
            "파일2 (./model/cordic_dec_val.txt) [411~420]:\n",
            "0.695801, 0.089355, 0.086426, 0.042480, 0.016113, 0.015137, 0.015137, 0.000488, 0.000488, 0.000488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 1대1 오차율을 계산하고,\n",
        "    정수 부분별 개수를 세어 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    - 오차율 정수 부분별 개수\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 불일치 예외 처리\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    # ✅ 오차율의 정수 부분 개수 세기\n",
        "    integer_parts = [int(x) for x in error_rates]  # 정수 부분만 추출\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "    sorted_counts = sorted(count_dict.items())  # 키(정수 부분) 기준 정렬\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index, sorted_counts\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_02_11.txt'  # 두 번째 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "error_rates, mean_error_rate, max_error, max_error_index, sorted_counts = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 오차율 10개 단위 출력\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "# ✅ 전체 평균 및 최대 오차율 출력\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n",
        "\n",
        "# ✅ 오차율 정수 부분 개수 출력\n",
        "print(\"\\n오차율 정수 부분 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "t7FLq284LuIe",
        "outputId": "751585ab-f39d-4ba7-86f4-c8106588ae2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "0.103197, 0.158920, 1.215494, 0.733964, 0.507472, 1.533857, 3.413383, 12.008857, 0.839151, 6.068030\n",
            "0.240297, 0.189093, 1.302581, 2.982521, 4.247265, 9.965741, 8.859651, 6.829620, 14.399079, 14.677612\n",
            "0.077202, 0.266254, 0.739496, 0.179681, 0.174592, 2.943648, 3.734500, 5.775061, 6.759188, 11.529057\n",
            "0.034847, 0.007182, 0.175317, 2.328239, 3.818016, 1.110729, 4.095066, 5.265172, 1.014433, 3.946078\n",
            "0.191927, 0.671869, 2.309529, 3.388904, 4.475655, 4.888571, 5.887059, 10.562167, 7.955048, 89.654051\n",
            "0.203086, 0.236856, 0.630939, 1.059059, 2.189915, 0.891696, 0.407602, 0.919941, 1.170337, 2.445823\n",
            "0.410430, 0.056969, 0.678516, 1.378017, 3.047289, 2.278100, 4.424290, 11.248748, 14.503416, 12.823546\n",
            "0.021143, 0.019726, 0.568235, 1.062001, 0.414543, 0.942007, 7.323325, 6.821745, 12.263552, 6.332244\n",
            "0.191522, 1.805454, 2.594647, 0.636354, 5.255133, 5.420617, 17.330821, 11.375242, 47.128488, 74.101476\n",
            "0.331032, 0.479319, 1.564987, 2.697380, 3.898653, 20.652100, 22.607664, 18.002184, 56.899880, 74.903350\n",
            "0.274705, 0.448905, 1.027005, 0.870512, 0.992683, 0.946021, 1.455801, 0.857005, 2.856585, 1.889877\n",
            "0.062781, 0.387353, 0.219916, 0.667256, 0.529696, 1.809541, 2.153334, 1.529868, 1.731424, 6.502030\n",
            "0.246583, 1.817803, 1.138960, 1.810300, 3.359786, 3.018466, 1.152789, 1.489256, 4.621715, 5.320764\n",
            "1.102257, 2.475788, 2.137111, 0.953237, 1.038759, 2.727134, 3.132087, 2.774970, 2.814113, 4.561903\n",
            "0.097584, 0.092863, 0.417148, 0.091581, 0.235233, 0.012540, 1.227160, 0.795145, 5.562565, 3.433373\n",
            "0.415304, 0.644272, 1.128897, 0.610600, 0.345503, 0.796446, 1.301568, 1.260849, 3.526541, 3.652377\n",
            "0.385523, 0.457200, 0.154347, 0.703232, 0.073418, 0.312579, 0.225749, 0.495692, 1.405650, 1.751848\n",
            "0.193181, 0.271658, 0.584096, 0.817963, 0.699703, 0.073229, 0.713557, 0.093551, 1.468368, 2.213586\n",
            "0.042122, 0.237522, 0.068082, 0.354730, 0.119526, 0.078069, 0.568548, 0.236287, 0.897504, 0.217325\n",
            "0.151541, 0.097048, 0.158565, 0.546840, 0.097773, 0.649704, 2.280134, 1.457440, 1.907110, 3.994053\n",
            "1.184344, 0.703642, 1.130059, 1.060541, 24.650387, 23.211392, 94.350088, 93.306302, 87.791108, 82.164221\n",
            "0.209283, 0.790367, 2.874423, 1.925386, 2.724985, 4.513752, 9.592924, 9.980604, 11.612946, 8.612562\n",
            "0.405579, 0.161764, 0.310098, 0.334435, 1.035306, 4.576345, 1.488113, 1.717219, 3.967875, 0.967404\n",
            "0.229583, 1.987667, 0.842799, 5.325493, 9.396823, 7.781391, 19.622882, 8.848772, 36.743181, 50.701496\n",
            "0.787461, 0.855966, 1.224408, 1.782441, 1.874871, 5.860452, 21.172864, 19.788297, 85.688500, 83.719890\n",
            "0.318648, 0.340988, 0.020586, 0.444319, 7.936935, 6.445383, 10.801508, 5.209433, 12.778003, 15.116360\n",
            "0.176617, 0.118965, 0.236974, 1.015848, 1.367011, 0.884451, 0.111940, 1.376518, 1.703489, 1.256137\n",
            "0.005670, 0.294144, 0.578545, 0.266562, 0.795201, 1.070991, 1.336001, 3.947287, 1.319039, 1.145340\n",
            "0.783024, 1.336027, 2.042162, 1.880340, 3.297489, 2.455539, 4.797396, 6.687014, 10.566931, 20.671811\n",
            "0.053423, 0.212018, 0.186598, 0.807693, 3.255134, 11.043549, 5.878212, 11.583434, 10.269138, 23.779460\n",
            "0.066516, 0.501149, 0.474197, 0.622122, 0.639316, 0.133981, 1.879934, 0.914847, 0.248854, 1.562643\n",
            "0.029041, 1.266120, 1.535720, 1.329629, 1.748214, 0.982182, 3.230020, 2.923061, 8.052544, 26.485896\n",
            "0.101526, 0.003146, 0.514552, 0.357297, 0.281097, 0.458822, 0.300877, 0.326388, 2.094487, 2.886873\n",
            "0.310582, 0.016587, 0.659313, 0.851632, 0.242767, 2.164749, 0.198245, 2.387871, 2.715996, 3.173922\n",
            "0.252959, 0.064699, 0.426453, 0.276324, 0.296572, 1.265661, 1.025071, 1.793559, 4.726657, 17.608110\n",
            "0.738672, 0.574866, 0.741431, 0.589192, 2.411063, 0.576041, 0.774269, 0.864021, 0.158393, 1.616749\n",
            "0.843705, 0.804722, 1.166512, 1.339721, 1.949484, 1.043439, 1.389857, 2.245638, 5.225111, 1.836512\n",
            "1.309651, 1.518127, 0.220322, 2.051259, 2.080743, 1.963198, 1.239170, 2.759825, 2.380464, 5.079273\n",
            "0.627974, 0.592768, 0.258054, 0.272485, 0.047152, 0.607905, 0.736098, 1.300514, 0.415529, 1.844928\n",
            "0.227136, 0.066375, 0.312201, 0.327693, 0.086690, 0.458414, 0.636317, 0.870473, 0.819659, 3.059972\n",
            "0.796858, 1.032572, 4.056073, 12.250523, 26.606014, 92.829264, 91.615979, 91.281783, 87.515757, 87.513810\n",
            "0.546035, 2.260260, 0.456564, 5.454640, 27.041555, 24.922283, 18.981890, 94.396544, 89.037883, 84.276332\n",
            "0.123450, 0.249334, 0.481492, 0.336988, 0.562179, 0.539548, 2.229204, 2.422561, 3.326738, 6.583524\n",
            "0.062093, 2.876117, 4.303209, 8.465621, 11.919006, 35.484992, 38.777691, 84.999733, 81.394842, 81.214824\n",
            "0.169068, 0.041898, 0.348322, 0.616272, 0.487697, 1.800190, 6.913104, 9.813840, 8.250188, 37.328214\n",
            "0.359624, 0.076459, 1.141135, 2.969233, 2.377376, 4.163078, 3.477700, 5.512677, 11.655913, 23.162195\n",
            "0.109597, 0.072829, 1.660660, 0.300570, 2.164296, 1.833967, 1.174319, 0.959431, 6.119311, 6.687206\n",
            "0.219736, 0.167545, 0.084747, 0.042934, 0.057702, 0.237985, 0.115844, 2.120763, 0.226949, 0.628807\n",
            "0.170215, 1.296634, 2.101194, 2.669643, 0.570092, 18.165154, 8.987213, 11.495473, 22.797721, 62.034849\n",
            "0.931181, 3.265842, 1.589529, 1.312104, 1.019106, 1.532281, 3.696638, 14.567501, 42.942068, 42.090647\n",
            "0.245448, 4.646394, 22.933087, 21.384806, 18.017618, 13.999190, 28.210699, 93.077629, 91.687656, 91.682616\n",
            "0.517656, 0.321295, 0.229031, 0.424505, 0.317117, 1.725388, 2.794502, 2.759374, 5.797262, 15.345251\n",
            "0.154744, 0.207773, 1.207706, 0.576130, 2.076452, 2.798437, 5.498776, 7.677348, 13.146041, 58.683840\n",
            "0.028444, 0.059367, 0.807372, 1.070101, 0.577944, 1.211906, 0.687408, 0.962455, 4.070542, 67.848316\n",
            "0.380104, 0.099907, 0.073810, 0.471298, 0.540047, 2.039735, 2.662209, 17.057563, 19.853111, 38.281420\n",
            "0.423145, 0.944133, 0.664012, 0.811629, 0.825798, 0.760956, 1.894775, 0.372906, 2.836106, 33.755544\n",
            "0.622784, 0.954976, 0.786508, 0.872019, 0.960014, 0.361398, 1.768479, 1.729379, 1.173874, 13.937369\n",
            "0.000039, 0.197345, 0.727435, 1.290524, 0.939761, 0.112885, 1.667220, 3.146075, 4.781711, 18.246267\n",
            "0.527645, 0.102545, 0.702697, 0.056175, 0.728570, 0.757174, 0.283776, 0.866768, 1.362604, 6.279150\n",
            "0.366711, 2.001171, 0.804206, 3.116428, 2.524292, 1.680599, 2.969670, 5.928121, 6.489516, 83.981905\n",
            "0.542114, 1.549744, 0.070330, 4.336480, 7.744642, 8.566308, 10.415168, 15.887362, 17.764830, 21.896195\n",
            "0.035982, 0.743484, 0.165803, 0.015657, 0.526090, 0.938858, 0.904112, 1.617405, 6.600577, 0.230635\n",
            "0.328385, 0.441287, 0.093864, 0.333026, 0.868897, 0.438487, 0.316088, 1.020189, 3.888688, 3.110178\n",
            "0.168517, 0.033671, 0.136142, 0.019122, 0.036189, 0.006908, 0.590395, 0.477428, 0.056890, 2.969139\n",
            "0.210645, 0.033641, 0.779331, 0.834295, 1.314145, 1.287877, 0.373252, 2.634158, 8.360290, 6.751445\n",
            "0.156034, 0.134185, 0.463034, 2.141691, 3.327751, 3.364676, 5.763802, 8.093046, 13.199877, 14.584789\n",
            "0.082767, 0.266054, 0.275966, 0.517089, 0.516301, 0.251919, 0.058786, 0.697403, 0.174694, 0.992347\n",
            "0.046330, 0.228865, 0.008304, 0.314725, 0.717844, 0.692847, 0.415632, 1.213685, 0.913272, 0.919404\n",
            "0.117861, 0.359600, 0.078616, 0.552250, 0.534998, 1.429837, 0.094996, 0.400171, 1.053957, 0.436973\n",
            "0.344494, 0.348408, 0.991365, 3.419812, 4.399062, 7.161752, 8.487958, 6.740427, 12.223583, 20.922950\n",
            "0.558695, 0.148161, 0.071114, 0.149727, 0.317054, 0.179338, 0.108717, 0.483203, 0.812959, 1.134000\n",
            "0.011188, 0.024789, 0.742086, 0.592899, 0.959590, 0.417844, 1.003652, 0.505100, 0.301279, 0.180689\n",
            "0.114017, 0.455213, 0.054431, 0.329955, 0.290059, 0.480968, 0.770469, 0.115234, 0.008902, 3.166871\n",
            "0.073094, 0.437340, 0.668462, 0.573230, 0.940139, 0.857799, 0.614752, 0.334926, 1.672162, 1.014402\n",
            "0.548874, 0.611216, 0.096562, 0.312168, 0.185651, 0.378354, 0.853520, 0.265449, 0.157675, 6.970034\n",
            "0.005924, 0.527583, 0.851034, 0.745712, 0.142738, 0.572202, 0.536003, 1.168730, 3.585958, 0.782879\n",
            "0.265601, 0.014520, 0.048267, 0.611748, 0.694126, 0.541378, 0.361498, 0.063053, 0.621602, 1.479227\n",
            "0.318860, 0.103052, 0.016480, 0.062344, 0.071302, 0.424090, 0.247724, 0.257534, 1.023789, 0.349366\n",
            "0.966573, 0.140832, 0.246397, 0.092649, 0.626185, 0.381989, 0.192934, 0.507660, 0.227288, 0.822872\n",
            "1.204230, 0.426937, 4.155074, 0.491563, 1.306040, 1.083575, 1.681558, 0.439524, 0.363056, 1.213205\n",
            "0.218044, 0.431536, 0.142371, 1.669273, 1.359645, 3.184738, 2.916192, 3.379190, 3.633211, 2.713353\n",
            "0.262557, 0.032276, 0.208116, 1.003585, 3.834181, 1.387132, 0.266232, 1.875047, 0.568872, 18.255548\n",
            "0.254340, 0.666638, 0.840053, 2.770895, 0.385933, 0.787739, 0.099046, 0.427245, 0.237475, 0.611925\n",
            "0.408343, 1.288168, 4.925868, 1.059301, 0.028957, 3.488861, 10.124351, 14.916470, 10.285349, 69.830066\n",
            "0.163734, 0.106022, 1.723345, 1.167033, 3.379588, 5.210365, 4.686266, 6.013838, 2.360922, 6.220628\n",
            "0.206478, 0.193528, 0.206558, 1.423894, 0.009648, 1.908549, 1.153557, 1.045758, 4.082284, 11.753719\n",
            "0.395619, 0.042331, 0.144062, 0.490508, 0.140140, 0.109002, 0.049194, 1.664787, 0.349236, 0.472400\n",
            "0.014699, 0.600186, 1.409241, 0.570256, 4.720717, 5.288237, 5.073504, 4.396979, 7.489102, 14.714657\n",
            "2.303373, 0.968512, 0.585986, 1.986080, 0.059823, 2.782482, 0.318102, 0.855433, 2.680803, 5.896658\n",
            "0.600618, 0.537754, 1.363609, 0.060493, 1.579399, 0.187863, 1.614240, 1.922148, 2.719231, 3.965341\n",
            "0.210681, 0.417376, 0.753893, 0.769377, 0.462520, 1.522807, 2.356690, 3.945153, 3.783751, 86.052815\n",
            "1.020891, 0.439493, 1.132786, 2.699531, 0.557453, 1.478916, 1.684458, 1.190669, 2.651454, 12.606928\n",
            "0.193780, 0.324691, 0.562322, 0.480852, 0.260714, 0.130503, 0.100087, 1.710195, 1.910018, 5.237856\n",
            "0.643739, 0.661462, 2.859351, 1.082793, 1.623257, 0.772962, 0.582574, 0.619942, 2.301245, 3.019492\n",
            "0.216350, 0.107811, 0.649304, 0.019812, 1.025918, 0.408015, 0.062410, 5.994908, 3.812127, 3.763095\n",
            "0.029198, 0.580063, 0.703590, 0.622662, 0.832133, 0.948356, 0.613915, 1.740616, 3.154199, 3.514047\n",
            "0.024479, 0.154934, 0.233925, 0.423809, 0.132552, 0.692081, 0.529628, 1.189488, 1.805302, 4.599820\n",
            "0.264554, 0.098759, 0.076489, 0.463998, 0.447590, 0.274417, 0.704187, 0.500654, 2.079324, 10.511618\n",
            "0.668406, 1.089022, 0.207198, 2.650824, 1.121528, 0.823666, 0.627735, 3.097175, 3.953490, 13.738286\n",
            "0.479047, 0.085934, 0.022716, 0.659599, 0.215161, 0.119702, 0.304343, 0.964403, 1.276046, 7.864061\n",
            "0.012466, 6.121357, 6.849746, 11.122077, 13.480098, 13.691852, 16.693161, 23.830711, 27.746135, 43.500152\n",
            "0.332287, 0.332730, 0.170765, 0.055424, 0.138546, 0.883383, 0.685827, 0.092976, 1.201535, 2.029654\n",
            "0.132413, 0.551276, 0.534917, 0.058478, 0.001207, 0.723356, 1.341419, 1.195190, 1.464687, 1.022829\n",
            "0.273954, 0.566334, 1.080638, 1.085022, 0.450782, 1.003322, 0.973046, 0.852982, 1.107727, 1.819035\n",
            "0.518231, 0.175004, 0.125990, 0.651594, 1.713966, 1.292902, 1.330916, 1.830660, 6.155196, 10.225113\n",
            "0.051186, 0.328425, 0.037817, 0.742558, 0.232823, 0.841842, 1.269512, 3.190945, 2.289238, 7.616073\n",
            "0.085843, 0.228007, 0.335183, 0.447985, 0.148297, 0.868862, 0.848746, 2.329113, 0.972899, 1.392312\n",
            "0.199222, 1.210346, 1.153180, 0.139103, 0.936925, 4.022444, 3.731115, 5.503381, 2.174783, 7.336281\n",
            "0.112970, 0.211061, 0.537435, 0.231456, 0.018464, 0.495623, 0.505657, 0.273503, 0.616214, 1.875721\n",
            "0.070930, 0.123552, 0.539585, 4.762910, 3.117291, 3.284080, 6.762047, 3.774870, 1.646281, 1.089532\n",
            "0.228441, 0.431510, 0.611843, 3.296163, 2.018090, 3.668849, 5.613605, 5.258296, 1.990650, 1.937271\n",
            "0.052530, 0.734544, 1.608374, 10.463649, 22.024127, 20.986254, 28.394200, 41.212014, 50.155751, 86.124078\n",
            "0.722964, 0.875637, 0.196507, 0.953529, 4.448602, 10.268259, 15.104295, 9.303403, 23.153794, 31.115898\n",
            "0.250155, 0.268064, 1.680409, 3.963313, 5.466400, 4.861124, 9.069511, 11.420982, 12.509114, 16.116636\n",
            "0.523120, 2.313167, 6.447170, 7.817029, 7.711091, 1.279789, 3.735893, 6.955858, 5.867991, 92.508842\n",
            "0.089721, 0.249933, 1.097326, 2.797535, 4.022958, 7.534884, 7.353277, 9.721592, 6.823546, 6.021377\n",
            "0.494574, 0.234580, 0.382295, 0.076246, 0.383088, 1.080471, 2.734588, 0.138685, 2.918373, 5.073212\n",
            "0.073669, 3.637201, 7.122340, 6.854615, 10.159615, 17.632631, 13.624649, 39.578524, 38.949174, 25.171294\n",
            "0.169672, 0.486004, 0.181811, 0.930806, 1.720111, 1.997235, 2.283745, 1.566672, 5.709112, 12.294280\n",
            "0.028013, 0.092658, 1.851321, 1.644530, 3.100394, 4.375019, 2.553126, 1.290504, 2.636007, 3.016141\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n",
            "\n",
            "오차율 정수 부분 개수:\n",
            "0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차 및 평균 오차를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - 전체 평균 오차\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ 오차율 계산 (음수값 유지)\n",
        "    error_rates = (differences / np.abs(values1)) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차 계산\n",
        "    mean_error = np.mean(np.abs(differences))  # 전체 차이 평균\n",
        "\n",
        "    return differences, mean_error\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, mean_error = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"전체 평균 차이: {mean_error:.6f}\")\n"
      ],
      "metadata": {
        "id": "OrQuhc19gboQ",
        "outputId": "8ad31a67-9ee8-4715-f49c-70cd629d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "전체 평균 차이: 0.000800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 RMSE(Root Mean Squared Error) 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - RMSE 값\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ RMSE 계산\n",
        "    rmse = np.sqrt(np.mean(differences ** 2))  # (차이 제곱 → 평균 → 루트)\n",
        "\n",
        "    return differences, rmse\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, rmse = calculate_rmse(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"✅ RMSE (Root Mean Squared Error): {rmse:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JGwrIV7NNw",
        "outputId": "9118d0f8-b468-41d8-d5e1-317c4db2cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "✅ RMSE (Root Mean Squared Error): 0.001001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def count_integer_parts(file_path):\n",
        "    \"\"\"\n",
        "    파일을 읽어 정수 부분별 개수를 세는 함수 (음수 0과 양수 0을 구별하여 정렬).\n",
        "\n",
        "    Args:\n",
        "    file_path: 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 정수 부분별 개수 딕셔너리 (출력 순서: -3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ... )\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 값 읽기\n",
        "    values = read_file(file_path)\n",
        "\n",
        "    # ✅ 음수와 양수의 0을 구별하여 저장\n",
        "    integer_parts = []\n",
        "    for x in values:\n",
        "        if x < 0:\n",
        "            integer_part = int(x) if abs(x) >= 1 else \"-0\"  # 음수 정수 또는 -0\n",
        "        else:\n",
        "            integer_part = int(x) if x >= 1 else \"+0\"  # 양수 정수 또는 +0\n",
        "        integer_parts.append(integer_part)\n",
        "\n",
        "    # ✅ 정수 부분 개수 세기\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "\n",
        "    # ✅ 정렬 (-3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ...)\n",
        "    sorted_counts = sorted(count_dict.items(), key=lambda x: (float(x[0]) if x[0] not in [\"-0\", \"+0\"] else -0.5 if x[0] == \"-0\" else 0.5))\n",
        "\n",
        "    return sorted_counts\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file_path = './model/error_rates_output.txt'  # 읽어올 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "sorted_counts = count_integer_parts(file_path)\n",
        "\n",
        "# ✅ 정수 부분 개수 출력\n",
        "print(\"\\n정수 부분별 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "3ABGD8kb1_-Q",
        "outputId": "1e931fbf-2e56-4d2b-b3f7-c7a3485e5bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "정수 부분별 개수:\n",
            "+0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_values_in_file(file_path):\n",
        "    \"\"\"\n",
        "    주어진 텍스트 파일에서 숫자 값을 추출하여\n",
        "    값의 순서를 변경하지 않고 한 줄씩 정리된 형태로 다시 저장하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file_path: 변환할 텍스트 파일 경로\n",
        "    \"\"\"\n",
        "    # 1. 파일 읽기\n",
        "    with open(file_path, 'r') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    # 2. 모든 숫자 값 추출 (형식 유지, 순서 변경 X)\n",
        "    cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "    values = cleaned_data.split()  # 공백 기준으로 숫자 분리\n",
        "\n",
        "    # 3. 같은 파일에 다시 한 줄씩 저장 (순서 유지)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(\"\\n\".join(values))\n",
        "\n",
        "    print(f\"✅ 파일이 성공적으로 변환되었습니다: {file_path}\")\n",
        "\n",
        "# ✅ 변환할 파일 경로 설정\n",
        "file_path = './model/sorted_SM_bert_2.txt'  # 파일 경로 변경 가능\n",
        "\n",
        "# ✅ 함수 실행\n",
        "reformat_values_in_file(file_path)\n"
      ],
      "metadata": {
        "id": "kXzSpyHfbSSU",
        "outputId": "7d68b92f-c938-49a5-b5ec-eaed4c00d6ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되었습니다: ./model/sorted_SM_bert_2.txt\n"
          ]
        }
      ]
    }
  ]
}