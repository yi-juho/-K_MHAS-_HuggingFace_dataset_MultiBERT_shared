{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9moVKInibnca",
        "dryCfxh4btMS",
        "wqqbD-tBcehO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa9bbf6b0fa24d18ba53086ade857b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaff078e57eb4c0fbf141e6f2d8baee2",
              "IPY_MODEL_ace3010f2d29467c8b1c38fc855adb7b",
              "IPY_MODEL_253c587f37694b92beff49be29e33b7f"
            ],
            "layout": "IPY_MODEL_e5270a90879849978fac6e2b2ae6c583"
          }
        },
        "eaff078e57eb4c0fbf141e6f2d8baee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50816af52e514b4db12363891add963b",
            "placeholder": "​",
            "style": "IPY_MODEL_b6ea0a2a4b8342f1b424404988ff7ebf",
            "value": "README.md: 100%"
          }
        },
        "ace3010f2d29467c8b1c38fc855adb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_227fd320f5e74c16b4005a6d30edbd87",
            "max": 10565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0851ad00a4c44e4da1c31b673406cf0c",
            "value": 10565
          }
        },
        "253c587f37694b92beff49be29e33b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab9eeb6bc644018b85451b79b95204d",
            "placeholder": "​",
            "style": "IPY_MODEL_07e8a54d11c94aada427186ddbb4a98c",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 222kB/s]"
          }
        },
        "e5270a90879849978fac6e2b2ae6c583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50816af52e514b4db12363891add963b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ea0a2a4b8342f1b424404988ff7ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "227fd320f5e74c16b4005a6d30edbd87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0851ad00a4c44e4da1c31b673406cf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ab9eeb6bc644018b85451b79b95204d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e8a54d11c94aada427186ddbb4a98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ca72cec325423c90300e6a3618a1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b8733def9a440fda60c19c12c785477",
              "IPY_MODEL_7df63c23f7ef4953aa7d3f5dca1389e2",
              "IPY_MODEL_ba3e2e633ee14526aea7f47af41781ba"
            ],
            "layout": "IPY_MODEL_0795a251f7514e198eb1b149f3002001"
          }
        },
        "2b8733def9a440fda60c19c12c785477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9504200259a24fa29c4577b2744cfbcb",
            "placeholder": "​",
            "style": "IPY_MODEL_9aec3ea08044466db86f66f9bb5add62",
            "value": "kmhas_korean_hate_speech.py: 100%"
          }
        },
        "7df63c23f7ef4953aa7d3f5dca1389e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac08ea6b71a046d89cb757d44c0e8edc",
            "max": 4730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dd1f9502e1a41898e9314a17a1a8b95",
            "value": 4730
          }
        },
        "ba3e2e633ee14526aea7f47af41781ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7e1af931174d4e90e2337158eea4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_4f46dbb7467c44eb8a79dded9ec94c9e",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "0795a251f7514e198eb1b149f3002001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9504200259a24fa29c4577b2744cfbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aec3ea08044466db86f66f9bb5add62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac08ea6b71a046d89cb757d44c0e8edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd1f9502e1a41898e9314a17a1a8b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c7e1af931174d4e90e2337158eea4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f46dbb7467c44eb8a79dded9ec94c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c90832b66ce4ee3b4a35a55d9038f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f2a739d17f94e35822bbe42a10aa88e",
              "IPY_MODEL_5f9d8bb36c334bada08df9a2c214cc80",
              "IPY_MODEL_50ee05d1da30456998a7845abe8024db"
            ],
            "layout": "IPY_MODEL_261259c1a2b24eb28c0a01fd919e154a"
          }
        },
        "0f2a739d17f94e35822bbe42a10aa88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e9ceb3d6254fae84fce13bb344a09e",
            "placeholder": "​",
            "style": "IPY_MODEL_608d160dce9c4c8eaf87bc68016a4cba",
            "value": "0000.parquet: 100%"
          }
        },
        "5f9d8bb36c334bada08df9a2c214cc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb60d5c77a547ce9a7212eb2ac1f138",
            "max": 5244851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61c237ebff314db8b3fb3f21fb3c6bd6",
            "value": 5244851
          }
        },
        "50ee05d1da30456998a7845abe8024db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbf4b0afdf043f587d76038eac5fad0",
            "placeholder": "​",
            "style": "IPY_MODEL_2b7e6afbffb14a7fb19574259f127663",
            "value": " 5.24M/5.24M [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "261259c1a2b24eb28c0a01fd919e154a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e9ceb3d6254fae84fce13bb344a09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608d160dce9c4c8eaf87bc68016a4cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb60d5c77a547ce9a7212eb2ac1f138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c237ebff314db8b3fb3f21fb3c6bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dbf4b0afdf043f587d76038eac5fad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7e6afbffb14a7fb19574259f127663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "408ac23badd44ba18c76bcce696fbcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a7b91eac2d44dd387c720902d466d0c",
              "IPY_MODEL_615f981baa8a42d9908c5ca22b3789ec",
              "IPY_MODEL_201ee06c3cd84e5d9c480d8509ba6b81"
            ],
            "layout": "IPY_MODEL_f8eb4b6b154e4a9bb4156f924870a27b"
          }
        },
        "6a7b91eac2d44dd387c720902d466d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f24519ca74b4768a7b7435d09795def",
            "placeholder": "​",
            "style": "IPY_MODEL_634a739447734337b90ac2b95faebad2",
            "value": "default/validation/0000.parquet: 100%"
          }
        },
        "615f981baa8a42d9908c5ca22b3789ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f99125db2dc479896e64656f235e0bb",
            "max": 578860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4de189085d1e44658946a795b46c303f",
            "value": 578860
          }
        },
        "201ee06c3cd84e5d9c480d8509ba6b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377176caefbb4249999b7ef8f4e8e3c4",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b123b6b3bf404397fa8f006fc56614",
            "value": " 579k/579k [00:00&lt;00:00, 2.63MB/s]"
          }
        },
        "f8eb4b6b154e4a9bb4156f924870a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f24519ca74b4768a7b7435d09795def": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634a739447734337b90ac2b95faebad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f99125db2dc479896e64656f235e0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de189085d1e44658946a795b46c303f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377176caefbb4249999b7ef8f4e8e3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b123b6b3bf404397fa8f006fc56614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2462695446324b70aee46890d6369aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc415e4e698c4fdb966ff8ebb86dcad0",
              "IPY_MODEL_5f3e30b343b54cb2a0b35cff1ea6c090",
              "IPY_MODEL_210876557d7b481bbd6aac7b32021bfd"
            ],
            "layout": "IPY_MODEL_e2eb27d9e98645609d4ab0dda4258f8a"
          }
        },
        "cc415e4e698c4fdb966ff8ebb86dcad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31252fa278943be8d8723e6f2eb77e1",
            "placeholder": "​",
            "style": "IPY_MODEL_dd0764724404420abd0b1f6cfd4fc632",
            "value": "0000.parquet: 100%"
          }
        },
        "5f3e30b343b54cb2a0b35cff1ea6c090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254c747ead30455fb7b7802f3f2c44b4",
            "max": 1458266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74aca04e58c2492282b91a59dc19ad4b",
            "value": 1458266
          }
        },
        "210876557d7b481bbd6aac7b32021bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881cfee2873a41c5b0467025d6742b29",
            "placeholder": "​",
            "style": "IPY_MODEL_87dd5d9f711b4e379058f3fe4dab2f57",
            "value": " 1.46M/1.46M [00:00&lt;00:00, 26.8MB/s]"
          }
        },
        "e2eb27d9e98645609d4ab0dda4258f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31252fa278943be8d8723e6f2eb77e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0764724404420abd0b1f6cfd4fc632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254c747ead30455fb7b7802f3f2c44b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74aca04e58c2492282b91a59dc19ad4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "881cfee2873a41c5b0467025d6742b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87dd5d9f711b4e379058f3fe4dab2f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd2b922761b4263ada91d11864b0244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f56adfd8b3b4791a9798eab4f5be2fb",
              "IPY_MODEL_18fd26eb4cc046d698319ca3efb18583",
              "IPY_MODEL_a7376f3476e348cc8b018007a860c3b7"
            ],
            "layout": "IPY_MODEL_7438744bc5f4462fa5326787122c01d4"
          }
        },
        "1f56adfd8b3b4791a9798eab4f5be2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd485aa3eab402c86720451bbc54523",
            "placeholder": "​",
            "style": "IPY_MODEL_753f6d43090748afb257e310b5949907",
            "value": "Generating train split: 100%"
          }
        },
        "18fd26eb4cc046d698319ca3efb18583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567dd25107884434b6e22a428cdeecc6",
            "max": 78977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb2f02900fbe4d3fbacd6fe204ab0064",
            "value": 78977
          }
        },
        "a7376f3476e348cc8b018007a860c3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fab0983d9204fe99226d23efeb04976",
            "placeholder": "​",
            "style": "IPY_MODEL_b69601e1bf274e8e9b3f2f1ffe743c68",
            "value": " 78977/78977 [00:00&lt;00:00, 189505.73 examples/s]"
          }
        },
        "7438744bc5f4462fa5326787122c01d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd485aa3eab402c86720451bbc54523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753f6d43090748afb257e310b5949907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "567dd25107884434b6e22a428cdeecc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb2f02900fbe4d3fbacd6fe204ab0064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fab0983d9204fe99226d23efeb04976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69601e1bf274e8e9b3f2f1ffe743c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0187485f7634819ae2d17123c82789c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_466b3c8a5290429a804143b9ec0f823e",
              "IPY_MODEL_1678c5aad7334d019b9c78d862df51e4",
              "IPY_MODEL_624a88ee123c4e978eb1d4a4f1f6a37c"
            ],
            "layout": "IPY_MODEL_2fa87f34520f47fd9b1cddafc79702b4"
          }
        },
        "466b3c8a5290429a804143b9ec0f823e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b05a694671641cf8688b08ef68eade8",
            "placeholder": "​",
            "style": "IPY_MODEL_027b89cc2827429f8846b04c4b1bcba1",
            "value": "Generating validation split: 100%"
          }
        },
        "1678c5aad7334d019b9c78d862df51e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c630072fc7f443c9991e6da7149657ea",
            "max": 8776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bafb45bfebd41918baeb3a3f40358ce",
            "value": 8776
          }
        },
        "624a88ee123c4e978eb1d4a4f1f6a37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0032d08bd34f8ab15f967726b9ce52",
            "placeholder": "​",
            "style": "IPY_MODEL_eb85894a37a84c1a9d94683dec38dc71",
            "value": " 8776/8776 [00:00&lt;00:00, 112565.02 examples/s]"
          }
        },
        "2fa87f34520f47fd9b1cddafc79702b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b05a694671641cf8688b08ef68eade8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027b89cc2827429f8846b04c4b1bcba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c630072fc7f443c9991e6da7149657ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bafb45bfebd41918baeb3a3f40358ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb0032d08bd34f8ab15f967726b9ce52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb85894a37a84c1a9d94683dec38dc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27772a2fa5f64e2b8d7908aea5ac205a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca5e60ab444a40c0be3a724c2beb1e1b",
              "IPY_MODEL_9e2b794319324f45826a052a525b5f4e",
              "IPY_MODEL_8f2d17e257bd40d49f488e8c4e9f52da"
            ],
            "layout": "IPY_MODEL_a82893983eb84a9fb30f5f7a920cbf29"
          }
        },
        "ca5e60ab444a40c0be3a724c2beb1e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ec780500824a44a8f937b7d253fa2f",
            "placeholder": "​",
            "style": "IPY_MODEL_19fdb2b120d8476499cf114fec679e08",
            "value": "Generating test split: 100%"
          }
        },
        "9e2b794319324f45826a052a525b5f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f66ddfedb0c4d1d93474b93b6fc752d",
            "max": 21939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfb05d48346a479bbd1bb4c2e0df2817",
            "value": 21939
          }
        },
        "8f2d17e257bd40d49f488e8c4e9f52da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec5c9414d474c69aed8be0ac1a16feb",
            "placeholder": "​",
            "style": "IPY_MODEL_6d9b7600f84e44ffb59b2a9a9a336998",
            "value": " 21939/21939 [00:00&lt;00:00, 118986.83 examples/s]"
          }
        },
        "a82893983eb84a9fb30f5f7a920cbf29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ec780500824a44a8f937b7d253fa2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19fdb2b120d8476499cf114fec679e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f66ddfedb0c4d1d93474b93b6fc752d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb05d48346a479bbd1bb4c2e0df2817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec5c9414d474c69aed8be0ac1a16feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9b7600f84e44ffb59b2a9a9a336998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cf3c86c4e38418193b3d53f078cf2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10ac9aab353b4daea6d97f7f10358e1f",
              "IPY_MODEL_007847edaefb4fa8ad7a57010868829e",
              "IPY_MODEL_f4b8fa8678b244c7855d8566dd7866d5"
            ],
            "layout": "IPY_MODEL_0190a305963a4bc584cc555ce3e6e032"
          }
        },
        "10ac9aab353b4daea6d97f7f10358e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be1fa9fc99344ef902ecda447256323",
            "placeholder": "​",
            "style": "IPY_MODEL_0f769cb5885843f080fe2565c831b809",
            "value": ""
          }
        },
        "007847edaefb4fa8ad7a57010868829e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e1b661fbde432bbec3b1fdf15bec66",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d61ed7594fcc44e380da29bad44318f3",
            "value": 0
          }
        },
        "f4b8fa8678b244c7855d8566dd7866d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2de008af1484b4ca24ac534ba610c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d5731ebb214bcbafa990695139d211",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "0190a305963a4bc584cc555ce3e6e032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be1fa9fc99344ef902ecda447256323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f769cb5885843f080fe2565c831b809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e1b661fbde432bbec3b1fdf15bec66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d61ed7594fcc44e380da29bad44318f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2de008af1484b4ca24ac534ba610c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d5731ebb214bcbafa990695139d211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804bbd492a2b489db635a035beb17f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acc5dc59eed74575bf02b7d928048c72",
              "IPY_MODEL_5472ce3390db4f2790d2a5f764480a58",
              "IPY_MODEL_04f698bbd4374e129e6ee78527b9d01e"
            ],
            "layout": "IPY_MODEL_6f7ef90438ae4f2db6becdbc14c36bb4"
          }
        },
        "acc5dc59eed74575bf02b7d928048c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309861711f614da18973a1a6ea7e92dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f2a74a41d2c64f82a015849603613e9f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5472ce3390db4f2790d2a5f764480a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb54862ae7d4599a55c4299fc8786a5",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_108be6684a4a4c2eb1f150715ae2f205",
            "value": 289
          }
        },
        "04f698bbd4374e129e6ee78527b9d01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_955ea13c27c847508ed9e0051f7c8fdf",
            "placeholder": "​",
            "style": "IPY_MODEL_49c916ad355a413c9c51273f541a23db",
            "value": " 289/289 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "6f7ef90438ae4f2db6becdbc14c36bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309861711f614da18973a1a6ea7e92dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a74a41d2c64f82a015849603613e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb54862ae7d4599a55c4299fc8786a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108be6684a4a4c2eb1f150715ae2f205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "955ea13c27c847508ed9e0051f7c8fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c916ad355a413c9c51273f541a23db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0b7e4a21c74897b9b65c6c4bfee97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73ae9d5c63fd433e88f9928d2585ee62",
              "IPY_MODEL_415044cebf5a4979803d9db16c5edab8",
              "IPY_MODEL_0efe427e5dfb4b6a8640d15ecf62ad0d"
            ],
            "layout": "IPY_MODEL_dc2fde727d3a4da1a32918b0d52d6253"
          }
        },
        "73ae9d5c63fd433e88f9928d2585ee62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bec0aa8de35453fa26205b85565627f",
            "placeholder": "​",
            "style": "IPY_MODEL_7bb0dc8814ec4e4eb07e66299f0186d1",
            "value": "vocab.txt: 100%"
          }
        },
        "415044cebf5a4979803d9db16c5edab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c008bb3be824ca8840953cdfa36844a",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5cd7ba20525462d896fca3bcf759238",
            "value": 248477
          }
        },
        "0efe427e5dfb4b6a8640d15ecf62ad0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd33f42e751c4c1eb34e8bdad16cb725",
            "placeholder": "​",
            "style": "IPY_MODEL_12283c25835d4c7e88abf12ae286a24a",
            "value": " 248k/248k [00:00&lt;00:00, 8.14MB/s]"
          }
        },
        "dc2fde727d3a4da1a32918b0d52d6253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bec0aa8de35453fa26205b85565627f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb0dc8814ec4e4eb07e66299f0186d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c008bb3be824ca8840953cdfa36844a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cd7ba20525462d896fca3bcf759238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd33f42e751c4c1eb34e8bdad16cb725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12283c25835d4c7e88abf12ae286a24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "301ece551f614f0ea3dc43471f4e611d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adbc22f8465544f8989e09c191423beb",
              "IPY_MODEL_c05a3c1494eb4101978f639e8ecf5a6d",
              "IPY_MODEL_1dc1ec9b2f334117b845dfe90a566bae"
            ],
            "layout": "IPY_MODEL_1e53a3ceacac4ff4b32758df19b00c4e"
          }
        },
        "adbc22f8465544f8989e09c191423beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3778b6dc8ce14b108ee5ae905a048407",
            "placeholder": "​",
            "style": "IPY_MODEL_8b309005d8b44e3388019d3fdcf6213c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c05a3c1494eb4101978f639e8ecf5a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3bb44a1a8324083b9d908701d1114f1",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd8dbf05c70a4911be2965c9341e04bf",
            "value": 125
          }
        },
        "1dc1ec9b2f334117b845dfe90a566bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aeaa5fe65484d22bc07b1eb21f00621",
            "placeholder": "​",
            "style": "IPY_MODEL_53ff8fbd2c434a4a8cb0ccfc571baf3d",
            "value": " 125/125 [00:00&lt;00:00, 3.05kB/s]"
          }
        },
        "1e53a3ceacac4ff4b32758df19b00c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3778b6dc8ce14b108ee5ae905a048407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b309005d8b44e3388019d3fdcf6213c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3bb44a1a8324083b9d908701d1114f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8dbf05c70a4911be2965c9341e04bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aeaa5fe65484d22bc07b1eb21f00621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ff8fbd2c434a4a8cb0ccfc571baf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "097983b81d37492bb5decaf22f623c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d978eab5aa134a1e881037db88c89d25",
              "IPY_MODEL_c277163c67fa4eecaa39b05c2b4199c1",
              "IPY_MODEL_af47aa1d7cdc4364aa6715d83e92a03f"
            ],
            "layout": "IPY_MODEL_d934cb113c1d452d87d402f7f30a500b"
          }
        },
        "d978eab5aa134a1e881037db88c89d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad455fec11a4f1a9098157102709635",
            "placeholder": "​",
            "style": "IPY_MODEL_a580879fb8ce4e70a5398e3da280e137",
            "value": "tokenizer.json: 100%"
          }
        },
        "c277163c67fa4eecaa39b05c2b4199c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d5c32464724f51b4b7dd9e6b72b010",
            "max": 494860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f894dfbdc46a440f8fad75478232e4bb",
            "value": 494860
          }
        },
        "af47aa1d7cdc4364aa6715d83e92a03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca3332c8afd495ebd32157d2627d7e2",
            "placeholder": "​",
            "style": "IPY_MODEL_249087a9cfa5436795f5c7d6c7254d7c",
            "value": " 495k/495k [00:00&lt;00:00, 16.1MB/s]"
          }
        },
        "d934cb113c1d452d87d402f7f30a500b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad455fec11a4f1a9098157102709635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a580879fb8ce4e70a5398e3da280e137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d5c32464724f51b4b7dd9e6b72b010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f894dfbdc46a440f8fad75478232e4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fca3332c8afd495ebd32157d2627d7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249087a9cfa5436795f5c7d6c7254d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1440fe218de04d199a8a4bb2d3085837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e67893a9f594b9f8ad2db85aedd4952",
              "IPY_MODEL_c88bdee966bb468d9a778b5fbe331193",
              "IPY_MODEL_8eb1b177c4944e6d8ef366dde44fec43"
            ],
            "layout": "IPY_MODEL_2c7969f690a6484ba5226c57446af3d5"
          }
        },
        "0e67893a9f594b9f8ad2db85aedd4952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a409161a124129b88038fdedeab68e",
            "placeholder": "​",
            "style": "IPY_MODEL_784b9ddb4685480c82cedbbd72d73f85",
            "value": "config.json: 100%"
          }
        },
        "c88bdee966bb468d9a778b5fbe331193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfa61eb9e964cadbab3a9dd9f773f3c",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6d918a429fb42df9c19471a45ba4cfe",
            "value": 425
          }
        },
        "8eb1b177c4944e6d8ef366dde44fec43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71d7a7e6f99498e9cd2212e52f25d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_5d24fda634f2467b80766d2f08b6fe2d",
            "value": " 425/425 [00:00&lt;00:00, 8.75kB/s]"
          }
        },
        "2c7969f690a6484ba5226c57446af3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a409161a124129b88038fdedeab68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784b9ddb4685480c82cedbbd72d73f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdfa61eb9e964cadbab3a9dd9f773f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d918a429fb42df9c19471a45ba4cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a71d7a7e6f99498e9cd2212e52f25d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d24fda634f2467b80766d2f08b6fe2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2aae104c53944a19df8e221de679723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd92cb05502f4bae9609436435779859",
              "IPY_MODEL_b197652267014d4fb080638c9b999e32",
              "IPY_MODEL_d9de55a318454d1abf2dd11e21e6b42c"
            ],
            "layout": "IPY_MODEL_3a83787a34ff40bf86ede62a29a6de13"
          }
        },
        "bd92cb05502f4bae9609436435779859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa4107e451e4b3a959fa903b0e87388",
            "placeholder": "​",
            "style": "IPY_MODEL_da4cf5a08fd64502abed85f560d57dc5",
            "value": "model.safetensors: 100%"
          }
        },
        "b197652267014d4fb080638c9b999e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a459586254284b60a2d1d638913521a0",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_369775153da4456fac9c659b1be478b0",
            "value": 445000316
          }
        },
        "d9de55a318454d1abf2dd11e21e6b42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c893dfd4344fe1a73c17cd2f830a04",
            "placeholder": "​",
            "style": "IPY_MODEL_5b13523da7634c808a7e11e46202d619",
            "value": " 445M/445M [00:02&lt;00:00, 186MB/s]"
          }
        },
        "3a83787a34ff40bf86ede62a29a6de13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa4107e451e4b3a959fa903b0e87388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da4cf5a08fd64502abed85f560d57dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a459586254284b60a2d1d638913521a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369775153da4456fac9c659b1be478b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4c893dfd4344fe1a73c17cd2f830a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b13523da7634c808a7e11e46202d619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/%5BK_MHAS%5D_HuggingFace_dataset_MultiBERT_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the K-MHaS dataset from [HuggingFace](https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech) and checking meta information (published @COLING2022)\n"
      ],
      "metadata": {
        "id": "4Lyor-OIrwd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets fsspec -y\n",
        "!pip install datasets==3.2.0 fsspec[http]==2024.9.0\n"
      ],
      "metadata": {
        "id": "WMoJHDlhbklf",
        "outputId": "a93e8303-7c9e-425c-d353-d22e8bfb567b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.10.0\n",
            "Uninstalling fsspec-2024.10.0:\n",
            "  Successfully uninstalled fsspec-2024.10.0\n",
            "Collecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec==2024.9.0 (from fsspec[http]==2024.9.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "outputId": "eafa6e98-1d46-419a-a75f-02d9859d6a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "outputId": "4f28e605-f0bf-4b20-a7d7-28c5997210e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "fa9bbf6b0fa24d18ba53086ade857b03",
            "eaff078e57eb4c0fbf141e6f2d8baee2",
            "ace3010f2d29467c8b1c38fc855adb7b",
            "253c587f37694b92beff49be29e33b7f",
            "e5270a90879849978fac6e2b2ae6c583",
            "50816af52e514b4db12363891add963b",
            "b6ea0a2a4b8342f1b424404988ff7ebf",
            "227fd320f5e74c16b4005a6d30edbd87",
            "0851ad00a4c44e4da1c31b673406cf0c",
            "4ab9eeb6bc644018b85451b79b95204d",
            "07e8a54d11c94aada427186ddbb4a98c",
            "32ca72cec325423c90300e6a3618a1cd",
            "2b8733def9a440fda60c19c12c785477",
            "7df63c23f7ef4953aa7d3f5dca1389e2",
            "ba3e2e633ee14526aea7f47af41781ba",
            "0795a251f7514e198eb1b149f3002001",
            "9504200259a24fa29c4577b2744cfbcb",
            "9aec3ea08044466db86f66f9bb5add62",
            "ac08ea6b71a046d89cb757d44c0e8edc",
            "6dd1f9502e1a41898e9314a17a1a8b95",
            "7c7e1af931174d4e90e2337158eea4dc",
            "4f46dbb7467c44eb8a79dded9ec94c9e",
            "0c90832b66ce4ee3b4a35a55d9038f77",
            "0f2a739d17f94e35822bbe42a10aa88e",
            "5f9d8bb36c334bada08df9a2c214cc80",
            "50ee05d1da30456998a7845abe8024db",
            "261259c1a2b24eb28c0a01fd919e154a",
            "73e9ceb3d6254fae84fce13bb344a09e",
            "608d160dce9c4c8eaf87bc68016a4cba",
            "fbb60d5c77a547ce9a7212eb2ac1f138",
            "61c237ebff314db8b3fb3f21fb3c6bd6",
            "2dbf4b0afdf043f587d76038eac5fad0",
            "2b7e6afbffb14a7fb19574259f127663",
            "408ac23badd44ba18c76bcce696fbcab",
            "6a7b91eac2d44dd387c720902d466d0c",
            "615f981baa8a42d9908c5ca22b3789ec",
            "201ee06c3cd84e5d9c480d8509ba6b81",
            "f8eb4b6b154e4a9bb4156f924870a27b",
            "9f24519ca74b4768a7b7435d09795def",
            "634a739447734337b90ac2b95faebad2",
            "9f99125db2dc479896e64656f235e0bb",
            "4de189085d1e44658946a795b46c303f",
            "377176caefbb4249999b7ef8f4e8e3c4",
            "c2b123b6b3bf404397fa8f006fc56614",
            "2462695446324b70aee46890d6369aed",
            "cc415e4e698c4fdb966ff8ebb86dcad0",
            "5f3e30b343b54cb2a0b35cff1ea6c090",
            "210876557d7b481bbd6aac7b32021bfd",
            "e2eb27d9e98645609d4ab0dda4258f8a",
            "c31252fa278943be8d8723e6f2eb77e1",
            "dd0764724404420abd0b1f6cfd4fc632",
            "254c747ead30455fb7b7802f3f2c44b4",
            "74aca04e58c2492282b91a59dc19ad4b",
            "881cfee2873a41c5b0467025d6742b29",
            "87dd5d9f711b4e379058f3fe4dab2f57",
            "cdd2b922761b4263ada91d11864b0244",
            "1f56adfd8b3b4791a9798eab4f5be2fb",
            "18fd26eb4cc046d698319ca3efb18583",
            "a7376f3476e348cc8b018007a860c3b7",
            "7438744bc5f4462fa5326787122c01d4",
            "0fd485aa3eab402c86720451bbc54523",
            "753f6d43090748afb257e310b5949907",
            "567dd25107884434b6e22a428cdeecc6",
            "eb2f02900fbe4d3fbacd6fe204ab0064",
            "7fab0983d9204fe99226d23efeb04976",
            "b69601e1bf274e8e9b3f2f1ffe743c68",
            "d0187485f7634819ae2d17123c82789c",
            "466b3c8a5290429a804143b9ec0f823e",
            "1678c5aad7334d019b9c78d862df51e4",
            "624a88ee123c4e978eb1d4a4f1f6a37c",
            "2fa87f34520f47fd9b1cddafc79702b4",
            "7b05a694671641cf8688b08ef68eade8",
            "027b89cc2827429f8846b04c4b1bcba1",
            "c630072fc7f443c9991e6da7149657ea",
            "3bafb45bfebd41918baeb3a3f40358ce",
            "bb0032d08bd34f8ab15f967726b9ce52",
            "eb85894a37a84c1a9d94683dec38dc71",
            "27772a2fa5f64e2b8d7908aea5ac205a",
            "ca5e60ab444a40c0be3a724c2beb1e1b",
            "9e2b794319324f45826a052a525b5f4e",
            "8f2d17e257bd40d49f488e8c4e9f52da",
            "a82893983eb84a9fb30f5f7a920cbf29",
            "61ec780500824a44a8f937b7d253fa2f",
            "19fdb2b120d8476499cf114fec679e08",
            "7f66ddfedb0c4d1d93474b93b6fc752d",
            "bfb05d48346a479bbd1bb4c2e0df2817",
            "1ec5c9414d474c69aed8be0ac1a16feb",
            "6d9b7600f84e44ffb59b2a9a9a336998"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa9bbf6b0fa24d18ba53086ade857b03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "kmhas_korean_hate_speech.py:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ca72cec325423c90300e6a3618a1cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c90832b66ce4ee3b4a35a55d9038f77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "default/validation/0000.parquet:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "408ac23badd44ba18c76bcce696fbcab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2462695446324b70aee46890d6369aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdd2b922761b4263ada91d11864b0244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0187485f7634819ae2d17123c82789c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27772a2fa5f64e2b8d7908aea5ac205a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "e5853049-0e21-4c68-8d12-7a80f6b50d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "1f26a548-a5ad-4eef-88df-59e166547928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "9e781c8f-312a-454d-d97f-5fdf86bde3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meta information\n",
        "\n",
        "print(dataset.info.description)\n",
        "print(dataset.info.homepage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AveWSDOj88",
        "outputId": "fcf5a3fa-9ce9-4e77-b3a9-26b46d73a97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\n",
            "The fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.\n",
            "\n",
            "https://github.com/adlnlp/K-MHaS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bsDpBwOxPx",
        "outputId": "640eae4b-003b-45ca-be04-eb428045efc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@inproceedings{lee-etal-2022-k,\n",
            "    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n",
            "    author = \"Lee, Jean  and\n",
            "      Lim, Taejun  and\n",
            "      Lee, Heejun  and\n",
            "      Jo, Bogeun  and\n",
            "      Kim, Yangsok  and\n",
            "      Yoon, Heegeun  and\n",
            "      Han, Soyeon Caren\",\n",
            "    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n",
            "    month = oct,\n",
            "    year = \"2022\",\n",
            "    address = \"Gyeongju, Republic of Korea\",\n",
            "    publisher = \"International Committee on Computational Linguistics\",\n",
            "    url = \"https://aclanthology.org/2022.coling-1.311\",\n",
            "    pages = \"3530--3538\",\n",
            "    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare data from train, validation, and test dataset\n",
        "- Multi-label is converted to multi-label one hot encodding\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin\n",
        "          1: physical\n",
        "          2: politics\n",
        "          3: profanity\n",
        "          4: age\n",
        "          5: gender\n",
        "          6: race\n",
        "          7: religion\n",
        "          8: not_hate_speech"
      ],
      "metadata": {
        "id": "qqO0w2cKsjN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fykcu8FKZiOI",
        "outputId": "c8ce45b6-8c22-4c5c-af71-f48e377989d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "-IczFOCZZfvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "id": "A5Jq_uiYcIWM",
        "outputId": "1c0c53b2-a93a-433e-81e6-d75fc97a292c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "2cf3c86c4e38418193b3d53f078cf2ce",
            "10ac9aab353b4daea6d97f7f10358e1f",
            "007847edaefb4fa8ad7a57010868829e",
            "f4b8fa8678b244c7855d8566dd7866d5",
            "0190a305963a4bc584cc555ce3e6e032",
            "4be1fa9fc99344ef902ecda447256323",
            "0f769cb5885843f080fe2565c831b809",
            "a7e1b661fbde432bbec3b1fdf15bec66",
            "d61ed7594fcc44e380da29bad44318f3",
            "b2de008af1484b4ca24ac534ba610c1e",
            "d8d5731ebb214bcbafa990695139d211"
          ]
        },
        "outputId": "1eb6f0b7-9f5e-4f92-e374-1361ad323835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cf3c86c4e38418193b3d53f078cf2ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, validation, and test dataset from HuggingFace\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding masking (able to remove this step depending on the model)\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multi-label to multi-label binary (one hot encoding)\n",
        "# [8] -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-xu24pnaxek",
        "outputId": "65258b45-9387-4baf-a2ac-0ec951cfe513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그만큼 길예르모가 잘했다고 보면되겠지 기대되네 셰이프 오브 워터 [SEP]',\n",
              " '[CLS] \"1. 8넘의 문재앙\" [SEP]',\n",
              " '[CLS] \"문재인 정권의 내로남불은 타의 추종을 불허하네. 자한당 욕할거리도 없음.\" [SEP]',\n",
              " '[CLS] \"짱개들 지나간 곳은 폐허된다 ㅋㅋ\" [SEP]',\n",
              " '[CLS] 곱창은 자갈치~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "ccab95b0-eae3-4aa9-f971-bca9921666ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for Pytorch"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing : bert-base-multilingual-cased\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)"
      ],
      "metadata": {
        "id": "VKYP2VNkR-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "804bbd492a2b489db635a035beb17f44",
            "acc5dc59eed74575bf02b7d928048c72",
            "5472ce3390db4f2790d2a5f764480a58",
            "04f698bbd4374e129e6ee78527b9d01e",
            "6f7ef90438ae4f2db6becdbc14c36bb4",
            "309861711f614da18973a1a6ea7e92dd",
            "f2a74a41d2c64f82a015849603613e9f",
            "6cb54862ae7d4599a55c4299fc8786a5",
            "108be6684a4a4c2eb1f150715ae2f205",
            "955ea13c27c847508ed9e0051f7c8fdf",
            "49c916ad355a413c9c51273f541a23db",
            "4a0b7e4a21c74897b9b65c6c4bfee97b",
            "73ae9d5c63fd433e88f9928d2585ee62",
            "415044cebf5a4979803d9db16c5edab8",
            "0efe427e5dfb4b6a8640d15ecf62ad0d",
            "dc2fde727d3a4da1a32918b0d52d6253",
            "0bec0aa8de35453fa26205b85565627f",
            "7bb0dc8814ec4e4eb07e66299f0186d1",
            "9c008bb3be824ca8840953cdfa36844a",
            "e5cd7ba20525462d896fca3bcf759238",
            "dd33f42e751c4c1eb34e8bdad16cb725",
            "12283c25835d4c7e88abf12ae286a24a",
            "301ece551f614f0ea3dc43471f4e611d",
            "adbc22f8465544f8989e09c191423beb",
            "c05a3c1494eb4101978f639e8ecf5a6d",
            "1dc1ec9b2f334117b845dfe90a566bae",
            "1e53a3ceacac4ff4b32758df19b00c4e",
            "3778b6dc8ce14b108ee5ae905a048407",
            "8b309005d8b44e3388019d3fdcf6213c",
            "c3bb44a1a8324083b9d908701d1114f1",
            "bd8dbf05c70a4911be2965c9341e04bf",
            "8aeaa5fe65484d22bc07b1eb21f00621",
            "53ff8fbd2c434a4a8cb0ccfc571baf3d",
            "097983b81d37492bb5decaf22f623c51",
            "d978eab5aa134a1e881037db88c89d25",
            "c277163c67fa4eecaa39b05c2b4199c1",
            "af47aa1d7cdc4364aa6715d83e92a03f",
            "d934cb113c1d452d87d402f7f30a500b",
            "dad455fec11a4f1a9098157102709635",
            "a580879fb8ce4e70a5398e3da280e137",
            "33d5c32464724f51b4b7dd9e6b72b010",
            "f894dfbdc46a440f8fad75478232e4bb",
            "fca3332c8afd495ebd32157d2627d7e2",
            "249087a9cfa5436795f5c7d6c7254d7c",
            "1440fe218de04d199a8a4bb2d3085837",
            "0e67893a9f594b9f8ad2db85aedd4952",
            "c88bdee966bb468d9a778b5fbe331193",
            "8eb1b177c4944e6d8ef366dde44fec43",
            "2c7969f690a6484ba5226c57446af3d5",
            "29a409161a124129b88038fdedeab68e",
            "784b9ddb4685480c82cedbbd72d73f85",
            "fdfa61eb9e964cadbab3a9dd9f773f3c",
            "e6d918a429fb42df9c19471a45ba4cfe",
            "a71d7a7e6f99498e9cd2212e52f25d6e",
            "5d24fda634f2467b80766d2f08b6fe2d"
          ]
        },
        "outputId": "8ae4cb39-d6e2-49d8-923b-2fd6c8409f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "804bbd492a2b489db635a035beb17f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0b7e4a21c74897b9b65c6c4bfee97b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "301ece551f614f0ea3dc43471f4e611d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "097983b81d37492bb5decaf22f623c51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1440fe218de04d199a8a4bb2d3085837"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks\n"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('testset size:', len(test_labels))\n",
        "print('trainset size:', len(train_labels))\n",
        "print('validset size:', len(validation_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "fffdbe4f-0a52-48a7-b60a-ed98b4cacefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset size: 21939\n",
            "trainset size: 78977\n",
            "validset size: 8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-BERT model"
      ],
      "metadata": {
        "id": "pXGKAsSXut0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setting"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfq1f2Y3Yhck",
        "outputId": "5759a8b8-e4ff-46ad-f528-877405325207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "63a34c58-e9ea-4d3a-db00-bc8809cd6c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setting"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936,
          "referenced_widgets": [
            "d2aae104c53944a19df8e221de679723",
            "bd92cb05502f4bae9609436435779859",
            "b197652267014d4fb080638c9b999e32",
            "d9de55a318454d1abf2dd11e21e6b42c",
            "3a83787a34ff40bf86ede62a29a6de13",
            "5fa4107e451e4b3a959fa903b0e87388",
            "da4cf5a08fd64502abed85f560d57dc5",
            "a459586254284b60a2d1d638913521a0",
            "369775153da4456fac9c659b1be478b0",
            "b4c893dfd4344fe1a73c17cd2f830a04",
            "5b13523da7634c808a7e11e46202d619"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "84d95d26-e6ff-4b22-db54-99b9f1d7ec44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2aae104c53944a19df8e221de679723"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "# change epochs for improving results (our paper : epochs = 4)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "yO_GNYxCSYfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca93cd4-d12a-4609-9bbe-a6a1e435451e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming_loss': hamming}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFH3QM6ctmP",
        "outputId": "31525220-5836-44cc-fe3f-53885b326162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:36,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:37.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [15:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:15:59.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:21,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.1362\n",
            "  Training epcoh took: 0:26:23\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0863\n",
            "  Training epcoh took: 0:26:33\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0641\n",
            "  Training epcoh took: 0:26:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:44.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:06,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:29.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0499\n",
            "  Training epcoh took: 0:26:31\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "PXTAMK1sc0Sq",
        "outputId": "ed123a8b-6629-4cf9-9602-6214ec84620a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n",
            "Hamming Loss: 0.0360\n",
            "Validation took: 0:00:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "\n",
        "# torch.save(model.state_dict(), path+\"BERT_model.pt\")"
      ],
      "metadata": {
        "id": "sdghDBnXdYlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "path = '/content/model/'\n",
        "#torch.save(model.state_dict(), path+\"BERT_multilabel_model.pt\")\n",
        "model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "a48a706b-90c2-4cff-ef49-372f46bb0b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d28ce5f3d4a8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "sgx14gm68ElU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "for batch in validation_dataloader:\n",
        " batch = tuple(t.to(device) for t in batch)\n",
        " b_input_ids, b_input_mask, b_labels = batch\n",
        " with torch.no_grad():\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " logits = outputs[0]\n",
        " logits = logits.detach().cpu().numpy()\n",
        " label_ids = b_labels.to('cpu').numpy()\n",
        " for b in logits:\n",
        "  accum_logits.append(list(b))\n",
        " for b in label_ids:\n",
        "  accum_label_ids.append(list(b))\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))"
      ],
      "metadata": {
        "id": "1jqF9y4E7YjT",
        "outputId": "f5337511-dfd8-465a-f649-ef6dd6b1f981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "accum_results = []\n",
        "accum_results.append(list(results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "8be033c2-949f-49bb-c74b-8d7011a3407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [00:23,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    686.    Elapsed: 0:00:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [00:45,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of    686.    Elapsed: 0:00:46.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [01:07,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of    686.    Elapsed: 0:01:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "400it [01:29,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of    686.    Elapsed: 0:01:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [01:52,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of    686.    Elapsed: 0:01:52.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "600it [02:14,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    686.    Elapsed: 0:02:15.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "686it [02:33,  4.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down evaluation"
      ],
      "metadata": {
        "id": "lInDyL-9hjhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_labels):\n",
        "    ith_label_ids, ith_logits = [], []\n",
        "\n",
        "    for j, labels in enumerate(accum_label_ids):\n",
        "        if len(np.where(labels)[0]) == i+1:\n",
        "            ith_label_ids.append(accum_label_ids[j].tolist())\n",
        "            ith_logits.append(accum_logits[j].tolist())\n",
        "\n",
        "    ith_label_ids = np.array(ith_label_ids)\n",
        "    ith_logits = np.array(ith_logits)\n",
        "\n",
        "    if len(ith_label_ids) == 0 and len(ith_logits) == 0:\n",
        "        continue\n",
        "\n",
        "    results = multi_label_metrics(ith_logits, ith_label_ids)\n",
        "    accum_results.append(list(results.values()))\n",
        "\n",
        "    print('# of labels:', i+1)\n",
        "    print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "    print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "    print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "    print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "    print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "    print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uVtTwWhnHy",
        "outputId": "a9586bb2-d12a-4fb3-e6e6-96fc2ea1411e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer,\n",
        "device=0, max_length=10,\n",
        " return_all_scores=True, function_to_apply='sigmoid')\n",
        "result = pipe('틀니들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)\n",
        "label_dict = {'LABEL_0' : '출신차별', 'LABEL_1' : '외모차별', 'LABEL_2' : '정치성향차별', 'LABEL_3': '혐오욕설', 'LABEL_4': '연령차별', 'LABEL_5': '성차별', 'LABEL_6' : '인종차별', 'LABEL_7': '종교차별', 'LABEL_8': '해당사항없음'}\n",
        "def prediction(text):\n",
        " result = pipe(text)\n",
        " return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]\n",
        "prediction('틀니들은 왜 그렇게 민폐를 끼치냐?')"
      ],
      "metadata": {
        "id": "798meQSe6c-Y",
        "outputId": "29f81dc5-4d82-4881-da65-b6d9e18cb133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "def predict_labels(text, model, tokenizer, label_names, threshold=0.1):\n",
        "    # 텍스트를 모델의 입력 형식으로 인코딩\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 10,\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 모델을 사용하여 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    # 예측 결과에서 확률 추출\n",
        "    logits = outputs.logits\n",
        "    #print(logits)\n",
        "    probs = sigmoid(logits)\n",
        "    #print(probs)\n",
        "\n",
        "    # CPU로 이동 후 numpy 배열로 변환\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    #print(probs)\n",
        "\n",
        "    # 예측된 레이블 결정\n",
        "    predicted_labels = [label_names[i] for i in range(len(label_names)) if probs[0][i] >= threshold]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "2FStXOPPcqnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"늙은 천주교 신자들은 다 속물이다\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "t18ZXNVec82c",
        "outputId": "7f1017bd-25a0-465e-c8fd-93d35c71b2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 늙은 천주교 신자들은 다 속물이다 & Predicted labels: ['연령차별', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1\n",
        "text = \"못생긴 경상도 여자들은 나가라\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} -> Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "Q4wfueAfdARU",
        "outputId": "4859f174-6d45-4814-ba80-4141cb41a408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 못생긴 경상도 여자들은 나가라 -> Predicted labels: ['출신차별', '외모차별', '성차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LV_-RJXdR5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VSCode 쪽 코드 (receive_data.py)\n",
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "xCHlbhrqdDuu",
        "outputId": "dfab927a-95c7-4912-c8ac-f2abdd2b3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1b184333c58d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/./content/model/attention_scores.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutputs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('문재앙')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f-0wLH1NexAK",
        "outputId": "aad1f501-1edb-4b93-8107-3e7969a40efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.007721984758973122}, {'label': 'LABEL_1', 'score': 0.0032311684917658567}, {'label': 'LABEL_2', 'score': 0.985312283039093}, {'label': 'LABEL_3', 'score': 0.005993321072310209}, {'label': 'LABEL_4', 'score': 0.0053891874849796295}, {'label': 'LABEL_5', 'score': 0.002821417059749365}, {'label': 'LABEL_6', 'score': 0.0012292619794607162}, {'label': 'LABEL_7', 'score': 0.002137931529432535}, {'label': 'LABEL_8', 'score': 0.007046678103506565}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = \"cpu\"\n",
        "\n",
        "# 모델을 CPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, max_length=10, return_all_scores=True)\n",
        "\n",
        "result = pipe('깜둥이들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PmW6CiNigW55",
        "outputId": "d5a7f40f-c0e2-470f-f103-32c8b4eac2a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.14709047973155975}, {'label': 'LABEL_1', 'score': 0.26493778824806213}, {'label': 'LABEL_2', 'score': 0.026825927197933197}, {'label': 'LABEL_3', 'score': 0.03060534968972206}, {'label': 'LABEL_4', 'score': 0.08758819103240967}, {'label': 'LABEL_5', 'score': 0.09902970492839813}, {'label': 'LABEL_6', 'score': 0.8641231060028076}, {'label': 'LABEL_7', 'score': 0.14547504484653473}, {'label': 'LABEL_8', 'score': 0.11148741096258163}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "lEvK_zHWgiKj",
        "outputId": "015cad8e-ab91-4641-8e3f-62dbda68a333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ㅅ발 천주교도들은 너무 말이 많아 & Predicted labels: ['혐오욕설', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = '/home/jyhan/HW-output-files/example.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "NH4-k_-Zgp5L",
        "outputId": "1675b92e-3162-4d6f-8956-2b22a852f997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file /home/jyhan/HW-output-files/example.txt does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def pickle_to_text(pickle_file_path, text_file_path):\n",
        "    # 피클 파일 불러오기\n",
        "    with open(pickle_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 텍스트 파일로 저장하기\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        for sublist in data:\n",
        "            # 각 서브리스트를 반복하고 숫자를 문자열로 변환하여 저장\n",
        "            for number in sublist:\n",
        "                f.write(f\"{number} \")\n",
        "            f.write(\"\\n\\n\\n\")  # 각 서브리스트 끝에 줄바꿈 추가"
      ],
      "metadata": {
        "id": "OpUp0tFHhvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def tanh_new(x) :\n",
        "    result = (F.tanh(x) + 1) /2\n",
        "    return result"
      ],
      "metadata": {
        "id": "_c7Qzz8DhxOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number(num):\n",
        "    \"\"\"숫자를 7비트 2의 보수 형식으로 인코딩하는 함수, 음수 소수 부분을 고려\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = abs(num - int_num)\n",
        "\n",
        "    # Round integer part towards zero if num is negative and has a fractional part\n",
        "    if num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num = int_num - 1  # Round integer part one more negative\n",
        "            frac_num = 1 - frac_num  # Subtract fractional part from 1 to make it positive\n",
        "\n",
        "    # Clamp the values to fit within the 7-bit range\n",
        "    if int_num < -64:\n",
        "        int_num = -64\n",
        "    elif int_num > 63:\n",
        "        int_num = 63\n",
        "\n",
        "    # Apply 2's complement if the number is negative\n",
        "    if int_num < 0:\n",
        "        int_num = (1 << 7) + int_num  # 1 << 7 is 128, representing the range of 7-bit integers\n",
        "\n",
        "    # Format the number into 7-bit binary\n",
        "    int_part_bin = format(int_num & 0b1111111, '07b')  # Only the last 7 bits are used\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = int_part_bin + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "4RMAodqch2WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_input(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number(num) for num in numbers]"
      ],
      "metadata": {
        "id": "_sD86m8Zh5dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools"
      ],
      "metadata": {
        "id": "6TPxkyv6h-nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number_output(num):\n",
        "    \"\"\"숫자를 3비트 정수와 13비트 소수 형식으로 인코딩하는 함수, 값은 0부터 1 사이의 양수\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Clamp the values to fit within the 0 to 1 range\n",
        "    if num < 0:\n",
        "        num = 0\n",
        "    elif num > 1:\n",
        "        num = 1\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = num - int_num\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = '000' + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jYW_te9oh_oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_output(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number_output(num) for num in numbers]"
      ],
      "metadata": {
        "id": "5a7CeXJmh_p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.0301, 0.0112, 0.0040, 0.7632, 0.0040, 0.0072, 0.0068, 0.8885, 0.0117]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "FFeQcYAWiMA8",
        "outputId": "736e8784-52f8-422c-98fa-4ff53d1e762d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000_0000011110110', '000_0000001011011', '000_0000000100000', '000_1100001101100', '000_0000000100000', '000_0000000111010', '000_0000000110111', '000_1110001101110', '000_0000001011111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [-3.0061, -4.5561, -3.7781, -4.6988, -1.8251, -4.0483, -4.8075,  4.6085, -5.1693]\n",
        "encoded_numbers = encode_numbers_input(probs)\n",
        "print(encoded_numbers)\n",
        "\n",
        "probs = [0.0472, 0.0104, 0.0224, 0.0090, 0.1388, 0.0172, 0.0081, 0.9901, 0.0057]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "W-j1Du8UiEQp",
        "outputId": "dc770265-811c-462e-9691-e11b53baa754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1111100_1111111001110', '1111011_0111000110100', '1111100_0011100011001', '1111011_0100110100011', '1111110_0010110011000', '1111011_1111001110100', '1111011_0011000101000', '0000100_1001101111000', '1111010_1101010010101']\n",
            "['000_0000110000010', '000_0000001010101', '000_0000010110111', '000_0000001001001', '000_0010001110001', '000_0000010001100', '000_0000001000010', '000_1111110101110', '000_0000000101110']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin, decimal_part_bin = encoded.split('.')\n",
        "\n",
        "    # Integer part processing\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # Negative number (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # Positive number\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # Fractional part processing\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # Adjust for negative numbers\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the function with provided values\n",
        "encoded_values = [\n",
        "    \"0000000.0101010000101\",\n",
        "    \"0000000.0010111100000\",\n",
        "    \"0000000.0010110110000\",\n",
        "    \"0000000.0010001111011\",\n",
        "    \"0000000.0010001101110\",\n",
        "    \"0000000.0001110010000\",\n",
        "    \"0000000.0001100000110\",\n",
        "    \"0000000.0000000000010\",\n",
        "    \"1111111.1101100010111\",\n",
        "    \"1111111.1101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "kzwvRVHhiM6-",
        "outputId": "bc68f1c5-1ccf-448b-d191-db922babb9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3287353515625,\n",
              " 0.18359375,\n",
              " 0.177734375,\n",
              " 0.1400146484375,\n",
              " 0.138427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " -0.1534423828125,\n",
              " -0.1597900390625]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    # 입력 문자열을 반으로 나누어 정수 부분과 소수 부분으로 분리\n",
        "    mid_index = len(encoded) // 2\n",
        "    int_part_bin = encoded[:mid_index]\n",
        "    decimal_part_bin = encoded[mid_index:]\n",
        "\n",
        "    # 정수 부분 처리\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"00000000101010000101\",\n",
        "    \"00000000010111100000\",\n",
        "    \"00000000010110110000\",\n",
        "    \"00000000010001111011\",\n",
        "    \"00000000010001101110\",\n",
        "    \"00000000001110010000\",\n",
        "    \"00000000001100000110\",\n",
        "    \"00000000000000000010\",\n",
        "    \"11111111101100010111\",\n",
        "    \"11111111101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "Fy0SQbOSiad-",
        "outputId": "065255d8-cb84-4e66-dfb3-6a9e2a11b288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0787353515625,\n",
              " 1.05859375,\n",
              " 1.052734375,\n",
              " 1.0150146484375,\n",
              " 1.013427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " 894.0965576171875,\n",
              " 894.0902099609375]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    if int(int_part_bin, 2) & (1 << 2):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 3)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0001000101001100\",\n",
        "    \"0000011001010100\",\n",
        "    \"0000000111011100\",\n",
        "    \"0000000111010100\",\n",
        "    \"0000000110110100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000011010100\",\n",
        "    \"0000000001100100\",\n",
        "    \"0000000001010100\",\n",
        "    \"0000000001000100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for encoded, decoded in zip(encoded_values, decoded_values):\n",
        "    print(f\"Encoded: {encoded} -> Decoded: {decoded}\")"
      ],
      "metadata": {
        "id": "i6y3VbyOiiIq",
        "outputId": "5a3c4faf-c316-4c0d-c6e4-b28dbbd12b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: 0001000101001100 -> Decoded: 0.54052734375\n",
            "Encoded: 0000011001010100 -> Decoded: 0.19775390625\n",
            "Encoded: 0000000111011100 -> Decoded: 0.05810546875\n",
            "Encoded: 0000000111010100 -> Decoded: 0.05712890625\n",
            "Encoded: 0000000110110100 -> Decoded: 0.05322265625\n",
            "Encoded: 0000000100000100 -> Decoded: 0.03173828125\n",
            "Encoded: 0000000011010100 -> Decoded: 0.02587890625\n",
            "Encoded: 0000000001100100 -> Decoded: 0.01220703125\n",
            "Encoded: 0000000001010100 -> Decoded: 0.01025390625\n",
            "Encoded: 0000000001000100 -> Decoded: 0.00830078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "\n",
        "    # 리스트를 문자열 형식으로 변환\n",
        "    formatted_hex_list = \"[\" + \", \".join(f'\"{hex_value}\"' for hex_value in hex_list) + \"]\"\n",
        "\n",
        "    return formatted_hex_list\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"06dc 05c4 0494 03c4 039c 02e4 017c 0144 00e4 00ac\"\n",
        "formatted_hex_list = format_hex_input(hex_input)\n",
        "\n",
        "print(formatted_hex_list)"
      ],
      "metadata": {
        "id": "KiL0Vi9sikfX",
        "outputId": "b64e353d-7b34-495a-d00c-926f5003b6c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n",
        "\n",
        "float_values = hexa_to_float(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, float_value in zip(hex_strings, float_values):\n",
        "    print(f\"{float_value}\")"
      ],
      "metadata": {
        "id": "6FquW2OFiogU",
        "outputId": "9471a4a4-e711-48db-cb4a-b03b9e786114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21435546875\n",
            "0.18017578125\n",
            "0.14306640625\n",
            "0.11767578125\n",
            "0.11279296875\n",
            "0.09033203125\n",
            "0.04638671875\n",
            "0.03955078125\n",
            "0.02783203125\n",
            "0.02099609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "    return hex_list\n",
        "\n",
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "def convert_hex_input_to_float(hex_input):\n",
        "    hex_strings = format_hex_input(hex_input)\n",
        "    float_values = hexa_to_float(hex_strings)\n",
        "    return float_values\n",
        "\n",
        "def chunk_floats(float_values, chunk_size=10):\n",
        "    # float 값을 chunk_size 크기로 분할하고 각 chunk 사이에 두 개의 엔터를 추가\n",
        "    chunked_result = \"\"\n",
        "    for i in range(0, len(float_values), chunk_size):\n",
        "        chunk = float_values[i:i + chunk_size]\n",
        "        chunked_result += \"\\n\".join(map(str, chunk)) + \"\\n\\n\"\n",
        "    return chunked_result.strip()\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"\"\"\n",
        "1404\n",
        "026c\n",
        "0234\n",
        "0214\n",
        "0184\n",
        "017c\n",
        "015c\n",
        "001c\n",
        "001c\n",
        "0004\n",
        "\"\"\"\n",
        "\n",
        "float_values = convert_hex_input_to_float(hex_input)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "chunked_result = chunk_floats(float_values)\n",
        "\n",
        "print(chunked_result)"
      ],
      "metadata": {
        "id": "w7Z4vjWsiwnS",
        "outputId": "65b8d244-71da-4786-982b-3c0cd7419a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62548828125\n",
            "0.07568359375\n",
            "0.06884765625\n",
            "0.06494140625\n",
            "0.04736328125\n",
            "0.04638671875\n",
            "0.04248046875\n",
            "0.00341796875\n",
            "0.00341796875\n",
            "0.00048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0000110101000100\",\n",
        "    \"0000100000100100\",\n",
        "    \"0000001101111100\",\n",
        "    \"0000001011111100\",\n",
        "    \"0000000111000100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000001110100\",\n",
        "    \"0000000001000100\",\n",
        "    \"0000000000111100\",\n",
        "    \"0000000000110100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for decoded in decoded_values:\n",
        "    print(decoded)\n"
      ],
      "metadata": {
        "id": "8BR8NGmgi0Ny",
        "outputId": "ce3ad4f4-77b8-4fc5-85fd-765aa943aee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41455078125\n",
            "0.25439453125\n",
            "0.10888671875\n",
            "0.09326171875\n",
            "0.05517578125\n",
            "0.03173828125\n",
            "0.01416015625\n",
            "0.00830078125\n",
            "0.00732421875\n",
            "0.00634765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "new_hex_strings = [\"0d44\", \"0824\", \"037c\", \"02fc\", \"01c4\", \"0104\", \"0074\", \"0044\", \"003c\", \"0034\"]\n",
        "new_binary_strings = hexa_to_binary(new_hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(new_hex_strings, new_binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "1W-StNJci3XU",
        "outputId": "095b0b15-ad21-40d5-f621-f7334809dcbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000110101000100\n",
            "0000100000100100\n",
            "0000001101111100\n",
            "0000001011111100\n",
            "0000000111000100\n",
            "0000000100000100\n",
            "0000000001110100\n",
            "0000000001000100\n",
            "0000000000111100\n",
            "0000000000110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"069c\", \"046c\", \"045c\", \"0434\", \"02fc\", \"02a4\", \"026c\", \"01d4\", \"00e4\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")"
      ],
      "metadata": {
        "id": "xyNYFw6ki5gk",
        "outputId": "42c1a8c9-4642-485d-b163-9d17a8ff02f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000011010011100\n",
            "0000010001101100\n",
            "0000010001011100\n",
            "0000010000110100\n",
            "0000001011111100\n",
            "0000001010100100\n",
            "0000001001101100\n",
            "0000000111010100\n",
            "0000000011100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "hex_strings = [\"045c\", \"0404\", \"03b4\", \"039c\", \"0374\", \"034c\", \"031c\", \"027c\", \"022c\", \"01bc\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "LCmwYD9Qi79m",
        "outputId": "c514a4dd-6d73-431b-efc1-8e4016735ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000010001011100\n",
            "0000010000000100\n",
            "0000001110110100\n",
            "0000001110011100\n",
            "0000001101110100\n",
            "0000001101001100\n",
            "0000001100011100\n",
            "0000001001111100\n",
            "0000001000101100\n",
            "0000000110111100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error_rates(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    list of float: 각 데이터에 대한 오차율 (백분율) 리스트\n",
        "    \"\"\"\n",
        "    if len(actual_values) != len(predicted_values):\n",
        "        raise ValueError(\"실제 값 리스트와 예측 값 리스트의 길이는 같아야 합니다.\")\n",
        "\n",
        "    error_rates = []\n",
        "    for actual, predicted in zip(actual_values, predicted_values):\n",
        "        if actual == 0:\n",
        "            error_rate = 0\n",
        "        else:\n",
        "            error = actual - predicted\n",
        "            error_rate = abs((error / actual) * 100)\n",
        "        error_rates.append(error_rate)\n",
        "\n",
        "    return error_rates\n",
        "\n",
        "def calculate_average_error_rate(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 평균 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    float: 평균 오차율 (백분율)\n",
        "    \"\"\"\n",
        "    error_rates = calculate_error_rates(actual_values, predicted_values)\n",
        "    average_error_rate = sum(error_rates) / len(error_rates)\n",
        "    return average_error_rate"
      ],
      "metadata": {
        "id": "D2-wjc8yi_Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용\n",
        "actual_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "predicted_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "average_error_rate = calculate_average_error_rate(actual_values, predicted_values)\n",
        "\n",
        "print(f\"최종 오차율: {average_error_rate}%\")"
      ],
      "metadata": {
        "id": "clf_RoSfjBeq",
        "outputId": "318aa51e-54dc-4846-8a77-40d840322127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 오차율: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정\n",
        "start_time = time.time()\n",
        "softmax_values = softmax(values)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Softmax output: {softmax_values}\")\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "i7BTwvyNjE92",
        "outputId": "63879604-4d50-44a2-b56b-3a5caf27a226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output: [0.12884706 0.078919   0.10701211 0.10971393 0.08327362 0.06426792\n",
            " 0.07816849 0.15625726 0.09706082 0.09647979]\n",
            "Execution time: 0.0002593994140625 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정 (timeit 모듈 사용)\n",
        "execution_time = timeit.timeit(lambda: softmax(values), number=100000)\n",
        "print(f\"Average execution time over 1000 runs: {execution_time / 100000} seconds\")\n"
      ],
      "metadata": {
        "id": "I7TbeCl0jFAe",
        "outputId": "7eac1eeb-81a8-4468-ba8c-9deee2c2c540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time over 1000 runs: 8.880072149999023e-06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "start_time = time.time()\n",
        "my_function()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "_Y3J9uF8jFCp",
        "outputId": "260a20bc-e04f-4264-9735-c14c28425431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.000253438949585 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "execution_time = timeit.timeit(my_function, number=1)\n",
        "print(f\"Execution time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "id": "9a5zh7itjK_1",
        "outputId": "aadab6eb-dc3f-4516-997f-d39e592f7f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0000678239999843 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "id": "XarrC_jbjPME",
        "outputId": "3524c1d8-2ee3-410e-b866-17c24aeb5aa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001747608184814 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import socket\n",
        "\n",
        "# HW -> SW connect\n",
        "# This should be fixed later when connecting with hardware.\n",
        "def receive_from_hardware(host: str, port: int, buffer_size: int = 1024) -> bytes:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.connect((host, port))\n",
        "        attention_probs_hw = s.recv(buffer_size)\n",
        "    return attention_probs_hw\n",
        "\n",
        "# HW 2진수 -> SW Decode\n",
        "def decode_values(encoded_values_list: list) -> list:\n",
        "    encoded_values = tuple(encoded_values_list)\n",
        "    decoded_values = []\n",
        "\n",
        "    for encoded_value in encoded_values:\n",
        "        special_value_bit = encoded_value[0]\n",
        "        if special_value_bit == '1':\n",
        "            decoded_values.append(0.0)\n",
        "        else:\n",
        "            sign_bit = encoded_value[1]\n",
        "            sign = -1 if sign_bit == '1' else 1\n",
        "\n",
        "            integer_part = int(encoded_value[2:5], 2)\n",
        "            fractional_part = int(encoded_value[5:], 2) / (1 << 13)\n",
        "\n",
        "            decoded_value = sign * (integer_part + fractional_part)\n",
        "            decoded_values.append(round(decoded_value, 7))\n",
        "\n",
        "    return decoded_values\n",
        "\n",
        "# 1D -> 4D 변환 코드\n",
        "def convert_to_4d(input_list):\n",
        "    # Step 1: Divide the list into sublists of 10 elements each\n",
        "    sublists = [input_list[i:i + 10] for i in range(0, len(input_list), 10)]\n",
        "\n",
        "    # Step 2: Group every 10 sublists into a larger list to form a [12, 10, 10] shape\n",
        "    grouped_sublists = [sublists[i:i + 10] for i in range(0, len(sublists), 10)]\n",
        "\n",
        "    # Step 3: Convert the final list to a tensor and add an extra dimension to form [1, 12, 10, 10]\n",
        "    attention_probs_4d = torch.tensor(grouped_sublists).unsqueeze(0)\n",
        "    return attention_probs_4d"
      ],
      "metadata": {
        "id": "vh30Ck9JjWVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_raw_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "GEln6Bi7whyh",
        "outputId": "d8351cc1-6a56-4d38-a36d-9e453897e9d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/softmax_bert_layer1.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_softmax_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "YgDd7AmYGVMO",
        "outputId": "3ef23da2-7403-405c-c27f-6b95c89b62c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/softmax_bert_layer1.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "05VQ55mWooaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import math\n",
        "attention_scores = layer_1_attention\n",
        "attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        " #Pickle 파일 저장\n",
        "if attention_mask is not None:\n",
        " # Apply the attention mask is (precomputed for all layers in BertModel\n",
        " attention_scores = attention_scores + attention_mask\n",
        " # attention_scores를 피클 파일로 저장합니다.\n",
        "attention_scores_list = attention_scores.tolist()  # torch.Tensor를 Python 리스트로 변환\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"wb\") as f:\n",
        " pickle.dump(attention_scores_list, f)\n",
        " #저장된 Pickle 파일 불러와서 plot\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        " outputs = pickle.load(f)\n",
        "out_chain3 = list(itertools.chain(*outputs))\n",
        "out_chain2 = list(itertools.chain(*out_chain3))\n",
        "out_chain1 = list(itertools.chain(*out_chain2))\n",
        "print(out_chain1)\n",
        "max_value = torch.max(attention_scores)\n",
        "min_value = torch.min(attention_scores)\n",
        "print(\"Max value in attention_scores:\", max_value.item())"
      ],
      "metadata": {
        "id": "YAV18-7XnknO",
        "outputId": "6677399f-036a-4de7-ea6f-d211165a955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b97d7302ca28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;31m#Pickle 파일 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "if2KlEtgI6bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#아무래도 진짜..코드 위에선  outputs.last_hidden_state 로 써서 12번째 레이어의 값으로 KQV 계산했을 수 있다.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        # BERT 모델의 기본 동작 수행\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # 어텐션 값 반환 활성화\n",
        "            output_hidden_states=True,  # 히든 스테이트 반환 활성화\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # 모델 설정값 가져오기\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 멀티헤드 개수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기 (64)\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        # === 첫 번째 Transformer 레이어에서 Query (Q), Key (K) 직접 가져오기 ===\n",
        "        first_layer = self.encoder.layer[0]  # 첫 번째 Transformer 레이어\n",
        "        input_tensor = outputs.hidden_states[0]  # 첫 번째 레이어 입력 (Embedding 후 결과)\n",
        "\n",
        "        # Query, Key 생성\n",
        "        Q = first_layer.attention.self.query(input_tensor)  # (1, 10, 768)\n",
        "        K = first_layer.attention.self.key(input_tensor)  # (1, 10, 768)\n",
        "\n",
        "        # === Multi-Head 형태로 변환 ===\n",
        "        # Query, Key의 shape을 (batch_size, num_heads, sequence_length, head_dim)로 변환\n",
        "        Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "        K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 계산 ===\n",
        "        raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # (1, 12, 10, 10)\n",
        "\n",
        "        return raw_attention, outputs.attentions[0]  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === 첫 번째 레이어의 Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "_beDp4MY8Ib_",
        "outputId": "8ee17bfc-a22d-4111-bb48-935ea4541144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder\n",
        "\n",
        "# === Softmax 이전 Attention Score 추출을 위한 BertSelfAttention 수정 ===\n",
        "class BertSelfAttentionWithRawScores(BertSelfAttention):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.raw_attention_scores = None  # Softmax 이전 Attention Score 저장\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        # === Query, Key, Value 생성 ===\n",
        "        mixed_query_layer = self.query(hidden_states)  # (batch, seq_len, hidden_dim)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        # === Multi-Head Attention 변환 ===\n",
        "        batch_size, seq_length, hidden_dim = hidden_states.shape\n",
        "        num_heads = self.num_attention_heads\n",
        "        head_dim = self.attention_head_size  # hidden_dim // num_heads (768/12=64)\n",
        "\n",
        "        assert hidden_dim == num_heads * head_dim  # 차원 검증\n",
        "\n",
        "        # Query, Key, Value를 (batch, num_heads, seq_len, head_dim) 형태로 변환\n",
        "        query_layer = mixed_query_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        key_layer = mixed_key_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "        value_layer = mixed_value_layer.view(batch_size, seq_length, num_heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 저장 ===\n",
        "        self.raw_attention_scores = torch.matmul(query_layer, key_layer.transpose(-2, -1)) / (head_dim ** 0.5)\n",
        "\n",
        "        # === Softmax 적용 ===\n",
        "        attention_probs = nn.functional.softmax(self.raw_attention_scores, dim=-1)\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.transpose(1, 2).contiguous()\n",
        "        context_layer = context_layer.view(batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Softmax 이전과 이후 값 반환 (BERT 내부 연산 유지)\n",
        "        if output_attentions:\n",
        "            return context_layer, attention_probs, self.raw_attention_scores  # Softmax 이후 값, Softmax 이전 값\n",
        "        return context_layer, attention_probs\n",
        "\n",
        "# === BERT Encoder에서 Custom BertSelfAttention 적용 ===\n",
        "class BertEncoderWithRawAttention(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        # 기존 BERT의 레이어를 유지하면서, BertSelfAttention을 수정한 레이어로 교체\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionWithRawScores(config)\n",
        "\n",
        "# === 새로운 BERT 모델 정의 ===\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.encoder = BertEncoderWithRawAttention(config)  # 수정된 Encoder 적용\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, inputs_embeds=None,\n",
        "                output_attentions=True, output_hidden_states=True, return_dict=True):\n",
        "\n",
        "        # BERT의 기본 forward 호출\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # === Softmax 이후 Attention Score ===\n",
        "        softmax_attention = outputs.attentions[0]\n",
        "\n",
        "        # === Softmax 이전 Attention Score ===\n",
        "        raw_attention = self.encoder.layer[0].attention.self.raw_attention_scores\n",
        "\n",
        "        return raw_attention, softmax_attention\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name)  # 모델 설정값 로드\n",
        "model = BertWithRawAttention.from_pretrained(model_name, config=config)  # 기존 가중치 로드\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Softmax 이전 Attention Score (Shape: {raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n",
        "\n",
        "# === Softmax 이후 Attention Score 확인 ===\n",
        "layer_1_softmax_attention = softmax_attention.numpy()\n",
        "print(f\"Softmax 이후 Attention Score (Shape: {softmax_attention.shape}):\")\n",
        "print(layer_1_softmax_attention)\n"
      ],
      "metadata": {
        "id": "PtMgJMl6-cXT",
        "outputId": "d4a28e44-4a48-4ccb-9186-dd81c1519048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 이전 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[ 3.479377    0.11714409  0.5856975  ...  0.49772462  2.0617602\n",
            "     1.4053444 ]\n",
            "   [ 1.6703308   3.3466518   5.793112   ...  2.3886065   1.5484276\n",
            "     1.9099072 ]\n",
            "   [ 3.3168168   4.502995    3.8073637  ...  1.6874914   2.6028967\n",
            "     1.5656495 ]\n",
            "   ...\n",
            "   [ 1.6387088   1.7666457   2.1017816  ...  2.9609547   3.9101954\n",
            "     4.537689  ]\n",
            "   [ 3.3072975   1.2618201   2.365435   ...  4.3632503   3.529175\n",
            "     5.7495446 ]\n",
            "   [ 4.5703983   3.1162205   2.4864216  ...  4.4660215   6.618206\n",
            "     5.1483626 ]]\n",
            "\n",
            "  [[-1.0886638   0.02555725  0.311149   ... -0.46038562 -0.6803706\n",
            "     0.9627847 ]\n",
            "   [-1.7430696  -0.5790163   0.7301598  ... -0.7375137  -0.6899191\n",
            "     0.97234195]\n",
            "   [-0.43296996 -0.34776625 -0.61825126 ... -0.0585902  -1.3146526\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.35978922  0.09165996  0.42240837 ... -0.33630806 -0.56914496\n",
            "     0.99600965]\n",
            "   [-0.96181583  0.22939461  0.1490941  ...  0.6880506  -0.33433583\n",
            "     0.4417293 ]\n",
            "   [-0.60645354 -0.3579516   0.47387433 ... -0.10441241 -0.4639737\n",
            "     0.81911325]]\n",
            "\n",
            "  [[ 2.8996303   0.02200214 -0.74852276 ... -0.14752409  4.0928345\n",
            "     2.411408  ]\n",
            "   [ 0.5878507   3.011582    3.9065943  ...  2.1310635  -0.09421223\n",
            "     0.98545116]\n",
            "   [ 0.6049058   2.2343197   2.6323042  ...  1.5101197   0.56835276\n",
            "     1.3811649 ]\n",
            "   ...\n",
            "   [ 2.1231966   0.84968215  1.4300145  ...  1.5934157   1.0071483\n",
            "     2.0823565 ]\n",
            "   [ 3.2195091   0.0096926   0.56950235 ...  0.2573312   1.7817802\n",
            "     2.0053072 ]\n",
            "   [ 3.912785    0.8497595   0.3867088  ...  0.9062026   4.1586957\n",
            "     2.9207473 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641907  -0.04179777 -0.03871024 ... -0.1011171  -0.61037153\n",
            "     1.11368   ]\n",
            "   [ 0.6315195   1.5662173   1.0136852  ...  1.0755258   0.36316153\n",
            "     1.5360875 ]\n",
            "   [-0.19636366  1.3796113   0.9972024  ...  0.53102773  0.60126495\n",
            "     1.431718  ]\n",
            "   ...\n",
            "   [-0.42347932  0.7645048   1.1695968  ...  1.8586993   1.3764335\n",
            "     1.3430959 ]\n",
            "   [-0.04602024  1.0310172   1.1641402  ...  0.95073116  1.0027801\n",
            "     1.6112568 ]\n",
            "   [-0.1204833   0.88820004  0.8350356  ...  0.6750055   0.5101989\n",
            "     1.052246  ]]\n",
            "\n",
            "  [[ 3.5113144   0.23125732  0.14855024 ... -0.6694767   0.04084282\n",
            "     0.70824903]\n",
            "   [ 1.7904973   2.2246804   2.806927   ...  2.6324604   1.0418186\n",
            "     2.819541  ]\n",
            "   [ 2.5830665   2.5436692   2.6789215  ...  1.4598      1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281339   3.5719974   3.1684306  ...  3.3282526   1.6605146\n",
            "     4.188968  ]\n",
            "   [ 3.7193854   2.3510675   2.3213775  ...  3.097043    1.2444317\n",
            "     2.0928166 ]\n",
            "   [ 5.245867    2.9236443   2.6110198  ...  3.372125    2.8552227\n",
            "     3.146039  ]]\n",
            "\n",
            "  [[ 1.7404832   0.20622298  0.17036484 ... -0.21828583  0.24408357\n",
            "     2.5945306 ]\n",
            "   [ 2.5038111   3.8067138  -0.9152964  ... -1.4174232   0.43165812\n",
            "     1.9661093 ]\n",
            "   [ 2.3395207  -1.5124058   1.7736304  ... -1.3535223   0.9409393\n",
            "     0.73563135]\n",
            "   ...\n",
            "   [ 1.5222133  -0.8623995  -0.37342417 ...  3.1788638   0.40442356\n",
            "     0.29755515]\n",
            "   [ 1.7944585   0.43165296 -0.3501598  ... -1.6325725  -1.2602837\n",
            "     0.9605556 ]\n",
            "   [ 1.9798651  -0.5624908  -0.7449863  ... -0.9195779  -0.8235787\n",
            "     0.9559839 ]]]]\n",
            "Softmax 이후 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[0.5283773  0.01831239 0.02925736 ... 0.02679347 0.12802093\n",
            "    0.06640536]\n",
            "   [0.00969707 0.05183908 0.5986064  ... 0.01988765 0.00858417\n",
            "    0.01232217]\n",
            "   [0.06677455 0.2186561  0.10905681 ... 0.01309194 0.03270088\n",
            "    0.01159014]\n",
            "   ...\n",
            "   [0.01616001 0.01836555 0.02567743 ... 0.06062973 0.15665187\n",
            "    0.293395  ]\n",
            "   [0.04999034 0.00646467 0.01949128 ... 0.14370786 0.06240886\n",
            "    0.5748314 ]\n",
            "   [0.06373078 0.01488702 0.0079303  ... 0.05741416 0.49397027\n",
            "    0.11359414]]\n",
            "\n",
            "  [[0.03568741 0.10874645 0.1446925  ... 0.06689178 0.05368272\n",
            "    0.2776181 ]\n",
            "   [0.01723383 0.05519805 0.20440505 ... 0.0471074  0.04940367\n",
            "    0.2604174 ]\n",
            "   [0.07099048 0.07730429 0.05898389 ... 0.10322649 0.02939613\n",
            "    0.3372574 ]\n",
            "   ...\n",
            "   [0.06292941 0.09883609 0.13758078 ... 0.06442455 0.05104246\n",
            "    0.24415724]\n",
            "   [0.03459279 0.11384704 0.10506249 ... 0.18009992 0.06478832\n",
            "    0.1407789 ]\n",
            "   [0.05027521 0.06445801 0.14809294 ... 0.08305917 0.05797384\n",
            "    0.2091557 ]]\n",
            "\n",
            "  [[0.15359114 0.00864228 0.00399939 ... 0.00729464 0.50648683\n",
            "    0.0942614 ]\n",
            "   [0.01585225 0.17893858 0.43792823 ... 0.0741822  0.00801447\n",
            "    0.0235921 ]\n",
            "   [0.03428007 0.17485864 0.2603332  ... 0.08475611 0.03304965\n",
            "    0.07450179]\n",
            "   ...\n",
            "   [0.18211858 0.05096522 0.09105611 ... 0.1072194  0.05965689\n",
            "    0.17483066]\n",
            "   [0.44636625 0.01801714 0.0315361  ... 0.02307989 0.10599701\n",
            "    0.13254708]\n",
            "   [0.2774437  0.0129694  0.00816243 ... 0.01372248 0.35479093\n",
            "    0.10288175]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.04930858 0.10154388 0.10185789 ... 0.09569554 0.05750762\n",
            "    0.3224567 ]\n",
            "   [0.08078458 0.20571339 0.11838616 ... 0.12593833 0.06177064\n",
            "    0.19960773]\n",
            "   [0.0412325  0.19937783 0.13601877 ... 0.08533785 0.09154727\n",
            "    0.2100422 ]\n",
            "   ...\n",
            "   [0.02443384 0.08015428 0.12018657 ... 0.23940288 0.14780325\n",
            "    0.14295706]\n",
            "   [0.04283044 0.12574883 0.14365427 ... 0.1160476  0.12224771\n",
            "    0.22464608]\n",
            "   [0.05391058 0.14782219 0.14016856 ... 0.11944017 0.10129216\n",
            "    0.17417422]]\n",
            "\n",
            "  [[0.7349549  0.0276535  0.02545838 ... 0.01123482 0.02285883\n",
            "    0.04455587]\n",
            "   [0.0558468  0.08621079 0.15432207 ... 0.12961587 0.02641504\n",
            "    0.15628102]\n",
            "   [0.11732682 0.11279433 0.12912983 ... 0.03815653 0.03798619\n",
            "    0.18773969]\n",
            "   ...\n",
            "   [0.02055062 0.1586586  0.10597336 ... 0.12433876 0.02345941\n",
            "    0.29404283]\n",
            "   [0.24240194 0.06169973 0.05989478 ... 0.1300937  0.02040222\n",
            "    0.04765695]\n",
            "   [0.40604973 0.03981538 0.02912593 ... 0.06234814 0.03718225\n",
            "    0.04973197]]\n",
            "\n",
            "  [[0.20841888 0.04493827 0.04335542 ... 0.02939372 0.04667228\n",
            "    0.4896042 ]\n",
            "   [0.17757389 0.65346533 0.00581406 ... 0.00351891 0.02235911\n",
            "    0.10371897]\n",
            "   [0.43387496 0.00921498 0.24637778 ... 0.01080181 0.10714414\n",
            "    0.08725781]\n",
            "   ...\n",
            "   [0.13022482 0.01199692 0.0195627  ... 0.6826026  0.04258374\n",
            "    0.03826763]\n",
            "   [0.42847222 0.1096639  0.05017955 ... 0.01391817 0.02019598\n",
            "    0.18610723]\n",
            "   [0.5374471  0.04228677 0.03523285 ... 0.02958855 0.03256983\n",
            "    0.19304997]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './model/attention_scores_2.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "Q0nZ4Onl21iB",
        "outputId": "71229106-fba1-4c96-bac1-f0616740206b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    0.11714409  0.5856975   0.6307755  -0.30920362  2.1947367\n",
            "  -0.14835791  0.49772462  2.0617602   1.4053444 ]\n",
            " [ 1.6703308   3.3466518   5.793112    4.621073    3.812749    2.3419719\n",
            "   1.8878778   2.3886065   1.5484276   1.9099072 ]\n",
            " [ 3.3168168   4.502995    3.8073637   5.2124023   2.3082643   3.0351076\n",
            "   2.4797425   1.6874914   2.6028967   1.5656495 ]\n",
            " [ 2.5718498   4.652975    6.7969666   3.8015726   5.3321524   2.659658\n",
            "   2.719986    2.416732    2.1785326   3.108758  ]\n",
            " [ 0.62522817  4.6419153   3.3077164   5.064213    3.339889    2.7762215\n",
            "   1.873533    3.4980125   2.023627    2.5917144 ]\n",
            " [ 3.9795005   2.6142015   2.2757936   2.9215946   3.511932    3.220555\n",
            "   3.0432897   2.8711824   4.3125715   4.3036885 ]\n",
            " [ 1.7959094   2.6852992   1.6750463   1.3191165   4.1721644   3.331105\n",
            "   2.4741642   4.5505824   2.6400094   3.1753776 ]\n",
            " [ 1.6387088   1.7666457   2.1017816   2.1071794   3.422982    3.3852067\n",
            "   4.2240024   2.9609547   3.9101954   4.537689  ]\n",
            " [ 3.3072975   1.2618201   2.365435    1.1282016   2.2333503   2.9970148\n",
            "   3.822887    4.3632503   3.529175    5.7495446 ]\n",
            " [ 4.5703983   3.1162205   2.4864216   3.426703    2.1799157   5.7463045\n",
            "   3.174025    4.4660215   6.618206    5.1483626 ]] [[-1.0886638e+00  2.5557250e-02  3.1114900e-01 -1.1854680e-01\n",
            "  -7.7044167e-02 -1.6976843e+00 -4.8572365e-02 -4.6038562e-01\n",
            "  -6.8037063e-01  9.6278471e-01]\n",
            " [-1.7430696e+00 -5.7901633e-01  7.3015982e-01  4.3518707e-01\n",
            "   6.1179582e-02 -1.1784676e+00 -2.2009215e-01 -7.3751372e-01\n",
            "  -6.8991911e-01  9.7234195e-01]\n",
            " [-4.3296996e-01 -3.4776625e-01 -6.1825126e-01 -5.5659747e-01\n",
            "  -2.0672473e-01 -1.1309534e+00  2.1543759e-01 -5.8590204e-02\n",
            "  -1.3146526e+00  1.1253307e+00]\n",
            " [-5.9080738e-01 -2.5380707e-01  2.4927259e-04  1.6821440e-02\n",
            "   4.5576128e-01 -2.5012723e-01  3.6733337e-02  1.4773999e-01\n",
            "  -3.3541751e-01  1.2667636e+00]\n",
            " [-1.7260594e+00 -3.7022546e-02  3.2314226e-01  9.6709438e-02\n",
            "  -2.5472367e-01 -1.5367095e+00  7.0705187e-01  6.5236461e-01\n",
            "  -1.2064693e+00  5.9022087e-01]\n",
            " [-1.2091219e+00  1.5285142e-01  3.8227442e-01  2.8489169e-01\n",
            "   3.7704596e-01 -8.5179329e-01  1.8399542e-02  4.3778053e-01\n",
            "  -4.9263728e-01  7.9981643e-01]\n",
            " [-2.8917280e-01  1.0043441e-01 -9.1151148e-02  3.6259271e-02\n",
            "   1.0675713e-01 -8.3618826e-01  2.0009780e-01  5.8339089e-01\n",
            "  -1.7491554e-01  6.0655284e-01]\n",
            " [-3.5978922e-01  9.1659956e-02  4.2240837e-01  1.1255670e-01\n",
            "  -6.4642429e-02 -1.3896195e+00  3.8931042e-01 -3.3630806e-01\n",
            "  -5.6914496e-01  9.9600965e-01]\n",
            " [-9.6181583e-01  2.2939461e-01  1.4909410e-01  1.6794282e-01\n",
            "   1.7030033e-01 -5.3991210e-01  3.4695931e-02  6.8805063e-01\n",
            "  -3.3433583e-01  4.4172931e-01]\n",
            " [-6.0645354e-01 -3.5795161e-01  4.7387433e-01  2.7014586e-01\n",
            "   2.5771543e-01 -9.0960979e-01  1.7429377e-01 -1.0441241e-01\n",
            "  -4.6397370e-01  8.1911325e-01]] [[ 2.8996303   0.02200214 -0.74852276  0.631462   -1.1275623   3.0894957\n",
            "   0.9280114  -0.14752409  4.0928345   2.411408  ]\n",
            " [ 0.5878507   3.011582    3.9065943   3.235908    0.50435984  0.34831482\n",
            "   0.17555894  2.1310635  -0.09421223  0.98545116]\n",
            " [ 0.6049058   2.2343197   2.6323042   2.430443    0.4869851   0.8571075\n",
            "   1.0000788   1.5101197   0.56835276  1.3811649 ]\n",
            " [ 1.430701    2.0099015   4.087019    3.0947237   0.56819826  0.75650877\n",
            "   0.33274144  1.465734   -0.30525357  0.9727164 ]\n",
            " [-0.3164355   1.5521222   3.0174787   1.4834703   2.2269187  -1.30088\n",
            "   1.1328936   3.5774622  -1.429762   -0.17385992]\n",
            " [ 3.4188118   0.62846535  0.07279523  0.71736014 -0.32747287  2.2898376\n",
            "   1.0576711   0.22138332  3.0749917   2.4532826 ]\n",
            " [ 1.9065028   0.88415587  1.2080953   0.14300826  0.593324    0.49050444\n",
            "   0.5708541   1.5033801   0.42657304  0.6549574 ]\n",
            " [ 2.1231966   0.84968215  1.4300145   1.3541062   1.0749373   1.852924\n",
            "   0.76707125  1.5934157   1.0071483   2.0823565 ]\n",
            " [ 3.2195091   0.0096926   0.56950235  0.23191671 -0.32239503  2.1220663\n",
            "   1.1799686   0.2573312   1.7817802   2.0053072 ]\n",
            " [ 3.912785    0.8497595   0.3867088   0.8289084   0.23973835  3.5320184\n",
            "   1.3169683   0.9062026   4.1586957   2.9207473 ]] [[-0.91819704 -0.73714244 -1.2835796  -1.3152801  -1.7907189  -2.3600693\n",
            "  -1.71575    -2.0585341  -0.88458973 -1.0391645 ]\n",
            " [ 0.76816994  2.8525796   0.98103195  1.0893993   1.291576   -0.3590138\n",
            "  -0.05392636  1.1377413  -1.1812421   0.5328254 ]\n",
            " [ 0.44077566  1.889281    1.394224    1.2403969   0.93400806 -0.6091448\n",
            "   0.37211862  1.1208864  -0.48069543  0.9152784 ]\n",
            " [-0.4079485   1.9117765   0.61145085  1.4986356   1.2874416  -0.2541298\n",
            "   0.17829615  0.8347929  -0.5898164   1.7898803 ]\n",
            " [ 0.5058691   1.6893194   0.8303908   0.35562584  1.9394354  -0.32631215\n",
            "  -0.15927449  1.2605628  -1.4803319   0.92400664]\n",
            " [ 0.47246826  1.049527    0.68996495  0.5756347   0.2827701   1.6729834\n",
            "   1.2482777   1.4437281   1.0102694   0.7912869 ]\n",
            " [ 1.2386009   1.133507    0.64457095  0.43742573  1.0146374  -0.527435\n",
            "   1.1386023   1.2811688  -0.267912   -0.3252511 ]\n",
            " [-0.6168757   0.9414549   0.6545312   0.44207764  1.0313237   0.28013933\n",
            "   0.6557309   1.4528047   0.10742482  2.0227776 ]\n",
            " [ 0.6610696   1.1441543   0.83005744  0.6699963   0.68824714  0.8841506\n",
            "   1.2305831   1.0789971   0.96978915  0.1847023 ]\n",
            " [ 0.48081017  0.5815153   0.65710616  0.34215644 -0.4203801  -1.0223608\n",
            "  -0.1397903   0.8336154   0.45186663 -0.02691434]] [[-0.4206367  -0.26431718 -0.8189321   0.5453431  -0.81877565  3.265758\n",
            "   1.123025   -0.45972508  3.0087957   4.069817  ]\n",
            " [ 1.711552    4.0104914   6.097168    4.062114    3.3517642   0.6797678\n",
            "   2.4742503   2.5503993   1.0404894   2.6415534 ]\n",
            " [ 1.6555488   2.8842583   3.6345613   2.4311733   2.4532597   1.8469099\n",
            "   1.1871887   2.1401596   2.593385    2.5239465 ]\n",
            " [ 2.897587    4.3002462   6.664719    2.8146844   4.007442    0.92588633\n",
            "   0.9355154   1.9416659   1.1508867   2.0899508 ]\n",
            " [ 1.4384526   4.5608745   3.7128031   3.3055158   2.5344577   0.3143406\n",
            "   2.7502472   3.773708    1.4212635   1.7340083 ]\n",
            " [-1.8715912   2.1050293   2.2834506   2.1121552   1.4853789   2.427682\n",
            "   3.0749145   1.8919368   3.9486756   4.785963  ]\n",
            " [ 0.63691103  1.810391    0.84790796  1.1583683   2.2992978   1.9338874\n",
            "   2.1868212   3.2546113   2.360936    3.5164182 ]\n",
            " [ 0.39985502  1.6061538   1.7325523   0.35841948  2.477663    1.037012\n",
            "   2.7054691   2.465773    1.360221    2.7568579 ]\n",
            " [-1.5197104   0.47858107  1.2087647   0.85278237  1.0399474   2.266237\n",
            "   3.0739172   2.0501065   2.4958704   4.687452  ]\n",
            " [ 3.000189   -0.7293791  -0.74419117  1.7917078   0.4763999   2.9361863\n",
            "   2.2864735   2.0922556   2.3336442   3.609223  ]] [[ 2.3518488  -2.4012413  -2.5848315  -2.5842254  -1.4390004  -1.3970611\n",
            "  -1.486853   -1.3146498  -1.5213429  -0.10409442]\n",
            " [-0.08029907  0.95492965  3.0861502   1.0803758   2.8016753   1.3075106\n",
            "   2.5004106   3.4115536   1.5283737   2.4000955 ]\n",
            " [-0.98470867  1.4555954   1.5423824   0.30919918  3.159526    1.3234267\n",
            "   2.0309644   3.8802829   0.77620506  2.2096994 ]\n",
            " [-1.3650285   1.9985721   3.1277943   0.9758086   3.153818    2.5558827\n",
            "   2.7993655   3.6075718   2.483896    3.5096714 ]\n",
            " [-0.53188324  2.7865634   2.933026    1.9947041   2.6538177   0.17108425\n",
            "   1.41041     3.5341537   0.09414454  2.1139412 ]\n",
            " [-0.05147918  2.960376    2.8401773   2.9880128   2.2146826   3.026591\n",
            "   2.6003537   2.4387147   3.1415412   3.8921413 ]\n",
            " [-0.9958864   2.6857972   2.583294    2.6029804   2.5345263   1.2893649\n",
            "   1.4581535   2.6380162   2.0204773   2.2150342 ]\n",
            " [ 0.04527869  2.9330308   3.2778075   2.720913    3.2038531   1.2107869\n",
            "   1.9810863   2.4970698   1.1165935   1.571423  ]\n",
            " [-0.23130603  2.2237506   2.6563025   2.6123178   2.1577914   2.2081223\n",
            "   2.521809    2.3261166   1.9723585   2.7725258 ]\n",
            " [ 0.2493442   3.188392    3.1076705   3.369534    2.6593766   3.4948716\n",
            "   2.873453    2.958899    3.7007978   5.390417  ]] [[ 1.8577769  -0.1782641  -0.8391258  -0.20157872  0.03677352  1.8336577\n",
            "  -0.5154236  -0.9360012  -0.36019903  2.0303364 ]\n",
            " [ 0.07594603  1.6416981   2.4703162   1.7014173   1.7434708   0.00997017\n",
            "   1.3008279   1.896263    1.5449183   1.616728  ]\n",
            " [ 0.6953787   2.1692429   2.1441464   1.7379965   2.1794832   0.00943146\n",
            "   1.3819319   2.406196    1.5149322   1.8323896 ]\n",
            " [ 1.5004507   2.191609    2.7665334   0.9322765   2.0782743  -0.32668146\n",
            "   1.5269834   2.6152775   1.2686868   2.566569  ]\n",
            " [-0.5223735   2.492464    1.484075    1.3629732   1.5521193  -0.75108665\n",
            "   1.1117117   2.8975577   1.2339579   0.7913337 ]\n",
            " [ 4.608461    2.6140327   1.6747181   1.5631702   1.1256423   2.156302\n",
            "   1.8067638   1.0583446   1.9421829   4.2106786 ]\n",
            " [ 2.443831    2.08211     1.7901441   1.5581807   2.1890495   1.9666604\n",
            "   1.4040198   2.1084352   1.0204064   2.4160697 ]\n",
            " [ 1.6170082   2.1157253   1.7847257   1.1339206   2.4702833   1.1112541\n",
            "   1.9466188   2.2814734   1.4104946   2.5419347 ]\n",
            " [ 2.5761323   1.8463246   1.4472572   1.2411208   1.1666892   1.2266266\n",
            "   2.137839    1.720331    1.3243217   2.4792182 ]\n",
            " [ 5.4560094   2.8533223   1.9060035   2.8041744   2.1872957   4.541738\n",
            "   2.3418133   2.6403146   3.3154905   5.353278  ]] [[-2.0872909e-01 -4.6765838e-02 -6.9208078e-02  2.2612049e-01\n",
            "  -5.2733558e-01 -3.8780876e-02 -3.5037673e-01 -2.4101785e-01\n",
            "  -3.8009610e-02 -4.4777170e-01]\n",
            " [ 3.9312774e-01 -7.2015625e-01 -1.1039566e-01 -4.7187504e-01\n",
            "  -6.2436187e-01 -5.5506319e-01 -6.3059740e-02  2.3725607e-01\n",
            "  -2.9921988e-01  6.7517275e-01]\n",
            " [ 9.3361211e-01 -3.0668795e-01 -1.2280265e+00 -2.3901877e-01\n",
            "   2.1531588e-01 -2.9213035e-02  1.8740971e-01  4.9287453e-01\n",
            "  -3.2362545e-01  5.3950977e-01]\n",
            " [ 4.4989973e-01 -7.8404926e-02 -7.0561624e-01 -6.7971748e-01\n",
            "  -3.2464612e-01 -2.4579277e-03  2.4341476e-01 -3.8152987e-01\n",
            "  -6.1979812e-01  6.9756246e-01]\n",
            " [ 7.5051486e-02 -3.4050646e-01 -2.0628366e-01 -3.5078533e-02\n",
            "  -2.1298897e+00 -4.6191064e-01  1.0249646e-01 -2.3292464e-01\n",
            "  -4.4878232e-01 -4.8854653e-02]\n",
            " [ 2.4236611e-01  2.4130446e-01 -1.3099633e-01  2.9947233e-01\n",
            "   2.8432137e-03  1.8978542e-01  3.0245671e-01  2.6455259e-02\n",
            "   3.2729067e-02  9.6456997e-02]\n",
            " [ 5.2392596e-01 -4.3888092e-01  6.0626990e-01 -1.6046394e-01\n",
            "  -4.5984539e-01 -4.0288302e-01 -3.4419575e-01 -3.1425059e-01\n",
            "  -3.3222637e-03 -1.9334584e-01]\n",
            " [-5.6612873e-01 -1.8855400e-01 -2.9994866e-02 -1.3156276e+00\n",
            "  -3.9713255e-01 -1.6519366e-01 -3.1032342e-01 -2.6127520e+00\n",
            "  -6.0051662e-01  4.2017855e-02]\n",
            " [ 2.3271590e-01  3.4710231e-01 -3.8753740e-02  6.4791903e-02\n",
            "  -1.9065240e-01  1.3848405e-01  6.7246199e-02 -8.6773224e-02\n",
            "   1.5828940e-01 -9.3004052e-03]\n",
            " [ 2.2022840e-01 -1.5427314e-01 -8.9312159e-02 -3.9955951e-02\n",
            "   1.0446525e-03 -2.8469656e-02 -6.6449180e-02 -6.2308647e-02\n",
            "   5.5042960e-02 -2.5045082e-01]] [[ 0.7274816   0.11507649  0.284214   -0.4026169  -0.22948742  0.5726925\n",
            "   0.7000268   0.13661313  2.2500303   2.2188106 ]\n",
            " [ 1.4019722   3.4689038   2.3157012   2.951157    1.1965826   1.1602786\n",
            "  -0.1770497   0.6572411   0.2278574   1.8796558 ]\n",
            " [ 1.2921461   0.8905095   3.709777    2.3455753   1.0153087   1.4283334\n",
            "   0.5606777   0.47134808  1.6395503   1.9080584 ]\n",
            " [ 1.8637079   3.003888    3.8354084   4.1362057   1.2275932   2.323182\n",
            "  -0.19235559  1.0532311   1.3310231   2.590262  ]\n",
            " [ 0.54005456  0.6143206   1.7547503   1.8359743   3.094353    0.6746429\n",
            "   0.2596902   1.5248697   0.47067168  1.3008693 ]\n",
            " [-0.9338605   0.5036669   0.87460697  0.45084783  0.901352   -0.10966269\n",
            "   1.9916923   1.3448064   2.0936713   0.80160993]\n",
            " [ 0.5728401  -0.04004947  0.45082232 -0.43184328  0.9820602   0.0408671\n",
            "   1.4810711   0.40630463  0.07374337  0.5373771 ]\n",
            " [ 2.0956993   0.6018912   0.6745899   0.5275235   1.8832694   0.7081071\n",
            "   1.0816227   3.1449246   0.19390348  2.3962045 ]\n",
            " [-0.3780636   0.18745206  1.7450609   0.46006605  0.8310921   0.57361317\n",
            "   2.0125527   1.6686664   1.5488706   1.1293051 ]\n",
            " [ 0.6197194   0.2847378   0.8111273   0.29930606  0.12218147  0.633571\n",
            "   1.7020148   1.1978279   2.0720472   1.3618188 ]] [[-0.7641907  -0.04179777 -0.03871024 -0.01029287  0.10982683 -3.409261\n",
            "  -0.8519444  -0.1011171  -0.61037153  1.11368   ]\n",
            " [ 0.6315195   1.5662173   1.0136852   0.79115003  0.5027024  -0.84586865\n",
            "  -0.60011023  1.0755258   0.36316153  1.5360875 ]\n",
            " [-0.19636366  1.3796113   0.9972024   0.42479315  0.7522633  -1.2828168\n",
            "  -0.24372143  0.53102773  0.60126495  1.431718  ]\n",
            " [-0.01733678  1.2261399   0.60732824 -0.3713482   1.0066447  -1.0930486\n",
            "  -0.34242573  1.2536769  -0.01925345  0.05428234]\n",
            " [-0.6089171   0.812452    0.73339826  0.27320436  1.0981218  -0.69458455\n",
            "   0.300511    1.9441388  -0.5859628   1.1883222 ]\n",
            " [-0.3862846   0.9120517   0.6206465   0.7143033   0.49330038 -1.0343239\n",
            "  -0.31964967  0.45504218  0.87512237  1.6519731 ]\n",
            " [-0.11572167  1.118077    1.1451776   0.45498532  0.7921902  -0.8244491\n",
            "   0.13255627  1.3740886   1.5412023   1.585442  ]\n",
            " [-0.42347932  0.7645048   1.1695968   0.8649328   1.0572455  -1.3920376\n",
            "   0.06315615  1.8586993   1.3764335   1.3430959 ]\n",
            " [-0.04602024  1.0310172   1.1641402   0.830472    0.55506825 -1.4279099\n",
            "  -0.305408    0.95073116  1.0027801   1.6112568 ]\n",
            " [-0.1204833   0.88820004  0.8350356   0.46982872  0.30827308 -1.1874206\n",
            "   0.06021432  0.6750055   0.5101989   1.052246  ]] [[ 3.5113144   0.23125732  0.14855024  0.31988123 -0.34488022  1.1630836\n",
            "  -0.23730999 -0.6694767   0.04084282  0.70824903]\n",
            " [ 1.7904973   2.2246804   2.806927    2.5454693   2.600652    2.0405247\n",
            "   2.0883412   2.6324604   1.0418186   2.819541  ]\n",
            " [ 2.5830665   2.5436692   2.6789215   2.552863    1.8923868   2.387744\n",
            "   2.497571    1.4598      1.4553257   3.0531595 ]\n",
            " [ 2.0304976   3.0259213   3.0475783   2.566625    2.3083878   2.8534472\n",
            "   2.431889    3.5424695   1.5133282   3.2522182 ]\n",
            " [ 0.85365546  2.1300118   2.9776423   2.764315    1.9021384   2.261848\n",
            "   0.78977865  2.7873087   1.51449     3.4065237 ]\n",
            " [ 4.7410984   2.2832878   2.5947425   2.7378526   1.9672732   3.6375775\n",
            "   2.2509813   3.3431032   1.4767879   2.352169  ]\n",
            " [ 1.3938805   2.63342     2.7286584   1.8677042   2.9486048   1.323737\n",
            "   0.75743663  3.4104338   1.7034984   2.298728  ]\n",
            " [ 1.5281339   3.5719974   3.1684306   2.4641638   3.45946     2.1354446\n",
            "   2.2208533   3.3282526   1.6605146   4.188968  ]\n",
            " [ 3.7193854   2.3510675   2.3213775   2.3511674   2.4487157   3.718595\n",
            "   2.4170146   3.097043    1.2444317   2.0928166 ]\n",
            " [ 5.245867    2.9236443   2.6110198   2.8997252   2.7353942   4.847442\n",
            "   2.6822622   3.372125    2.8552227   3.146039  ]] [[ 1.7404832   0.20622298  0.17036484  0.14028859 -0.0875273  -0.28903437\n",
            "  -0.05346468 -0.21828583  0.24408357  2.5945306 ]\n",
            " [ 2.5038111   3.8067138  -0.9152964  -1.0867347  -0.66055036 -0.3236773\n",
            "  -0.31045496 -1.4174232   0.43165812  1.9661093 ]\n",
            " [ 2.3395207  -1.5124058   1.7736304  -0.67819226 -1.0566123   0.19052632\n",
            "  -0.78984517 -1.3535223   0.9409393   0.73563135]\n",
            " [ 1.2547673   0.34710675 -0.44897196  2.7757225  -0.33859655 -0.15644921\n",
            "  -0.6115687  -0.48662195  0.41058114  0.87479126]\n",
            " [ 0.6738987   0.4476631  -1.602245   -0.6992324   3.0947883  -0.30546984\n",
            "  -0.6876085  -0.13776019  0.14923412  0.28215185]\n",
            " [ 1.546602   -0.46327224 -1.2862829  -1.491924   -1.288245   -1.6702429\n",
            "  -0.73712903 -1.5902119  -0.9095844   1.7985494 ]\n",
            " [ 1.4186683   0.2906626  -0.9079117  -1.503863   -0.35724834 -0.79060125\n",
            "   1.2171147  -1.3592548  -0.53071135  0.48501337]\n",
            " [ 1.5222133  -0.8623995  -0.37342417 -0.85203713 -1.0658941  -0.4834577\n",
            "   0.21761012  3.1788638   0.40442356  0.29755515]\n",
            " [ 1.7944585   0.43165296 -0.3501598  -0.7924533   0.07014562 -0.5650798\n",
            "  -0.51980543 -1.6325725  -1.2602837   0.9605556 ]\n",
            " [ 1.9798651  -0.5624908  -0.7449863  -1.232003   -0.63779896 -0.6748462\n",
            "  -0.8677051  -0.9195779  -0.8235787   0.9559839 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 각 최소 단위(10x10 행렬의 10개 값) 내림차순 정렬\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 최소 단위(10개) 값을 내림차순으로 정렬\n",
        "            sorted_attention_scores[i, j, k] = np.sort(attention_scores[i, j, k])[::-1]\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gTTz4HV13uLB",
        "outputId": "c3ed3f37-b54c-4005-a82a-18738bb4b24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEeT1XRCxsN",
        "outputId": "34985c77-579d-4c7d-f60d-a0e05ec2fb5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/softmax_bert_layer1.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rL1fG-obHzeW",
        "outputId": "4d20c490-6bd7-40c1-8871-5944473b9b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_SM_bert.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/sorted_attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "-vdLamvD6Vcc",
        "outputId": "ebb7c8f2-0e95-4d80-fab9-5fec8ed982d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.50276214 0.18352194 0.07385454 ... 0.02399363 0.01801627\n",
            "    0.00693945]\n",
            "   [0.28548524 0.15781423 0.12932299 ... 0.0462996  0.03935906\n",
            "    0.03413377]\n",
            "   [0.42965856 0.23049009 0.119009   ... 0.03273839 0.02393627\n",
            "    0.01153364]\n",
            "   ...\n",
            "   [0.3043518  0.23911789 0.14382176 ... 0.02023179 0.00734722\n",
            "    0.00598513]\n",
            "   [0.42806664 0.27252406 0.0660226  ... 0.03525357 0.02467276\n",
            "    0.0087873 ]\n",
            "   [0.35068387 0.13904521 0.13328184 ... 0.01395757 0.00985229\n",
            "    0.00765489]]\n",
            "\n",
            "  [[0.2325552  0.13501358 0.11216996 ... 0.06796568 0.04669739\n",
            "    0.01961427]\n",
            "   [0.3069954  0.1544281  0.12369999 ... 0.0540519  0.03094326\n",
            "    0.01976733]\n",
            "   [0.3473453  0.17405728 0.11080742 ... 0.02729124 0.0272199\n",
            "    0.01510452]\n",
            "   ...\n",
            "   [0.34108797 0.14767179 0.09490318 ... 0.05895856 0.02201105\n",
            "    0.01425752]\n",
            "   [0.16335478 0.15715772 0.1307724  ... 0.07702713 0.06241015\n",
            "    0.02915837]\n",
            "   [0.21095937 0.16749963 0.14411137 ... 0.04625707 0.04081224\n",
            "    0.03196875]]\n",
            "\n",
            "  [[0.20825657 0.19249158 0.18383561 ... 0.02142655 0.01533512\n",
            "    0.00476936]\n",
            "   [0.24235135 0.18242025 0.17155178 ... 0.03665771 0.03388991\n",
            "    0.03156955]\n",
            "   [0.18842699 0.1846192  0.15932496 ... 0.0527045  0.05176065\n",
            "    0.04646761]\n",
            "   ...\n",
            "   [0.25251973 0.16754884 0.15158708 ... 0.03404357 0.03329607\n",
            "    0.02462847]\n",
            "   [0.2571161  0.21102408 0.18693537 ... 0.02713428 0.02467851\n",
            "    0.02251801]\n",
            "   [0.41005656 0.19873372 0.1137526  ... 0.02479132 0.01154065\n",
            "    0.00977826]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2592011  0.15715222 0.12888864 ... 0.05018471 0.01325505\n",
            "    0.0045917 ]\n",
            "   [0.33733252 0.17494407 0.15267216 ... 0.02646148 0.01087068\n",
            "    0.00389986]\n",
            "   [0.3181143  0.13679282 0.12702297 ... 0.02282469 0.02214158\n",
            "    0.01064354]\n",
            "   ...\n",
            "   [0.26751333 0.18797602 0.13342448 ... 0.04374462 0.0292747\n",
            "    0.00853144]\n",
            "   [0.18074659 0.15957834 0.15265188 ... 0.05979285 0.03502361\n",
            "    0.01639437]\n",
            "   [0.20700881 0.16873328 0.13372055 ... 0.06887838 0.02255044\n",
            "    0.00934925]]\n",
            "\n",
            "  [[0.37489742 0.2901547  0.11512411 ... 0.02215154 0.01872855\n",
            "    0.00941682]\n",
            "   [0.18999724 0.13898917 0.12236455 ... 0.07654192 0.06884889\n",
            "    0.0477233 ]\n",
            "   [0.27175546 0.12120829 0.1138563  ... 0.0570039  0.05632794\n",
            "    0.05246266]\n",
            "   ...\n",
            "   [0.20520656 0.13339986 0.12312736 ... 0.05491564 0.05075939\n",
            "    0.03485935]\n",
            "   [0.19427177 0.18163337 0.17536202 ... 0.03484033 0.02603423\n",
            "    0.0250867 ]\n",
            "   [0.2918996  0.27665862 0.26320818 ... 0.02027144 0.01506835\n",
            "    0.01499027]]\n",
            "\n",
            "  [[0.43601793 0.18579273 0.07530626 ... 0.03807148 0.03671275\n",
            "    0.03654618]\n",
            "   [0.29635048 0.23618098 0.07779395 ... 0.05147965 0.04919232\n",
            "    0.04249952]\n",
            "   [0.39474365 0.36150783 0.1024332  ... 0.01188225 0.00715878\n",
            "    0.00597612]\n",
            "   ...\n",
            "   [0.34529865 0.27073318 0.1501966  ... 0.03340842 0.02463462\n",
            "    0.01474646]\n",
            "   [0.2451356  0.24132645 0.16123603 ... 0.02899556 0.02688335\n",
            "    0.02529364]\n",
            "   [0.51953447 0.18517023 0.07776037 ... 0.02618033 0.01927708\n",
            "    0.01510626]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "3IpQeei26iui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = \"/./content/model/sorted_attention_scores_2.txt\"  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "dhImdkUJ62U5",
        "outputId": "dcc9a8e2-3659-477e-fc1a-dc245a6b6edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    2.1947367   2.0617602   1.4053444   0.6307755   0.5856975\n",
            "   0.49772462  0.11714409 -0.14835791 -0.30920362]\n",
            " [ 5.793112    4.621073    3.812749    3.3466518   2.3886065   2.3419719\n",
            "   1.9099072   1.8878778   1.6703308   1.5484276 ]\n",
            " [ 5.2124023   4.502995    3.8073637   3.3168168   3.0351076   2.6028967\n",
            "   2.4797425   2.3082643   1.6874914   1.5656495 ]\n",
            " [ 6.7969666   5.3321524   4.652975    3.8015726   3.108758    2.719986\n",
            "   2.659658    2.5718498   2.416732    2.1785326 ]\n",
            " [ 5.064213    4.6419153   3.4980125   3.339889    3.3077164   2.7762215\n",
            "   2.5917144   2.023627    1.873533    0.62522817]\n",
            " [ 4.3125715   4.3036885   3.9795005   3.511932    3.220555    3.0432897\n",
            "   2.9215946   2.8711824   2.6142015   2.2757936 ]\n",
            " [ 4.5505824   4.1721644   3.331105    3.1753776   2.6852992   2.6400094\n",
            "   2.4741642   1.7959094   1.6750463   1.3191165 ]\n",
            " [ 4.537689    4.2240024   3.9101954   3.422982    3.3852067   2.9609547\n",
            "   2.1071794   2.1017816   1.7666457   1.6387088 ]\n",
            " [ 5.7495446   4.3632503   3.822887    3.529175    3.3072975   2.9970148\n",
            "   2.365435    2.2333503   1.2618201   1.1282016 ]\n",
            " [ 6.618206    5.7463045   5.1483626   4.5703983   4.4660215   3.426703\n",
            "   3.174025    3.1162205   2.4864216   2.1799157 ]] [[ 0.9627847   0.311149    0.02555725 -0.04857237 -0.07704417 -0.1185468\n",
            "  -0.46038562 -0.6803706  -1.0886638  -1.6976843 ]\n",
            " [ 0.97234195  0.7301598   0.43518707  0.06117958 -0.22009215 -0.5790163\n",
            "  -0.6899191  -0.7375137  -1.1784676  -1.7430696 ]\n",
            " [ 1.1253307   0.21543759 -0.0585902  -0.20672473 -0.34776625 -0.43296996\n",
            "  -0.5565975  -0.61825126 -1.1309534  -1.3146526 ]\n",
            " [ 1.2667636   0.45576128  0.14773999  0.03673334  0.01682144  0.00024927\n",
            "  -0.25012723 -0.25380707 -0.3354175  -0.5908074 ]\n",
            " [ 0.7070519   0.6523646   0.59022087  0.32314226  0.09670944 -0.03702255\n",
            "  -0.25472367 -1.2064693  -1.5367095  -1.7260594 ]\n",
            " [ 0.7998164   0.43778053  0.38227442  0.37704596  0.2848917   0.15285142\n",
            "   0.01839954 -0.49263728 -0.8517933  -1.209122  ]\n",
            " [ 0.60655284  0.5833909   0.2000978   0.10675713  0.10043441  0.03625927\n",
            "  -0.09115115 -0.17491554 -0.2891728  -0.83618826]\n",
            " [ 0.99600965  0.42240837  0.38931042  0.1125567   0.09165996 -0.06464243\n",
            "  -0.33630806 -0.35978922 -0.56914496 -1.3896195 ]\n",
            " [ 0.6880506   0.4417293   0.22939461  0.17030033  0.16794282  0.1490941\n",
            "   0.03469593 -0.33433583 -0.5399121  -0.96181583]\n",
            " [ 0.81911325  0.47387433  0.27014586  0.25771543  0.17429377 -0.10441241\n",
            "  -0.3579516  -0.4639737  -0.60645354 -0.9096098 ]] [[ 4.0928345   3.0894957   2.8996303   2.411408    0.9280114   0.631462\n",
            "   0.02200214 -0.14752409 -0.74852276 -1.1275623 ]\n",
            " [ 3.9065943   3.235908    3.011582    2.1310635   0.98545116  0.5878507\n",
            "   0.50435984  0.34831482  0.17555894 -0.09421223]\n",
            " [ 2.6323042   2.430443    2.2343197   1.5101197   1.3811649   1.0000788\n",
            "   0.8571075   0.6049058   0.56835276  0.4869851 ]\n",
            " [ 4.087019    3.0947237   2.0099015   1.465734    1.430701    0.9727164\n",
            "   0.75650877  0.56819826  0.33274144 -0.30525357]\n",
            " [ 3.5774622   3.0174787   2.2269187   1.5521222   1.4834703   1.1328936\n",
            "  -0.17385992 -0.3164355  -1.30088    -1.429762  ]\n",
            " [ 3.4188118   3.0749917   2.4532826   2.2898376   1.0576711   0.71736014\n",
            "   0.62846535  0.22138332  0.07279523 -0.32747287]\n",
            " [ 1.9065028   1.5033801   1.2080953   0.88415587  0.6549574   0.593324\n",
            "   0.5708541   0.49050444  0.42657304  0.14300826]\n",
            " [ 2.1231966   2.0823565   1.852924    1.5934157   1.4300145   1.3541062\n",
            "   1.0749373   1.0071483   0.84968215  0.76707125]\n",
            " [ 3.2195091   2.1220663   2.0053072   1.7817802   1.1799686   0.56950235\n",
            "   0.2573312   0.23191671  0.0096926  -0.32239503]\n",
            " [ 4.1586957   3.912785    3.5320184   2.9207473   1.3169683   0.9062026\n",
            "   0.8497595   0.8289084   0.3867088   0.23973835]] [[-0.73714244 -0.88458973 -0.91819704 -1.0391645  -1.2835796  -1.3152801\n",
            "  -1.71575    -1.7907189  -2.0585341  -2.3600693 ]\n",
            " [ 2.8525796   1.291576    1.1377413   1.0893993   0.98103195  0.76816994\n",
            "   0.5328254  -0.05392636 -0.3590138  -1.1812421 ]\n",
            " [ 1.889281    1.394224    1.2403969   1.1208864   0.93400806  0.9152784\n",
            "   0.44077566  0.37211862 -0.48069543 -0.6091448 ]\n",
            " [ 1.9117765   1.7898803   1.4986356   1.2874416   0.8347929   0.61145085\n",
            "   0.17829615 -0.2541298  -0.4079485  -0.5898164 ]\n",
            " [ 1.9394354   1.6893194   1.2605628   0.92400664  0.8303908   0.5058691\n",
            "   0.35562584 -0.15927449 -0.32631215 -1.4803319 ]\n",
            " [ 1.6729834   1.4437281   1.2482777   1.049527    1.0102694   0.7912869\n",
            "   0.68996495  0.5756347   0.47246826  0.2827701 ]\n",
            " [ 1.2811688   1.2386009   1.1386023   1.133507    1.0146374   0.64457095\n",
            "   0.43742573 -0.267912   -0.3252511  -0.527435  ]\n",
            " [ 2.0227776   1.4528047   1.0313237   0.9414549   0.6557309   0.6545312\n",
            "   0.44207764  0.28013933  0.10742482 -0.6168757 ]\n",
            " [ 1.2305831   1.1441543   1.0789971   0.96978915  0.8841506   0.83005744\n",
            "   0.68824714  0.6699963   0.6610696   0.1847023 ]\n",
            " [ 0.8336154   0.65710616  0.5815153   0.48081017  0.45186663  0.34215644\n",
            "  -0.02691434 -0.1397903  -0.4203801  -1.0223608 ]] [[ 4.069817    3.265758    3.0087957   1.123025    0.5453431  -0.26431718\n",
            "  -0.4206367  -0.45972508 -0.81877565 -0.8189321 ]\n",
            " [ 6.097168    4.062114    4.0104914   3.3517642   2.6415534   2.5503993\n",
            "   2.4742503   1.711552    1.0404894   0.6797678 ]\n",
            " [ 3.6345613   2.8842583   2.593385    2.5239465   2.4532597   2.4311733\n",
            "   2.1401596   1.8469099   1.6555488   1.1871887 ]\n",
            " [ 6.664719    4.3002462   4.007442    2.897587    2.8146844   2.0899508\n",
            "   1.9416659   1.1508867   0.9355154   0.92588633]\n",
            " [ 4.5608745   3.773708    3.7128031   3.3055158   2.7502472   2.5344577\n",
            "   1.7340083   1.4384526   1.4212635   0.3143406 ]\n",
            " [ 4.785963    3.9486756   3.0749145   2.427682    2.2834506   2.1121552\n",
            "   2.1050293   1.8919368   1.4853789  -1.8715912 ]\n",
            " [ 3.5164182   3.2546113   2.360936    2.2992978   2.1868212   1.9338874\n",
            "   1.810391    1.1583683   0.84790796  0.63691103]\n",
            " [ 2.7568579   2.7054691   2.477663    2.465773    1.7325523   1.6061538\n",
            "   1.360221    1.037012    0.39985502  0.35841948]\n",
            " [ 4.687452    3.0739172   2.4958704   2.266237    2.0501065   1.2087647\n",
            "   1.0399474   0.85278237  0.47858107 -1.5197104 ]\n",
            " [ 3.609223    3.000189    2.9361863   2.3336442   2.2864735   2.0922556\n",
            "   1.7917078   0.4763999  -0.7293791  -0.74419117]] [[ 2.3518488  -0.10409442 -1.3146498  -1.3970611  -1.4390004  -1.486853\n",
            "  -1.5213429  -2.4012413  -2.5842254  -2.5848315 ]\n",
            " [ 3.4115536   3.0861502   2.8016753   2.5004106   2.4000955   1.5283737\n",
            "   1.3075106   1.0803758   0.95492965 -0.08029907]\n",
            " [ 3.8802829   3.159526    2.2096994   2.0309644   1.5423824   1.4555954\n",
            "   1.3234267   0.77620506  0.30919918 -0.98470867]\n",
            " [ 3.6075718   3.5096714   3.153818    3.1277943   2.7993655   2.5558827\n",
            "   2.483896    1.9985721   0.9758086  -1.3650285 ]\n",
            " [ 3.5341537   2.933026    2.7865634   2.6538177   2.1139412   1.9947041\n",
            "   1.41041     0.17108425  0.09414454 -0.53188324]\n",
            " [ 3.8921413   3.1415412   3.026591    2.9880128   2.960376    2.8401773\n",
            "   2.6003537   2.4387147   2.2146826  -0.05147918]\n",
            " [ 2.6857972   2.6380162   2.6029804   2.583294    2.5345263   2.2150342\n",
            "   2.0204773   1.4581535   1.2893649  -0.9958864 ]\n",
            " [ 3.2778075   3.2038531   2.9330308   2.720913    2.4970698   1.9810863\n",
            "   1.571423    1.2107869   1.1165935   0.04527869]\n",
            " [ 2.7725258   2.6563025   2.6123178   2.521809    2.3261166   2.2237506\n",
            "   2.2081223   2.1577914   1.9723585  -0.23130603]\n",
            " [ 5.390417    3.7007978   3.4948716   3.369534    3.188392    3.1076705\n",
            "   2.958899    2.873453    2.6593766   0.2493442 ]] [[ 2.0303364   1.8577769   1.8336577   0.03677352 -0.1782641  -0.20157872\n",
            "  -0.36019903 -0.5154236  -0.8391258  -0.9360012 ]\n",
            " [ 2.4703162   1.896263    1.7434708   1.7014173   1.6416981   1.616728\n",
            "   1.5449183   1.3008279   0.07594603  0.00997017]\n",
            " [ 2.406196    2.1794832   2.1692429   2.1441464   1.8323896   1.7379965\n",
            "   1.5149322   1.3819319   0.6953787   0.00943146]\n",
            " [ 2.7665334   2.6152775   2.566569    2.191609    2.0782743   1.5269834\n",
            "   1.5004507   1.2686868   0.9322765  -0.32668146]\n",
            " [ 2.8975577   2.492464    1.5521193   1.484075    1.3629732   1.2339579\n",
            "   1.1117117   0.7913337  -0.5223735  -0.75108665]\n",
            " [ 4.608461    4.2106786   2.6140327   2.156302    1.9421829   1.8067638\n",
            "   1.6747181   1.5631702   1.1256423   1.0583446 ]\n",
            " [ 2.443831    2.4160697   2.1890495   2.1084352   2.08211     1.9666604\n",
            "   1.7901441   1.5581807   1.4040198   1.0204064 ]\n",
            " [ 2.5419347   2.4702833   2.2814734   2.1157253   1.9466188   1.7847257\n",
            "   1.6170082   1.4104946   1.1339206   1.1112541 ]\n",
            " [ 2.5761323   2.4792182   2.137839    1.8463246   1.720331    1.4472572\n",
            "   1.3243217   1.2411208   1.2266266   1.1666892 ]\n",
            " [ 5.4560094   5.353278    4.541738    3.3154905   2.8533223   2.8041744\n",
            "   2.6403146   2.3418133   2.1872957   1.9060035 ]] [[ 0.22612049 -0.03800961 -0.03878088 -0.04676584 -0.06920808 -0.20872909\n",
            "  -0.24101785 -0.35037673 -0.4477717  -0.5273356 ]\n",
            " [ 0.67517275  0.39312774  0.23725607 -0.06305974 -0.11039566 -0.29921988\n",
            "  -0.47187504 -0.5550632  -0.6243619  -0.72015625]\n",
            " [ 0.9336121   0.5395098   0.49287453  0.21531588  0.18740971 -0.02921304\n",
            "  -0.23901877 -0.30668795 -0.32362545 -1.2280265 ]\n",
            " [ 0.69756246  0.44989973  0.24341476 -0.00245793 -0.07840493 -0.32464612\n",
            "  -0.38152987 -0.6197981  -0.6797175  -0.70561624]\n",
            " [ 0.10249646  0.07505149 -0.03507853 -0.04885465 -0.20628366 -0.23292464\n",
            "  -0.34050646 -0.44878232 -0.46191064 -2.1298897 ]\n",
            " [ 0.3024567   0.29947233  0.2423661   0.24130446  0.18978542  0.096457\n",
            "   0.03272907  0.02645526  0.00284321 -0.13099633]\n",
            " [ 0.6062699   0.52392596 -0.00332226 -0.16046394 -0.19334584 -0.3142506\n",
            "  -0.34419575 -0.40288302 -0.43888092 -0.4598454 ]\n",
            " [ 0.04201785 -0.02999487 -0.16519366 -0.188554   -0.31032342 -0.39713255\n",
            "  -0.56612873 -0.6005166  -1.3156276  -2.612752  ]\n",
            " [ 0.3471023   0.2327159   0.1582894   0.13848405  0.0672462   0.0647919\n",
            "  -0.00930041 -0.03875374 -0.08677322 -0.1906524 ]\n",
            " [ 0.2202284   0.05504296  0.00104465 -0.02846966 -0.03995595 -0.06230865\n",
            "  -0.06644918 -0.08931216 -0.15427314 -0.25045082]] [[ 2.2500303   2.2188106   0.7274816   0.7000268   0.5726925   0.284214\n",
            "   0.13661313  0.11507649 -0.22948742 -0.4026169 ]\n",
            " [ 3.4689038   2.951157    2.3157012   1.8796558   1.4019722   1.1965826\n",
            "   1.1602786   0.6572411   0.2278574  -0.1770497 ]\n",
            " [ 3.709777    2.3455753   1.9080584   1.6395503   1.4283334   1.2921461\n",
            "   1.0153087   0.8905095   0.5606777   0.47134808]\n",
            " [ 4.1362057   3.8354084   3.003888    2.590262    2.323182    1.8637079\n",
            "   1.3310231   1.2275932   1.0532311  -0.19235559]\n",
            " [ 3.094353    1.8359743   1.7547503   1.5248697   1.3008693   0.6746429\n",
            "   0.6143206   0.54005456  0.47067168  0.2596902 ]\n",
            " [ 2.0936713   1.9916923   1.3448064   0.901352    0.87460697  0.80160993\n",
            "   0.5036669   0.45084783 -0.10966269 -0.9338605 ]\n",
            " [ 1.4810711   0.9820602   0.5728401   0.5373771   0.45082232  0.40630463\n",
            "   0.07374337  0.0408671  -0.04004947 -0.43184328]\n",
            " [ 3.1449246   2.3962045   2.0956993   1.8832694   1.0816227   0.7081071\n",
            "   0.6745899   0.6018912   0.5275235   0.19390348]\n",
            " [ 2.0125527   1.7450609   1.6686664   1.5488706   1.1293051   0.8310921\n",
            "   0.57361317  0.46006605  0.18745206 -0.3780636 ]\n",
            " [ 2.0720472   1.7020148   1.3618188   1.1978279   0.8111273   0.633571\n",
            "   0.6197194   0.29930606  0.2847378   0.12218147]] [[ 1.11368     0.10982683 -0.01029287 -0.03871024 -0.04179777 -0.1011171\n",
            "  -0.61037153 -0.7641907  -0.8519444  -3.409261  ]\n",
            " [ 1.5662173   1.5360875   1.0755258   1.0136852   0.79115003  0.6315195\n",
            "   0.5027024   0.36316153 -0.60011023 -0.84586865]\n",
            " [ 1.431718    1.3796113   0.9972024   0.7522633   0.60126495  0.53102773\n",
            "   0.42479315 -0.19636366 -0.24372143 -1.2828168 ]\n",
            " [ 1.2536769   1.2261399   1.0066447   0.60732824  0.05428234 -0.01733678\n",
            "  -0.01925345 -0.34242573 -0.3713482  -1.0930486 ]\n",
            " [ 1.9441388   1.1883222   1.0981218   0.812452    0.73339826  0.300511\n",
            "   0.27320436 -0.5859628  -0.6089171  -0.69458455]\n",
            " [ 1.6519731   0.9120517   0.87512237  0.7143033   0.6206465   0.49330038\n",
            "   0.45504218 -0.31964967 -0.3862846  -1.0343239 ]\n",
            " [ 1.585442    1.5412023   1.3740886   1.1451776   1.118077    0.7921902\n",
            "   0.45498532  0.13255627 -0.11572167 -0.8244491 ]\n",
            " [ 1.8586993   1.3764335   1.3430959   1.1695968   1.0572455   0.8649328\n",
            "   0.7645048   0.06315615 -0.42347932 -1.3920376 ]\n",
            " [ 1.6112568   1.1641402   1.0310172   1.0027801   0.95073116  0.830472\n",
            "   0.55506825 -0.04602024 -0.305408   -1.4279099 ]\n",
            " [ 1.052246    0.88820004  0.8350356   0.6750055   0.5101989   0.46982872\n",
            "   0.30827308  0.06021432 -0.1204833  -1.1874206 ]] [[ 3.5113144   1.1630836   0.70824903  0.31988123  0.23125732  0.14855024\n",
            "   0.04084282 -0.23730999 -0.34488022 -0.6694767 ]\n",
            " [ 2.819541    2.806927    2.6324604   2.600652    2.5454693   2.2246804\n",
            "   2.0883412   2.0405247   1.7904973   1.0418186 ]\n",
            " [ 3.0531595   2.6789215   2.5830665   2.552863    2.5436692   2.497571\n",
            "   2.387744    1.8923868   1.4598      1.4553257 ]\n",
            " [ 3.5424695   3.2522182   3.0475783   3.0259213   2.8534472   2.566625\n",
            "   2.431889    2.3083878   2.0304976   1.5133282 ]\n",
            " [ 3.4065237   2.9776423   2.7873087   2.764315    2.261848    2.1300118\n",
            "   1.9021384   1.51449     0.85365546  0.78977865]\n",
            " [ 4.7410984   3.6375775   3.3431032   2.7378526   2.5947425   2.352169\n",
            "   2.2832878   2.2509813   1.9672732   1.4767879 ]\n",
            " [ 3.4104338   2.9486048   2.7286584   2.63342     2.298728    1.8677042\n",
            "   1.7034984   1.3938805   1.323737    0.75743663]\n",
            " [ 4.188968    3.5719974   3.45946     3.3282526   3.1684306   2.4641638\n",
            "   2.2208533   2.1354446   1.6605146   1.5281339 ]\n",
            " [ 3.7193854   3.718595    3.097043    2.4487157   2.4170146   2.3511674\n",
            "   2.3510675   2.3213775   2.0928166   1.2444317 ]\n",
            " [ 5.245867    4.847442    3.372125    3.146039    2.9236443   2.8997252\n",
            "   2.8552227   2.7353942   2.6822622   2.6110198 ]] [[ 2.5945306   1.7404832   0.24408357  0.20622298  0.17036484  0.14028859\n",
            "  -0.05346468 -0.0875273  -0.21828583 -0.28903437]\n",
            " [ 3.8067138   2.5038111   1.9661093   0.43165812 -0.31045496 -0.3236773\n",
            "  -0.66055036 -0.9152964  -1.0867347  -1.4174232 ]\n",
            " [ 2.3395207   1.7736304   0.9409393   0.73563135  0.19052632 -0.67819226\n",
            "  -0.78984517 -1.0566123  -1.3535223  -1.5124058 ]\n",
            " [ 2.7757225   1.2547673   0.87479126  0.41058114  0.34710675 -0.15644921\n",
            "  -0.33859655 -0.44897196 -0.48662195 -0.6115687 ]\n",
            " [ 3.0947883   0.6738987   0.4476631   0.28215185  0.14923412 -0.13776019\n",
            "  -0.30546984 -0.6876085  -0.6992324  -1.602245  ]\n",
            " [ 1.7985494   1.546602   -0.46327224 -0.73712903 -0.9095844  -1.2862829\n",
            "  -1.288245   -1.491924   -1.5902119  -1.6702429 ]\n",
            " [ 1.4186683   1.2171147   0.48501337  0.2906626  -0.35724834 -0.53071135\n",
            "  -0.79060125 -0.9079117  -1.3592548  -1.503863  ]\n",
            " [ 3.1788638   1.5222133   0.40442356  0.29755515  0.21761012 -0.37342417\n",
            "  -0.4834577  -0.85203713 -0.8623995  -1.0658941 ]\n",
            " [ 1.7944585   0.9605556   0.43165296  0.07014562 -0.3501598  -0.51980543\n",
            "  -0.5650798  -0.7924533  -1.2602837  -1.6325725 ]\n",
            " [ 1.9798651   0.9559839  -0.5624908  -0.63779896 -0.6748462  -0.7449863\n",
            "  -0.8235787  -0.8677051  -0.9195779  -1.232003  ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path = \"./model/softmax_attention_scores.pkl\"\n",
        "with open(softmax_file_path, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax attention_scores가 {softmax_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "WUVvB7pr7RBf",
        "outputId": "b5f65e1b-76b3-429b-cd41-c8f2f15e29a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792055 0.09109741 0.09164357 ... 0.09258842 0.09229336\n",
            "    0.09513694]\n",
            "   [0.12004586 0.10268968 0.10120098 ... 0.09385469 0.09336554\n",
            "    0.09450836]\n",
            "   [0.09188308 0.11296417 0.10104739 ... 0.09287033 0.09284727\n",
            "    0.09269542]\n",
            "   ...\n",
            "   [0.09724706 0.09072162 0.09059814 ... 0.09612775 0.12209511\n",
            "    0.1143846 ]\n",
            "   [0.09323013 0.09044815 0.09189644 ... 0.11774409 0.09348241\n",
            "    0.13755944]\n",
            "   [0.10347308 0.09130668 0.09073301 ... 0.10249271 0.0964129\n",
            "    0.10287845]]\n",
            "\n",
            "  [[0.09785708 0.1010711  0.09990909 ... 0.1006773  0.09957507\n",
            "    0.11400125]\n",
            "   [0.09519613 0.09198768 0.10206269 ... 0.09563526 0.09920019\n",
            "    0.12259457]\n",
            "   [0.0963392  0.09690202 0.09143765 ... 0.10719077 0.10062093\n",
            "    0.12747219]\n",
            "   ...\n",
            "   [0.09908457 0.09758333 0.09906299 ... 0.0961072  0.0978529\n",
            "    0.12674263]\n",
            "   [0.09308667 0.10304288 0.09866013 ... 0.10144265 0.09808288\n",
            "    0.10579788]\n",
            "   [0.09461471 0.1043413  0.0984853  ... 0.10681042 0.09746661\n",
            "    0.11155472]]\n",
            "\n",
            "  [[0.10933199 0.09290536 0.09061925 ... 0.09214136 0.09332465\n",
            "    0.10667202]\n",
            "   [0.10829917 0.10341936 0.09385677 ... 0.09627965 0.09360978\n",
            "    0.10712849]\n",
            "   [0.10907564 0.09717342 0.0946402  ... 0.09514245 0.09607369\n",
            "    0.1086611 ]\n",
            "   ...\n",
            "   [0.10199555 0.10672598 0.09804323 ... 0.11619101 0.09668372\n",
            "    0.10503597]\n",
            "   [0.0949479  0.11661825 0.09678788 ... 0.09768786 0.09655614\n",
            "    0.10871448]\n",
            "   [0.1353592  0.0939795  0.09070874 ... 0.09208083 0.09304921\n",
            "    0.10064787]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09984183 0.10561763 0.10010299 ... 0.09757758 0.1026743\n",
            "    0.11696494]\n",
            "   [0.10077073 0.1048938  0.1072562  ... 0.09442478 0.09245645\n",
            "    0.1261673 ]\n",
            "   [0.09222058 0.10335313 0.12389978 ... 0.09829431 0.10070038\n",
            "    0.1023483 ]\n",
            "   ...\n",
            "   [0.09290123 0.09680557 0.11789276 ... 0.10309868 0.09550235\n",
            "    0.1088791 ]\n",
            "   [0.09593145 0.10086945 0.10162396 ... 0.10526626 0.09792026\n",
            "    0.10599791]\n",
            "   [0.09677328 0.09897416 0.11110785 ... 0.10325618 0.0989797\n",
            "    0.10693549]]\n",
            "\n",
            "  [[0.13062458 0.09245858 0.0914835  ... 0.09063558 0.09179717\n",
            "    0.09474251]\n",
            "   [0.09483223 0.09760492 0.10083348 ... 0.09685693 0.10389443\n",
            "    0.09879342]\n",
            "   [0.09761009 0.09560166 0.10119431 ... 0.09553706 0.09628828\n",
            "    0.11850341]\n",
            "   ...\n",
            "   [0.10222587 0.10328139 0.09508933 ... 0.09548536 0.09791066\n",
            "    0.11097045]\n",
            "   [0.09551324 0.10601512 0.09348555 ... 0.10826695 0.1075901\n",
            "    0.10964395]\n",
            "   [0.11690799 0.09121044 0.09121756 ... 0.0916934  0.09208853\n",
            "    0.09284412]]\n",
            "\n",
            "  [[0.10810776 0.0942751  0.09505253 ... 0.09378396 0.09679952\n",
            "    0.13884439]\n",
            "   [0.12123886 0.11415911 0.09557965 ... 0.09468964 0.09405801\n",
            "    0.09743701]\n",
            "   [0.132849   0.09005725 0.12850621 ... 0.0927122  0.09285689\n",
            "    0.09917664]\n",
            "   ...\n",
            "   [0.12697606 0.0912357  0.09214232 ... 0.1178524  0.09399209\n",
            "    0.10446963]\n",
            "   [0.11475074 0.09405647 0.10441453 ... 0.09398486 0.11518867\n",
            "    0.1059187 ]\n",
            "   [0.15028572 0.09182073 0.0938767  ... 0.09661791 0.09353498\n",
            "    0.10757346]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 1.0\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 1.0\n",
            "Sum of softmax values in [0, 9, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax attention_scores가 ./model/softmax_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "\n",
        "# 파일에서 데이터 로드\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(f\"Shape of attention_scores: {np.array(attention_scores).shape}\")\n"
      ],
      "metadata": {
        "id": "EvyTkAln9iH7",
        "outputId": "83609b4b-dd62-4e02-854d-d3e2d785f8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_scores: (1, 12, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"./model/attention_scores.pkl\"  # 기존 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 정렬 및 인덱스 저장\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)\n",
        "original_indices = np.zeros_like(attention_scores, dtype=int)\n",
        "\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 인덱스와 정렬된 배열 저장\n",
        "            sorted_indices = np.argsort(attention_scores[i, j, k])[::-1]  # 내림차순 인덱스\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][sorted_indices]\n",
        "            original_indices[i, j, k] = sorted_indices  # 원래의 순서 저장\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "# 4. 원래 인덱스 데이터를 새로운 파일로 저장\n",
        "indices_file_path = \"./model/original_indices.pkl\"\n",
        "with open(indices_file_path, \"wb\") as f:\n",
        "    pickle.dump(original_indices, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores와 원래 인덱스가 각각 {sorted_file_path}, {indices_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "eOuBuIM67wL7",
        "outputId": "979679d1-1b75-4729-b2e0-de81d1e48f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores와 원래 인덱스가 각각 ./model/sorted_attention_scores.pkl, ./model/original_indices.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path2 = \"./model/softmax_sorted_attention_scores.pkl\"\n",
        "with open(softmax_file_path2, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax sorted_attention_scores가 {softmax_file_path2}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "jM9BFbZ2-5sn",
        "outputId": "ac2b6b8e-77f6-414a-9f03-27ea529d3ff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.52837735 0.14622849 0.12802094 ... 0.01831239 0.01404232\n",
            "    0.01195596]\n",
            "   [0.59860635 0.18540919 0.08261914 ... 0.01205369 0.00969707\n",
            "    0.00858417]\n",
            "   [0.44448107 0.21865611 0.1090568  ... 0.02435579 0.01309194\n",
            "    0.01159014]\n",
            "   ...\n",
            "   [0.293395   0.21439777 0.15665188 ... 0.02567743 0.01836554\n",
            "    0.01616001]\n",
            "   [0.5748314  0.14370786 0.08371508 ... 0.01707956 0.00646467\n",
            "    0.00565609]\n",
            "   [0.49397027 0.20655645 0.11359414 ... 0.01488702 0.0079303\n",
            "    0.00583681]]\n",
            "\n",
            "  [[0.27761808 0.14469248 0.10874643 ... 0.05368271 0.0356874\n",
            "    0.01940979]\n",
            "   [0.2604174  0.20440505 0.15219016 ... 0.0471074  0.03030995\n",
            "    0.01723383]\n",
            "   [0.33725736 0.13576876 0.10322648 ... 0.05898388 0.03532398\n",
            "    0.02939613]\n",
            "   ...\n",
            "   [0.24415724 0.13758077 0.13310166 ... 0.06292941 0.05104246\n",
            "    0.02247005]\n",
            "   [0.18009992 0.14077887 0.11384703 ... 0.06478832 0.05274922\n",
            "    0.03459279]\n",
            "   [0.20915571 0.14809294 0.12079702 ... 0.05797385 0.05027522\n",
            "    0.03712742]]\n",
            "\n",
            "  [[0.50648683 0.18570502 0.15359116 ... 0.00729464 0.00399939\n",
            "    0.00273765]\n",
            "   [0.43792823 0.2239379  0.1789386  ... 0.01247561 0.01049627\n",
            "    0.00801447]\n",
            "   [0.2603332  0.21274649 0.17485866 ... 0.03428007 0.03304965\n",
            "    0.03046698]\n",
            "   ...\n",
            "   [0.18211861 0.17483069 0.13898772 ... 0.0596569  0.05096523\n",
            "    0.04692417]\n",
            "   [0.44636625 0.14896284 0.13254707 ... 0.02250072 0.01801714\n",
            "    0.01292593]\n",
            "   [0.35479093 0.2774437  0.18958764 ... 0.01270177 0.00816243\n",
            "    0.00704678]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.32245672 0.11816898 0.10479394 ... 0.04930858 0.04516599\n",
            "    0.00350093]\n",
            "   [0.20571339 0.19960773 0.12593834 ... 0.06177064 0.02357428\n",
            "    0.01843771]\n",
            "   [0.21004221 0.19937786 0.13601878 ... 0.0412325  0.03932534\n",
            "    0.01391231]\n",
            "   ...\n",
            "   [0.23940286 0.14780323 0.14295705 ... 0.03974979 0.02443384\n",
            "    0.00927582]\n",
            "   [0.22464608 0.14365427 0.12574883 ... 0.04283044 0.0330447\n",
            "    0.01075488]\n",
            "   [0.17417422 0.1478222  0.14016856 ... 0.06458773 0.05391058\n",
            "    0.01854851]]\n",
            "\n",
            "  [[0.73495495 0.07021614 0.04455587 ... 0.01730828 0.01554307\n",
            "    0.01123482]\n",
            "   [0.15628102 0.15432207 0.12961586 ... 0.07171068 0.05584679\n",
            "    0.02641504]\n",
            "   [0.18773967 0.12912983 0.11732682 ... 0.05880833 0.03815652\n",
            "    0.03798618]\n",
            "   ...\n",
            "   [0.29404283 0.15865861 0.14177158 ... 0.03772043 0.02345941\n",
            "    0.02055062]\n",
            "   [0.24240194 0.24221043 0.13009368 ... 0.05989478 0.04765695\n",
            "    0.02040222]\n",
            "   [0.40604967 0.27261236 0.06234813 ... 0.03298335 0.03127662\n",
            "    0.02912592]]\n",
            "\n",
            "  [[0.48960426 0.20841889 0.04667228 ... 0.0334998  0.02939372\n",
            "    0.02738602]\n",
            "   [0.65346533 0.17757389 0.10371896 ... 0.00581406 0.00489807\n",
            "    0.00351891]\n",
            "   [0.43387496 0.24637778 0.10714414 ... 0.01453593 0.01080181\n",
            "    0.00921498]\n",
            "   ...\n",
            "   [0.6826026  0.13022482 0.04258374 ... 0.01212188 0.01199692\n",
            "    0.00978798]\n",
            "   [0.4284722  0.1861072  0.1096639  ... 0.03224343 0.02019598\n",
            "    0.01391816]\n",
            "   [0.5374471  0.19304998 0.04228677 ... 0.03116389 0.02958855\n",
            "    0.02164906]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0\n",
            "Sum of softmax values in [0, 0, 1]: 1.0\n",
            "Sum of softmax values in [0, 0, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 5]: 1.0\n",
            "Sum of softmax values in [0, 1, 6]: 1.0\n",
            "Sum of softmax values in [0, 1, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 5]: 1.0\n",
            "Sum of softmax values in [0, 2, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 8]: 1.0\n",
            "Sum of softmax values in [0, 2, 9]: 1.0\n",
            "Sum of softmax values in [0, 3, 0]: 1.0\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 1.0\n",
            "Sum of softmax values in [0, 3, 5]: 1.0\n",
            "Sum of softmax values in [0, 3, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 0]: 1.0\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 4]: 1.0\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 5, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 1.0\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 5, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0\n",
            "Sum of softmax values in [0, 6, 3]: 1.0\n",
            "Sum of softmax values in [0, 6, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 1.0\n",
            "Sum of softmax values in [0, 6, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 1.0\n",
            "Sum of softmax values in [0, 7, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 1.0\n",
            "Sum of softmax values in [0, 8, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 5]: 1.0\n",
            "Sum of softmax values in [0, 8, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 7]: 1.0\n",
            "Sum of softmax values in [0, 8, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 7]: 0.9999998211860657\n",
            "Sum of softmax values in [0, 9, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 1.0\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 1]: 1.0\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax sorted_attention_scores가 ./model/softmax_sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1Pr9O46V_Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "hhRL4CRO_QSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_SM_bert.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_SM_bert_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "6xc2_wJsIB-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_bert_layer1.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_bert_layer1.pkl_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1jdq5E2fjNWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/restored_softmax.pkl\"\n",
        "text_file_path = \"/./content/model/restored_softmax_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "V-oYzGDQCZvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/softmax_sorted_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "THbCGtMz_twq",
        "outputId": "112c2397-825f-4837-ce06-6a4df446ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.10749399 0.09632882 0.0954031  0.09513693 0.09258841\n",
            "  0.09229334 0.09164356 0.0910974  0.0900939 ]\n",
            " [0.12004588 0.10565753 0.10268969 0.10120098 0.09709173 0.0958351\n",
            "  0.09575053 0.09450836 0.0938547  0.09336555]\n",
            " [0.13786007 0.11296417 0.10104739 0.09357624 0.09350549 0.09287033\n",
            "  0.09284727 0.09269542 0.09188308 0.09075052]\n",
            " [0.11074849 0.10814226 0.10393477 0.10047178 0.10030901 0.09913348\n",
            "  0.09670201 0.09443171 0.09372903 0.09239744]\n",
            " [0.1193184  0.10324923 0.10189565 0.09932904 0.09908514 0.09784093\n",
            "  0.09755905 0.0950703  0.09426644 0.09238588]\n",
            " [0.1328674  0.10326969 0.09898279 0.09854479 0.09625035 0.09615592\n",
            "  0.0958468  0.09484941 0.09185758 0.0913753 ]\n",
            " [0.11864013 0.1089671  0.10785589 0.10248473 0.09685351 0.09558748\n",
            "  0.09497281 0.09192704 0.0917357  0.0909756 ]\n",
            " [0.12209511 0.1143846  0.10398746 0.09853819 0.09724706 0.09612775\n",
            "  0.09440193 0.09189809 0.09072162 0.09059814]\n",
            " [0.13755944 0.11774409 0.09577599 0.0939422  0.09348241 0.09323013\n",
            "  0.09304722 0.09287393 0.09189644 0.09044815]\n",
            " [0.12786184 0.10347308 0.10287845 0.10249271 0.09869479 0.0964129\n",
            "  0.0952139  0.09130668 0.09093261 0.09073301]] [[0.11400125 0.1034065  0.1010711  0.1006773  0.09990909 0.09957507\n",
            "  0.09785708 0.09670063 0.09466569 0.09213626]\n",
            " [0.12259456 0.10524756 0.10206269 0.09920018 0.09916254 0.09589188\n",
            "  0.09563524 0.09519612 0.09302149 0.09198767]\n",
            " [0.12747219 0.10719077 0.10062093 0.09860631 0.09690202 0.0963392\n",
            "  0.09631989 0.09255879 0.0925522  0.09143765]\n",
            " [0.10658482 0.10630877 0.10104766 0.1003748  0.10008461 0.09871509\n",
            "  0.0979219  0.09733845 0.09657256 0.09505137]\n",
            " [0.11034425 0.10167924 0.10102019 0.10027704 0.10000083 0.09928491\n",
            "  0.09772887 0.09770507 0.09617376 0.0957859 ]\n",
            " [0.10516495 0.10368128 0.10063306 0.1006038  0.10018845 0.09995812\n",
            "  0.09989405 0.09896458 0.09562299 0.09528879]\n",
            " [0.11380466 0.10230775 0.1017336  0.10014401 0.09873901 0.09837577\n",
            "  0.09824028 0.09637209 0.09522659 0.0950562 ]\n",
            " [0.12674263 0.10445353 0.09908456 0.09906299 0.0978529  0.09758332\n",
            "  0.09610719 0.09558626 0.09211903 0.09140754]\n",
            " [0.10645555 0.10579788 0.10304288 0.10144265 0.09954634 0.09866013\n",
            "  0.09808288 0.097651   0.09623402 0.09308667]\n",
            " [0.11155472 0.10681042 0.1043413  0.10225179 0.0984853  0.09746661\n",
            "  0.09710175 0.09461471 0.09410094 0.09327243]] [[0.11106927 0.109332   0.10838971 0.10667203 0.10396456 0.09332467\n",
            "  0.09290537 0.09214137 0.09158181 0.09061927]\n",
            " [0.11498808 0.10829917 0.10712849 0.10341936 0.09627965 0.0959329\n",
            "  0.09385677 0.09360978 0.09335104 0.09313468]\n",
            " [0.10907564 0.1086611  0.10594706 0.10251999 0.09717342 0.09607369\n",
            "  0.09553417 0.09523229 0.09514245 0.0946402 ]\n",
            " [0.12777801 0.11388236 0.09597065 0.09547208 0.09541373 0.09527735\n",
            "  0.09474532 0.09463353 0.09392282 0.09290416]\n",
            " [0.11447315 0.10678963 0.10269815 0.10112287 0.10047487 0.09732886\n",
            "  0.0970234  0.09365991 0.09344386 0.09298529]\n",
            " [0.11844434 0.10639787 0.10390373 0.10112502 0.09893835 0.09716936\n",
            "  0.0958861  0.09353664 0.0925469  0.09205168]\n",
            " [0.11324795 0.10864487 0.10467929 0.10341784 0.10152826 0.09656344\n",
            "  0.09464015 0.0934985  0.09244199 0.09133781]\n",
            " [0.11619101 0.10672598 0.10503597 0.10199555 0.09804323 0.09668372\n",
            "  0.09610645 0.09338766 0.0933179  0.09251253]\n",
            " [0.11661826 0.11136508 0.10871449 0.09768787 0.09678789 0.09655615\n",
            "  0.09494792 0.09265881 0.09243154 0.09223206]\n",
            " [0.13535918 0.10957498 0.10064787 0.09704289 0.09668809 0.0939795\n",
            "  0.0930492  0.09208082 0.09086873 0.09070873]] [[0.1255899  0.10366833 0.10065787 0.09996307 0.09845075 0.09556752\n",
            "  0.09483397 0.09431619 0.09430879 0.09264354]\n",
            " [0.13242505 0.1023296  0.1009952  0.09722893 0.0965215  0.09473015\n",
            "  0.09469819 0.09453561 0.09363452 0.09290122]\n",
            " [0.10879505 0.10861369 0.10704175 0.0996678  0.09955349 0.0962432\n",
            "  0.09612511 0.09592903 0.09408776 0.09394309]\n",
            " [0.12335853 0.109509   0.10271551 0.09744254 0.09695764 0.09671901\n",
            "  0.09527482 0.09343539 0.09332724 0.09126032]\n",
            " [0.1051129  0.1042406  0.1015951  0.10096215 0.10058594 0.09961344\n",
            "  0.09938804 0.09867377 0.09613637 0.09369161]\n",
            " [0.11151089 0.10542171 0.10479862 0.10213321 0.0991762  0.09746461\n",
            "  0.09690585 0.09604911 0.09489696 0.09164282]\n",
            " [0.10953204 0.10539693 0.10379548 0.10073565 0.100105   0.09728067\n",
            "  0.09637927 0.09632144 0.09549578 0.09495777]\n",
            " [0.11535057 0.11265247 0.10442845 0.10190308 0.0975237  0.09578036\n",
            "  0.094757   0.0945795  0.09181842 0.09120651]\n",
            " [0.11083733 0.10423398 0.10382918 0.10361786 0.09832249 0.09829199\n",
            "  0.0961586  0.09549905 0.0948538  0.09435575]\n",
            " [0.12480727 0.10181123 0.1017132  0.09872679 0.09662166 0.09624251\n",
            "  0.09611325 0.09551828 0.094544   0.0939018 ]] [[0.13122697 0.11838867 0.09999187 0.09693875 0.09442222 0.0934737\n",
            "  0.09302619 0.09113406 0.09096654 0.090431  ]\n",
            " [0.11642858 0.11028487 0.10202178 0.09834425 0.09758889 0.09684826\n",
            "  0.09614606 0.0955855  0.09482107 0.09193079]\n",
            " [0.13121082 0.11401134 0.10236181 0.09529249 0.09509484 0.09347839\n",
            "  0.09292267 0.09219655 0.09185337 0.09157771]\n",
            " [0.11182034 0.11131455 0.10122852 0.09885452 0.09775028 0.09756619\n",
            "  0.0970481  0.09618475 0.09485637 0.09337639]\n",
            " [0.1190371  0.11268517 0.10337377 0.09892204 0.09817803 0.09598743\n",
            "  0.09449787 0.0939927  0.09308489 0.09024091]\n",
            " [0.1231669  0.11651503 0.10195184 0.09985358 0.09462189 0.09450209\n",
            "  0.0933025  0.09328135 0.09239239 0.09041242]\n",
            " [0.13613823 0.11589173 0.09990533 0.09561177 0.09451851 0.09313484\n",
            "  0.09205063 0.09152158 0.09145974 0.08976758]\n",
            " [0.1390204  0.11394679 0.10029403 0.09454747 0.09414111 0.09320738\n",
            "  0.09201896 0.09160782 0.0911697  0.09004641]\n",
            " [0.12268637 0.11812288 0.09949172 0.09598787 0.09570937 0.09495543\n",
            "  0.09386134 0.09341761 0.09317895 0.0925884 ]\n",
            " [0.11522201 0.10869771 0.10425299 0.10174679 0.09862161 0.09762945\n",
            "  0.09581748 0.09348565 0.0927586  0.09176765]] [[0.19221878 0.09784383 0.08963636 0.08957554 0.08923525 0.08854745\n",
            "  0.08842815 0.08823875 0.08822448 0.08805135]\n",
            " [0.11539409 0.10904791 0.10234714 0.10070689 0.09962562 0.09711855\n",
            "  0.09595603 0.09456613 0.09366652 0.09157109]\n",
            " [0.11589902 0.11491495 0.10738936 0.10107232 0.09720412 0.09633563\n",
            "  0.09241604 0.09182198 0.09179646 0.09115013]\n",
            " [0.11951818 0.10833368 0.10711588 0.09994849 0.09823545 0.09602655\n",
            "  0.09344209 0.09324856 0.09276845 0.09136264]\n",
            " [0.11600425 0.10421543 0.10398513 0.09926617 0.09877275 0.09778262\n",
            "  0.09739378 0.09617388 0.09505376 0.09135223]\n",
            " [0.11857469 0.10661126 0.1019878  0.09983031 0.09922573 0.09874775\n",
            "  0.09660321 0.09393042 0.09363413 0.09085469]\n",
            " [0.13629879 0.09932628 0.09855013 0.09824003 0.09734751 0.0959255\n",
            "  0.09526379 0.09510257 0.09359585 0.09034953]\n",
            " [0.1166717  0.10794695 0.10213608 0.10188431 0.10099822 0.09603059\n",
            "  0.09559518 0.09504844 0.09319708 0.09049152]\n",
            " [0.10728315 0.1037925  0.10343576 0.10218531 0.10196406 0.10056645\n",
            "  0.09859848 0.09630246 0.0945216  0.09135017]\n",
            " [0.18254873 0.09307522 0.09207456 0.09193303 0.09161045 0.09072111\n",
            "  0.0906655  0.08960212 0.08930827 0.08846102]] [[0.11651556 0.11437199 0.11160105 0.09936865 0.09705305 0.09333326\n",
            "  0.09255443 0.09213877 0.09158062 0.09148257]\n",
            " [0.11088444 0.10870033 0.10675944 0.10344209 0.10087191 0.09622392\n",
            "  0.09453411 0.09344795 0.09310738 0.09202842]\n",
            " [0.10944903 0.10575333 0.10088027 0.10072865 0.09912886 0.09830763\n",
            "  0.0975268  0.09695422 0.09693255 0.09433866]\n",
            " [0.10834975 0.10484561 0.10161021 0.10110388 0.10089392 0.0985859\n",
            "  0.09677326 0.09623311 0.09595081 0.0956535 ]\n",
            " [0.11836878 0.10995642 0.10637329 0.10316958 0.10050903 0.09407511\n",
            "  0.09224288 0.09195571 0.09188712 0.09146208]\n",
            " [0.11637533 0.107494   0.10246739 0.10176704 0.10082836 0.09627321\n",
            "  0.0941247  0.09410713 0.09370921 0.0928537 ]\n",
            " [0.17207588 0.10849798 0.09107385 0.09054288 0.09051681 0.08970771\n",
            "  0.08961482 0.0895204  0.08928338 0.08916631]\n",
            " [0.11313932 0.10984481 0.10417305 0.1018426  0.10149228 0.09582976\n",
            "  0.09468491 0.09335858 0.09303081 0.09260397]\n",
            " [0.12644607 0.10036467 0.10026442 0.09970112 0.09940325 0.0972826\n",
            "  0.09482437 0.09429312 0.09427355 0.09314673]\n",
            " [0.1405463  0.1159537  0.10057663 0.09612732 0.09178676 0.09127815\n",
            "  0.09113301 0.09111058 0.0908433  0.09064425]] [[0.10564238 0.10292613 0.10179431 0.10042136 0.09872103 0.09872036\n",
            "  0.09871954 0.09819727 0.09806671 0.09679093]\n",
            " [0.12064464 0.10207136 0.10152597 0.10133596 0.09803465 0.09705557\n",
            "  0.09630508 0.09615217 0.09468193 0.09219266]\n",
            " [0.10665165 0.10452332 0.10275489 0.10125034 0.10006174 0.09947256\n",
            "  0.09891605 0.097019   0.09581892 0.0935316 ]\n",
            " [0.11108197 0.1069545  0.10360119 0.10301835 0.09847432 0.09757042\n",
            "  0.09722493 0.0958219  0.09537969 0.09087261]\n",
            " [0.10333292 0.10259257 0.10245122 0.10149055 0.1004594  0.09958882\n",
            "  0.09949169 0.09887893 0.09800059 0.09371338]\n",
            " [0.10969684 0.10169461 0.10050323 0.09977714 0.09924264 0.0991381\n",
            "  0.09875637 0.09777958 0.09685702 0.09655443]\n",
            " [0.10171361 0.10146581 0.10124384 0.10099129 0.09960892 0.09923731\n",
            "  0.09916671 0.09902416 0.09887232 0.098676  ]\n",
            " [0.10602034 0.10511005 0.10080007 0.10076638 0.09995149 0.09937529\n",
            "  0.09768594 0.09724063 0.09691003 0.09613974]\n",
            " [0.10654233 0.10577352 0.10148946 0.10047438 0.10002071 0.0985586\n",
            "  0.09784236 0.09719845 0.0961601  0.09594019]\n",
            " [0.10370079 0.10097425 0.10082368 0.10058665 0.10050481 0.09954733\n",
            "  0.09918906 0.09886386 0.09817427 0.0976353 ]] [[0.13101614 0.10155541 0.09949803 0.09879939 0.09736524 0.09523892\n",
            "  0.09497467 0.09472965 0.0946505  0.09217209]\n",
            " [0.16043125 0.09743757 0.09690606 0.09600316 0.09286897 0.09224714\n",
            "  0.09165689 0.09157068 0.09061959 0.09025875]\n",
            " [0.12229677 0.10795741 0.09818567 0.09794795 0.09757593 0.09644455\n",
            "  0.0955545  0.09544124 0.09520435 0.09339152]\n",
            " [0.14856924 0.10204253 0.10037015 0.09949326 0.09272838 0.09220155\n",
            "  0.09164988 0.09154554 0.09090395 0.0904955 ]\n",
            " [0.13742623 0.10216511 0.10204151 0.09627024 0.0957383  0.09423456\n",
            "  0.09366982 0.09324936 0.09266366 0.09254126]\n",
            " [0.10827874 0.10729821 0.10317886 0.10045856 0.09872456 0.09777663\n",
            "  0.09749199 0.09618194 0.09610833 0.09450217]\n",
            " [0.13456634 0.10423085 0.10157086 0.09865664 0.09621219 0.09613518\n",
            "  0.09293942 0.09284518 0.09169888 0.0911445 ]\n",
            " [0.15805185 0.09799827 0.09751602 0.09492274 0.09333222 0.09234674\n",
            "  0.0920763  0.0920596  0.09175216 0.0899441 ]\n",
            " [0.15166666 0.10440575 0.09550705 0.09392787 0.0938193  0.09349321\n",
            "  0.09203372 0.0918356  0.09167873 0.09163215]\n",
            " [0.10974686 0.10353356 0.10199118 0.10157139 0.10014214 0.09902046\n",
            "  0.09866758 0.09735171 0.09568052 0.09229465]] [[0.11696494 0.10561763 0.1026743  0.10018165 0.10010299 0.09984183\n",
            "  0.09757758 0.09490325 0.09146243 0.09067347]\n",
            " [0.12616728 0.10725618 0.10489378 0.10077072 0.09898864 0.09442478\n",
            "  0.09362216 0.09245644 0.09102614 0.09039382]\n",
            " [0.12389978 0.10335313 0.1023483  0.10156903 0.10070038 0.09829431\n",
            "  0.09435275 0.09222058 0.09215761 0.09110405]\n",
            " [0.13135895 0.11509195 0.09834989 0.09702215 0.09552077 0.09462588\n",
            "  0.09443802 0.09247658 0.09081339 0.09030242]\n",
            " [0.11786105 0.10425267 0.10283441 0.10009396 0.0991247  0.098704\n",
            "  0.09789151 0.09510923 0.09314692 0.09098157]\n",
            " [0.11120586 0.11066937 0.10239101 0.1016436  0.09920651 0.09874985\n",
            "  0.09706905 0.09613745 0.0918766  0.09105068]\n",
            " [0.11243922 0.11034236 0.1020238  0.10166942 0.09871032 0.09781794\n",
            "  0.0956016  0.09512395 0.09494527 0.09132624]\n",
            " [0.11789278 0.10887911 0.1030987  0.10161806 0.09805292 0.09680559\n",
            "  0.09550236 0.09425528 0.09290124 0.09099401]\n",
            " [0.10826562 0.10599791 0.10526626 0.10162396 0.10086945 0.09868338\n",
            "  0.09792026 0.09593145 0.09358449 0.09185722]\n",
            " [0.11110785 0.10693549 0.10325618 0.10216829 0.0989797  0.09897416\n",
            "  0.09823224 0.09677328 0.09239224 0.09118057]] [[0.13062459 0.12001117 0.10074113 0.09474252 0.09386603 0.09363971\n",
            "  0.09245858 0.09179718 0.0914835  0.09063558]\n",
            " [0.10933135 0.10389441 0.10218149 0.10083347 0.0987934  0.09805172\n",
            "  0.09762    0.09760492 0.09685692 0.09483222]\n",
            " [0.11850341 0.10194103 0.10119431 0.09937377 0.09878195 0.09761009\n",
            "  0.09628828 0.09560166 0.09553706 0.09516849]\n",
            " [0.1064885  0.10433034 0.10290188 0.10156679 0.1006103  0.09858835\n",
            "  0.09808301 0.09728806 0.09667599 0.09346682]\n",
            " [0.11237273 0.10942037 0.10832172 0.0995042  0.09650969 0.0957105\n",
            "  0.09499046 0.09493661 0.09430388 0.09392986]\n",
            " [0.10560665 0.10434524 0.10314914 0.10254232 0.1011281  0.09828933\n",
            "  0.09727395 0.09697267 0.09606361 0.094629  ]\n",
            " [0.12966645 0.11357925 0.11246008 0.09314593 0.09302556 0.09259983\n",
            "  0.09171455 0.09159797 0.091246   0.09096438]\n",
            " [0.11097045 0.10328139 0.10222587 0.10110361 0.10058366 0.09976029\n",
            "  0.09791066 0.09548536 0.09508933 0.09358936]\n",
            " [0.10964395 0.10826695 0.1075901  0.10601512 0.09815793 0.0960831\n",
            "  0.09551324 0.09348555 0.09266593 0.09257816]\n",
            " [0.12031083 0.11849108 0.11690799 0.09304062 0.09284412 0.09219547\n",
            "  0.09208853 0.0916934  0.09121756 0.09121044]] [[0.13884439 0.10810776 0.09679952 0.09505253 0.0942751  0.09378396\n",
            "  0.09362106 0.0932615  0.09313487 0.09311935]\n",
            " [0.12123885 0.11415909 0.097437   0.09722511 0.09567007 0.09557963\n",
            "  0.09503611 0.09490646 0.09468962 0.09405799]\n",
            " [0.132849   0.12850621 0.09917664 0.09285689 0.0927122  0.0919118\n",
            "  0.09117553 0.0905907  0.09016381 0.09005725]\n",
            " [0.1297989  0.12024375 0.1006963  0.09401721 0.09367883 0.09252627\n",
            "  0.09244621 0.09233411 0.09221454 0.09204385]\n",
            " [0.12638246 0.12465423 0.099479   0.09614468 0.09545842 0.09220749\n",
            "  0.09193899 0.09154938 0.0913196  0.09086577]\n",
            " [0.13141826 0.12846188 0.09653927 0.09354375 0.09281931 0.09193935\n",
            "  0.09180678 0.09180298 0.09110983 0.09055864]\n",
            " [0.1273724  0.11926056 0.09824953 0.09632255 0.09553046 0.09303466\n",
            "  0.09287931 0.09279443 0.09237044 0.09218565]\n",
            " [0.12697604 0.1178524  0.10446963 0.09399208 0.09357508 0.09352376\n",
            "  0.09327863 0.09295432 0.09214232 0.0912357 ]\n",
            " [0.11518867 0.11475074 0.1059187  0.10441453 0.09405647 0.09398486\n",
            "  0.09382902 0.09279858 0.09260277 0.09245568]\n",
            " [0.15028572 0.10757346 0.09661791 0.0938767  0.09353498 0.09265015\n",
            "  0.09182073 0.09176069 0.09112944 0.09075014]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open( \"/./content/model/softmax_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "xhGzU2ZG_t3b",
        "outputId": "54c8137e-eff2-4565-b7b1-e1c1542b0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792055 0.09109741 0.09164357 0.09009392 0.09632883 0.09540311\n",
            "  0.107494   0.09258842 0.09229336 0.09513694]\n",
            " [0.12004586 0.10268968 0.10120098 0.09575053 0.09583508 0.09709172\n",
            "  0.10565752 0.09385469 0.09336554 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185757 0.09137529 0.09854478 0.09584679 0.0948494\n",
            "  0.09615591 0.13286738 0.09898278 0.10326968]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519613 0.09198768 0.10206269 0.10524758 0.0930215  0.09916256\n",
            "  0.09589189 0.09563526 0.09920019 0.12259457]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.09578589 0.0992849  0.10167923 0.10000082 0.09617375 0.10027704\n",
            "  0.09772886 0.09770505 0.10102018 0.11034424]\n",
            " [0.09562298 0.09995811 0.10516494 0.10018844 0.09989404 0.10063305\n",
            "  0.10060379 0.09528878 0.10368127 0.09896457]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908457 0.09758333 0.09906299 0.10445354 0.09140754 0.09558626\n",
            "  0.09211904 0.0961072  0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.10933199 0.09290536 0.09061925 0.0915818  0.1083897  0.10396454\n",
            "  0.11106926 0.09214136 0.09332465 0.10667202]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639788 0.09716938 0.10112503 0.09205169 0.09254691\n",
            "  0.09353665 0.11844435 0.09588612 0.09893835]\n",
            " [0.11324794 0.09464014 0.0913378  0.09244198 0.10467927 0.10152824\n",
            "  0.10341783 0.09349848 0.09656344 0.10864485]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.0949479  0.11661825 0.09678788 0.11136506 0.0926588  0.09223205\n",
            "  0.09243153 0.09768786 0.09655614 0.10871448]\n",
            " [0.1353592  0.0939795  0.09070874 0.09086874 0.0966881  0.0970429\n",
            "  0.10957499 0.09208083 0.09304921 0.10064787]] [[0.09431619 0.09845076 0.10366833 0.09264354 0.10065788 0.09556752\n",
            "  0.0943088  0.09483398 0.09996308 0.12558992]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113407 0.09302621 0.09096655 0.09999189 0.09347371\n",
            "  0.11838868 0.09693877 0.09442223 0.13122699]\n",
            " [0.11642858 0.09614605 0.11028486 0.09684824 0.09834424 0.09758888\n",
            "  0.10202176 0.09558548 0.09193078 0.09482107]\n",
            " [0.09292267 0.1023618  0.13121082 0.11401133 0.0915777  0.09347839\n",
            "  0.09219654 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024093 0.0939927  0.09598744 0.09817804 0.09449788 0.09892205\n",
            "  0.10337377 0.11268519 0.0930849  0.11903711]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152159 0.09205063 0.09145974 0.09561178 0.09990533\n",
            "  0.09451851 0.11589174 0.09313484 0.13613825]\n",
            " [0.09160781 0.09116969 0.09004641 0.09201896 0.09454746 0.0941411\n",
            "  0.10029402 0.11394678 0.09320737 0.13902038]\n",
            " [0.09258841 0.09495544 0.09341762 0.09949172 0.09386135 0.09570938\n",
            "  0.09598789 0.11812289 0.09317896 0.12268639]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.0904915  0.10794695 0.10099821 0.09559517 0.1166717  0.10213607\n",
            "  0.1018843  0.09319707 0.09603058 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912887 0.10944904 0.09433867 0.10088028 0.09830764 0.0975268\n",
            "  0.10072865 0.09693256 0.09695423 0.10575334]\n",
            " [0.10161023 0.09677327 0.10834976 0.10484561 0.10110389 0.09623312\n",
            "  0.0985859  0.0956535  0.09595082 0.10089393]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246737 0.10176703 0.09412469 0.10082835 0.0937092  0.09410712\n",
            "  0.0928537  0.11637531 0.0962732  0.10749398]\n",
            " [0.17207587 0.08952039 0.08916631 0.0897077  0.09107384 0.08961482\n",
            "  0.0905168  0.09054288 0.08928337 0.10849796]\n",
            " [0.1098448  0.10417304 0.0930308  0.0946849  0.09335857 0.09582975\n",
            "  0.09260397 0.10184258 0.10149226 0.11313931]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.14054629 0.09064424 0.09111057 0.0908433  0.09612731 0.09127814\n",
            "  0.10057662 0.09178675 0.091133   0.11595369]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665164 0.10275488 0.09353159 0.10125034 0.09947255 0.10006173\n",
            "  0.09701899 0.09581891 0.09891603 0.10452331]\n",
            " [0.11108198 0.09722494 0.09757043 0.09087262 0.09847433 0.10360121\n",
            "  0.09582192 0.10695451 0.0953797  0.10301836]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654232 0.1000207  0.09855858 0.09616009 0.10047437 0.09784234\n",
            "  0.09719844 0.10148945 0.09594018 0.1057735 ]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743756 0.16043124 0.09025874 0.09600315 0.09286896 0.09061958\n",
            "  0.09224714 0.09157067 0.09165689 0.09690605]\n",
            " [0.12229678 0.09520435 0.10795742 0.09818569 0.09339153 0.09644455\n",
            "  0.09794796 0.09544125 0.09757594 0.09555452]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872455 0.09450217 0.09777661 0.10317885 0.09749197 0.09618193\n",
            "  0.09610832 0.10827873 0.10045855 0.1072982 ]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.08994411 0.09333223 0.09175216 0.09207631\n",
            "  0.09234674 0.15805186 0.09799828 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077073 0.1048938  0.1072562  0.09898866 0.09102615 0.09362218\n",
            "  0.09039383 0.09442478 0.09245645 0.1261673 ]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135894 0.09834988 0.09081338 0.09247658\n",
            "  0.09030242 0.09443802 0.09552076 0.11509194]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290123 0.09680557 0.11789276 0.10161805 0.09425527 0.0980529\n",
            "  0.090994   0.10309868 0.09550235 0.1088791 ]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062458 0.09245858 0.0914835  0.09386603 0.10074112 0.09363971\n",
            "  0.12001116 0.09063558 0.09179717 0.09474251]\n",
            " [0.09483223 0.09760492 0.10083348 0.10933136 0.1021815  0.09805173\n",
            "  0.09762    0.09685693 0.10389443 0.09879342]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123886 0.11415911 0.09557965 0.09490647 0.09503613 0.09567008\n",
            "  0.09722512 0.09468964 0.09405801 0.09743701]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024376 0.09221455 0.09204386 0.12979892 0.09252628 0.09244622\n",
            "  0.09233411 0.09401721 0.09367883 0.10069631]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.0928193  0.09193934 0.09055864 0.09180677 0.09110983\n",
            "  0.09180297 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697606 0.0912357  0.09214232 0.09352377 0.09357508 0.09295433\n",
            "  0.09327864 0.1178524  0.09399209 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 정렬된 데이터와 원래 인덱스 로드\n",
        "sorted_file_path3 = \"./model/sorted_attention_scores.pkl\"\n",
        "indices_file_path3 = \"./model/original_indices.pkl\"\n",
        "restored_file_path3 = \"./model/restored_softmax.pkl\"\n",
        "\n",
        "with open(sorted_file_path3, \"rb\") as f:\n",
        "    sorted_attention_scores = pickle.load(f)\n",
        "\n",
        "with open(indices_file_path3, \"rb\") as f:\n",
        "    original_indices = pickle.load(f)\n",
        "\n",
        "# 2. 원래 순서로 복원\n",
        "restored_attention_scores = np.zeros_like(sorted_attention_scores)\n",
        "for i in range(sorted_attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(sorted_attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(sorted_attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 순서로 복원\n",
        "            inverse_indices = np.argsort(original_indices[i, j, k])  # 원래 순서 찾기\n",
        "            restored_attention_scores[i, j, k] = sorted_attention_scores[i, j, k][inverse_indices]\n",
        "\n",
        "# 3. 복원된 결과를 새로운 파일에 저장\n",
        "with open(restored_file_path3, \"wb\") as f:\n",
        "    pickle.dump(restored_attention_scores, f)\n",
        "\n",
        "print(f\"복원된 softmax attention_scores가 {restored_file_path3}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "MIofHJFRCG0b",
        "outputId": "ea3b115a-5c7c-49f1-89e6-6715fa22bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복원된 softmax attention_scores가 ./model/restored_softmax.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/restored_softmax_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "BIQ4u34qCk1E",
        "outputId": "b31e641a-a68a-4c58-f0ea-68cecc2a221f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.0910974  0.09164356 0.0900939  0.09632882 0.0954031\n",
            "  0.10749399 0.09258841 0.09229334 0.09513693]\n",
            " [0.12004588 0.10268969 0.10120098 0.09575053 0.0958351  0.09709173\n",
            "  0.10565753 0.0938547  0.09336555 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185758 0.0913753  0.09854479 0.0958468  0.09484941\n",
            "  0.09615592 0.1328674  0.09898279 0.10326969]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519612 0.09198767 0.10206269 0.10524756 0.09302149 0.09916254\n",
            "  0.09589188 0.09563524 0.09920018 0.12259456]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.0957859  0.09928491 0.10167924 0.10000083 0.09617376 0.10027704\n",
            "  0.09772887 0.09770507 0.10102019 0.11034425]\n",
            " [0.09562299 0.09995812 0.10516495 0.10018845 0.09989405 0.10063306\n",
            "  0.1006038  0.09528879 0.10368128 0.09896458]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908456 0.09758332 0.09906299 0.10445353 0.09140754 0.09558626\n",
            "  0.09211903 0.09610719 0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.109332   0.09290537 0.09061927 0.09158181 0.10838971 0.10396456\n",
            "  0.11106927 0.09214137 0.09332467 0.10667203]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639787 0.09716936 0.10112502 0.09205168 0.0925469\n",
            "  0.09353664 0.11844434 0.0958861  0.09893835]\n",
            " [0.11324795 0.09464015 0.09133781 0.09244199 0.10467929 0.10152826\n",
            "  0.10341784 0.0934985  0.09656344 0.10864487]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.09494792 0.11661826 0.09678789 0.11136508 0.09265881 0.09223206\n",
            "  0.09243154 0.09768787 0.09655615 0.10871449]\n",
            " [0.13535918 0.0939795  0.09070873 0.09086873 0.09668809 0.09704289\n",
            "  0.10957498 0.09208082 0.0930492  0.10064787]] [[0.09431619 0.09845075 0.10366833 0.09264354 0.10065787 0.09556752\n",
            "  0.09430879 0.09483397 0.09996307 0.1255899 ]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113406 0.09302619 0.09096654 0.09999187 0.0934737\n",
            "  0.11838867 0.09693875 0.09442222 0.13122697]\n",
            " [0.11642858 0.09614606 0.11028487 0.09684826 0.09834425 0.09758889\n",
            "  0.10202178 0.0955855  0.09193079 0.09482107]\n",
            " [0.09292267 0.10236181 0.13121082 0.11401134 0.09157771 0.09347839\n",
            "  0.09219655 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024091 0.0939927  0.09598743 0.09817803 0.09449787 0.09892204\n",
            "  0.10337377 0.11268517 0.09308489 0.1190371 ]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152158 0.09205063 0.09145974 0.09561177 0.09990533\n",
            "  0.09451851 0.11589173 0.09313484 0.13613823]\n",
            " [0.09160782 0.0911697  0.09004641 0.09201896 0.09454747 0.09414111\n",
            "  0.10029403 0.11394679 0.09320738 0.1390204 ]\n",
            " [0.0925884  0.09495543 0.09341761 0.09949172 0.09386134 0.09570937\n",
            "  0.09598787 0.11812288 0.09317895 0.12268637]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.09049152 0.10794695 0.10099822 0.09559518 0.1166717  0.10213608\n",
            "  0.10188431 0.09319708 0.09603059 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912886 0.10944903 0.09433866 0.10088027 0.09830763 0.0975268\n",
            "  0.10072865 0.09693255 0.09695422 0.10575333]\n",
            " [0.10161021 0.09677326 0.10834975 0.10484561 0.10110388 0.09623311\n",
            "  0.0985859  0.0956535  0.09595081 0.10089392]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246739 0.10176704 0.0941247  0.10082836 0.09370921 0.09410713\n",
            "  0.0928537  0.11637533 0.09627321 0.107494  ]\n",
            " [0.17207588 0.0895204  0.08916631 0.08970771 0.09107385 0.08961482\n",
            "  0.09051681 0.09054288 0.08928338 0.10849798]\n",
            " [0.10984481 0.10417305 0.09303081 0.09468491 0.09335858 0.09582976\n",
            "  0.09260397 0.1018426  0.10149228 0.11313932]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.1405463  0.09064425 0.09111058 0.0908433  0.09612732 0.09127815\n",
            "  0.10057663 0.09178676 0.09113301 0.1159537 ]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665165 0.10275489 0.0935316  0.10125034 0.09947256 0.10006174\n",
            "  0.097019   0.09581892 0.09891605 0.10452332]\n",
            " [0.11108197 0.09722493 0.09757042 0.09087261 0.09847432 0.10360119\n",
            "  0.0958219  0.1069545  0.09537969 0.10301835]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654233 0.10002071 0.0985586  0.0961601  0.10047438 0.09784236\n",
            "  0.09719845 0.10148946 0.09594019 0.10577352]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743757 0.16043125 0.09025875 0.09600316 0.09286897 0.09061959\n",
            "  0.09224714 0.09157068 0.09165689 0.09690606]\n",
            " [0.12229677 0.09520435 0.10795741 0.09818567 0.09339152 0.09644455\n",
            "  0.09794795 0.09544124 0.09757593 0.0955545 ]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872456 0.09450217 0.09777663 0.10317886 0.09749199 0.09618194\n",
            "  0.09610833 0.10827874 0.10045856 0.10729821]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.0899441  0.09333222 0.09175216 0.0920763\n",
            "  0.09234674 0.15805185 0.09799827 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077072 0.10489378 0.10725618 0.09898864 0.09102614 0.09362216\n",
            "  0.09039382 0.09442478 0.09245644 0.12616728]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135895 0.09834989 0.09081339 0.09247658\n",
            "  0.09030242 0.09443802 0.09552077 0.11509195]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290124 0.09680559 0.11789278 0.10161806 0.09425528 0.09805292\n",
            "  0.09099401 0.1030987  0.09550236 0.10887911]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062459 0.09245858 0.0914835  0.09386603 0.10074113 0.09363971\n",
            "  0.12001117 0.09063558 0.09179718 0.09474252]\n",
            " [0.09483222 0.09760492 0.10083347 0.10933135 0.10218149 0.09805172\n",
            "  0.09762    0.09685692 0.10389441 0.0987934 ]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123885 0.11415909 0.09557963 0.09490646 0.09503611 0.09567007\n",
            "  0.09722511 0.09468962 0.09405799 0.097437  ]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024375 0.09221454 0.09204385 0.1297989  0.09252627 0.09244621\n",
            "  0.09233411 0.09401721 0.09367883 0.1006963 ]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.09281931 0.09193935 0.09055864 0.09180678 0.09110983\n",
            "  0.09180298 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697604 0.0912357  0.09214232 0.09352376 0.09357508 0.09295432\n",
            "  0.09327863 0.1178524  0.09399208 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_text_file(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    # 데이터 전처리: 불필요한 문자 제거 및 정리\n",
        "    data = data.replace(\"\\n\", \" \")  # 줄바꿈 제거\n",
        "    data = data.replace(\"[\", \"\").replace(\"]\", \"\")  # 대괄호 제거\n",
        "    data = data.split()  # 공백 기준으로 나눔\n",
        "\n",
        "    # 문자열을 float으로 변환\n",
        "    try:\n",
        "        data_list = [float(value) for value in data]\n",
        "        return np.array(data_list)  # numpy 배열로 변환\n",
        "    except ValueError as e:\n",
        "        print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "        raise\n",
        "\n",
        "# 두 파일의 데이터 읽기\n",
        "try:\n",
        "    restored_data = parse_text_file('./model/restored_softmax_2.txt')\n",
        "    original_data = parse_text_file('./model/attention_scores_2.txt')\n",
        "\n",
        "    # 데이터 형태 확인\n",
        "    print(f\"Restored data shape: {restored_data.shape}\")\n",
        "    print(f\"Original data shape: {original_data.shape}\")\n",
        "\n",
        "    # 데이터 값 하나하나 비교\n",
        "    if np.array_equal(restored_data, original_data):\n",
        "        print(\"두 데이터는 형태와 값이 모두 동일합니다.\")\n",
        "    else:\n",
        "        print(\"데이터에 차이가 있습니다.\")\n",
        "\n",
        "        # 값이 다를 경우, 차이를 확인\n",
        "        differences = np.where(restored_data != original_data)\n",
        "        print(f\"값이 다른 위치: {differences}\")\n",
        "        print(f\"Restored data at differences: {restored_data[differences]}\")\n",
        "        print(f\"Original data at differences: {original_data[differences]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"파일 처리 중 오류 발생: {e}\")\n"
      ],
      "metadata": {
        "id": "NqnBhDHgkSWH",
        "outputId": "5b70cbcc-752c-49ec-fba2-149541753efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored data shape: (1200,)\n",
            "Original data shape: (1200,)\n",
            "두 데이터는 형태와 값이 모두 동일합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    음수의 경우 정수부를 내림하여 변환하고, 남은 값을 소수부로 변환.\n",
        "    \"\"\"\n",
        "    max_int_value = 2**(int_bits - 1) - 1  # 7비트 최대값 (63)\n",
        "    min_int_value = -2**(int_bits - 1)     # 7비트 최소값 (-64)\n",
        "    max_frac_value = 2**frac_bits           # 13비트 정밀도 (8192)\n",
        "\n",
        "    # ✅ 정수부 조정 (floor 적용하여 내림)\n",
        "    int_part = int(np.floor(value))\n",
        "    frac_part = abs(value - int_part)\n",
        "\n",
        "    # ✅ 정수부 범위 확인\n",
        "    if int_part < min_int_value or int_part > max_int_value:\n",
        "        raise ValueError(f\"정수부 {int_part}가 {min_int_value} ~ {max_int_value} 범위를 벗어남!\")\n",
        "\n",
        "    # ✅ 2의 보수 변환 (정수부 7비트)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 앞 12비트는 항상 0 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트, 항상 양수)\n",
        "    frac_binary = format(int(round(frac_part * max_frac_value)), f'0{frac_bits}b')\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "id": "gNlyfcx-D_Mi",
        "outputId": "89520f01-c66a-4afc-b777-ddf29f6ed032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjoyAYqcE8Rj",
        "outputId": "0902e2bf-cbf3-4230-ee62-0f0c5b77c1e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/output.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "y9gvMWCUC7wz",
        "outputId": "3a8d45ad-e8a8-415b-e9f8-0d52b58e6857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000000000000110111101010111 00000000000000000100011000111011 00000000000000000100000111111010 00000000000000000010110011111001 00000000000000000001010000101111 00000000000000000001001010111110\n",
            "00000000000000000000111111101101 00000000000000000000001111000000 00000000000011111111101101000001 00000000000011111111011000011011\n",
            "00000000000000001011100101100001 00000000000000001001001111100000 00000000000000000111101000000010 00000000000000000110101100011000 00000000000000000100110001101111 00000000000000000100101011110001\n",
            "00000000000000000011110100011110 00000000000000000011110001101001 00000000000000000011010101110011 00000000000000000011000110001101\n",
            "00000000000000001010011011001100 00000000000000001001000000011001 00000000000000000111100111010110 00000000000000000110101000100011 00000000000000000110000100100000 00000000000000000101001101001011\n",
            "00000000000000000100111101011010 00000000000000000100100111011101 00000000000000000011011000000000 00000000000000000011001000011010\n",
            "00000000000000001101100110000001 00000000000000001010101010100001 00000000000000001001010011100101 00000000000000000111100110100110 00000000000000000110001101111011 00000000000000000101011100001010\n",
            "00000000000000000101010100011100 00000000000000000101001001001101 00000000000000000100110101010110 00000000000000000100010110110111\n",
            "00000000000000001010001000001110 00000000000000001001010010001011 00000000000000000110111111110000 00000000000000000110101011100000 00000000000000000110100111011001 00000000000000000101100011010111\n",
            "00000000000000000101001011101111 00000000000000000100000011000010 00000000000000000011101111110100 00000000000000000001010000000010\n",
            "00000000000000001000101000000001 00000000000000001000100110111000 00000000000000000111111101011000 00000000000000000111000001100010 00000000000000000110011100001111 00000000000000000110000101100011\n",
            "00000000000000000101110101111110 00000000000000000101101111100001 00000000000000000101001110101000 00000000000000000100100011010011\n",
            "00000000000000001001000110011110 00000000000000001000010110000010 00000000000000000110101010011000 00000000000000000110010110011101 00000000000000000101010111101110 00000000000000000101010001111011\n",
            "00000000000000000100111100101100 00000000000000000011100101111000 00000000000000000011010110011010 00000000000000000010101000110110\n",
            "00000000000000001001000100110101 00000000000000001000011100101011 00000000000000000111110100100000 00000000000000000110110110001001 00000000000000000110110001010100 00000000000000000101111011000000\n",
            "00000000000000000100001101101110 00000000000000000100001101000010 00000000000000000011100010001000 00000000000000000011010001110000\n",
            "00000000000000001011011111111100 00000000000000001000101110100000 00000000000000000111101001010101 00000000000000000111000011101111 00000000000000000110100111010101 00000000000000000101111111101000\n",
            "00000000000000000100101110110010 00000000000000000100011101111000 00000000000000000010100001100001 00000000000000000010010000011010\n",
            "00000000000000001101001111001000 00000000000000001011011111100010 00000000000000001010010010111111 00000000000000001001001001000001 00000000000000001000111011101010 00000000000000000110110110101000\n",
            "00000000000000000110010110010010 00000000000000000110001110111000 00000000000000000100111110010001 00000000000000000100010111000010 00000000000000000001111011001111 00000000000000000000100111110101 00000000000000000000000011010001 00000000000011111111111001110010 00000000000011111111110110001001 00000000000011111111110000110101\n",
            "00000000000011111111000101000101 00000000000011111110101000111010 00000000000011111101110100101010 00000000000011111100100110101101\n",
            "00000000000000000001111100011101 00000000000000000001011101011101 00000000000000000000110111101101 00000000000000000000000111110101 00000000000011111111100011110101 00000000000011111110110101111001\n",
            "00000000000011111110100111101100 00000000000011111110100001100110 00000000000011111101101001001010 00000000000011111100100000111001\n",
            "00000000000000000010010000000011 00000000000000000000011011100101 00000000000011111111111000100000 00000000000011111111100101100011 00000000000011111111010011011111 00000000000011111111001000100101\n",
            "00000000000011111110111000110000 00000000000011111110110000110111 00000000000011111101101111001111 00000000000011111101010111101110\n",
            "00000000000000000010100010001001 00000000000000000000111010010110 00000000000000000000010010111010 00000000000000000000000100101101 00000000000000000000000010001010 00000000000000000000000000000010\n",
            "00000000000011111111011111111111 00000000000011111111011111100001 00000000000011111111010101000100 00000000000011111110110100011000\n",
            "00000000000000000001011010100000 00000000000000000001010011100000 00000000000000000001001011100011 00000000000000000000101001010111 00000000000000000000001100011000 00000000000011111111111011010001\n",
            "00000000000011111111011111011001 00000000000011111101100101100101 00000000000011111100111011010011 00000000000011111100100011000100\n",
            "00000000000000000001100110011000 00000000000000000000111000000010 00000000000000000000110000111100 00000000000000000000110000010001 00000000000000000000100100011110 00000000000000000000010011100100\n",
            "00000000000000000000000010010111 00000000000011111111000000111100 00000000000011111110010010111110 00000000000011111101100101001111\n",
            "00000000000000000001001101101001 00000000000000000001001010101011 00000000000000000000011001100111 00000000000000000000001101101011 00000000000000000000001100110111 00000000000000000000000100101001\n",
            "00000000000011111111110100010101 00000000000011111111101001100111 00000000000011111111011010111111 00000000000011111110010100111110\n",
            "00000000000000000001111111011111 00000000000000000000110110000100 00000000000000000000110001110101 00000000000000000000001110011010 00000000000000000000001011101111 00000000000011111111110111101110\n",
            "00000000000011111111010100111101 00000000000011111111010001111101 00000000000011111110110111001010 00000000000011111101001110001000\n",
            "00000000000000000001011000000101 00000000000000000000111000100011 00000000000000000000011101010111 00000000000000000000010101110011 00000000000000000000010101100000 00000000000000000000010011000101\n",
            "00000000000000000000000100011100 00000000000011111111010101001101 00000000000011111110111010111001 00000000000011111110000100111001\n",
            "00000000000000000001101000110110 00000000000000000000111100101010 00000000000000000000100010100101 00000000000000000000100000111111 00000000000000000000010110010100 00000000000011111111110010101001\n",
            "00000000000011111111010010001100 00000000000011111111000100100111 00000000000011111110110010011000 00000000000011111110001011100100 00000000000000001000001011111001 00000000000000000110001011011101 00000000000000000101110011001010 00000000000000000100110100101010 00000000000000000001110110110010 00000000000000000001010000110101\n",
            "00000000000000000000000010110100 00000000000011111111101101000111 00000000000011111110100000001100 00000000000011111101101111101011\n",
            "00000000000000000111110100000011 00000000000000000110011110001101 00000000000000000110000001011111 00000000000000000100010000110010 00000000000000000001111110001001 00000000000000000001001011010000\n",
            "00000000000000000001000000100100 00000000000000000000101100100101 00000000000000000000010110011110 00000000000011111111110011111100\n",
            "00000000000000000101010000111100 00000000000000000100110111000110 00000000000000000100011110000000 00000000000000000011000001010011 00000000000000000010110000110011 00000000000000000010000000000001\n",
            "00000000000000000001101101101101 00000000000000000001001101011011 00000000000000000001001000110000 00000000000000000000111110010101\n",
            "00000000000000001000001011001001 00000000000000000110001100001000 00000000000000000100000001010001 00000000000000000010111011100111 00000000000000000010110111001000 00000000000000000001111100100000\n",
            "00000000000000000001100000110101 00000000000000000001001000101111 00000000000000000000101010100110 00000000000011111111011000111011\n",
            "00000000000000000111001001111011 00000000000000000110000010001111 00000000000000000100011101000011 00000000000000000011000110101011 00000000000000000010111101111001 00000000000000000010010001000001\n",
            "00000000000011111111101001110000 00000000000011111111010111100000 00000000000011111101011001011111 00000000000011111101001000111111\n",
            "00000000000000000110110101100111 00000000000000000110001001100110 00000000000000000100111010000001 00000000000000000100100101000110 00000000000000000010000111011000 00000000000000000001011011110101\n",
            "00000000000000000001010000011100 00000000000000000000011100010110 00000000000000000000001001010100 00000000000011111111010110000101\n",
            "00000000000000000011110100000010 00000000000000000011000000011100 00000000000000000010011010101001 00000000000000000001110001001011 00000000000000000001010011110101 00000000000000000001001011111101\n",
            "00000000000000000001001001000100 00000000000000000000111110110010 00000000000000000000110110100110 00000000000000000000010010010100\n",
            "00000000000000000100001111110001 00000000000000000100001010100011 00000000000000000011101101001011 00000000000000000011001011111101 00000000000000000010110111000011 00000000000000000010101101010101\n",
            "00000000000000000010001001100110 00000000000000000010000000111011 00000000000000000001101100110001 00000000000000000001100010001100\n",
            "00000000000000000110011100000110 00000000000000000100001111101000 00000000000000000100000000101011 00000000000000000011100100000100 00000000000000000010010111000010 00000000000000000001001000111001\n",
            "00000000000000000000100000111100 00000000000000000000011101101100 00000000000000000000000001001111 00000000000011111111010110101111\n",
            "00000000000000001000010100010100 00000000000000000111110100110110 00000000000000000111000100000110 00000000000000000101110101110111 00000000000000000010101000100101 00000000000000000001110100000000\n",
            "00000000000000000001101100110001 00000000000000000001101010000110 00000000000000000000110001100000 00000000000000000000011110101100 00000000000011111110100001101001 00000000000011111110001110110001 00000000000011111110001010011110 00000000000011111101111010111111 00000000000011111101011011101101 00000000000011111101010111101001\n",
            "00000000000011111100100100011001 00000000000011111100011010110010 00000000000011111011111000100000 00000000000011111011010001111010\n",
            "00000000000000000101101101001000 00000000000000000010100101010101 00000000000000000010010001101000 00000000000000000010001011011100 00000000000000000001111101100101 00000000000000000001100010010101\n",
            "00000000000000000001000100001101 00000000000011111111111001000110 00000000000011111111010010000011 00000000000011111101101000110011\n",
            "00000000000000000011110001110101 00000000000000000010110010011101 00000000000000000010011110110001 00000000000000000010001111011110 00000000000000000001110111100011 00000000000000000001110101001010\n",
            "00000000000000000000111000011011 00000000000000000000101111101000 00000000000011111111000010011110 00000000000011111110110010000010\n",
            "00000000000000000011110100101101 00000000000000000011100101000111 00000000000000000010111111110101 00000000000000000010100100110011 00000000000000000001101010110111 00000000000000000001001110010001\n",
            "00000000000000000000010110110101 00000000000011111111011111011110 00000000000011111111001011110010 00000000000011111110110100100000\n",
            "00000000000000000011111000010000 00000000000000000011011000001111 00000000000000000010100001010111 00000000000000000001110110010001 00000000000000000001101010010011 00000000000000000001000000110000\n",
            "00000000000000000000101101100001 00000000000011111111101011100111 00000000000011111111010110001111 00000000000011111101000010100001\n",
            "00000000000000000011010110001001 00000000000000000010111000110011 00000000000000000010011111110010 00000000000000000010000110010110 00000000000000000010000001010100 00000000000000000001100101010010\n",
            "00000000000000000001011000010100 00000000000000000001001001101100 00000000000000000000111100011110 00000000000000000000100100001100\n",
            "00000000000000000010100011111111 00000000000000000010011110100011 00000000000000000010010001101111 00000000000000000010010001000110 00000000000000000010000001111000 00000000000000000001010010100000\n",
            "00000000000000000000110111111111 00000000000011111111011101101101 00000000000011111111010110011000 00000000000011111110111100011111\n",
            "00000000000000000100000010111011 00000000000000000010111001111101 00000000000000000010000100000001 00000000000000000001111000100000 00000000000000000001010011111100 00000000000000000001010011110010\n",
            "00000000000000000000111000100110 00000000000000000000100011110111 00000000000000000000001101110000 00000000000011111110110001000011\n",
            "00000000000000000010011101100001 00000000000000000010010010011101 00000000000000000010001010000111 00000000000000000001111100001001 00000000000000000001110001001011 00000000000000000001101010010000\n",
            "00000000000000000001011000000110 00000000000000000001010101110001 00000000000000000001010100100111 00000000000000000000010111101001\n",
            "00000000000000000001101010101101 00000000000000000001010100000111 00000000000000000001001010011100 00000000000000000000111101100011 00000000000000000000111001110110 00000000000000000000101011110011\n",
            "00000000000011111111111100100100 00000000000011111111101110000111 00000000000011111111001010001100 00000000000011111101111101001001 00000000000000001000001000111100 00000000000000000110100010000001 00000000000000000110000001001000 00000000000000000010001111110000 00000000000000000001000101110011 00000000000011111111011110001011\n",
            "00000000000011111111001010001010 00000000000011111111000101001010 00000000000011111110010111001101 00000000000011111110010111001011\n",
            "00000000000000001100001100011100 00000000000000001000000111111101 00000000000000001000000001010110 00000000000000000110101101000010 00000000000000000101010010001000 00000000000000000101000110011101\n",
            "00000000000000000100111100101101 00000000000000000011011011000101 00000000000000000010000101001100 00000000000000000001010111000001\n",
            "00000000000000000111010001001110 00000000000000000101110001001100 00000000000000000101001011111101 00000000000000000101000011000100 00000000000000000100111010000001 00000000000000000100110111001100\n",
            "00000000000000000100010001111100 00000000000000000011101100011010 00000000000000000011010011111010 00000000000000000010010111111101\n",
            "00000000000000001101010101000101 00000000000000001000100110011100 00000000000000001000000000111101 00000000000000000101110010111001 00000000000000000101101000010010 00000000000000000100001011100001\n",
            "00000000000000000011111000100010 00000000000000000010010011010100 00000000000000000001110111110000 00000000000000000001110110100001\n",
            "00000000000000001001000111110011 00000000000000000111100011000010 00000000000000000111011011001111 00000000000000000110100111000111 00000000000000000101100000000010 00000000000000000101000100011010\n",
            "00000000000000000011011101111101 00000000000000000010111000001000 00000000000000000010110101111011 00000000000000000000101000001111\n",
            "00000000000000001001100100100111 00000000000000000111111001011100 00000000000000000110001001100110 00000000000000000100110110110000 00000000000000000100100100010010 00000000000000000100001110010111\n",
            "00000000000000000100001101011100 00000000000000000011110010001011 00000000000000000010111110001000 00000000000011111100010000011100\n",
            "00000000000000000111000010000110 00000000000000000110100000100110 00000000000000000100101110001101 00000000000000000100100110010100 00000000000000000100010111111010 00000000000000000011110111100010\n",
            "00000000000000000011100111101111 00000000000000000010010100010001 00000000000000000001101100100010 00000000000000000001010001100010\n",
            "00000000000000000101100000111000 00000000000000000101011010010011 00000000000000000100111101001001 00000000000000000100111011101000 00000000000000000011011101110001 00000000000000000011001101100110\n",
            "00000000000000000010101110000111 00000000000000000010000100101111 00000000000000000000110011001100 00000000000000000000101101111000\n",
            "00000000000000001001011000000000 00000000000000000110001001011110 00000000000000000100111111011110 00000000000000000100100010000101 00000000000000000100000110011010 00000000000000000010011010101110\n",
            "00000000000000000010000101000111 00000000000000000001101101001010 00000000000000000000111101010001 00000000000011111100111101011111\n",
            "00000000000000000111001101111111 00000000000000000110000000000010 00000000000000000101110111110101 00000000000000000100101010101101 00000000000000000100100100101011 00000000000000000100001011110100\n",
            "00000000000000000011100101010110 00000000000000000000111100111111 00000000000011111110100010101001 00000000000011111110100000110000 00000000000000000100101101000010 00000000000011111111110010101011 00000000000011111101010111101110 00000000000011111101001101001011 00000000000011111101000111110100 00000000000011111101000001101100\n",
            "00000000000011111100111101010001 00000000000011111011001100101001 00000000000011111010110101001110 00000000000011111010110101001001\n",
            "00000000000000000110110100101011 00000000000000000110001011000010 00000000000000000101100110100111 00000000000000000101000000000011 00000000000000000100110011001110 00000000000000000011000011101000\n",
            "00000000000000000010100111010111 00000000000000000010001010010010 00000000000000000001111010001111 00000000000011111111110101101110\n",
            "00000000000000000111110000101011 00000000000000000110010100011011 00000000000000000100011010110110 00000000000000000100000011111110 00000000000000000011000101011011 00000000000000000010111010010100\n",
            "00000000000000000010101001011010 00000000000000000001100011010111 00000000000000000000100111100101 00000000000011111110000001111101\n",
            "00000000000000000111001101110001 00000000000000000111000001001111 00000000000000000110010011101100 00000000000000000110010000010111 00000000000000000101100110010100 00000000000000000101000111001010\n",
            "00000000000000000100111101111100 00000000000000000011111111110100 00000000000000000001111100111010 00000000000011111101010001010010\n",
            "00000000000000000111000100011000 00000000000000000101110111011011 00000000000000000101100100101100 00000000000000000101010011101100 00000000000000000100001110100101 00000000000000000011111111010101\n",
            "00000000000000000010110100100010 00000000000000000000010101111010 00000000000000000000001100000011 00000000000011111110111011111011\n",
            "00000000000000000111110010001100 00000000000000000110010010001000 00000000000000000110000011011010 00000000000000000101111110011110 00000000000000000101111010111011 00000000000000000101101011100011\n",
            "00000000000000000101001100110110 00000000000000000100111000001010 00000000000000000100011011011111 00000000000011111111111001011010\n",
            "00000000000000000101010111110010 00000000000000000101010001101011 00000000000000000101001101001100 00000000000000000101001010101010 00000000000000000101000100011011 00000000000000000100011011100010\n",
            "00000000000000000100000010101000 00000000000000000010111010101001 00000000000000000010100101000010 00000000000011111110000000100010\n",
            "00000000000000000110100011100100 00000000000000000110011010000110 00000000000000000101110111011011 00000000000000000101011100010010 00000000000000000100111111101000 00000000000000000011111101100101\n",
            "00000000000000000011001001001001 00000000000000000010011010111111 00000000000000000010001110111011 00000000000000000000000101110011\n",
            "00000000000000000101100010111001 00000000000000000101010100000000 00000000000000000101001110011000 00000000000000000101000010110011 00000000000000000100101001110000 00000000000000000100011100101001\n",
            "00000000000000000100011010101001 00000000000000000100010100001101 00000000000000000011111100011110 00000000000011111111100010011001\n",
            "00000000000000001010110001111110 00000000000000000111011001101101 00000000000000000110111111010110 00000000000000000110101111010011 00000000000000000110011000000111 00000000000000000110001101110010\n",
            "00000000000000000101111010101111 00000000000000000101101111110011 00000000000000000101010100011010 00000000000000000000011111111011 00000000000000000100000011111001 00000000000000000011101101110011 00000000000000000011101010101101 00000000000000000000000100101101 00000000000011111111101001001100 00000000000011111111100110001101\n",
            "00000000000011111111010001111001 00000000000011111110111110000010 00000000000011111110010100100110 00000000000011111110001000001100\n",
            "00000000000000000100111100001101 00000000000000000011110010101110 00000000000000000011011111001011 00000000000000000011011001110010 00000000000000000011010010001001 00000000000000000011001110111100\n",
            "00000000000000000011000101110000 00000000000000000010100110100000 00000000000000000000001001101110 00000000000000000000000001010010\n",
            "00000000000000000100110100000000 00000000000000000100010110111110 00000000000000000100010101101010 00000000000000000100010010011101 00000000000000000011101010100011 00000000000000000011011110011110\n",
            "00000000000000000011000001111010 00000000000000000010110000111001 00000000000000000001011001000001 00000000000000000000000001001101\n",
            "00000000000000000101100010000111 00000000000000000101001110110000 00000000000000000101001000100001 00000000000000000100011000100010 00000000000000000100001010000001 00000000000000000011000011011101\n",
            "00000000000000000011000000000100 00000000000000000010100010011001 00000000000000000001110111010101 00000000000011111111010110001100\n",
            "00000000000000000101110010111001 00000000000000000100111111000010 00000000000000000011000110101011 00000000000000000010111101111110 00000000000000000010101110011101 00000000000000000010011101111101\n",
            "00000000000000000010001110010011 00000000000000000001100101010011 00000000000011111110111101001001 00000000000011111110011111110111\n",
            "00000000000000001001001101111001 00000000000000001000011010111110 00000000000000000101001110100110 00000000000000000100010100000000 00000000000000000011111000100110 00000000000000000011100111010001\n",
            "00000000000000000011010110010111 00000000000000000011001000000101 00000000000000000010010000000101 00000000000000000010000111011110\n",
            "00000000000000000100111000110100 00000000000000000100110101010000 00000000000000000100011000001101 00000000000000000100001101111000 00000000000000000100001010100001 00000000000000000011111011101111\n",
            "00000000000000000011100101001001 00000000000000000011000111011101 00000000000000000010110011101110 00000000000000000010000010100111\n",
            "00000000000000000101000101011000 00000000000000000100111100001101 00000000000000000100100100000010 00000000000000000100001110110100 00000000000000000011111001001011 00000000000000000011100100011100\n",
            "00000000000000000011001110111111 00000000000000000010110100100011 00000000000000000010010001001001 00000000000000000010001110001111\n",
            "00000000000000000101001001110000 00000000000000000100111101010110 00000000000000000100010001101001 00000000000000000011101100010101 00000000000000000011011100001101 00000000000000000010111001010000\n",
            "00000000000000000010101001100001 00000000000000000010011110110111 00000000000000000010011101000001 00000000000000000010010101010110\n",
            "00000000000000001010111010011000 00000000000000001010101101001110 00000000000000001001000101010110 00000000000000000110101000011000 00000000000000000101101101001110 00000000000000000101100110111100\n",
            "00000000000000000101010001111101 00000000000000000100101011110000 00000000000000000100010111111110 00000000000000000011110011111110 00000000000000000000011100111100 00000000000011111111111011001001 00000000000011111111111011000010 00000000000011111111111010000001 00000000000011111111110111001001 00000000000011111111100101010010\n",
            "00000000000011111111100001001010 00000000000011111111010011001010 00000000000011111111000110101100 00000000000011111110111100100000\n",
            "00000000000000000001010110011011 00000000000000000000110010010101 00000000000000000000011110011000 00000000000011111111110111111011 00000000000011111111110001111000 00000000000011111111011001101101\n",
            "00000000000011111111000011100110 00000000000011111110111000111101 00000000000011111110110000000101 00000000000011111110100011110100\n",
            "00000000000000000001110111100000 00000000000000000001000101000100 00000000000000000000111111000110 00000000000000000000011011100100 00000000000000000000010111111111 00000000000011111111111100010001\n",
            "00000000000011111111100001011010 00000000000011111111011000110000 00000000000011111111010110100101 00000000000011111101100010110100\n",
            "00000000000000000001011001010010 00000000000000000000111001100110 00000000000000000000011111001010 00000000000011111111111111101100 00000000000011111111110101111110 00000000000011111111010110011100\n",
            "00000000000011111111001111001011 00000000000011111110110000101011 00000000000011111110101001000000 00000000000011111110100101101100\n",
            "00000000000000000000001101001000 00000000000000000000001001100111 00000000000011111111111011100001 00000000000011111111111001110000 00000000000011111111100101100110 00000000000011111111100010001100\n",
            "00000000000011111111010100011011 00000000000011111111000110100100 00000000000011111111000100111000 00000000000011111011101111011000\n",
            "00000000000000000000100110101110 00000000000000000000100110010101 00000000000000000000011111000001 00000000000000000000011110111001 00000000000000000000011000010011 00000000000000000000001100010110\n",
            "00000000000000000000000100001100 00000000000000000000000011011001 00000000000000000000000000010111 00000000000011111111101111001111\n",
            "00000000000000000001001101100111 00000000000000000001000011000100 00000000000011111111111111100101 00000000000011111111101011011101 00000000000011111111100111010000 00000000000011111111010111110010\n",
            "00000000000011111111010011111100 00000000000011111111001100011100 00000000000011111111000111110101 00000000000011111111000101001001\n",
            "00000000000000000000000101011000 00000000000011111111111100001010 00000000000011111111101010110111 00000000000011111111100111110111 00000000000011111111011000010010 00000000000011111111001101001011\n",
            "00000000000011111110110111100010 00000000000011111110110011001001 00000000000011111101010111100110 00000000000011111010110001100100\n",
            "00000000000000000000101100011011 00000000000000000000011101110010 00000000000000000000010100010001 00000000000000000000010001101110 00000000000000000000001000100111 00000000000000000000001000010011\n",
            "00000000000011111111111110110100 00000000000011111111111011000011 00000000000011111111110100111001 00000000000011111111100111100110\n",
            "00000000000000000000011100001100 00000000000000000000000111000011 00000000000000000000000000001001 00000000000011111111111100010111 00000000000011111111111010111001 00000000000011111111111000000010\n",
            "00000000000011111111110111100000 00000000000011111111110100100100 00000000000011111111101100010000 00000000000011111111011111111100 00000000000000000100100000000000 00000000000000000100011100000000 00000000000000000001011101001000 00000000000000000001011001100111 00000000000000000001001001010011 00000000000000000000100100011000\n",
            "00000000000000000000010001011111 00000000000000000000001110101111 00000000000011111111100010101000 00000000000011111111001100011110\n",
            "00000000000000000110111100000001 00000000000000000101111001110000 00000000000000000100101000011010 00000000000000000011110000100110 00000000000000000010110011011101 00000000000000000010011001001010\n",
            "00000000000000000010010100100001 00000000000000000001010100001000 00000000000000000000011101001011 00000000000011111111101001010110\n",
            "00000000000000000111011010110110 00000000000000000100101100001111 00000000000000000011110100001111 00000000000000000011010001110111 00000000000000000010110110110101 00000000000000000010100101011001\n",
            "00000000000000000010000001111101 00000000000000000001110001111111 00000000000000000001000111110001 00000000000000000000111100010101\n",
            "00000000000000001000010001011100 00000000000000000111101010111100 00000000000000000110000000100000 00000000000000000101001011100011 00000000000000000100101001011000 00000000000000000011101110100011\n",
            "00000000000000000010101010011000 00000000000000000010011101001000 00000000000000000010000110110100 00000000000011111111100111011000\n",
            "00000000000000000110001100000101 00000000000000000011101011000000 00000000000000000011100000100111 00000000000000000011000011001100 00000000000000000010100110100001 00000000000000000001010110010111\n",
            "00000000000000000001001110101001 00000000000000000001000101001000 00000000000000000000111100010000 00000000000000000000100001001111\n",
            "00000000000000000100001011111111 00000000000000000011111110111100 00000000000000000010101100001001 00000000000000000001110011011000 00000000000000000001101111111101 00000000000000000001100110100111\n",
            "00000000000000000001000000011110 00000000000000000000111001101101 00000000000011111111110001111110 00000000000011111110001000011110\n",
            "00000000000000000010111101100101 00000000000000000001111101101101 00000000000000000001001001010101 00000000000000000001000100110010 00000000000000000000111001101101 00000000000000000000110100000000\n",
            "00000000000000000000001001011100 00000000000000000000000101001111 00000000000011111111111010111000 00000000000011111111001000101110\n",
            "00000000000000000110010010100011 00000000000000000100110010101110 00000000000000000100001100010000 00000000000000000011110001000100 00000000000000000010001010011101 00000000000000000001011010101001\n",
            "00000000000000000001010110010110 00000000000000000001001101000011 00000000000000000001000011100001 00000000000000000000011000110100\n",
            "00000000000000000100000001100111 00000000000000000011011111011000 00000000000000000011010101100110 00000000000000000011000110010000 00000000000000000010010000100011 00000000000000000001101010011000\n",
            "00000000000000000001001001011011 00000000000000000000111010111001 00000000000000000000011000000000 00000000000011111111001111100111\n",
            "00000000000000000100001001001110 00000000000000000011011001110111 00000000000000000010101110010100 00000000000000000010011001010101 00000000000000000001100111110101 00000000000000000001010001000110\n",
            "00000000000000000001001111010101 00000000000000000000100110010100 00000000000000000000100100011101 00000000000000000000001111101001 00000000000000000010001110100011 00000000000000000000001110000100 00000000000011111111111110101100 00000000000011111111111011000011 00000000000011111111111010101010 00000000000011111111110011000100\n",
            "00000000000011111110110001111000 00000000000011111110011110001100 00000000000011111110010010111101 00000000000011111001001011100111\n",
            "00000000000000000011001000011110 00000000000000000011000100101000 00000000000000000010001001101011 00000000000000000010000001110000 00000000000000000001100101010001 00000000000000000001010000110101\n",
            "00000000000000000001000000010110 00000000000000000000101110011111 00000000000011111110110011001100 00000000000011111110010011101111\n",
            "00000000000000000010110111010001 00000000000000000010110000100110 00000000000000000001111111101001 00000000000000000001100000010011 00000000000000000001001100111110 00000000000000000001000011111110\n",
            "00000000000000000000110110011000 00000000000011111111100110110111 00000000000011111111100000110011 00000000000011111101011011110011\n",
            "00000000000000000010100000011110 00000000000000000010011100111101 00000000000000000010000000110110 00000000000000000001001101101111 00000000000000000000000110111101 00000000000011111111111101110010\n",
            "00000000000011111111111101100010 00000000000011111111010100001011 00000000000011111111010000011110 00000000000011111101110100000110\n",
            "00000000000000000011111000110110 00000000000000000010011000000111 00000000000000000010001100100100 00000000000000000001101000000000 00000000000000000001011101111000 00000000000000000000100110011110\n",
            "00000000000000000000100010111110 00000000000011111110110101000000 00000000000011111110110010000100 00000000000011111110100111000110\n",
            "00000000000000000011010011011101 00000000000000000001110100110000 00000000000000000001110000000001 00000000000000000001011011011100 00000000000000000001001111011100 00000000000000000000111111001001\n",
            "00000000000000000000111010010000 00000000000011111111010111000101 00000000000011111111001110100100 00000000000011111101111011100111\n",
            "00000000000000000011001010111100 00000000000000000011000101010010 00000000000000000010101111111001 00000000000000000010010010100101 00000000000000000010001111000111 00000000000000000001100101011010\n",
            "00000000000000000000111010001111 00000000000000000000010000111110 00000000000011111111110001001100 00000000000011111110010110011110\n",
            "00000000000000000011101101111010 00000000000000000010110000001100 00000000000000000010101011111011 00000000000000000010010101101101 00000000000000000010000111010101 00000000000000000001101110101110\n",
            "00000000000000000001100001110111 00000000000000000000001000000101 00000000000011111111001001110011 00000000000011111101001101110100\n",
            "00000000000000000011001110001111 00000000000000000010010101000001 00000000000000000010000011111110 00000000000000000010000000010111 00000000000000000001111001101100 00000000000000000001101010010011\n",
            "00000000000000000001000111000011 00000000000011111111111010000111 00000000000011111111011000111010 00000000000011111101001001001111\n",
            "00000000000000000010000110101100 00000000000000000001110001101100 00000000000000000001101010111001 00000000000000000001010110011010 00000000000000000001000001010100 00000000000000000000111100001001\n",
            "00000000000000000000100111011101 00000000000000000000000111101101 00000000000011111111110000100101 00000000000011111101101000000001 00000000000000000111000001011101 00000000000000000010010100111000 00000000000000000001011010101010 00000000000000000000101000111100 00000000000000000000011101100110 00000000000000000000010011000001\n",
            "00000000000000000000000101001111 00000000000011111111100001101000 00000000000011111111010011110111 00000000000011111110101010010100\n",
            "00000000000000000101101000111010 00000000000000000101100111010010 00000000000000000101010000111101 00000000000000000101001100111001 00000000000000000101000101110100 00000000000000000100011100110001\n",
            "00000000000000000100001011010100 00000000000000000100000101001100 00000000000000000011100101001100 00000000000000000010000101010111\n",
            "00000000000000000110000110110011 00000000000000000101010110111010 00000000000000000101001010101000 00000000000000000101000110110001 00000000000000000101000101100110 00000000000000000100111111101100\n",
            "00000000000000000100110001101000 00000000000000000011110010001110 00000000000000000010111010110111 00000000000000000010111010010010\n",
            "00000000000000000111000101011100 00000000000000000110100000010010 00000000000000000110000110000110 00000000000000000110000011010100 00000000000000000101101101001111 00000000000000000101001000100010\n",
            "00000000000000000100110111010010 00000000000000000100100111011110 00000000000000000100000011111010 00000000000000000011000001101101\n",
            "00000000000000000110110100000010 00000000000000000101111101001001 00000000000000000101100100110010 00000000000000000101100001110101 00000000000000000100100001100001 00000000000000000100010000101001\n",
            "00000000000000000011110011011110 00000000000000000011000001110111 00000000000000000001101101010001 00000000000000000001100101000110\n",
            "00000000000000001001011110110111 00000000000000000111010001100111 00000000000000000110101011111011 00000000000000000101011110011100 00000000000000000101001100001000 00000000000000000100101101000101\n",
            "00000000000000000100100100010001 00000000000000000100100000001000 00000000000000000011111011110100 00000000000000000010111101000010\n",
            "00000000000000000110110100100010 00000000000000000101111001011011 00000000000000000101011101010001 00000000000000000101010001000101 00000000000000000100100110001111 00000000000000000011101111000100\n",
            "00000000000000000011011010000011 00000000000000000010110010011011 00000000000000000010101001011100 00000000000000000001100000111101\n",
            "00000000000000001000011000001100 00000000000000000111001001001110 00000000000000000110111010110100 00000000000000000110101010000001 00000000000000000110010101100100 00000000000000000100111011011010\n",
            "00000000000000000100011100010001 00000000000000000100010001010110 00000000000000000011010100100011 00000000000000000011000011100110\n",
            "00000000000000000111011100000101 00000000000000000111011011111111 00000000000000000110001100011011 00000000000000000100111001011100 00000000000000000100110101011000 00000000000000000100101100111101\n",
            "00000000000000000100101100111100 00000000000000000100101001001001 00000000000000000100001011111000 00000000000000000010011111010010\n",
            "00000000000000001010011111011110 00000000000000001001101100011110 00000000000000000110101111101000 00000000000000000110010010101100 00000000000000000101110110001110 00000000000000000101110011001011\n",
            "00000000000000000101101101011110 00000000000000000101011110001000 00000000000000000101010111010101 00000000000000000101001110001101 00000000000000000101001100000110 00000000000000000011011110110010 00000000000000000000011111010000 00000000000000000000011010011001 00000000000000000000010101110100 00000000000000000000010001111101\n",
            "00000000000011111111111001001010 00000000000011111111110100110011 00000000000011111111100100000100 00000000000011111111011011000000\n",
            "00000000000000000111100111010001 00000000000000000101000000011111 00000000000000000011111011101010 00000000000000000000110111010000 00000000000011111111011000010001 00000000000011111111010110100100\n",
            "00000000000011111110101011011101 00000000000011111110001010110110 00000000000011111101110100111001 00000000000011111101001010100100\n",
            "00000000000000000100101011011101 00000000000000000011100011000010 00000000000000000001111000011100 00000000000000000001011110001010 00000000000000000000011000011001 00000000000011111110101001001100\n",
            "00000000000011111110011010111010 00000000000011111101111000110000 00000000000011111101010010110000 00000000000011111100111110011010\n",
            "00000000000000000101100011010011 00000000000000000010100000100111 00000000000000000001101111111110 00000000000000000000110100100011 00000000000000000000101100011011 00000000000011111111101011111110\n",
            "00000000000011111111010100101010 00000000000011111111000110100010 00000000000011111111000001101110 00000000000011111110110001101110\n",
            "00000000000000000110001100001001 00000000000000000001010110010001 00000000000000000000111001010011 00000000000000000000100100000111 00000000000000000000010011000111 00000000000011111111101110010111\n",
            "00000000000011111111011000111010 00000000000011111110100111111111 00000000000011111110100110100000 00000000000011111100110010111010\n",
            "00000000000000000011100110001110 00000000000000000011000101111110 00000000000011111111000100101101 00000000000011111110100001101001 00000000000011111110001011100101 00000000000011111101011011010111\n",
            "00000000000011111101011011000111 00000000000011111101000001000010 00000000000011111100110100011101 00000000000011111100101010001101\n",
            "00000000000000000010110101100110 00000000000000000010011011110011 00000000000000000000111110000101 00000000000000000000100101001101 00000000000011111111010010010001 00000000000011111110111100000100\n",
            "00000000000011111110011010110011 00000000000011111110001011110010 00000000000011111101010010000001 00000000000011111100111111100000\n",
            "00000000000000000110010110111001 00000000000000000011000010110110 00000000000000000000110011110001 00000000000000000000100110000110 00000000000000000000011011110111 00000000000011111111010000001101\n",
            "00000000000011111111000010001000 00000000000011111110010010111100 00000000000011111110010001100111 00000000000011111101110111100100\n",
            "00000000000000000011100101101100 00000000000000000001111010111101 00000000000000000000110111010000 00000000000000000000001000111111 00000000000011111111010011001011 00000000000011111110111101011110\n",
            "00000000000011111110110111101011 00000000000011111110011010100100 00000000000011111101011110101100 00000000000011111100101111000010\n",
            "00000000000000000011111101011011 00000000000000000001111010010111 00000000000011111110111000000000 00000000000011111110101110010111 00000000000011111110101001101000 00000000000011111110100000101001\n",
            "00000000000011111110010110100101 00000000000011111110010000111100 00000000000011111110001010010011 00000000000011111101100010010011\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt(input_file, output_file):\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # txt 파일 읽기 및 값 분리\n",
        "    with open(input_file, 'r') as f:\n",
        "        content = f.read()  # 파일 전체 내용을 읽음\n",
        "        binary_values = content.split()  # 스페이스와 줄바꿈을 기준으로 값을 분리\n",
        "\n",
        "    # 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            # 줄 생성\n",
        "            line = template.format(index=i + 9, binary_value=binary_value)  # index는 9부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "# 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output.txt'  # 입력 파일 경로 (값들이 스페이스/줄바꿈으로 구별됨)\n",
        "output_code_file = './model/generated_code.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# 코드 생성 함수 호출\n",
        "generate_code_from_txt(input_txt_file, output_code_file)\n",
        "print(f\"코드가 성공적으로 생성되어 {output_code_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "bBrrgb7-GxN3",
        "outputId": "a3b5732c-d300-4a67-8813-dca7cab8cb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코드가 성공적으로 생성되어 ./model/generated_code.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hex_to_16bit_binary(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일 내용 읽기 및 분리 (스페이스 및 줄바꿈 기준)\n",
        "        hex_values = f.read().split()\n",
        "\n",
        "    # 16진수 -> 16비트 2진수 변환\n",
        "    binary_values = [format(int(hex_value, 16), '016b') for hex_value in hex_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for binary_value in binary_values:\n",
        "            f.write(binary_value + \"\\n\")  # 각 값을 줄바꿈으로 저장\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/cordic_result02-11.txt'  # 16진수 값이 저장된 입력 파일\n",
        "output_txt_file = './model/binary_values.txt'  # 변환된 16비트 2진수를 저장할 출력 파일https://github.com/MMujtabaRoohani/RISC-V-Processor/blob/master/PipelinedProcessor/Control_Unit.v\n",
        "# 함수 호출\n",
        "convert_hex_to_16bit_binary(input_txt_file, output_txt_file)\n",
        "print(f\"16진수 값이 16비트 2진수로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "cCw_Fb3iL9zA",
        "outputId": "b77b4666-36e4-4976-8c27-448d2539e19f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16진수 값이 16비트 2진수로 변환되어 ./model/binary_values.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary_to_decimal(input_file, output_file):\n",
        "    def binary_to_decimal(binary_str):\n",
        "        # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "        int_part = int(binary_str[:3], 2)  # 정수부\n",
        "        frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "        return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 16비트 바이너리 값 읽기\n",
        "        binary_values = f.read().splitlines()\n",
        "\n",
        "    # 16비트 이진수를 10진수로 변환\n",
        "    decimal_values = [binary_to_decimal(binary) for binary in binary_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for decimal in decimal_values:\n",
        "            f.write(f\"{decimal:.10f}\\n\")  # 소수점 10자리까지 출력\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/binary_values.txt'  # 16비트 바이너리 입력 파일\n",
        "output_txt_file = './model/cordic_dec_val.txt'  # 변환된 10진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_binary_to_decimal(input_txt_file, output_txt_file)\n",
        "print(f\"16비트 바이너리 값이 10진수 소수점 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "6YmJ4ZPhM_Nb",
        "outputId": "40c0c986-469b-40b7-b7eb-e0dbb6d23a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16비트 바이너리 값이 10진수 소수점 값으로 변환되어 ./model/cordic_dec_val.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_fixed_point_hex(input_file, output_file):\n",
        "    def float_to_fixed_point(value):\n",
        "        \"\"\"\n",
        "        10진수 소수를 16비트 고정소수점 표현으로 변환:\n",
        "        - 앞 3비트: 정수부 (0~7)\n",
        "        - 뒤 13비트: 소수부\n",
        "        \"\"\"\n",
        "        # 정수부: value의 정수 부분 (0~7 사이 값)\n",
        "        int_part = int(value)\n",
        "        if int_part > 7:\n",
        "            raise ValueError(f\"정수부가 3비트를 초과했습니다: {value}\")\n",
        "\n",
        "        # 소수부: value의 소수 부분을 13비트로 표현\n",
        "        frac_part = value - int_part\n",
        "        frac_binary = int(round(frac_part * (2 ** 13)))  # 소수부를 2^13로 스케일링\n",
        "\n",
        "        # 16비트 바이너리 표현\n",
        "        binary_value = f\"{int_part:03b}{frac_binary:013b}\"\n",
        "        return binary_value\n",
        "\n",
        "    def binary_to_hex(binary_str):\n",
        "        \"\"\"\n",
        "        16비트 바이너리를 16진수(hex)로 변환.\n",
        "        \"\"\"\n",
        "        return f\"0x{int(binary_str, 2):04X}\"\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 10진수 소수점 값 읽기 (불필요한 문자 제거)\n",
        "        raw_data = f.read()\n",
        "        cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "        decimal_values = [float(value) for value in cleaned_data.split()]\n",
        "\n",
        "    # 10진수를 16비트 고정소수점 -> 16진수로 변환\n",
        "    hex_values = []\n",
        "    for value in decimal_values:\n",
        "        binary_value = float_to_fixed_point(value)  # 16비트 바이너리 변환\n",
        "        hex_value = binary_to_hex(binary_value)  # 16진수 변환\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for hex_value in hex_values:\n",
        "            f.write(f\"{hex_value}\\n\")\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/softmax_sorted_attention_scores_2.txt'  # 입력 파일\n",
        "output_txt_file = './model/converted_fixed_point_hex.txt'  # 변환된 16진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "decimal_to_fixed_point_hex(input_txt_file, output_txt_file)\n",
        "print(f\"소수점 값이 16비트 16진수 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jaDSmkz7Rmej",
        "outputId": "1be6d348-7a2d-4fe4-b519-52be78856cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소수점 값이 16비트 16진수 값으로 변환되어 ./model/converted_fixed_point_hex.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"각 값의 오차율 (퍼센트):\\n{error_rates}\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "ubtP_IPwR_KR",
        "outputId": "396ebd1f-03c7-4485-af3c-9a8c586109eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "[0.10319686 0.15891993 1.21549359 ... 1.29050385 2.63600683 3.01614112]\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# numpy 배열 전체 출력 설정 (생략 없이)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# ✅ 결과 출력 (10개 단위 줄바꿈)\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "tVsIMaMrF_jQ",
        "outputId": "855f0aa7-b38c-4a0a-b8dd-e81b76459651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "0.103206, 0.158927, 1.215501, 0.733964, 0.507472, 1.533857, 3.413383, 12.008857, 0.839151, 6.068030\n",
            "0.240288, 0.189093, 1.302569, 2.982521, 4.247265, 9.965741, 8.859651, 6.829620, 14.399079, 14.677612\n",
            "0.077202, 0.266250, 0.739506, 0.179681, 0.174592, 2.943618, 3.734500, 5.775100, 6.759188, 11.529057\n",
            "0.034854, 0.007163, 0.175304, 2.328239, 3.818016, 1.110729, 4.095156, 5.265172, 1.014433, 3.946078\n",
            "0.191910, 0.671858, 2.309506, 3.388890, 4.475641, 4.888547, 5.887031, 10.562167, 7.955048, 89.654051\n",
            "0.203095, 0.236846, 0.630939, 1.059059, 2.189915, 0.891696, 0.407620, 0.919960, 1.170337, 2.445823\n",
            "0.410438, 0.056957, 0.678506, 1.378017, 3.047271, 2.278081, 4.424290, 11.248748, 14.503416, 12.823546\n",
            "0.021143, 0.019730, 0.055155, 1.062001, 0.414553, 0.942007, 3.540640, 3.018551, 6.946140, 6.332244\n",
            "0.191522, 1.805454, 2.594647, 0.636354, 5.255114, 5.420617, 17.330821, 11.375242, 47.128488, 74.101476\n",
            "0.331032, 0.479309, 1.564987, 2.697380, 3.898653, 20.652100, 22.607664, 18.002184, 56.899880, 74.903350\n",
            "0.274698, 0.448891, 1.027023, 0.870492, 0.992683, 0.946010, 1.455786, 0.856987, 2.856558, 1.889877\n",
            "0.062781, 0.387353, 0.219916, 0.667246, 0.529696, 1.809541, 2.153334, 1.529868, 1.731424, 6.502030\n",
            "0.246571, 1.817781, 1.138951, 1.810289, 3.359761, 3.018453, 1.152789, 1.489239, 4.621715, 5.320764\n",
            "1.102257, 2.475788, 2.137121, 0.953225, 1.038759, 2.727134, 3.132087, 2.774985, 2.814113, 4.561924\n",
            "0.097595, 0.092857, 0.417154, 0.091581, 0.235224, 0.012551, 1.227160, 0.795145, 5.562565, 3.433373\n",
            "0.415304, 0.644280, 1.128897, 0.610600, 0.345495, 0.796446, 1.301568, 1.260849, 3.526541, 3.652377\n",
            "0.385529, 0.457200, 0.154337, 0.703232, 0.073428, 0.312568, 0.225761, 0.495692, 1.405665, 1.751848\n",
            "0.193181, 0.271650, 0.584096, 0.817963, 0.699693, 0.073229, 0.713557, 0.093551, 1.468368, 2.213586\n",
            "0.042122, 0.237544, 0.068073, 0.354721, 0.119516, 0.078059, 0.568548, 0.236287, 0.897523, 0.217325\n",
            "0.151536, 0.097048, 0.158573, 0.546848, 0.097782, 0.649704, 2.280149, 1.457457, 1.907130, 3.994053\n",
            "1.184344, 0.703642, 1.130072, 1.060552, 24.650387, 23.211392, 94.350088, 93.306302, 87.791108, 82.164221\n",
            "0.432279, 0.790367, 2.874411, 1.925386, 2.724985, 4.513752, 9.592924, 9.980604, 11.612946, 8.612562\n",
            "0.405579, 0.161764, 0.310110, 0.334435, 1.035306, 4.576345, 1.488113, 1.717219, 3.967875, 0.967404\n",
            "0.293232, 0.577403, 0.842813, 2.928671, 1.949986, 7.781354, 19.622882, 8.848772, 14.417244, 36.616120\n",
            "0.787453, 0.855977, 1.224391, 1.782424, 1.874871, 5.860452, 21.172864, 19.788297, 85.688500, 83.719890\n",
            "0.051488, 0.341000, 0.020586, 0.444327, 7.936935, 6.445383, 10.801468, 5.209369, 12.778003, 15.116360\n",
            "0.176629, 0.118977, 0.236974, 1.015848, 1.367025, 0.884451, 0.111940, 1.376518, 1.703489, 1.256137\n",
            "0.005654, 0.294161, 0.578559, 0.266571, 0.795212, 1.071014, 1.336016, 3.947270, 1.319059, 1.145361\n",
            "0.783024, 1.336027, 2.042170, 1.880340, 3.297489, 2.455539, 4.797396, 6.687014, 10.566931, 20.671811\n",
            "0.053423, 0.212018, 0.186598, 0.807693, 3.255134, 11.043549, 5.878212, 11.583434, 10.269138, 23.779460\n",
            "0.066511, 0.501135, 0.474190, 0.622122, 0.639316, 0.133971, 1.879919, 0.914864, 0.248854, 1.562643\n",
            "0.229305, 1.266110, 0.423118, 1.329629, 0.446866, 0.982166, 3.230000, 2.923061, 8.052544, 15.176032\n",
            "0.101526, 0.003159, 0.514559, 0.357289, 0.281097, 0.458822, 0.300877, 0.326388, 2.094487, 2.886873\n",
            "0.096345, 0.016577, 0.659301, 0.851624, 0.242767, 2.164749, 2.105163, 2.387871, 2.715954, 3.173872\n",
            "0.252959, 0.064685, 0.426453, 0.276324, 0.296572, 1.265646, 1.025071, 1.793559, 1.262173, 6.622526\n",
            "0.738672, 0.574853, 0.741431, 0.589182, 2.411063, 0.576041, 0.774255, 0.864021, 0.158393, 1.616749\n",
            "0.843705, 0.804722, 0.491887, 0.661643, 1.949476, 1.043461, 1.389857, 2.245610, 2.308960, 1.836512\n",
            "1.309651, 1.518127, 0.220322, 2.051259, 2.080743, 1.963211, 1.239170, 2.759825, 2.380464, 5.079273\n",
            "0.627974, 0.592783, 0.258063, 0.272485, 0.047152, 0.607905, 0.736086, 1.300527, 0.415517, 1.844928\n",
            "0.227142, 0.066389, 0.312201, 0.327701, 0.086681, 0.458414, 0.636317, 0.870473, 0.819659, 3.059972\n",
            "0.796858, 1.032572, 4.056073, 12.250491, 26.606014, 92.829264, 91.615979, 91.281783, 87.515757, 87.513810\n",
            "0.546041, 2.260281, 0.456575, 5.454661, 27.041588, 24.922320, 18.981890, 94.396544, 89.037883, 84.276332\n",
            "0.123443, 0.249319, 0.481511, 0.336988, 0.562190, 0.539560, 2.229219, 2.422561, 3.326762, 6.583524\n",
            "0.062081, 2.876130, 4.303209, 8.465621, 11.919057, 35.484992, 38.777691, 84.999733, 81.394842, 81.214824\n",
            "0.169068, 0.041881, 0.348335, 0.616272, 0.487697, 1.800190, 6.913104, 9.813840, 8.250188, 37.328214\n",
            "0.359624, 0.076450, 1.141135, 2.969233, 2.377376, 4.163078, 3.477700, 5.512677, 11.655913, 23.162195\n",
            "0.109597, 0.072825, 1.660660, 0.300559, 2.164296, 1.833967, 1.174319, 0.959431, 6.119311, 6.687260\n",
            "0.219750, 0.167530, 0.084734, 0.042921, 0.057702, 0.237985, 0.115844, 2.120763, 0.226949, 0.628807\n",
            "0.170215, 1.296634, 2.101194, 2.669643, 0.570070, 18.165154, 8.987213, 11.495473, 22.797721, 62.034849\n",
            "0.931181, 3.265854, 1.589529, 1.312104, 1.019117, 1.532281, 3.696638, 14.567501, 42.942068, 42.090647\n",
            "0.245436, 4.646394, 22.933087, 21.384806, 18.017618, 13.999190, 28.210699, 93.077639, 91.687656, 91.682616\n",
            "0.517656, 0.321295, 0.229031, 0.424514, 0.317107, 1.725388, 2.794502, 2.759374, 5.797262, 15.345251\n",
            "0.154744, 0.207782, 1.207706, 0.576116, 2.076452, 2.798437, 5.498776, 7.677348, 13.146041, 58.683840\n",
            "0.028444, 0.059367, 0.807372, 1.070101, 0.577934, 1.211906, 0.687408, 0.962455, 4.070542, 67.848316\n",
            "0.380104, 0.099907, 0.073804, 0.471283, 0.540047, 2.039735, 2.662209, 17.057563, 19.853111, 38.281420\n",
            "0.423145, 0.167225, 0.664021, 0.811629, 0.825789, 0.760956, 0.560010, 0.372906, 2.836106, 14.828559\n",
            "0.622791, 0.954990, 0.786529, 0.872025, 0.960014, 0.361418, 1.768467, 1.729422, 1.173899, 13.937369\n",
            "0.000039, 0.197349, 0.727435, 1.290531, 0.939761, 0.112885, 1.667220, 3.146075, 4.781748, 18.246267\n",
            "0.527626, 0.102524, 0.702689, 0.056159, 0.728560, 0.757152, 0.283765, 0.866768, 1.362577, 6.279150\n",
            "0.366711, 2.001191, 0.804206, 3.116442, 2.524292, 1.680599, 2.969670, 5.928121, 6.489516, 83.981905\n",
            "0.863836, 1.167413, 0.070322, 4.336503, 4.815901, 5.568510, 6.902037, 11.784306, 12.093438, 21.896195\n",
            "0.035982, 0.743484, 0.165803, 0.015657, 0.526100, 0.037114, 0.144532, 1.617405, 2.044507, 0.230635\n",
            "0.206031, 0.441301, 0.093885, 0.333040, 0.868907, 0.438508, 0.316088, 1.020204, 0.931416, 3.110178\n",
            "0.168512, 0.033665, 0.136130, 0.019130, 0.036180, 0.006908, 0.590395, 0.477428, 0.056890, 2.969139\n",
            "0.210656, 0.033641, 0.779353, 0.834295, 1.314159, 1.287862, 0.373252, 2.634158, 8.360290, 6.751445\n",
            "0.156034, 0.183354, 0.463034, 2.141691, 3.327751, 0.149336, 1.753751, 3.609779, 6.255866, 7.157380\n",
            "0.533126, 0.266041, 0.275958, 0.517089, 0.516301, 0.251909, 1.125342, 0.697403, 1.567475, 0.992347\n",
            "0.046319, 0.228859, 0.008304, 0.314725, 0.717844, 0.692835, 0.415618, 1.213685, 0.913272, 0.919381\n",
            "0.117861, 0.359600, 0.078616, 0.552240, 0.534998, 1.429837, 0.094996, 0.400171, 1.053957, 0.436993\n",
            "0.344494, 0.348408, 0.991379, 3.419812, 4.399097, 7.161752, 8.488000, 6.740427, 12.223583, 20.922950\n",
            "0.558695, 0.148143, 0.071114, 0.149718, 0.317063, 0.179338, 0.108717, 0.483191, 0.812932, 1.134000\n",
            "0.011183, 0.024770, 0.009541, 0.592889, 0.077503, 0.417831, 1.003622, 0.505084, 0.301279, 0.180708\n",
            "0.114017, 0.455213, 0.054445, 0.329945, 0.290059, 0.480956, 0.770469, 0.115234, 0.008886, 3.166911\n",
            "0.073089, 0.437321, 0.668455, 0.573211, 0.940139, 0.857785, 0.614752, 0.334926, 1.672162, 1.014383\n",
            "0.548874, 0.611216, 0.096562, 0.312160, 0.185632, 0.378335, 0.853520, 0.265449, 0.157663, 6.970034\n",
            "0.824017, 0.527592, 0.851043, 0.745730, 1.071662, 1.591984, 0.550883, 0.075003, 2.466098, 0.782892\n",
            "0.244559, 0.014520, 0.048257, 0.486476, 0.440821, 0.541378, 0.361485, 0.063068, 0.621602, 0.002304\n",
            "0.318872, 0.103052, 0.016480, 0.062360, 0.071302, 0.424100, 0.247712, 0.257510, 1.023789, 0.349366\n",
            "0.219150, 0.140841, 0.246387, 0.092658, 0.626185, 0.381989, 0.192945, 0.507660, 0.227288, 0.456833\n",
            "1.204214, 0.426919, 4.155084, 0.491543, 1.306030, 1.083575, 1.681547, 0.439514, 0.363056, 1.213205\n",
            "0.218056, 0.431523, 0.142385, 1.669288, 1.359662, 3.184738, 2.916192, 3.379215, 3.633211, 2.713353\n",
            "0.262536, 0.032258, 0.208141, 1.003597, 3.834181, 1.387157, 0.266232, 1.875047, 0.568937, 18.255548\n",
            "0.254340, 0.666638, 0.840053, 2.770895, 0.385933, 0.787739, 0.099017, 0.427245, 0.237475, 0.611925\n",
            "0.408351, 1.288178, 4.925868, 1.059313, 0.028957, 3.488861, 10.124351, 14.916512, 10.285349, 69.830066\n",
            "0.388568, 0.897374, 0.865034, 0.086891, 2.028254, 2.682642, 2.001372, 3.121955, 2.360922, 2.392936\n",
            "0.206478, 0.193523, 0.206566, 1.423894, 0.009648, 1.908535, 1.153576, 1.045758, 4.082284, 11.753719\n",
            "0.780936, 0.676983, 1.099621, 1.489610, 1.219695, 1.237714, 0.049194, 1.588486, 2.112983, 4.746946\n",
            "0.014691, 0.600197, 1.409248, 0.570266, 4.720717, 5.288237, 5.073504, 4.397010, 7.489102, 14.714657\n",
            "2.303392, 0.968488, 0.585967, 1.986059, 0.059790, 2.782453, 0.318102, 0.855412, 2.680803, 5.896658\n",
            "0.600618, 0.537754, 1.363609, 0.060493, 1.579412, 0.187863, 1.614256, 1.922170, 2.719231, 3.965367\n",
            "0.210688, 0.417367, 0.753893, 0.769377, 0.462530, 1.522818, 2.356690, 3.945153, 3.783729, 86.052815\n",
            "1.020891, 0.439493, 1.132793, 2.699522, 0.557453, 1.478916, 1.684458, 1.190669, 2.651454, 12.606928\n",
            "0.193775, 0.324706, 0.562330, 0.480862, 0.260714, 0.130492, 0.100087, 1.710195, 1.910018, 5.237924\n",
            "0.643735, 0.661462, 2.859351, 1.082776, 1.623257, 0.772945, 0.582574, 0.619919, 2.301222, 3.019492\n",
            "0.216350, 0.107811, 0.649304, 0.019822, 1.025928, 0.408015, 0.062394, 5.994908, 3.812127, 3.763095\n",
            "0.029198, 0.580047, 0.703590, 0.622662, 0.832133, 0.948356, 0.613915, 1.740616, 3.154172, 3.514047\n",
            "0.024474, 0.154934, 0.233919, 0.423817, 0.132544, 0.692058, 0.529628, 1.189488, 1.805302, 4.599764\n",
            "0.143371, 0.098772, 0.076496, 0.348565, 0.447581, 0.274405, 0.704175, 0.500654, 2.079324, 10.511618\n",
            "0.668406, 1.089022, 0.207198, 2.650824, 0.280009, 0.823676, 0.627735, 3.097175, 3.953490, 13.738286\n",
            "0.479047, 0.085927, 0.022716, 0.659599, 0.215151, 0.119702, 0.304355, 0.964403, 1.276046, 7.864061\n",
            "0.012473, 4.730549, 4.657975, 7.890153, 9.948673, 9.855934, 12.421015, 18.188542, 21.463191, 34.807867\n",
            "0.332287, 0.332730, 0.170757, 0.055432, 0.138546, 0.883383, 0.685813, 0.092962, 1.201517, 2.029654\n",
            "0.132423, 0.551276, 0.534917, 0.058487, 0.001198, 0.723346, 1.341409, 1.195173, 1.464661, 1.022803\n",
            "0.273954, 0.566334, 1.080638, 1.085022, 0.450782, 1.003310, 0.973046, 0.852982, 1.107727, 1.819035\n",
            "0.518231, 0.175016, 0.125983, 0.651601, 1.713966, 1.292916, 1.330916, 1.830660, 6.155196, 10.225113\n",
            "0.162827, 0.316774, 0.828311, 0.843955, 2.063432, 3.174975, 3.769018, 3.190945, 2.289238, 7.616073\n",
            "0.085843, 0.228007, 0.335191, 0.447985, 0.148297, 0.868862, 0.848746, 2.329140, 0.972899, 1.392312\n",
            "0.199222, 1.210353, 1.153166, 0.139095, 0.936935, 4.022444, 3.731139, 5.503381, 2.174783, 7.336281\n",
            "0.112970, 0.211061, 0.537419, 0.231456, 0.018464, 0.495623, 0.505657, 0.273503, 0.616214, 1.875721\n",
            "0.070915, 0.123567, 0.539569, 4.762871, 3.117267, 3.284080, 6.762047, 3.774840, 1.646281, 1.089498\n",
            "0.228429, 0.431515, 0.611843, 3.296163, 2.018090, 3.668872, 5.613605, 5.258296, 1.990650, 1.937307\n",
            "0.052530, 0.734544, 1.608364, 10.463649, 22.024127, 20.986254, 28.394200, 41.212014, 50.155751, 86.124078\n",
            "0.722964, 0.875637, 0.196507, 0.953518, 4.448602, 10.268259, 15.104295, 9.303403, 23.153794, 31.115898\n",
            "0.422006, 0.268064, 1.680421, 3.963331, 5.466418, 4.861124, 9.069547, 11.420982, 12.509114, 16.116636\n",
            "0.523120, 2.313167, 6.447170, 7.817007, 7.711091, 1.279789, 3.735893, 6.955858, 5.867991, 92.508842\n",
            "0.089736, 0.249933, 1.097305, 2.797535, 4.022958, 7.534884, 7.353232, 9.721592, 6.823546, 6.021377\n",
            "0.494583, 0.234592, 0.382295, 0.076246, 0.383088, 1.080493, 2.734588, 0.138718, 2.918373, 5.073212\n",
            "0.073669, 3.637201, 7.122340, 6.854615, 10.159615, 17.632631, 13.624649, 39.578524, 38.949174, 25.171294\n",
            "0.169677, 0.486020, 0.181811, 0.930806, 1.720091, 1.997235, 2.283721, 1.566672, 5.709112, 12.294217\n",
            "0.028013, 0.092663, 1.851321, 1.644530, 3.100394, 4.375019, 2.553126, 1.290504, 2.636007, 3.016141\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 5.316387\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2, output_file):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 오차율을 계산하고 저장.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "    output_file: 오차율 결과를 저장할 파일 경로\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 오차율 결과를 TXT 파일로 저장\n",
        "    np.savetxt(output_file, error_rates, fmt=\"%.6f\", delimiter=\"\\n\")\n",
        "\n",
        "    # ✅ 전체 평균 및 최대 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)\n",
        "\n",
        "    return mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'\n",
        "file2_path = './model/cordic_dec_val.txt'\n",
        "output_file = './model/error_rates_output.txt'  # 저장할 파일\n",
        "\n",
        "# ✅ 함수 실행 (오차율 계산 및 저장)\n",
        "mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path, output_file)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"오차율 결과가 '{output_file}'에 저장되었습니다!\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "FlxQvesTKOA6",
        "outputId": "8828c4cd-f177-4bd3-f458-f10e2eda2748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차율 결과가 './model/error_rates_output.txt'에 저장되었습니다!\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_values_from_files(file1, file2, section):\n",
        "    \"\"\"\n",
        "    두 파일에서 section 값(1부터 시작)을 기준으로 10개 단위의 값을 가져와 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "    section: 출력할 10개 단위의 번호 (1부터 시작)\n",
        "\n",
        "    출력:\n",
        "    - 두 파일에서 해당 범위의 10개 값을 한 줄씩 출력\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 데이터 읽기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 시작 및 끝 인덱스 계산\n",
        "    start_idx = (section - 1) * 10\n",
        "    end_idx = start_idx + 10\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    if start_idx >= len(values1) or start_idx >= len(values2):\n",
        "        raise ValueError(f\"입력한 section={section}이 데이터 길이를 초과했습니다.\")\n",
        "\n",
        "    # 해당 구간의 데이터 추출\n",
        "    extracted_values1 = values1[start_idx:end_idx]\n",
        "    extracted_values2 = values2[start_idx:end_idx]\n",
        "\n",
        "    # 출력\n",
        "    print(f\"파일1 ({file1}) [{start_idx + 1}~{min(end_idx, len(values1))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values1))\n",
        "\n",
        "    print(f\"\\n파일2 ({file2}) [{start_idx + 1}~{min(end_idx, len(values2))}]:\")\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in extracted_values2))\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_attention_scores_2.txt'\n",
        "file2_path = './model/cordic_dec_val.txt'\n",
        "\n",
        "# ✅ section 번호 입력\n",
        "section_number = 42  # 원하는 section 값 입력 (1부터 시작)\n",
        "\n",
        "# 함수 실행\n",
        "extract_values_from_files(file1_path, file2_path, section_number)\n"
      ],
      "metadata": {
        "id": "6iGJh7Z_Imbo",
        "outputId": "ea83fb4d-ca22-4a39-d9ef-9f1e452cd6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일1 (./model/sorted_attention_scores_2.txt) [411~420]:\n",
            "6.097168, 4.062114, 4.010491, 3.351764, 2.641553, 2.550399, 2.474250, 1.711552, 1.040489, 0.679768\n",
            "\n",
            "파일2 (./model/cordic_dec_val.txt) [411~420]:\n",
            "0.695801, 0.089355, 0.086426, 0.042480, 0.016113, 0.015137, 0.015137, 0.000488, 0.000488, 0.000488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 1대1 오차율을 계산하고,\n",
        "    정수 부분별 개수를 세어 출력하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    - 오차율 정수 부분별 개수\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 불일치 예외 처리\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    # ✅ 오차율의 정수 부분 개수 세기\n",
        "    integer_parts = [int(x) for x in error_rates]  # 정수 부분만 추출\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "    sorted_counts = sorted(count_dict.items())  # 키(정수 부분) 기준 정렬\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index, sorted_counts\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/sorted_SM_bert_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val_02_11.txt'  # 두 번째 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "error_rates, mean_error_rate, max_error, max_error_index, sorted_counts = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 오차율 10개 단위 출력\n",
        "print(\"각 값의 오차율 (퍼센트):\")\n",
        "for i in range(0, len(error_rates), 10):\n",
        "    print(\", \".join(f\"{x:.6f}\" for x in error_rates[i:i+10]))  # 10개 단위로 출력\n",
        "\n",
        "# ✅ 전체 평균 및 최대 오차율 출력\n",
        "print(f\"\\n전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n",
        "\n",
        "# ✅ 오차율 정수 부분 개수 출력\n",
        "print(\"\\n오차율 정수 부분 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "t7FLq284LuIe",
        "outputId": "751585ab-f39d-4ba7-86f4-c8106588ae2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "0.103197, 0.158920, 1.215494, 0.733964, 0.507472, 1.533857, 3.413383, 12.008857, 0.839151, 6.068030\n",
            "0.240297, 0.189093, 1.302581, 2.982521, 4.247265, 9.965741, 8.859651, 6.829620, 14.399079, 14.677612\n",
            "0.077202, 0.266254, 0.739496, 0.179681, 0.174592, 2.943648, 3.734500, 5.775061, 6.759188, 11.529057\n",
            "0.034847, 0.007182, 0.175317, 2.328239, 3.818016, 1.110729, 4.095066, 5.265172, 1.014433, 3.946078\n",
            "0.191927, 0.671869, 2.309529, 3.388904, 4.475655, 4.888571, 5.887059, 10.562167, 7.955048, 89.654051\n",
            "0.203086, 0.236856, 0.630939, 1.059059, 2.189915, 0.891696, 0.407602, 0.919941, 1.170337, 2.445823\n",
            "0.410430, 0.056969, 0.678516, 1.378017, 3.047289, 2.278100, 4.424290, 11.248748, 14.503416, 12.823546\n",
            "0.021143, 0.019726, 0.568235, 1.062001, 0.414543, 0.942007, 7.323325, 6.821745, 12.263552, 6.332244\n",
            "0.191522, 1.805454, 2.594647, 0.636354, 5.255133, 5.420617, 17.330821, 11.375242, 47.128488, 74.101476\n",
            "0.331032, 0.479319, 1.564987, 2.697380, 3.898653, 20.652100, 22.607664, 18.002184, 56.899880, 74.903350\n",
            "0.274705, 0.448905, 1.027005, 0.870512, 0.992683, 0.946021, 1.455801, 0.857005, 2.856585, 1.889877\n",
            "0.062781, 0.387353, 0.219916, 0.667256, 0.529696, 1.809541, 2.153334, 1.529868, 1.731424, 6.502030\n",
            "0.246583, 1.817803, 1.138960, 1.810300, 3.359786, 3.018466, 1.152789, 1.489256, 4.621715, 5.320764\n",
            "1.102257, 2.475788, 2.137111, 0.953237, 1.038759, 2.727134, 3.132087, 2.774970, 2.814113, 4.561903\n",
            "0.097584, 0.092863, 0.417148, 0.091581, 0.235233, 0.012540, 1.227160, 0.795145, 5.562565, 3.433373\n",
            "0.415304, 0.644272, 1.128897, 0.610600, 0.345503, 0.796446, 1.301568, 1.260849, 3.526541, 3.652377\n",
            "0.385523, 0.457200, 0.154347, 0.703232, 0.073418, 0.312579, 0.225749, 0.495692, 1.405650, 1.751848\n",
            "0.193181, 0.271658, 0.584096, 0.817963, 0.699703, 0.073229, 0.713557, 0.093551, 1.468368, 2.213586\n",
            "0.042122, 0.237522, 0.068082, 0.354730, 0.119526, 0.078069, 0.568548, 0.236287, 0.897504, 0.217325\n",
            "0.151541, 0.097048, 0.158565, 0.546840, 0.097773, 0.649704, 2.280134, 1.457440, 1.907110, 3.994053\n",
            "1.184344, 0.703642, 1.130059, 1.060541, 24.650387, 23.211392, 94.350088, 93.306302, 87.791108, 82.164221\n",
            "0.209283, 0.790367, 2.874423, 1.925386, 2.724985, 4.513752, 9.592924, 9.980604, 11.612946, 8.612562\n",
            "0.405579, 0.161764, 0.310098, 0.334435, 1.035306, 4.576345, 1.488113, 1.717219, 3.967875, 0.967404\n",
            "0.229583, 1.987667, 0.842799, 5.325493, 9.396823, 7.781391, 19.622882, 8.848772, 36.743181, 50.701496\n",
            "0.787461, 0.855966, 1.224408, 1.782441, 1.874871, 5.860452, 21.172864, 19.788297, 85.688500, 83.719890\n",
            "0.318648, 0.340988, 0.020586, 0.444319, 7.936935, 6.445383, 10.801508, 5.209433, 12.778003, 15.116360\n",
            "0.176617, 0.118965, 0.236974, 1.015848, 1.367011, 0.884451, 0.111940, 1.376518, 1.703489, 1.256137\n",
            "0.005670, 0.294144, 0.578545, 0.266562, 0.795201, 1.070991, 1.336001, 3.947287, 1.319039, 1.145340\n",
            "0.783024, 1.336027, 2.042162, 1.880340, 3.297489, 2.455539, 4.797396, 6.687014, 10.566931, 20.671811\n",
            "0.053423, 0.212018, 0.186598, 0.807693, 3.255134, 11.043549, 5.878212, 11.583434, 10.269138, 23.779460\n",
            "0.066516, 0.501149, 0.474197, 0.622122, 0.639316, 0.133981, 1.879934, 0.914847, 0.248854, 1.562643\n",
            "0.029041, 1.266120, 1.535720, 1.329629, 1.748214, 0.982182, 3.230020, 2.923061, 8.052544, 26.485896\n",
            "0.101526, 0.003146, 0.514552, 0.357297, 0.281097, 0.458822, 0.300877, 0.326388, 2.094487, 2.886873\n",
            "0.310582, 0.016587, 0.659313, 0.851632, 0.242767, 2.164749, 0.198245, 2.387871, 2.715996, 3.173922\n",
            "0.252959, 0.064699, 0.426453, 0.276324, 0.296572, 1.265661, 1.025071, 1.793559, 4.726657, 17.608110\n",
            "0.738672, 0.574866, 0.741431, 0.589192, 2.411063, 0.576041, 0.774269, 0.864021, 0.158393, 1.616749\n",
            "0.843705, 0.804722, 1.166512, 1.339721, 1.949484, 1.043439, 1.389857, 2.245638, 5.225111, 1.836512\n",
            "1.309651, 1.518127, 0.220322, 2.051259, 2.080743, 1.963198, 1.239170, 2.759825, 2.380464, 5.079273\n",
            "0.627974, 0.592768, 0.258054, 0.272485, 0.047152, 0.607905, 0.736098, 1.300514, 0.415529, 1.844928\n",
            "0.227136, 0.066375, 0.312201, 0.327693, 0.086690, 0.458414, 0.636317, 0.870473, 0.819659, 3.059972\n",
            "0.796858, 1.032572, 4.056073, 12.250523, 26.606014, 92.829264, 91.615979, 91.281783, 87.515757, 87.513810\n",
            "0.546035, 2.260260, 0.456564, 5.454640, 27.041555, 24.922283, 18.981890, 94.396544, 89.037883, 84.276332\n",
            "0.123450, 0.249334, 0.481492, 0.336988, 0.562179, 0.539548, 2.229204, 2.422561, 3.326738, 6.583524\n",
            "0.062093, 2.876117, 4.303209, 8.465621, 11.919006, 35.484992, 38.777691, 84.999733, 81.394842, 81.214824\n",
            "0.169068, 0.041898, 0.348322, 0.616272, 0.487697, 1.800190, 6.913104, 9.813840, 8.250188, 37.328214\n",
            "0.359624, 0.076459, 1.141135, 2.969233, 2.377376, 4.163078, 3.477700, 5.512677, 11.655913, 23.162195\n",
            "0.109597, 0.072829, 1.660660, 0.300570, 2.164296, 1.833967, 1.174319, 0.959431, 6.119311, 6.687206\n",
            "0.219736, 0.167545, 0.084747, 0.042934, 0.057702, 0.237985, 0.115844, 2.120763, 0.226949, 0.628807\n",
            "0.170215, 1.296634, 2.101194, 2.669643, 0.570092, 18.165154, 8.987213, 11.495473, 22.797721, 62.034849\n",
            "0.931181, 3.265842, 1.589529, 1.312104, 1.019106, 1.532281, 3.696638, 14.567501, 42.942068, 42.090647\n",
            "0.245448, 4.646394, 22.933087, 21.384806, 18.017618, 13.999190, 28.210699, 93.077629, 91.687656, 91.682616\n",
            "0.517656, 0.321295, 0.229031, 0.424505, 0.317117, 1.725388, 2.794502, 2.759374, 5.797262, 15.345251\n",
            "0.154744, 0.207773, 1.207706, 0.576130, 2.076452, 2.798437, 5.498776, 7.677348, 13.146041, 58.683840\n",
            "0.028444, 0.059367, 0.807372, 1.070101, 0.577944, 1.211906, 0.687408, 0.962455, 4.070542, 67.848316\n",
            "0.380104, 0.099907, 0.073810, 0.471298, 0.540047, 2.039735, 2.662209, 17.057563, 19.853111, 38.281420\n",
            "0.423145, 0.944133, 0.664012, 0.811629, 0.825798, 0.760956, 1.894775, 0.372906, 2.836106, 33.755544\n",
            "0.622784, 0.954976, 0.786508, 0.872019, 0.960014, 0.361398, 1.768479, 1.729379, 1.173874, 13.937369\n",
            "0.000039, 0.197345, 0.727435, 1.290524, 0.939761, 0.112885, 1.667220, 3.146075, 4.781711, 18.246267\n",
            "0.527645, 0.102545, 0.702697, 0.056175, 0.728570, 0.757174, 0.283776, 0.866768, 1.362604, 6.279150\n",
            "0.366711, 2.001171, 0.804206, 3.116428, 2.524292, 1.680599, 2.969670, 5.928121, 6.489516, 83.981905\n",
            "0.542114, 1.549744, 0.070330, 4.336480, 7.744642, 8.566308, 10.415168, 15.887362, 17.764830, 21.896195\n",
            "0.035982, 0.743484, 0.165803, 0.015657, 0.526090, 0.938858, 0.904112, 1.617405, 6.600577, 0.230635\n",
            "0.328385, 0.441287, 0.093864, 0.333026, 0.868897, 0.438487, 0.316088, 1.020189, 3.888688, 3.110178\n",
            "0.168517, 0.033671, 0.136142, 0.019122, 0.036189, 0.006908, 0.590395, 0.477428, 0.056890, 2.969139\n",
            "0.210645, 0.033641, 0.779331, 0.834295, 1.314145, 1.287877, 0.373252, 2.634158, 8.360290, 6.751445\n",
            "0.156034, 0.134185, 0.463034, 2.141691, 3.327751, 3.364676, 5.763802, 8.093046, 13.199877, 14.584789\n",
            "0.082767, 0.266054, 0.275966, 0.517089, 0.516301, 0.251919, 0.058786, 0.697403, 0.174694, 0.992347\n",
            "0.046330, 0.228865, 0.008304, 0.314725, 0.717844, 0.692847, 0.415632, 1.213685, 0.913272, 0.919404\n",
            "0.117861, 0.359600, 0.078616, 0.552250, 0.534998, 1.429837, 0.094996, 0.400171, 1.053957, 0.436973\n",
            "0.344494, 0.348408, 0.991365, 3.419812, 4.399062, 7.161752, 8.487958, 6.740427, 12.223583, 20.922950\n",
            "0.558695, 0.148161, 0.071114, 0.149727, 0.317054, 0.179338, 0.108717, 0.483203, 0.812959, 1.134000\n",
            "0.011188, 0.024789, 0.742086, 0.592899, 0.959590, 0.417844, 1.003652, 0.505100, 0.301279, 0.180689\n",
            "0.114017, 0.455213, 0.054431, 0.329955, 0.290059, 0.480968, 0.770469, 0.115234, 0.008902, 3.166871\n",
            "0.073094, 0.437340, 0.668462, 0.573230, 0.940139, 0.857799, 0.614752, 0.334926, 1.672162, 1.014402\n",
            "0.548874, 0.611216, 0.096562, 0.312168, 0.185651, 0.378354, 0.853520, 0.265449, 0.157675, 6.970034\n",
            "0.005924, 0.527583, 0.851034, 0.745712, 0.142738, 0.572202, 0.536003, 1.168730, 3.585958, 0.782879\n",
            "0.265601, 0.014520, 0.048267, 0.611748, 0.694126, 0.541378, 0.361498, 0.063053, 0.621602, 1.479227\n",
            "0.318860, 0.103052, 0.016480, 0.062344, 0.071302, 0.424090, 0.247724, 0.257534, 1.023789, 0.349366\n",
            "0.966573, 0.140832, 0.246397, 0.092649, 0.626185, 0.381989, 0.192934, 0.507660, 0.227288, 0.822872\n",
            "1.204230, 0.426937, 4.155074, 0.491563, 1.306040, 1.083575, 1.681558, 0.439524, 0.363056, 1.213205\n",
            "0.218044, 0.431536, 0.142371, 1.669273, 1.359645, 3.184738, 2.916192, 3.379190, 3.633211, 2.713353\n",
            "0.262557, 0.032276, 0.208116, 1.003585, 3.834181, 1.387132, 0.266232, 1.875047, 0.568872, 18.255548\n",
            "0.254340, 0.666638, 0.840053, 2.770895, 0.385933, 0.787739, 0.099046, 0.427245, 0.237475, 0.611925\n",
            "0.408343, 1.288168, 4.925868, 1.059301, 0.028957, 3.488861, 10.124351, 14.916470, 10.285349, 69.830066\n",
            "0.163734, 0.106022, 1.723345, 1.167033, 3.379588, 5.210365, 4.686266, 6.013838, 2.360922, 6.220628\n",
            "0.206478, 0.193528, 0.206558, 1.423894, 0.009648, 1.908549, 1.153557, 1.045758, 4.082284, 11.753719\n",
            "0.395619, 0.042331, 0.144062, 0.490508, 0.140140, 0.109002, 0.049194, 1.664787, 0.349236, 0.472400\n",
            "0.014699, 0.600186, 1.409241, 0.570256, 4.720717, 5.288237, 5.073504, 4.396979, 7.489102, 14.714657\n",
            "2.303373, 0.968512, 0.585986, 1.986080, 0.059823, 2.782482, 0.318102, 0.855433, 2.680803, 5.896658\n",
            "0.600618, 0.537754, 1.363609, 0.060493, 1.579399, 0.187863, 1.614240, 1.922148, 2.719231, 3.965341\n",
            "0.210681, 0.417376, 0.753893, 0.769377, 0.462520, 1.522807, 2.356690, 3.945153, 3.783751, 86.052815\n",
            "1.020891, 0.439493, 1.132786, 2.699531, 0.557453, 1.478916, 1.684458, 1.190669, 2.651454, 12.606928\n",
            "0.193780, 0.324691, 0.562322, 0.480852, 0.260714, 0.130503, 0.100087, 1.710195, 1.910018, 5.237856\n",
            "0.643739, 0.661462, 2.859351, 1.082793, 1.623257, 0.772962, 0.582574, 0.619942, 2.301245, 3.019492\n",
            "0.216350, 0.107811, 0.649304, 0.019812, 1.025918, 0.408015, 0.062410, 5.994908, 3.812127, 3.763095\n",
            "0.029198, 0.580063, 0.703590, 0.622662, 0.832133, 0.948356, 0.613915, 1.740616, 3.154199, 3.514047\n",
            "0.024479, 0.154934, 0.233925, 0.423809, 0.132552, 0.692081, 0.529628, 1.189488, 1.805302, 4.599820\n",
            "0.264554, 0.098759, 0.076489, 0.463998, 0.447590, 0.274417, 0.704187, 0.500654, 2.079324, 10.511618\n",
            "0.668406, 1.089022, 0.207198, 2.650824, 1.121528, 0.823666, 0.627735, 3.097175, 3.953490, 13.738286\n",
            "0.479047, 0.085934, 0.022716, 0.659599, 0.215161, 0.119702, 0.304343, 0.964403, 1.276046, 7.864061\n",
            "0.012466, 6.121357, 6.849746, 11.122077, 13.480098, 13.691852, 16.693161, 23.830711, 27.746135, 43.500152\n",
            "0.332287, 0.332730, 0.170765, 0.055424, 0.138546, 0.883383, 0.685827, 0.092976, 1.201535, 2.029654\n",
            "0.132413, 0.551276, 0.534917, 0.058478, 0.001207, 0.723356, 1.341419, 1.195190, 1.464687, 1.022829\n",
            "0.273954, 0.566334, 1.080638, 1.085022, 0.450782, 1.003322, 0.973046, 0.852982, 1.107727, 1.819035\n",
            "0.518231, 0.175004, 0.125990, 0.651594, 1.713966, 1.292902, 1.330916, 1.830660, 6.155196, 10.225113\n",
            "0.051186, 0.328425, 0.037817, 0.742558, 0.232823, 0.841842, 1.269512, 3.190945, 2.289238, 7.616073\n",
            "0.085843, 0.228007, 0.335183, 0.447985, 0.148297, 0.868862, 0.848746, 2.329113, 0.972899, 1.392312\n",
            "0.199222, 1.210346, 1.153180, 0.139103, 0.936925, 4.022444, 3.731115, 5.503381, 2.174783, 7.336281\n",
            "0.112970, 0.211061, 0.537435, 0.231456, 0.018464, 0.495623, 0.505657, 0.273503, 0.616214, 1.875721\n",
            "0.070930, 0.123552, 0.539585, 4.762910, 3.117291, 3.284080, 6.762047, 3.774870, 1.646281, 1.089532\n",
            "0.228441, 0.431510, 0.611843, 3.296163, 2.018090, 3.668849, 5.613605, 5.258296, 1.990650, 1.937271\n",
            "0.052530, 0.734544, 1.608374, 10.463649, 22.024127, 20.986254, 28.394200, 41.212014, 50.155751, 86.124078\n",
            "0.722964, 0.875637, 0.196507, 0.953529, 4.448602, 10.268259, 15.104295, 9.303403, 23.153794, 31.115898\n",
            "0.250155, 0.268064, 1.680409, 3.963313, 5.466400, 4.861124, 9.069511, 11.420982, 12.509114, 16.116636\n",
            "0.523120, 2.313167, 6.447170, 7.817029, 7.711091, 1.279789, 3.735893, 6.955858, 5.867991, 92.508842\n",
            "0.089721, 0.249933, 1.097326, 2.797535, 4.022958, 7.534884, 7.353277, 9.721592, 6.823546, 6.021377\n",
            "0.494574, 0.234580, 0.382295, 0.076246, 0.383088, 1.080471, 2.734588, 0.138685, 2.918373, 5.073212\n",
            "0.073669, 3.637201, 7.122340, 6.854615, 10.159615, 17.632631, 13.624649, 39.578524, 38.949174, 25.171294\n",
            "0.169672, 0.486004, 0.181811, 0.930806, 1.720111, 1.997235, 2.283745, 1.566672, 5.709112, 12.294280\n",
            "0.028013, 0.092658, 1.851321, 1.644530, 3.100394, 4.375019, 2.553126, 1.290504, 2.636007, 3.016141\n",
            "\n",
            "전체 평균 오차율 (퍼센트): 5.486190\n",
            "최대 오차율 (퍼센트): 94.396544 (위치: 417)\n",
            "\n",
            "오차율 정수 부분 개수:\n",
            "0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차 및 평균 오차를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - 전체 평균 오차\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ 오차율 계산 (음수값 유지)\n",
        "    error_rates = (differences / np.abs(values1)) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차 계산\n",
        "    mean_error = np.mean(np.abs(differences))  # 전체 차이 평균\n",
        "\n",
        "    return differences, mean_error\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, mean_error = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"전체 평균 차이: {mean_error:.6f}\")\n"
      ],
      "metadata": {
        "id": "OrQuhc19gboQ",
        "outputId": "8ad31a67-9ee8-4715-f49c-70cd629d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "전체 평균 차이: 0.000800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 RMSE(Root Mean Squared Error) 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - RMSE 값\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ RMSE 계산\n",
        "    rmse = np.sqrt(np.mean(differences ** 2))  # (차이 제곱 → 평균 → 루트)\n",
        "\n",
        "    return differences, rmse\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, rmse = calculate_rmse(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"✅ RMSE (Root Mean Squared Error): {rmse:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JGwrIV7NNw",
        "outputId": "9118d0f8-b468-41d8-d5e1-317c4db2cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "✅ RMSE (Root Mean Squared Error): 0.001001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def count_integer_parts(file_path):\n",
        "    \"\"\"\n",
        "    파일을 읽어 정수 부분별 개수를 세는 함수 (음수 0과 양수 0을 구별하여 정렬).\n",
        "\n",
        "    Args:\n",
        "    file_path: 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 정수 부분별 개수 딕셔너리 (출력 순서: -3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ... )\n",
        "    \"\"\"\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 파일에서 값 읽기\n",
        "    values = read_file(file_path)\n",
        "\n",
        "    # ✅ 음수와 양수의 0을 구별하여 저장\n",
        "    integer_parts = []\n",
        "    for x in values:\n",
        "        if x < 0:\n",
        "            integer_part = int(x) if abs(x) >= 1 else \"-0\"  # 음수 정수 또는 -0\n",
        "        else:\n",
        "            integer_part = int(x) if x >= 1 else \"+0\"  # 양수 정수 또는 +0\n",
        "        integer_parts.append(integer_part)\n",
        "\n",
        "    # ✅ 정수 부분 개수 세기\n",
        "    count_dict = Counter(integer_parts)  # 개수 카운트\n",
        "\n",
        "    # ✅ 정렬 (-3 → -2 → -1 → -0 → +0 → 1 → 2 → 3 ...)\n",
        "    sorted_counts = sorted(count_dict.items(), key=lambda x: (float(x[0]) if x[0] not in [\"-0\", \"+0\"] else -0.5 if x[0] == \"-0\" else 0.5))\n",
        "\n",
        "    return sorted_counts\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file_path = './model/error_rates_output.txt'  # 읽어올 파일\n",
        "\n",
        "# ✅ 함수 호출\n",
        "sorted_counts = count_integer_parts(file_path)\n",
        "\n",
        "# ✅ 정수 부분 개수 출력\n",
        "print(\"\\n정수 부분별 개수:\")\n",
        "for int_part, count in sorted_counts:\n",
        "    print(f\"{int_part}: {count}개\")\n"
      ],
      "metadata": {
        "id": "3ABGD8kb1_-Q",
        "outputId": "1e931fbf-2e56-4d2b-b3f7-c7a3485e5bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "정수 부분별 개수:\n",
            "+0: 594개\n",
            "1: 191개\n",
            "2: 84개\n",
            "3: 62개\n",
            "4: 32개\n",
            "5: 32개\n",
            "6: 29개\n",
            "7: 16개\n",
            "8: 11개\n",
            "9: 8개\n",
            "10: 12개\n",
            "11: 12개\n",
            "12: 9개\n",
            "13: 8개\n",
            "14: 7개\n",
            "15: 4개\n",
            "16: 2개\n",
            "17: 5개\n",
            "18: 6개\n",
            "19: 3개\n",
            "20: 4개\n",
            "21: 3개\n",
            "22: 4개\n",
            "23: 5개\n",
            "24: 2개\n",
            "25: 1개\n",
            "26: 2개\n",
            "27: 2개\n",
            "28: 2개\n",
            "31: 1개\n",
            "33: 1개\n",
            "35: 1개\n",
            "36: 1개\n",
            "37: 1개\n",
            "38: 3개\n",
            "39: 1개\n",
            "41: 1개\n",
            "42: 2개\n",
            "43: 1개\n",
            "47: 1개\n",
            "50: 2개\n",
            "56: 1개\n",
            "58: 1개\n",
            "62: 1개\n",
            "67: 1개\n",
            "69: 1개\n",
            "74: 2개\n",
            "81: 2개\n",
            "82: 1개\n",
            "83: 2개\n",
            "84: 2개\n",
            "85: 1개\n",
            "86: 2개\n",
            "87: 3개\n",
            "89: 2개\n",
            "91: 4개\n",
            "92: 2개\n",
            "93: 2개\n",
            "94: 2개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_values_in_file(file_path):\n",
        "    \"\"\"\n",
        "    주어진 텍스트 파일에서 숫자 값을 추출하여\n",
        "    값의 순서를 변경하지 않고 한 줄씩 정리된 형태로 다시 저장하는 함수.\n",
        "\n",
        "    Args:\n",
        "    file_path: 변환할 텍스트 파일 경로\n",
        "    \"\"\"\n",
        "    # 1. 파일 읽기\n",
        "    with open(file_path, 'r') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    # 2. 모든 숫자 값 추출 (형식 유지, 순서 변경 X)\n",
        "    cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "    values = cleaned_data.split()  # 공백 기준으로 숫자 분리\n",
        "\n",
        "    # 3. 같은 파일에 다시 한 줄씩 저장 (순서 유지)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(\"\\n\".join(values))\n",
        "\n",
        "    print(f\"✅ 파일이 성공적으로 변환되었습니다: {file_path}\")\n",
        "\n",
        "# ✅ 변환할 파일 경로 설정\n",
        "file_path = './model/sorted_SM_bert_2.txt'  # 파일 경로 변경 가능\n",
        "\n",
        "# ✅ 함수 실행\n",
        "reformat_values_in_file(file_path)\n"
      ],
      "metadata": {
        "id": "kXzSpyHfbSSU",
        "outputId": "7d68b92f-c938-49a5-b5ec-eaed4c00d6ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되었습니다: ./model/sorted_SM_bert_2.txt\n"
          ]
        }
      ]
    }
  ]
}