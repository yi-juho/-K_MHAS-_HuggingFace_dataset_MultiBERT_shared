{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9moVKInibnca",
        "dryCfxh4btMS",
        "wqqbD-tBcehO"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "434384122ddd480a8c1408c5e1f7a53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e92ea90d5c94e8da35c706ae3245367",
              "IPY_MODEL_d8594408289a4a2d8789be32fcf61f9e",
              "IPY_MODEL_be1b228196bd4ed69358e9b027c20acf"
            ],
            "layout": "IPY_MODEL_b4934d5fc9ec4b28bb4e11660b9588b2"
          }
        },
        "0e92ea90d5c94e8da35c706ae3245367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8fa5ae17ff4fb7a4213dfe79629028",
            "placeholder": "​",
            "style": "IPY_MODEL_22cca95432a44d7d84f6e94a2baec285",
            "value": "README.md: 100%"
          }
        },
        "d8594408289a4a2d8789be32fcf61f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac323774676d4489a273315615590bf1",
            "max": 10565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38d30c8ec1c94a8da8fbd2cc6363e0ae",
            "value": 10565
          }
        },
        "be1b228196bd4ed69358e9b027c20acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bd04fc5c4747d08a7846342a426684",
            "placeholder": "​",
            "style": "IPY_MODEL_580bf16082f240b2be86e3177d3c3737",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 258kB/s]"
          }
        },
        "b4934d5fc9ec4b28bb4e11660b9588b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8fa5ae17ff4fb7a4213dfe79629028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22cca95432a44d7d84f6e94a2baec285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac323774676d4489a273315615590bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d30c8ec1c94a8da8fbd2cc6363e0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53bd04fc5c4747d08a7846342a426684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580bf16082f240b2be86e3177d3c3737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c3ace598d841f09aa25f8df4b46b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_185bb10f4dff490e82452ffd7f000243",
              "IPY_MODEL_e27206a6573c4dd18e85a14d43bacf29",
              "IPY_MODEL_57c40c40a16941e1bffed6971f39f08e"
            ],
            "layout": "IPY_MODEL_4a035d6237f047f4a9d14eacf0a087ae"
          }
        },
        "185bb10f4dff490e82452ffd7f000243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12df4770a3d04cf988c15c3ceff4f62c",
            "placeholder": "​",
            "style": "IPY_MODEL_7148f4b1e9144a65b2d203b0f9037a60",
            "value": "kmhas_korean_hate_speech.py: 100%"
          }
        },
        "e27206a6573c4dd18e85a14d43bacf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea449a4cb74f46f1967fa7b192ec5974",
            "max": 4730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c342884842d460db77a77f51abdc776",
            "value": 4730
          }
        },
        "57c40c40a16941e1bffed6971f39f08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e8fa1eae0d4e70a43810d5eb08ae85",
            "placeholder": "​",
            "style": "IPY_MODEL_0855975dca2448e093ca8b7c6a97bee7",
            "value": " 4.73k/4.73k [00:00&lt;00:00, 83.4kB/s]"
          }
        },
        "4a035d6237f047f4a9d14eacf0a087ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12df4770a3d04cf988c15c3ceff4f62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7148f4b1e9144a65b2d203b0f9037a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea449a4cb74f46f1967fa7b192ec5974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c342884842d460db77a77f51abdc776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86e8fa1eae0d4e70a43810d5eb08ae85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0855975dca2448e093ca8b7c6a97bee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15bd494f5dad4f6885a65b89925effb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48e9b4c9b2324affbc6a2d5e630c5f5b",
              "IPY_MODEL_9bbf3d9f83cc4620b306491f53020ef0",
              "IPY_MODEL_69949ffbbbe24e9c904e0d73a2ffd24b"
            ],
            "layout": "IPY_MODEL_6f5093f3b363474b885f9df44f9af8ae"
          }
        },
        "48e9b4c9b2324affbc6a2d5e630c5f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e677fc9a49a4e39bff7978f6445556a",
            "placeholder": "​",
            "style": "IPY_MODEL_52b22b0708d4473ca302804f8d23c44b",
            "value": "0000.parquet: 100%"
          }
        },
        "9bbf3d9f83cc4620b306491f53020ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8216106977564bc89c251ab4257b641b",
            "max": 5244851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30c95366dc174ab4b0d5ad21d7cc8cd3",
            "value": 5244851
          }
        },
        "69949ffbbbe24e9c904e0d73a2ffd24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4794f15e7b4fc0bcba877d1ed664ac",
            "placeholder": "​",
            "style": "IPY_MODEL_ffb230876e564d4f82cd0e9161ba3e92",
            "value": " 5.24M/5.24M [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "6f5093f3b363474b885f9df44f9af8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e677fc9a49a4e39bff7978f6445556a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b22b0708d4473ca302804f8d23c44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8216106977564bc89c251ab4257b641b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c95366dc174ab4b0d5ad21d7cc8cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4794f15e7b4fc0bcba877d1ed664ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb230876e564d4f82cd0e9161ba3e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be23d32b271644cdbfd0fff3d93890cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44bdff56f27147a397f66f1c9c961821",
              "IPY_MODEL_16f3fbd4fda3498998a6f550ffac0aaa",
              "IPY_MODEL_db87e09b5dcb4478ac2a8b8e0433c9c5"
            ],
            "layout": "IPY_MODEL_a5274af7efc64212b961c316e2fbf0ac"
          }
        },
        "44bdff56f27147a397f66f1c9c961821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b75855630a4ffdb633c3676c9067c8",
            "placeholder": "​",
            "style": "IPY_MODEL_fc2e5f84b1c54edcbeb39120fbddcbc2",
            "value": "default/validation/0000.parquet: 100%"
          }
        },
        "16f3fbd4fda3498998a6f550ffac0aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd2be392b4d4406d8fea841d9a8bea48",
            "max": 578860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_460ae976b8444f6c8ef6eb2f6cb98d56",
            "value": 578860
          }
        },
        "db87e09b5dcb4478ac2a8b8e0433c9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_727379a1947844608e85139793b89f44",
            "placeholder": "​",
            "style": "IPY_MODEL_e8f70aab429f475ea4abe5c8335acaaf",
            "value": " 579k/579k [00:00&lt;00:00, 7.48MB/s]"
          }
        },
        "a5274af7efc64212b961c316e2fbf0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b75855630a4ffdb633c3676c9067c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2e5f84b1c54edcbeb39120fbddcbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2be392b4d4406d8fea841d9a8bea48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460ae976b8444f6c8ef6eb2f6cb98d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "727379a1947844608e85139793b89f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f70aab429f475ea4abe5c8335acaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "671bb46790a44245a886c605aaa691e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f395d3585b74f4b8469d8e57e3295b4",
              "IPY_MODEL_f64f87ab171040f99d03c0848c98aefc",
              "IPY_MODEL_df0fbddcfb6144d29a128b47e43206d4"
            ],
            "layout": "IPY_MODEL_c2d05b7e30674c6abfa10685e80e7767"
          }
        },
        "7f395d3585b74f4b8469d8e57e3295b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f551a1bb25c84c57b3893f7adc0c63ed",
            "placeholder": "​",
            "style": "IPY_MODEL_697e896464c34dd5aeafd06b21730f26",
            "value": "0000.parquet: 100%"
          }
        },
        "f64f87ab171040f99d03c0848c98aefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6c50a32efa4ec9865d93e70b036f0e",
            "max": 1458266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00e3fadb746d4e3d9a8231ec72ce8d28",
            "value": 1458266
          }
        },
        "df0fbddcfb6144d29a128b47e43206d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50dc2c937b64742ae2259c8b0253ada",
            "placeholder": "​",
            "style": "IPY_MODEL_6909266cf1404fe0a8ecb5b8651633b0",
            "value": " 1.46M/1.46M [00:00&lt;00:00, 27.1MB/s]"
          }
        },
        "c2d05b7e30674c6abfa10685e80e7767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f551a1bb25c84c57b3893f7adc0c63ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697e896464c34dd5aeafd06b21730f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db6c50a32efa4ec9865d93e70b036f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e3fadb746d4e3d9a8231ec72ce8d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b50dc2c937b64742ae2259c8b0253ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6909266cf1404fe0a8ecb5b8651633b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11e50365e74648bca825b16b3113a20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d2b03b5f2964414bb4425019de0807e",
              "IPY_MODEL_61909eb0f8474def8dbfd08cca0ad444",
              "IPY_MODEL_72b504fec3944b6e9a4cefb6aa881308"
            ],
            "layout": "IPY_MODEL_448d3fc28ea644569b789e0947b20a3f"
          }
        },
        "7d2b03b5f2964414bb4425019de0807e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37640d13e2594ea78c95d45e2469dc4b",
            "placeholder": "​",
            "style": "IPY_MODEL_81912421ae034a7882b3ba696cd697e4",
            "value": "Generating train split: 100%"
          }
        },
        "61909eb0f8474def8dbfd08cca0ad444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b7961522cc41159fbf7a47a43c73f2",
            "max": 78977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98bd03feb02d431b99118cc3821f8cfd",
            "value": 78977
          }
        },
        "72b504fec3944b6e9a4cefb6aa881308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e37b8ecd5514462a80997e45076e8dc",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb726cf1fe740e1b8994c4e0ecc4860",
            "value": " 78977/78977 [00:00&lt;00:00, 223731.26 examples/s]"
          }
        },
        "448d3fc28ea644569b789e0947b20a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37640d13e2594ea78c95d45e2469dc4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81912421ae034a7882b3ba696cd697e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b7961522cc41159fbf7a47a43c73f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bd03feb02d431b99118cc3821f8cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e37b8ecd5514462a80997e45076e8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb726cf1fe740e1b8994c4e0ecc4860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ea3934a1e94469ae765222dc6c35ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ec6f09f906c46aa8c9b9e2802014e91",
              "IPY_MODEL_a6670dece4a44267894a2e3b667cdd4e",
              "IPY_MODEL_5e67413951f34e72a6bb0b8eb9bbb6a3"
            ],
            "layout": "IPY_MODEL_d26c9706e4d54cd4a8f8126972f43a67"
          }
        },
        "7ec6f09f906c46aa8c9b9e2802014e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7446b67e969745bc92a1eb6b2de618a3",
            "placeholder": "​",
            "style": "IPY_MODEL_f3491034a33242b29caf9a0259169fee",
            "value": "Generating validation split: 100%"
          }
        },
        "a6670dece4a44267894a2e3b667cdd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf6efe8941014998bdf985438c7287a8",
            "max": 8776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ef7d39e5b044d5eae7daa425296756d",
            "value": 8776
          }
        },
        "5e67413951f34e72a6bb0b8eb9bbb6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565fb3d3da8e4eeab093fb59f1b6278e",
            "placeholder": "​",
            "style": "IPY_MODEL_b6475d56a2fc4c8ab4dd8dd2e6a82353",
            "value": " 8776/8776 [00:00&lt;00:00, 159483.25 examples/s]"
          }
        },
        "d26c9706e4d54cd4a8f8126972f43a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7446b67e969745bc92a1eb6b2de618a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3491034a33242b29caf9a0259169fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf6efe8941014998bdf985438c7287a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef7d39e5b044d5eae7daa425296756d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "565fb3d3da8e4eeab093fb59f1b6278e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6475d56a2fc4c8ab4dd8dd2e6a82353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ad022bd45fa469bb9588c5e9c5053c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e5327dc02294090aa6df364961df0af",
              "IPY_MODEL_bc87cd693ccd4355b5855eefcdd40081",
              "IPY_MODEL_1251d9609a7c41c99825df0ff4357475"
            ],
            "layout": "IPY_MODEL_c4db462c8ac540308c37bb4d891c9cd1"
          }
        },
        "8e5327dc02294090aa6df364961df0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfdd13a55fb4352b28f34b757a9b490",
            "placeholder": "​",
            "style": "IPY_MODEL_4d8b874edbb44ba5b1023fe556d1dfd2",
            "value": "Generating test split: 100%"
          }
        },
        "bc87cd693ccd4355b5855eefcdd40081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7e810fb0a14c608f396c51640151c7",
            "max": 21939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8f80eddfd3c4c02869b319f3590b52f",
            "value": 21939
          }
        },
        "1251d9609a7c41c99825df0ff4357475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bfbe5d4f334479597dc3a1d45b33ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_dc39ae8f540046c9932822da4cbb2aa4",
            "value": " 21939/21939 [00:00&lt;00:00, 305637.31 examples/s]"
          }
        },
        "c4db462c8ac540308c37bb4d891c9cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cfdd13a55fb4352b28f34b757a9b490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8b874edbb44ba5b1023fe556d1dfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7e810fb0a14c608f396c51640151c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f80eddfd3c4c02869b319f3590b52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bfbe5d4f334479597dc3a1d45b33ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc39ae8f540046c9932822da4cbb2aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5314d5b54653483b831244d7397dc536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_074cf696f16c4bec9c8fe52f5a90e36e",
              "IPY_MODEL_9dc5d3225afd48efa6c560d3951e6eaa",
              "IPY_MODEL_b6b90be20a574927ada0bfbead49b44b"
            ],
            "layout": "IPY_MODEL_637539eb5aac44e2a4178e6a68821763"
          }
        },
        "074cf696f16c4bec9c8fe52f5a90e36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0779a8f624634ef0953b0335b748e73a",
            "placeholder": "​",
            "style": "IPY_MODEL_71b096aea0b3441a849f122512d62150",
            "value": ""
          }
        },
        "9dc5d3225afd48efa6c560d3951e6eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b67928bb30749acbf8cc030aa0609b7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46ea7e8c8428440cb96def36f2a6546a",
            "value": 0
          }
        },
        "b6b90be20a574927ada0bfbead49b44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1774824ae96d4db491e0d38c1f58b900",
            "placeholder": "​",
            "style": "IPY_MODEL_261a9db432014a9b844f3a494a0a2464",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "637539eb5aac44e2a4178e6a68821763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0779a8f624634ef0953b0335b748e73a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b096aea0b3441a849f122512d62150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b67928bb30749acbf8cc030aa0609b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "46ea7e8c8428440cb96def36f2a6546a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1774824ae96d4db491e0d38c1f58b900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261a9db432014a9b844f3a494a0a2464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afbc5142ad224a0faa1978a84bab2d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b2e903b8ecf4145b8e83439d037fb9c",
              "IPY_MODEL_a830e5bb2fa547c0ba60f57173d2bb56",
              "IPY_MODEL_e5db61d1ebe94044906335daefc23a33"
            ],
            "layout": "IPY_MODEL_9f793bbd48374615a15a94add060b540"
          }
        },
        "5b2e903b8ecf4145b8e83439d037fb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc52627801340f497453ba3fc9f6c96",
            "placeholder": "​",
            "style": "IPY_MODEL_02d59c0fda3b4b4f96e34390b3dee0e2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a830e5bb2fa547c0ba60f57173d2bb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3d472bbf9a4396888a8108260cc9e6",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_215fa220d398452b85439e997ebc8fbd",
            "value": 289
          }
        },
        "e5db61d1ebe94044906335daefc23a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af83ab37de9540d1b1c0795886601f9d",
            "placeholder": "​",
            "style": "IPY_MODEL_ca9f43c22ab8482788d2a965b835ec11",
            "value": " 289/289 [00:00&lt;00:00, 6.84kB/s]"
          }
        },
        "9f793bbd48374615a15a94add060b540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcc52627801340f497453ba3fc9f6c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d59c0fda3b4b4f96e34390b3dee0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec3d472bbf9a4396888a8108260cc9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215fa220d398452b85439e997ebc8fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af83ab37de9540d1b1c0795886601f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9f43c22ab8482788d2a965b835ec11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c79fd390d7e4f659853b2b0ca163044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e37c4dc678e848f9ac3645e699304b5c",
              "IPY_MODEL_71b19b285db34149858b4949044313f3",
              "IPY_MODEL_9599f28d55ae41b8a005c66332e7b34a"
            ],
            "layout": "IPY_MODEL_138ed54d4e1e4383aa52aab8f6a364f5"
          }
        },
        "e37c4dc678e848f9ac3645e699304b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e2ea84602ff444bb9f896cc6efb283d",
            "placeholder": "​",
            "style": "IPY_MODEL_70b544359b77436dbc69e63bd561dd1c",
            "value": "vocab.txt: 100%"
          }
        },
        "71b19b285db34149858b4949044313f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cd092c1a0246abbf8518e4656076ce",
            "max": 248477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c2c8963d0e04f5eb12c3c7608a1a046",
            "value": 248477
          }
        },
        "9599f28d55ae41b8a005c66332e7b34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b41bc10cb3964335b24b0b07f63ce713",
            "placeholder": "​",
            "style": "IPY_MODEL_8209290571954ee4ac6e69f995d82306",
            "value": " 248k/248k [00:00&lt;00:00, 3.01MB/s]"
          }
        },
        "138ed54d4e1e4383aa52aab8f6a364f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e2ea84602ff444bb9f896cc6efb283d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b544359b77436dbc69e63bd561dd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3cd092c1a0246abbf8518e4656076ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2c8963d0e04f5eb12c3c7608a1a046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b41bc10cb3964335b24b0b07f63ce713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8209290571954ee4ac6e69f995d82306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61ac1b608ca04f0abb4a3e1846165dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_270f19a2c2824f29ba91d685bfbc47d8",
              "IPY_MODEL_214386283c5d4a328e5e347255e825bf",
              "IPY_MODEL_5be80dd3b5704850be3c19f36f783411"
            ],
            "layout": "IPY_MODEL_fc57657743dc4e4b8a533d0a7786f9bc"
          }
        },
        "270f19a2c2824f29ba91d685bfbc47d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0127ac37ccc54f11a3e0ae35f8f59514",
            "placeholder": "​",
            "style": "IPY_MODEL_0ed07c4c8a394a83bc02867a0c8b75a8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "214386283c5d4a328e5e347255e825bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81814d4a3cc4352859235c14ebb883c",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4763153921234a6cb2d9a1e2ce1a5f16",
            "value": 125
          }
        },
        "5be80dd3b5704850be3c19f36f783411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3a5c8007164c75b142ee9c9eeb0638",
            "placeholder": "​",
            "style": "IPY_MODEL_3c63efdf2bd943d18c1bfbd0d281dec8",
            "value": " 125/125 [00:00&lt;00:00, 135B/s]"
          }
        },
        "fc57657743dc4e4b8a533d0a7786f9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0127ac37ccc54f11a3e0ae35f8f59514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed07c4c8a394a83bc02867a0c8b75a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b81814d4a3cc4352859235c14ebb883c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4763153921234a6cb2d9a1e2ce1a5f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3a5c8007164c75b142ee9c9eeb0638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c63efdf2bd943d18c1bfbd0d281dec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15a096328b7040778e2409acdfe3170e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_698a192cff044a15b49e27b078274c08",
              "IPY_MODEL_1feb0e268227447bb21db61dc980f10b",
              "IPY_MODEL_80a4de9297d840718be11369fb6f470a"
            ],
            "layout": "IPY_MODEL_cb973947183346f2ba1490adb41589c7"
          }
        },
        "698a192cff044a15b49e27b078274c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea8b1443bbd4cabb50950fd27db979f",
            "placeholder": "​",
            "style": "IPY_MODEL_0cc0af10df9744e8bf9dff421247a705",
            "value": "tokenizer.json: 100%"
          }
        },
        "1feb0e268227447bb21db61dc980f10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69ebf36c6d7400d8fb64ef16380a961",
            "max": 494860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb566543b2d049d1bf8427dec589d3ea",
            "value": 494860
          }
        },
        "80a4de9297d840718be11369fb6f470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_921d611914f54bdc91cefe16d673c7a0",
            "placeholder": "​",
            "style": "IPY_MODEL_6b983511089642b7aafb39c25c113611",
            "value": " 495k/495k [00:00&lt;00:00, 2.00MB/s]"
          }
        },
        "cb973947183346f2ba1490adb41589c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea8b1443bbd4cabb50950fd27db979f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc0af10df9744e8bf9dff421247a705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e69ebf36c6d7400d8fb64ef16380a961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb566543b2d049d1bf8427dec589d3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "921d611914f54bdc91cefe16d673c7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b983511089642b7aafb39c25c113611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fed32948e80e4b1f9625480075ba769c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6562cc231ddc43a68a85691bfb33f7d0",
              "IPY_MODEL_f3799a82cd1a4c2387c13115eb444c47",
              "IPY_MODEL_149412df938c4d8c87eaf14ae06bfb49"
            ],
            "layout": "IPY_MODEL_c9c3c8a938a1441eb4314f2bb58fb5c7"
          }
        },
        "6562cc231ddc43a68a85691bfb33f7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b9076bd2d7c4ba199244c92580c8cad",
            "placeholder": "​",
            "style": "IPY_MODEL_a11bcc64a5df41bc96a69e9e639d9235",
            "value": "config.json: 100%"
          }
        },
        "f3799a82cd1a4c2387c13115eb444c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f844fb47c67947eeac6c78dc2e9d27ac",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bd75c22f1d84af1b7b1fde7741e0dd0",
            "value": 425
          }
        },
        "149412df938c4d8c87eaf14ae06bfb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3f8f2eb3c34c75aa319b98630337c9",
            "placeholder": "​",
            "style": "IPY_MODEL_13bca487fcd54e8f847b74195bb62cf6",
            "value": " 425/425 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "c9c3c8a938a1441eb4314f2bb58fb5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9076bd2d7c4ba199244c92580c8cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11bcc64a5df41bc96a69e9e639d9235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f844fb47c67947eeac6c78dc2e9d27ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd75c22f1d84af1b7b1fde7741e0dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3f8f2eb3c34c75aa319b98630337c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bca487fcd54e8f847b74195bb62cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd5215eb01546e7a99448fe0822c46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dc68c321afe4c35a19533bbe6d8c485",
              "IPY_MODEL_8cbcbbf8ae08452281a9eed8801cff10",
              "IPY_MODEL_32522a85a0f5458d876aba63fe5f347a"
            ],
            "layout": "IPY_MODEL_981dfe688155490bb2266baf730d269e"
          }
        },
        "2dc68c321afe4c35a19533bbe6d8c485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647e1787dd5349f78c0edd8ef835e054",
            "placeholder": "​",
            "style": "IPY_MODEL_72622a847e144bbd9bda2a12032f9939",
            "value": "model.safetensors: 100%"
          }
        },
        "8cbcbbf8ae08452281a9eed8801cff10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77aeb55159ea415eb7e1a02cce7726b8",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_597af808f7834236aa18bcee5c2c51ca",
            "value": 445000316
          }
        },
        "32522a85a0f5458d876aba63fe5f347a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a70b3840a9438ea2036e0a933a0457",
            "placeholder": "​",
            "style": "IPY_MODEL_710b9f5934ef4a6a8ff9f6a7505aae9a",
            "value": " 445M/445M [00:02&lt;00:00, 232MB/s]"
          }
        },
        "981dfe688155490bb2266baf730d269e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "647e1787dd5349f78c0edd8ef835e054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72622a847e144bbd9bda2a12032f9939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77aeb55159ea415eb7e1a02cce7726b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597af808f7834236aa18bcee5c2c51ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53a70b3840a9438ea2036e0a933a0457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710b9f5934ef4a6a8ff9f6a7505aae9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/%5BK_MHAS%5D_HuggingFace_dataset_MultiBERT_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-MHaS (Korean Multi-label Hate Speech Dataset)"
      ],
      "metadata": {
        "id": "t2rd2GYlnYGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "ewJFnCDHriqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the K-MHaS dataset from [HuggingFace](https://huggingface.co/datasets/jeanlee/kmhas_korean_hate_speech) and checking meta information (published @COLING2022)\n"
      ],
      "metadata": {
        "id": "4Lyor-OIrwd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets fsspec -y\n",
        "!pip install datasets==3.2.0 fsspec[http]==2024.9.0\n"
      ],
      "metadata": {
        "id": "WMoJHDlhbklf",
        "outputId": "f950898a-3422-402c-910a-96d5c5ff8b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: fsspec 2024.10.0\n",
            "Uninstalling fsspec-2024.10.0:\n",
            "  Successfully uninstalled fsspec-2024.10.0\n",
            "Collecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec==2024.9.0 (from fsspec[http]==2024.9.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "X7_xRg2EJ6RM",
        "outputId": "8206bcf8-6ac9-45e7-ddf8-69b569ab1ecf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "slfabpsGOFR5",
        "outputId": "e005272f-705b-4616-c074-65b3448415c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "434384122ddd480a8c1408c5e1f7a53a",
            "0e92ea90d5c94e8da35c706ae3245367",
            "d8594408289a4a2d8789be32fcf61f9e",
            "be1b228196bd4ed69358e9b027c20acf",
            "b4934d5fc9ec4b28bb4e11660b9588b2",
            "5c8fa5ae17ff4fb7a4213dfe79629028",
            "22cca95432a44d7d84f6e94a2baec285",
            "ac323774676d4489a273315615590bf1",
            "38d30c8ec1c94a8da8fbd2cc6363e0ae",
            "53bd04fc5c4747d08a7846342a426684",
            "580bf16082f240b2be86e3177d3c3737",
            "f6c3ace598d841f09aa25f8df4b46b20",
            "185bb10f4dff490e82452ffd7f000243",
            "e27206a6573c4dd18e85a14d43bacf29",
            "57c40c40a16941e1bffed6971f39f08e",
            "4a035d6237f047f4a9d14eacf0a087ae",
            "12df4770a3d04cf988c15c3ceff4f62c",
            "7148f4b1e9144a65b2d203b0f9037a60",
            "ea449a4cb74f46f1967fa7b192ec5974",
            "1c342884842d460db77a77f51abdc776",
            "86e8fa1eae0d4e70a43810d5eb08ae85",
            "0855975dca2448e093ca8b7c6a97bee7",
            "15bd494f5dad4f6885a65b89925effb9",
            "48e9b4c9b2324affbc6a2d5e630c5f5b",
            "9bbf3d9f83cc4620b306491f53020ef0",
            "69949ffbbbe24e9c904e0d73a2ffd24b",
            "6f5093f3b363474b885f9df44f9af8ae",
            "8e677fc9a49a4e39bff7978f6445556a",
            "52b22b0708d4473ca302804f8d23c44b",
            "8216106977564bc89c251ab4257b641b",
            "30c95366dc174ab4b0d5ad21d7cc8cd3",
            "8a4794f15e7b4fc0bcba877d1ed664ac",
            "ffb230876e564d4f82cd0e9161ba3e92",
            "be23d32b271644cdbfd0fff3d93890cc",
            "44bdff56f27147a397f66f1c9c961821",
            "16f3fbd4fda3498998a6f550ffac0aaa",
            "db87e09b5dcb4478ac2a8b8e0433c9c5",
            "a5274af7efc64212b961c316e2fbf0ac",
            "b7b75855630a4ffdb633c3676c9067c8",
            "fc2e5f84b1c54edcbeb39120fbddcbc2",
            "cd2be392b4d4406d8fea841d9a8bea48",
            "460ae976b8444f6c8ef6eb2f6cb98d56",
            "727379a1947844608e85139793b89f44",
            "e8f70aab429f475ea4abe5c8335acaaf",
            "671bb46790a44245a886c605aaa691e6",
            "7f395d3585b74f4b8469d8e57e3295b4",
            "f64f87ab171040f99d03c0848c98aefc",
            "df0fbddcfb6144d29a128b47e43206d4",
            "c2d05b7e30674c6abfa10685e80e7767",
            "f551a1bb25c84c57b3893f7adc0c63ed",
            "697e896464c34dd5aeafd06b21730f26",
            "db6c50a32efa4ec9865d93e70b036f0e",
            "00e3fadb746d4e3d9a8231ec72ce8d28",
            "b50dc2c937b64742ae2259c8b0253ada",
            "6909266cf1404fe0a8ecb5b8651633b0",
            "11e50365e74648bca825b16b3113a20b",
            "7d2b03b5f2964414bb4425019de0807e",
            "61909eb0f8474def8dbfd08cca0ad444",
            "72b504fec3944b6e9a4cefb6aa881308",
            "448d3fc28ea644569b789e0947b20a3f",
            "37640d13e2594ea78c95d45e2469dc4b",
            "81912421ae034a7882b3ba696cd697e4",
            "99b7961522cc41159fbf7a47a43c73f2",
            "98bd03feb02d431b99118cc3821f8cfd",
            "4e37b8ecd5514462a80997e45076e8dc",
            "cfb726cf1fe740e1b8994c4e0ecc4860",
            "37ea3934a1e94469ae765222dc6c35ae",
            "7ec6f09f906c46aa8c9b9e2802014e91",
            "a6670dece4a44267894a2e3b667cdd4e",
            "5e67413951f34e72a6bb0b8eb9bbb6a3",
            "d26c9706e4d54cd4a8f8126972f43a67",
            "7446b67e969745bc92a1eb6b2de618a3",
            "f3491034a33242b29caf9a0259169fee",
            "cf6efe8941014998bdf985438c7287a8",
            "6ef7d39e5b044d5eae7daa425296756d",
            "565fb3d3da8e4eeab093fb59f1b6278e",
            "b6475d56a2fc4c8ab4dd8dd2e6a82353",
            "5ad022bd45fa469bb9588c5e9c5053c6",
            "8e5327dc02294090aa6df364961df0af",
            "bc87cd693ccd4355b5855eefcdd40081",
            "1251d9609a7c41c99825df0ff4357475",
            "c4db462c8ac540308c37bb4d891c9cd1",
            "3cfdd13a55fb4352b28f34b757a9b490",
            "4d8b874edbb44ba5b1023fe556d1dfd2",
            "0c7e810fb0a14c608f396c51640151c7",
            "e8f80eddfd3c4c02869b319f3590b52f",
            "6bfbe5d4f334479597dc3a1d45b33ac7",
            "dc39ae8f540046c9932822da4cbb2aa4"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "434384122ddd480a8c1408c5e1f7a53a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "kmhas_korean_hate_speech.py:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6c3ace598d841f09aa25f8df4b46b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/5.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15bd494f5dad4f6885a65b89925effb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "default/validation/0000.parquet:   0%|          | 0.00/579k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be23d32b271644cdbfd0fff3d93890cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/1.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "671bb46790a44245a886c605aaa691e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/78977 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11e50365e74648bca825b16b3113a20b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/8776 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ea3934a1e94469ae765222dc6c35ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/21939 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ad022bd45fa469bb9588c5e9c5053c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAgpDHwOT91",
        "outputId": "2ba15f73-4eca-4758-dbff-412f12b7e30d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 78977\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8776\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 21939\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "6dUuXmnFOYda"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-n4DHMy8ZIb",
        "outputId": "61d24d5c-5524-4526-cce9-177a3277d3f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 21939\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nub35uuW_ZKM",
        "outputId": "34c685b8-169b-4486-c8ea-567eade86e62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Sequence(feature=ClassLabel(names=['origin', 'physical', 'politics', 'profanity', 'age', 'gender', 'race', 'religion', 'not_hate_speech'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# meta information\n",
        "\n",
        "print(dataset.info.description)\n",
        "print(dataset.info.homepage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9AveWSDOj88",
        "outputId": "585becf9-520e-464c-f30b-47ffe2ee0694"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\n",
            "The fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.\n",
            "\n",
            "https://github.com/adlnlp/K-MHaS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.info.citation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bsDpBwOxPx",
        "outputId": "022e35bf-2863-4be7-dee5-13c1b1f2086d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@inproceedings{lee-etal-2022-k,\n",
            "    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n",
            "    author = \"Lee, Jean  and\n",
            "      Lim, Taejun  and\n",
            "      Lee, Heejun  and\n",
            "      Jo, Bogeun  and\n",
            "      Kim, Yangsok  and\n",
            "      Yoon, Heegeun  and\n",
            "      Han, Soyeon Caren\",\n",
            "    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n",
            "    month = oct,\n",
            "    year = \"2022\",\n",
            "    address = \"Gyeongju, Republic of Korea\",\n",
            "    publisher = \"International Committee on Computational Linguistics\",\n",
            "    url = \"https://aclanthology.org/2022.coling-1.311\",\n",
            "    pages = \"3530--3538\",\n",
            "    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "Qz98cJCasPgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prepare data from train, validation, and test dataset\n",
        "- Multi-label is converted to multi-label one hot encodding\n",
        "\n",
        "      class_label:\n",
        "        names:\n",
        "          0: origin\n",
        "          1: physical\n",
        "          2: politics\n",
        "          3: profanity\n",
        "          4: age\n",
        "          5: gender\n",
        "          6: race\n",
        "          7: religion\n",
        "          8: not_hate_speech"
      ],
      "metadata": {
        "id": "qqO0w2cKsjN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fykcu8FKZiOI",
        "outputId": "539bb7a9-8c25-4ede-814a-05b0d8520d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
      ],
      "metadata": {
        "id": "-IczFOCZZfvx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing\n"
      ],
      "metadata": {
        "id": "A5Jq_uiYcIWM",
        "outputId": "57aacfd0-4e16-4a1f-c1f4-03f963c1b3b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras_preprocessing) (1.17.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "ocBb-25SR-a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "5314d5b54653483b831244d7397dc536",
            "074cf696f16c4bec9c8fe52f5a90e36e",
            "9dc5d3225afd48efa6c560d3951e6eaa",
            "b6b90be20a574927ada0bfbead49b44b",
            "637539eb5aac44e2a4178e6a68821763",
            "0779a8f624634ef0953b0335b748e73a",
            "71b096aea0b3441a849f122512d62150",
            "9b67928bb30749acbf8cc030aa0609b7",
            "46ea7e8c8428440cb96def36f2a6546a",
            "1774824ae96d4db491e0d38c1f58b900",
            "261a9db432014a9b844f3a494a0a2464"
          ]
        },
        "outputId": "49317d0e-6492-4457-e0e9-0b57409798a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5314d5b54653483b831244d7397dc536"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, validation, and test dataset from HuggingFace\n",
        "\n",
        "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
        "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
        "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")"
      ],
      "metadata": {
        "id": "RC8MYtHzQkuR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding masking (able to remove this step depending on the model)\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train['text']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', validation['text']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test['text']))"
      ],
      "metadata": {
        "id": "UW48-pSDRJta"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multi-label to multi-label binary (one hot encoding)\n",
        "# [8] -> [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "enc = MultiLabelBinarizer()\n",
        "\n",
        "def multi_label(example):\n",
        "    enc_label = enc.fit_transform(example['label'])\n",
        "    float_arr = np.vstack(enc_label[:]).astype(float)\n",
        "    update_label = float_arr.tolist()\n",
        "    return update_label\n",
        "\n",
        "train_labels = multi_label(train)\n",
        "validation_labels = multi_label(validation)\n",
        "test_labels = multi_label(test)"
      ],
      "metadata": {
        "id": "s271-vIKRzNF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-xu24pnaxek",
        "outputId": "5d58dd3b-ecb1-46be-a826-00dc2bb1b3ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 그만큼 길예르모가 잘했다고 보면되겠지 기대되네 셰이프 오브 워터 [SEP]',\n",
              " '[CLS] \"1. 8넘의 문재앙\" [SEP]',\n",
              " '[CLS] \"문재인 정권의 내로남불은 타의 추종을 불허하네. 자한당 욕할거리도 없음.\" [SEP]',\n",
              " '[CLS] \"짱개들 지나간 곳은 폐허된다 ㅋㅋ\" [SEP]',\n",
              " '[CLS] 곱창은 자갈치~~~~~ [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvikrw0UUh4",
        "outputId": "85c082ee-62a0-4322-90c0-60d384b5634b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for Pytorch"
      ],
      "metadata": {
        "id": "WCsmRkSzbVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing : bert-base-multilingual-cased\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', do_lower_case=False)"
      ],
      "metadata": {
        "id": "VKYP2VNkR-Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "afbc5142ad224a0faa1978a84bab2d03",
            "5b2e903b8ecf4145b8e83439d037fb9c",
            "a830e5bb2fa547c0ba60f57173d2bb56",
            "e5db61d1ebe94044906335daefc23a33",
            "9f793bbd48374615a15a94add060b540",
            "dcc52627801340f497453ba3fc9f6c96",
            "02d59c0fda3b4b4f96e34390b3dee0e2",
            "ec3d472bbf9a4396888a8108260cc9e6",
            "215fa220d398452b85439e997ebc8fbd",
            "af83ab37de9540d1b1c0795886601f9d",
            "ca9f43c22ab8482788d2a965b835ec11",
            "2c79fd390d7e4f659853b2b0ca163044",
            "e37c4dc678e848f9ac3645e699304b5c",
            "71b19b285db34149858b4949044313f3",
            "9599f28d55ae41b8a005c66332e7b34a",
            "138ed54d4e1e4383aa52aab8f6a364f5",
            "9e2ea84602ff444bb9f896cc6efb283d",
            "70b544359b77436dbc69e63bd561dd1c",
            "e3cd092c1a0246abbf8518e4656076ce",
            "5c2c8963d0e04f5eb12c3c7608a1a046",
            "b41bc10cb3964335b24b0b07f63ce713",
            "8209290571954ee4ac6e69f995d82306",
            "61ac1b608ca04f0abb4a3e1846165dbd",
            "270f19a2c2824f29ba91d685bfbc47d8",
            "214386283c5d4a328e5e347255e825bf",
            "5be80dd3b5704850be3c19f36f783411",
            "fc57657743dc4e4b8a533d0a7786f9bc",
            "0127ac37ccc54f11a3e0ae35f8f59514",
            "0ed07c4c8a394a83bc02867a0c8b75a8",
            "b81814d4a3cc4352859235c14ebb883c",
            "4763153921234a6cb2d9a1e2ce1a5f16",
            "2b3a5c8007164c75b142ee9c9eeb0638",
            "3c63efdf2bd943d18c1bfbd0d281dec8",
            "15a096328b7040778e2409acdfe3170e",
            "698a192cff044a15b49e27b078274c08",
            "1feb0e268227447bb21db61dc980f10b",
            "80a4de9297d840718be11369fb6f470a",
            "cb973947183346f2ba1490adb41589c7",
            "9ea8b1443bbd4cabb50950fd27db979f",
            "0cc0af10df9744e8bf9dff421247a705",
            "e69ebf36c6d7400d8fb64ef16380a961",
            "eb566543b2d049d1bf8427dec589d3ea",
            "921d611914f54bdc91cefe16d673c7a0",
            "6b983511089642b7aafb39c25c113611",
            "fed32948e80e4b1f9625480075ba769c",
            "6562cc231ddc43a68a85691bfb33f7d0",
            "f3799a82cd1a4c2387c13115eb444c47",
            "149412df938c4d8c87eaf14ae06bfb49",
            "c9c3c8a938a1441eb4314f2bb58fb5c7",
            "5b9076bd2d7c4ba199244c92580c8cad",
            "a11bcc64a5df41bc96a69e9e639d9235",
            "f844fb47c67947eeac6c78dc2e9d27ac",
            "5bd75c22f1d84af1b7b1fde7741e0dd0",
            "6c3f8f2eb3c34c75aa319b98630337c9",
            "13bca487fcd54e8f847b74195bb62cf6"
          ]
        },
        "outputId": "88a34e4d-e274-4015-bd25-91871e7191ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afbc5142ad224a0faa1978a84bab2d03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c79fd390d7e4f659853b2b0ca163044"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61ac1b608ca04f0abb4a3e1846165dbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15a096328b7040778e2409acdfe3170e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fed32948e80e4b1f9625480075ba769c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks\n"
      ],
      "metadata": {
        "id": "It8LGkXNVVkJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "l-d01QBdWudY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pdH2mkqjYYpD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('testset size:', len(test_labels))\n",
        "print('trainset size:', len(train_labels))\n",
        "print('validset size:', len(validation_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBFn1XQ9SY4_",
        "outputId": "d709d337-9ced-4ae3-edd7-3b52e927fc9c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset size: 21939\n",
            "trainset size: 78977\n",
            "validset size: 8776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-BERT model"
      ],
      "metadata": {
        "id": "pXGKAsSXut0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU setting"
      ],
      "metadata": {
        "id": "9moVKInibnca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfq1f2Y3Yhck",
        "outputId": "3036a7e0-9abe-4468-c816-c35e3cdd0baf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UoM8bpuYhSN",
        "outputId": "01dfdf45-6016-47cc-ac81-aa52a38e5ffb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model setting"
      ],
      "metadata": {
        "id": "dryCfxh4btMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 9\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916,
          "referenced_widgets": [
            "5bd5215eb01546e7a99448fe0822c46f",
            "2dc68c321afe4c35a19533bbe6d8c485",
            "8cbcbbf8ae08452281a9eed8801cff10",
            "32522a85a0f5458d876aba63fe5f347a",
            "981dfe688155490bb2266baf730d269e",
            "647e1787dd5349f78c0edd8ef835e054",
            "72622a847e144bbd9bda2a12032f9939",
            "77aeb55159ea415eb7e1a02cce7726b8",
            "597af808f7834236aa18bcee5c2c51ca",
            "53a70b3840a9438ea2036e0a933a0457",
            "710b9f5934ef4a6a8ff9f6a7505aae9a"
          ]
        },
        "id": "2TPO6di_YhGV",
        "outputId": "bc4c655f-840c-42ec-ea0a-ff93593f552d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bd5215eb01546e7a99448fe0822c46f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "# change epochs for improving results (our paper : epochs = 4)\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "yO_GNYxCSYfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79399aaf-6dab-4827-ca25-72b289d60003"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss"
      ],
      "metadata": {
        "id": "03Da8x9OcVDy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming_loss': hamming}\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "UPNdiK3McYWd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "wqqbD-tBcehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFH3QM6ctmP",
        "outputId": "31525220-5836-44cc-fe3f-53885b326162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:36,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:37.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [15:58,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:15:59.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:21,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:21.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:23,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.1362\n",
            "  Training epcoh took: 0:26:23\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0863\n",
            "  Training epcoh took: 0:26:33\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:23.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:45,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:45.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:30.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:32,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0641\n",
            "  Training epcoh took: 0:26:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "500it [05:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  2,469.    Elapsed: 0:05:22.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [10:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  2,469.    Elapsed: 0:10:44.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1500it [16:06,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,469.    Elapsed: 0:16:07.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [21:29,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,469.    Elapsed: 0:21:29.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2469it [26:31,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.0499\n",
            "  Training epcoh took: 0:26:31\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Validation\n",
        "# ========================================\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "PXTAMK1sc0Sq",
        "outputId": "ed123a8b-6629-4cf9-9602-6214ec84620a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n",
            "Hamming Loss: 0.0360\n",
            "Validation took: 0:00:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jd_MC6kOc8JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model save\n",
        "\n",
        "# torch.save(model.state_dict(), path+\"BERT_model.pt\")"
      ],
      "metadata": {
        "id": "sdghDBnXdYlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "\n",
        "path = '/content/model/'\n",
        "#torch.save(model.state_dict(), path+\"BERT_multilabel_model.pt\")\n",
        "model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWMZ4QRcde9",
        "outputId": "1b7e0989-aabe-4a6e-999f-d2dbbb5cb0f8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d28ce5f3d4a8>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path+\"BERT_multilabel_model.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "sgx14gm68ElU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "for batch in validation_dataloader:\n",
        " batch = tuple(t.to(device) for t in batch)\n",
        " b_input_ids, b_input_mask, b_labels = batch\n",
        " with torch.no_grad():\n",
        "  outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        " logits = outputs[0]\n",
        " logits = logits.detach().cpu().numpy()\n",
        " label_ids = b_labels.to('cpu').numpy()\n",
        " for b in logits:\n",
        "  accum_logits.append(list(b))\n",
        " for b in label_ids:\n",
        "  accum_label_ids.append(list(b))\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))"
      ],
      "metadata": {
        "id": "1jqF9y4E7YjT",
        "outputId": "2f66be25-1787-43f8-a355-fc4a8eb174ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8122\n",
            "F1 (Macro) Score: 0.7599\n",
            "F1 (Micro) Score: 0.8558\n",
            "F1 (Weighted) Score: 0.8550\n",
            "ROC-AUC: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        accum_logits.append(list(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(list(b))\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = multi_label_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "accum_results = []\n",
        "accum_results.append(list(results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OESVuxzOdEkI",
        "outputId": "59def84d-48d2-4370-dfe6-b0e04b2b2d27"
      },
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "101it [00:20,  4.94it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of    686.    Elapsed: 0:00:20.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "200it [00:40,  4.78it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of    686.    Elapsed: 0:00:41.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "300it [01:01,  4.84it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of    686.    Elapsed: 0:01:02.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "401it [01:22,  4.94it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of    686.    Elapsed: 0:01:22.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "500it [01:42,  4.91it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of    686.    Elapsed: 0:01:42.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "600it [02:02,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of    686.    Elapsed: 0:02:03.\n",
            "  Batch   600  of    686.    Elapsed: 0:02:03.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "686it [02:20,  4.89it/s]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:21\n",
            "\n",
            "Accuracy: 0.8073\n",
            "F1 (Macro) Score: 0.7727\n",
            "F1 (Micro) Score: 0.8549\n",
            "F1 (Weighted) Score: 0.8545\n",
            "ROC-AUC: 0.9149\n",
            "Hamming Loss: 0.0366\n",
            "Test took: 0:02:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down evaluation"
      ],
      "metadata": {
        "id": "lInDyL-9hjhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_labels):\n",
        "    ith_label_ids, ith_logits = [], []\n",
        "\n",
        "    for j, labels in enumerate(accum_label_ids):\n",
        "        if len(np.where(labels)[0]) == i+1:\n",
        "            ith_label_ids.append(accum_label_ids[j].tolist())\n",
        "            ith_logits.append(accum_logits[j].tolist())\n",
        "\n",
        "    ith_label_ids = np.array(ith_label_ids)\n",
        "    ith_logits = np.array(ith_logits)\n",
        "\n",
        "    if len(ith_label_ids) == 0 and len(ith_logits) == 0:\n",
        "        continue\n",
        "\n",
        "    results = multi_label_metrics(ith_logits, ith_label_ids)\n",
        "    accum_results.append(list(results.values()))\n",
        "\n",
        "    print('# of labels:', i+1)\n",
        "    print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "    print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "    print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "    print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))\n",
        "    print(\"ROC-AUC: {0:.4f}\".format(results['roc_auc']))\n",
        "    print(\"Hamming Loss: {0:.4f}\".format(results['hamming_loss']))\n",
        "\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uVtTwWhnHy",
        "outputId": "8a25de2c-c47c-4bb2-8fe3-d096c7199dd4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 1\n",
            "Accuracy: 0.8351\n",
            "F1 (Macro) Score: 0.7588\n",
            "F1 (Micro) Score: 0.8556\n",
            "F1 (Weighted) Score: 0.8576\n",
            "ROC-AUC: 0.9241\n",
            "Hamming Loss: 0.0326\n",
            "\n",
            "\n",
            "# of labels: 2\n",
            "Accuracy: 0.6499\n",
            "F1 (Macro) Score: 0.7102\n",
            "F1 (Micro) Score: 0.8614\n",
            "F1 (Weighted) Score: 0.8708\n",
            "ROC-AUC: 0.8935\n",
            "Hamming Loss: 0.0576\n",
            "\n",
            "\n",
            "# of labels: 3\n",
            "Accuracy: 0.3448\n",
            "F1 (Macro) Score: 0.6232\n",
            "F1 (Micro) Score: 0.8063\n",
            "F1 (Weighted) Score: 0.8054\n",
            "ROC-AUC: 0.8417\n",
            "Hamming Loss: 0.1130\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n",
            "# of labels: 4\n",
            "Accuracy: 0.2000\n",
            "F1 (Macro) Score: 0.5363\n",
            "F1 (Micro) Score: 0.7861\n",
            "F1 (Weighted) Score: 0.7787\n",
            "ROC-AUC: 0.8200\n",
            "Hamming Loss: 0.1644\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer,\n",
        "device=0, max_length=10,\n",
        " return_all_scores=True, function_to_apply='sigmoid')\n",
        "result = pipe('틀니들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)\n",
        "label_dict = {'LABEL_0' : '출신차별', 'LABEL_1' : '외모차별', 'LABEL_2' : '정치성향차별', 'LABEL_3': '혐오욕설', 'LABEL_4': '연령차별', 'LABEL_5': '성차별', 'LABEL_6' : '인종차별', 'LABEL_7': '종교차별', 'LABEL_8': '해당사항없음'}\n",
        "def prediction(text):\n",
        " result = pipe(text)\n",
        " return [label_dict[res['label']] for res in result[0] if res['score'] > 0.5]\n",
        "prediction('틀니들은 왜 그렇게 민폐를 끼치냐?')"
      ],
      "metadata": {
        "id": "798meQSe6c-Y",
        "outputId": "25b7ee59-8efb-4a6d-b282-5effb36fd5f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n",
            "[[{'label': 'LABEL_0', 'score': 0.006339981686323881}, {'label': 'LABEL_1', 'score': 0.007088158279657364}, {'label': 'LABEL_2', 'score': 0.007644087076187134}, {'label': 'LABEL_3', 'score': 0.005460667889565229}, {'label': 'LABEL_4', 'score': 0.9843930602073669}, {'label': 'LABEL_5', 'score': 0.010978417471051216}, {'label': 'LABEL_6', 'score': 0.0012231196742504835}, {'label': 'LABEL_7', 'score': 0.002903062617406249}, {'label': 'LABEL_8', 'score': 0.007692909799516201}]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연령차별']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "def predict_labels(text, model, tokenizer, label_names, threshold=0.1):\n",
        "    # 텍스트를 모델의 입력 형식으로 인코딩\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 10,\n",
        "                        padding = 'max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                        )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    # 모델을 사용하여 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    # 예측 결과에서 확률 추출\n",
        "    logits = outputs.logits\n",
        "    #print(logits)\n",
        "    probs = sigmoid(logits)\n",
        "    #print(probs)\n",
        "\n",
        "    # CPU로 이동 후 numpy 배열로 변환\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    #print(probs)\n",
        "\n",
        "    # 예측된 레이블 결정\n",
        "    predicted_labels = [label_names[i] for i in range(len(label_names)) if probs[0][i] >= threshold]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "2FStXOPPcqnO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"늙은 천주교 신자들은 다 속물이다\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "t18ZXNVec82c",
        "outputId": "66979472-4fa8-437b-86b1-bf60da20ac1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 늙은 천주교 신자들은 다 속물이다 & Predicted labels: ['연령차별', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['출신차별', '외모차별', '정치성향차별', '혐오욕설', '연령차별', '성차별', '인종차별', '종교차별', '혐오아님']\n",
        "threshold = 0.1\n",
        "text = \"못생긴 경상도 여자들은 나가라\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} -> Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "Q4wfueAfdARU",
        "outputId": "fd2fc5fd-4ed1-4ba5-cac2-b36f9fbf8954",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 못생긴 경상도 여자들은 나가라 -> Predicted labels: ['출신차별', '외모차별', '성차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7LV_-RJXdR5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VSCode 쪽 코드 (receive_data.py)\n",
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "xCHlbhrqdDuu",
        "outputId": "dfab927a-95c7-4912-c8ac-f2abdd2b3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1b184333c58d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/./content/model/attention_scores.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutputs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/./content/model/attention_scores.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('문재앙')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "f-0wLH1NexAK",
        "outputId": "dd71019e-4caf-4567-b3d9-a1d4ed86b158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.007721993140876293}, {'label': 'LABEL_1', 'score': 0.0032311684917658567}, {'label': 'LABEL_2', 'score': 0.985312283039093}, {'label': 'LABEL_3', 'score': 0.005993323866277933}, {'label': 'LABEL_4', 'score': 0.0053891874849796295}, {'label': 'LABEL_5', 'score': 0.0028214144986122847}, {'label': 'LABEL_6', 'score': 0.001229260116815567}, {'label': 'LABEL_7', 'score': 0.00213793246075511}, {'label': 'LABEL_8', 'score': 0.007046674843877554}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = \"cpu\"\n",
        "\n",
        "# 모델을 CPU로 이동\n",
        "model = model.to(device)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, max_length=10, return_all_scores=True)\n",
        "\n",
        "result = pipe('깜둥이들은 왜 그렇게 민폐를 끼치냐?')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "PmW6CiNigW55",
        "outputId": "2bdac7f6-cc79-4374-d81a-910426905f52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.14709043502807617}, {'label': 'LABEL_1', 'score': 0.2649373412132263}, {'label': 'LABEL_2', 'score': 0.026825901120901108}, {'label': 'LABEL_3', 'score': 0.030605364590883255}, {'label': 'LABEL_4', 'score': 0.08758822828531265}, {'label': 'LABEL_5', 'score': 0.09902966767549515}, {'label': 'LABEL_6', 'score': 0.8641229867935181}, {'label': 'LABEL_7', 'score': 0.14547504484653473}, {'label': 'LABEL_8', 'score': 0.11148739606142044}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "predicted_labels = predict_labels(text, model, tokenizer, label_names)\n",
        "print(f\"Text: {text} & Predicted labels: {predicted_labels}\")"
      ],
      "metadata": {
        "id": "lEvK_zHWgiKj",
        "outputId": "0ff0471e-2bb4-477e-c945-c099126b1659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: ㅅ발 천주교도들은 너무 말이 많아 & Predicted labels: ['혐오욕설', '종교차별']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = '/home/jyhan/HW-output-files/example.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "NH4-k_-Zgp5L",
        "outputId": "9fd53535-91b8-454e-b524-ae6a27a64079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file /home/jyhan/HW-output-files/example.txt does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def pickle_to_text(pickle_file_path, text_file_path):\n",
        "    # 피클 파일 불러오기\n",
        "    with open(pickle_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    # 텍스트 파일로 저장하기\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        for sublist in data:\n",
        "            # 각 서브리스트를 반복하고 숫자를 문자열로 변환하여 저장\n",
        "            for number in sublist:\n",
        "                f.write(f\"{number} \")\n",
        "            f.write(\"\\n\\n\\n\")  # 각 서브리스트 끝에 줄바꿈 추가"
      ],
      "metadata": {
        "id": "OpUp0tFHhvQQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def tanh_new(x) :\n",
        "    result = (F.tanh(x) + 1) /2\n",
        "    return result"
      ],
      "metadata": {
        "id": "_c7Qzz8DhxOh"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number(num):\n",
        "    \"\"\"숫자를 7비트 2의 보수 형식으로 인코딩하는 함수, 음수 소수 부분을 고려\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = abs(num - int_num)\n",
        "\n",
        "    # Round integer part towards zero if num is negative and has a fractional part\n",
        "    if num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num = int_num - 1  # Round integer part one more negative\n",
        "            frac_num = 1 - frac_num  # Subtract fractional part from 1 to make it positive\n",
        "\n",
        "    # Clamp the values to fit within the 7-bit range\n",
        "    if int_num < -64:\n",
        "        int_num = -64\n",
        "    elif int_num > 63:\n",
        "        int_num = 63\n",
        "\n",
        "    # Apply 2's complement if the number is negative\n",
        "    if int_num < 0:\n",
        "        int_num = (1 << 7) + int_num  # 1 << 7 is 128, representing the range of 7-bit integers\n",
        "\n",
        "    # Format the number into 7-bit binary\n",
        "    int_part_bin = format(int_num & 0b1111111, '07b')  # Only the last 7 bits are used\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = int_part_bin + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "4RMAodqch2WA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_input(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number(num) for num in numbers]"
      ],
      "metadata": {
        "id": "_sD86m8Zh5dr"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import numpy as np\n",
        "from torch.nn.functional import sigmoid, softmax\n",
        "from itertools import chain\n",
        "import itertools"
      ],
      "metadata": {
        "id": "6TPxkyv6h-nI"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_number_output(num):\n",
        "    \"\"\"숫자를 3비트 정수와 13비트 소수 형식으로 인코딩하는 함수, 값은 0부터 1 사이의 양수\"\"\"\n",
        "    num = float(num)  # 입력된 숫자가 문자열이라면, 실수형으로 변환\n",
        "\n",
        "    # Clamp the values to fit within the 0 to 1 range\n",
        "    if num < 0:\n",
        "        num = 0\n",
        "    elif num > 1:\n",
        "        num = 1\n",
        "\n",
        "    # Extract integer and fractional parts\n",
        "    int_num = int(num)\n",
        "    frac_num = num - int_num\n",
        "\n",
        "    # Convert the fractional part to binary (13 bits)\n",
        "    decimal_part_bin = format(int(frac_num * (1 << 13)), '013b')\n",
        "\n",
        "    # Combine all parts\n",
        "    encoded = '000' + '_' + decimal_part_bin\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "jYW_te9oh_oY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_numbers_output(numbers):\n",
        "    \"\"\"리스트의 숫자들을 인코딩하는 함수\"\"\"\n",
        "    return [encode_number_output(num) for num in numbers]"
      ],
      "metadata": {
        "id": "5a7CeXJmh_p6"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [0.0301, 0.0112, 0.0040, 0.7632, 0.0040, 0.0072, 0.0068, 0.8885, 0.0117]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "FFeQcYAWiMA8",
        "outputId": "034f411c-44d1-4972-a2c5-7b315d2a9042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['000_0000011110110', '000_0000001011011', '000_0000000100000', '000_1100001101100', '000_0000000100000', '000_0000000111010', '000_0000000110111', '000_1110001101110', '000_0000001011111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [-3.0061, -4.5561, -3.7781, -4.6988, -1.8251, -4.0483, -4.8075,  4.6085, -5.1693]\n",
        "encoded_numbers = encode_numbers_input(probs)\n",
        "print(encoded_numbers)\n",
        "\n",
        "probs = [0.0472, 0.0104, 0.0224, 0.0090, 0.1388, 0.0172, 0.0081, 0.9901, 0.0057]\n",
        "encoded_numbers = encode_numbers_output(probs)\n",
        "print(encoded_numbers)"
      ],
      "metadata": {
        "id": "W-j1Du8UiEQp",
        "outputId": "3f2730a8-b336-4ae3-967c-eac500986f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1111100_1111111001110', '1111011_0111000110100', '1111100_0011100011001', '1111011_0100110100011', '1111110_0010110011000', '1111011_1111001110100', '1111011_0011000101000', '0000100_1001101111000', '1111010_1101010010101']\n",
            "['000_0000110000010', '000_0000001010101', '000_0000010110111', '000_0000001001001', '000_0010001110001', '000_0000010001100', '000_0000001000010', '000_1111110101110', '000_0000000101110']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin, decimal_part_bin = encoded.split('.')\n",
        "\n",
        "    # Integer part processing\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # Negative number (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # Positive number\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # Fractional part processing\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # Adjust for negative numbers\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test the function with provided values\n",
        "encoded_values = [\n",
        "    \"0000000.0101010000101\",\n",
        "    \"0000000.0010111100000\",\n",
        "    \"0000000.0010110110000\",\n",
        "    \"0000000.0010001111011\",\n",
        "    \"0000000.0010001101110\",\n",
        "    \"0000000.0001110010000\",\n",
        "    \"0000000.0001100000110\",\n",
        "    \"0000000.0000000000010\",\n",
        "    \"1111111.1101100010111\",\n",
        "    \"1111111.1101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "kzwvRVHhiM6-",
        "outputId": "eb88968f-a1a8-4b89-ae9f-b41ab24d2c7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3287353515625,\n",
              " 0.18359375,\n",
              " 0.177734375,\n",
              " 0.1400146484375,\n",
              " 0.138427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " -0.1534423828125,\n",
              " -0.1597900390625]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_number(encoded):\n",
        "    \"\"\"7비트 2의 보수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    # 입력 문자열을 반으로 나누어 정수 부분과 소수 부분으로 분리\n",
        "    mid_index = len(encoded) // 2\n",
        "    int_part_bin = encoded[:mid_index]\n",
        "    decimal_part_bin = encoded[mid_index:]\n",
        "\n",
        "    # 정수 부분 처리\n",
        "    if int(int_part_bin, 2) & (1 << 6):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 7)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"00000000101010000101\",\n",
        "    \"00000000010111100000\",\n",
        "    \"00000000010110110000\",\n",
        "    \"00000000010001111011\",\n",
        "    \"00000000010001101110\",\n",
        "    \"00000000001110010000\",\n",
        "    \"00000000001100000110\",\n",
        "    \"00000000000000000010\",\n",
        "    \"11111111101100010111\",\n",
        "    \"11111111101011100011\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_number(value) for value in encoded_values]\n",
        "decoded_values"
      ],
      "metadata": {
        "id": "Fy0SQbOSiad-",
        "outputId": "109209cd-f0a0-4cfc-d28e-67129ecf0c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0787353515625,\n",
              " 1.05859375,\n",
              " 1.052734375,\n",
              " 1.0150146484375,\n",
              " 1.013427734375,\n",
              " 0.111328125,\n",
              " 0.094482421875,\n",
              " 0.000244140625,\n",
              " 894.0965576171875,\n",
              " 894.0902099609375]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    if int(int_part_bin, 2) & (1 << 2):  # 음수인 경우 (2의 보수)\n",
        "        int_num = int(int_part_bin, 2) - (1 << 3)\n",
        "    else:  # 양수인 경우\n",
        "        int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 음수 조정\n",
        "    if int_num < 0:\n",
        "        if frac_num > 0:\n",
        "            int_num += 1\n",
        "            frac_num = 1 - frac_num\n",
        "        result = int_num - frac_num\n",
        "    else:\n",
        "        result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0001000101001100\",\n",
        "    \"0000011001010100\",\n",
        "    \"0000000111011100\",\n",
        "    \"0000000111010100\",\n",
        "    \"0000000110110100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000011010100\",\n",
        "    \"0000000001100100\",\n",
        "    \"0000000001010100\",\n",
        "    \"0000000001000100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for encoded, decoded in zip(encoded_values, decoded_values):\n",
        "    print(f\"Encoded: {encoded} -> Decoded: {decoded}\")"
      ],
      "metadata": {
        "id": "i6y3VbyOiiIq",
        "outputId": "81057643-f2b3-4377-c252-080c4590e452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: 0001000101001100 -> Decoded: 0.54052734375\n",
            "Encoded: 0000011001010100 -> Decoded: 0.19775390625\n",
            "Encoded: 0000000111011100 -> Decoded: 0.05810546875\n",
            "Encoded: 0000000111010100 -> Decoded: 0.05712890625\n",
            "Encoded: 0000000110110100 -> Decoded: 0.05322265625\n",
            "Encoded: 0000000100000100 -> Decoded: 0.03173828125\n",
            "Encoded: 0000000011010100 -> Decoded: 0.02587890625\n",
            "Encoded: 0000000001100100 -> Decoded: 0.01220703125\n",
            "Encoded: 0000000001010100 -> Decoded: 0.01025390625\n",
            "Encoded: 0000000001000100 -> Decoded: 0.00830078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "\n",
        "    # 리스트를 문자열 형식으로 변환\n",
        "    formatted_hex_list = \"[\" + \", \".join(f'\"{hex_value}\"' for hex_value in hex_list) + \"]\"\n",
        "\n",
        "    return formatted_hex_list\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"06dc 05c4 0494 03c4 039c 02e4 017c 0144 00e4 00ac\"\n",
        "formatted_hex_list = format_hex_input(hex_input)\n",
        "\n",
        "print(formatted_hex_list)"
      ],
      "metadata": {
        "id": "KiL0Vi9sikfX",
        "outputId": "ec08850a-b43d-4fff-bd0c-b0c283cf931e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"06dc\", \"05c4\", \"0494\", \"03c4\", \"039c\", \"02e4\", \"017c\", \"0144\", \"00e4\", \"00ac\"]\n",
        "\n",
        "float_values = hexa_to_float(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, float_value in zip(hex_strings, float_values):\n",
        "    print(f\"{float_value}\")"
      ],
      "metadata": {
        "id": "6FquW2OFiogU",
        "outputId": "24d060e9-06ec-4953-f1e9-ef1406fda6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21435546875\n",
            "0.18017578125\n",
            "0.14306640625\n",
            "0.11767578125\n",
            "0.11279296875\n",
            "0.09033203125\n",
            "0.04638671875\n",
            "0.03955078125\n",
            "0.02783203125\n",
            "0.02099609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_hex_input(hex_input):\n",
        "    # 공백을 기준으로 입력값을 분할하여 리스트로 변환\n",
        "    hex_list = hex_input.split()\n",
        "    return hex_list\n",
        "\n",
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "def hexa_to_float(hex_strings):\n",
        "    binary_strings = hexa_to_binary(hex_strings)\n",
        "    float_values = [decode_int3_float13(binary_string) for binary_string in binary_strings]\n",
        "    return float_values\n",
        "\n",
        "def convert_hex_input_to_float(hex_input):\n",
        "    hex_strings = format_hex_input(hex_input)\n",
        "    float_values = hexa_to_float(hex_strings)\n",
        "    return float_values\n",
        "\n",
        "def chunk_floats(float_values, chunk_size=10):\n",
        "    # float 값을 chunk_size 크기로 분할하고 각 chunk 사이에 두 개의 엔터를 추가\n",
        "    chunked_result = \"\"\n",
        "    for i in range(0, len(float_values), chunk_size):\n",
        "        chunk = float_values[i:i + chunk_size]\n",
        "        chunked_result += \"\\n\".join(map(str, chunk)) + \"\\n\\n\"\n",
        "    return chunked_result.strip()\n",
        "\n",
        "# 입력값\n",
        "hex_input = \"\"\"\n",
        "1404\n",
        "026c\n",
        "0234\n",
        "0214\n",
        "0184\n",
        "017c\n",
        "015c\n",
        "001c\n",
        "001c\n",
        "0004\n",
        "\"\"\"\n",
        "\n",
        "float_values = convert_hex_input_to_float(hex_input)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "chunked_result = chunk_floats(float_values)\n",
        "\n",
        "print(chunked_result)"
      ],
      "metadata": {
        "id": "w7Z4vjWsiwnS",
        "outputId": "dbe86673-8e87-4e44-d117-ca01ffe6aa7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.62548828125\n",
            "0.07568359375\n",
            "0.06884765625\n",
            "0.06494140625\n",
            "0.04736328125\n",
            "0.04638671875\n",
            "0.04248046875\n",
            "0.00341796875\n",
            "0.00341796875\n",
            "0.00048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_int3_float13(encoded):\n",
        "    \"\"\"3비트 정수 + 13비트 소수 형식으로 인코딩된 값을 float으로 디코딩하는 함수\"\"\"\n",
        "    int_part_bin = encoded[:3]\n",
        "    decimal_part_bin = encoded[3:]\n",
        "\n",
        "    # 정수 부분 처리 (3비트)\n",
        "    int_num = int(int_part_bin, 2)\n",
        "\n",
        "    # 소수 부분 처리 (13비트)\n",
        "    frac_num = int(decimal_part_bin, 2) / (1 << 13)\n",
        "\n",
        "    # 결과 계산\n",
        "    result = int_num + frac_num\n",
        "\n",
        "    return result\n",
        "\n",
        "# 제공된 값으로 함수를 테스트합니다\n",
        "encoded_values = [\n",
        "    \"0000110101000100\",\n",
        "    \"0000100000100100\",\n",
        "    \"0000001101111100\",\n",
        "    \"0000001011111100\",\n",
        "    \"0000000111000100\",\n",
        "    \"0000000100000100\",\n",
        "    \"0000000001110100\",\n",
        "    \"0000000001000100\",\n",
        "    \"0000000000111100\",\n",
        "    \"0000000000110100\"\n",
        "]\n",
        "\n",
        "decoded_values = [decode_int3_float13(value) for value in encoded_values]\n",
        "\n",
        "# 결과 출력\n",
        "for decoded in decoded_values:\n",
        "    print(decoded)\n"
      ],
      "metadata": {
        "id": "8BR8NGmgi0Ny",
        "outputId": "db8f469f-3636-4cc6-b13c-7286a464fa40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41455078125\n",
            "0.25439453125\n",
            "0.10888671875\n",
            "0.09326171875\n",
            "0.05517578125\n",
            "0.03173828125\n",
            "0.01416015625\n",
            "0.00830078125\n",
            "0.00732421875\n",
            "0.00634765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "new_hex_strings = [\"0d44\", \"0824\", \"037c\", \"02fc\", \"01c4\", \"0104\", \"0074\", \"0044\", \"003c\", \"0034\"]\n",
        "new_binary_strings = hexa_to_binary(new_hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(new_hex_strings, new_binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "1W-StNJci3XU",
        "outputId": "dd7e6790-5e93-4aa0-8c38-89082fc2ca8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000110101000100\n",
            "0000100000100100\n",
            "0000001101111100\n",
            "0000001011111100\n",
            "0000000111000100\n",
            "0000000100000100\n",
            "0000000001110100\n",
            "0000000001000100\n",
            "0000000000111100\n",
            "0000000000110100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hexa_to_binary(hex_strings):\n",
        "    binary_strings = [bin(int(hex_string, 16))[2:].zfill(16) for hex_string in hex_strings]\n",
        "    return binary_strings\n",
        "\n",
        "# 새로운 입력값\n",
        "hex_strings = [\"069c\", \"046c\", \"045c\", \"0434\", \"02fc\", \"02a4\", \"026c\", \"01d4\", \"00e4\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")"
      ],
      "metadata": {
        "id": "xyNYFw6ki5gk",
        "outputId": "f2583d25-0e49-469d-da97-97d94f3180e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000011010011100\n",
            "0000010001101100\n",
            "0000010001011100\n",
            "0000010000110100\n",
            "0000001011111100\n",
            "0000001010100100\n",
            "0000001001101100\n",
            "0000000111010100\n",
            "0000000011100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 입력값\n",
        "hex_strings = [\"045c\", \"0404\", \"03b4\", \"039c\", \"0374\", \"034c\", \"031c\", \"027c\", \"022c\", \"01bc\"]\n",
        "binary_strings = hexa_to_binary(hex_strings)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "for hex_string, binary_string in zip(hex_strings, binary_strings):\n",
        "    print(f\"{binary_string}\")\n"
      ],
      "metadata": {
        "id": "LCmwYD9Qi79m",
        "outputId": "a6c49f8a-4788-49e5-fcd1-4e7b6842da4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000010001011100\n",
            "0000010000000100\n",
            "0000001110110100\n",
            "0000001110011100\n",
            "0000001101110100\n",
            "0000001101001100\n",
            "0000001100011100\n",
            "0000001001111100\n",
            "0000001000101100\n",
            "0000000110111100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error_rates(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    list of float: 각 데이터에 대한 오차율 (백분율) 리스트\n",
        "    \"\"\"\n",
        "    if len(actual_values) != len(predicted_values):\n",
        "        raise ValueError(\"실제 값 리스트와 예측 값 리스트의 길이는 같아야 합니다.\")\n",
        "\n",
        "    error_rates = []\n",
        "    for actual, predicted in zip(actual_values, predicted_values):\n",
        "        if actual == 0:\n",
        "            error_rate = 0\n",
        "        else:\n",
        "            error = actual - predicted\n",
        "            error_rate = abs((error / actual) * 100)\n",
        "        error_rates.append(error_rate)\n",
        "\n",
        "    return error_rates\n",
        "\n",
        "def calculate_average_error_rate(actual_values, predicted_values):\n",
        "    \"\"\"\n",
        "    여러 개의 실제 값과 예측 값에 대한 평균 오차율을 계산하는 함수.\n",
        "\n",
        "    매개변수:\n",
        "    actual_values (list of float): 실제 값 리스트\n",
        "    predicted_values (list of float): 예측 값 리스트\n",
        "\n",
        "    반환값:\n",
        "    float: 평균 오차율 (백분율)\n",
        "    \"\"\"\n",
        "    error_rates = calculate_error_rates(actual_values, predicted_values)\n",
        "    average_error_rate = sum(error_rates) / len(error_rates)\n",
        "    return average_error_rate"
      ],
      "metadata": {
        "id": "D2-wjc8yi_Ij"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용\n",
        "actual_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "predicted_values = [3.447215, 2.4453104, 1.2259121, 1.2043934, 1.1346276, 0.6330924, 0.4353165, -0.2769869, -0.47311664, -0.6537097]\n",
        "average_error_rate = calculate_average_error_rate(actual_values, predicted_values)\n",
        "\n",
        "print(f\"최종 오차율: {average_error_rate}%\")"
      ],
      "metadata": {
        "id": "clf_RoSfjBeq",
        "outputId": "00ffc700-46b4-40ef-a17d-b6d00a83375a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 오차율: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정\n",
        "start_time = time.time()\n",
        "softmax_values = softmax(values)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Softmax output: {softmax_values}\")\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "i7BTwvyNjE92",
        "outputId": "b999086b-b272-4992-bd14-41ce40aebc70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax output: [0.15355578 0.16079324 0.07440393 0.13852536 0.07058606 0.11775769\n",
            " 0.06605177 0.06064859 0.09803082 0.05964678]\n",
            "Execution time: 0.00022268295288085938 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# 10개의 값을 생성\n",
        "values = np.random.rand(10)\n",
        "\n",
        "# 실행 시간 측정 (timeit 모듈 사용)\n",
        "execution_time = timeit.timeit(lambda: softmax(values), number=100000)\n",
        "print(f\"Average execution time over 1000 runs: {execution_time / 100000} seconds\")\n"
      ],
      "metadata": {
        "id": "I7TbeCl0jFAe",
        "outputId": "a2b65b0e-33b2-420f-9bf8-f863187f3a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average execution time over 1000 runs: 1.6280943279999747e-05 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "start_time = time.time()\n",
        "my_function()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "_Y3J9uF8jFCp",
        "outputId": "26b690f7-d3db-418e-8f77-5a7f1b19ce71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.000325918197632 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "execution_time = timeit.timeit(my_function, number=1)\n",
        "print(f\"Execution time: {execution_time} seconds\")\n"
      ],
      "metadata": {
        "id": "9a5zh7itjK_1",
        "outputId": "fcb0dc02-51e6-4bb0-a306-24ec145fccb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0000968580000063 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Execution time: {end_time - start_time} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@measure_time\n",
        "def my_function():\n",
        "    # 실행할 코드\n",
        "    time.sleep(2)  # 예시로 2초 지연\n",
        "\n",
        "my_function()"
      ],
      "metadata": {
        "id": "XarrC_jbjPME",
        "outputId": "978ce2a6-e207-406a-e6df-f3d74c06252d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 2.0001320838928223 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import socket\n",
        "\n",
        "# HW -> SW connect\n",
        "# This should be fixed later when connecting with hardware.\n",
        "def receive_from_hardware(host: str, port: int, buffer_size: int = 1024) -> bytes:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.connect((host, port))\n",
        "        attention_probs_hw = s.recv(buffer_size)\n",
        "    return attention_probs_hw\n",
        "\n",
        "# HW 2진수 -> SW Decode\n",
        "def decode_values(encoded_values_list: list) -> list:\n",
        "    encoded_values = tuple(encoded_values_list)\n",
        "    decoded_values = []\n",
        "\n",
        "    for encoded_value in encoded_values:\n",
        "        special_value_bit = encoded_value[0]\n",
        "        if special_value_bit == '1':\n",
        "            decoded_values.append(0.0)\n",
        "        else:\n",
        "            sign_bit = encoded_value[1]\n",
        "            sign = -1 if sign_bit == '1' else 1\n",
        "\n",
        "            integer_part = int(encoded_value[2:5], 2)\n",
        "            fractional_part = int(encoded_value[5:], 2) / (1 << 13)\n",
        "\n",
        "            decoded_value = sign * (integer_part + fractional_part)\n",
        "            decoded_values.append(round(decoded_value, 7))\n",
        "\n",
        "    return decoded_values\n",
        "\n",
        "# 1D -> 4D 변환 코드\n",
        "def convert_to_4d(input_list):\n",
        "    # Step 1: Divide the list into sublists of 10 elements each\n",
        "    sublists = [input_list[i:i + 10] for i in range(0, len(input_list), 10)]\n",
        "\n",
        "    # Step 2: Group every 10 sublists into a larger list to form a [12, 10, 10] shape\n",
        "    grouped_sublists = [sublists[i:i + 10] for i in range(0, len(sublists), 10)]\n",
        "\n",
        "    # Step 3: Convert the final list to a tensor and add an extra dimension to form [1, 12, 10, 10]\n",
        "    attention_probs_4d = torch.tensor(grouped_sublists).unsqueeze(0)\n",
        "    return attention_probs_4d"
      ],
      "metadata": {
        "id": "vh30Ck9JjWVj"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "03UOsodCJaEg",
        "outputId": "8d458338-9def-49ed-a01c-6b54c0b452fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'layer_1_attention' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-546e3a501010>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 함수 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msave_attention_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attention scores가 {file_path}에 저장되었습니다!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_1_attention' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# attention_scores 저장 함수 정의\n",
        "def save_attention_scores(attention_scores, file_path):\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(attention_scores, f)\n",
        "\n",
        "\n",
        "# 파일 경로 지정\n",
        "file_path = './model/attention_scores.pkl'\n",
        "\n",
        "# 함수 호출\n",
        "save_attention_scores(layer_1_raw_attention, file_path)\n",
        "\n",
        "print(f\"Attention scores가 {file_path}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "GEln6Bi7whyh",
        "outputId": "f7a96f65-748a-460e-928f-52997239a657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores가 ./model/attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "05VQ55mWooaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import math\n",
        "attention_scores = layer_1_attention\n",
        "attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        " #Pickle 파일 저장\n",
        "if attention_mask is not None:\n",
        " # Apply the attention mask is (precomputed for all layers in BertModel\n",
        " attention_scores = attention_scores + attention_mask\n",
        " # attention_scores를 피클 파일로 저장합니다.\n",
        "attention_scores_list = attention_scores.tolist()  # torch.Tensor를 Python 리스트로 변환\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"wb\") as f:\n",
        " pickle.dump(attention_scores_list, f)\n",
        " #저장된 Pickle 파일 불러와서 plot\n",
        "with open(\"/./content/model/attention_scores.pkl\", \"rb\") as f:\n",
        " outputs = pickle.load(f)\n",
        "out_chain3 = list(itertools.chain(*outputs))\n",
        "out_chain2 = list(itertools.chain(*out_chain3))\n",
        "out_chain1 = list(itertools.chain(*out_chain2))\n",
        "print(out_chain1)\n",
        "max_value = torch.max(attention_scores)\n",
        "min_value = torch.min(attention_scores)\n",
        "print(\"Max value in attention_scores:\", max_value.item())"
      ],
      "metadata": {
        "id": "YAV18-7XnknO",
        "outputId": "6677399f-036a-4de7-ea6f-d211165a955b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'self' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b97d7302ca28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_1_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m  \u001b[0;31m#Pickle 파일 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "if2KlEtgI6bj"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # Attention 값 활성화\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        # Attention Score (Softmax 이후 값)\n",
        "        attention_probs = outputs.attentions  # (batch, num_heads, seq_length, seq_length)\n",
        "\n",
        "        # Softmax 이전 값 = Scaled Dot-Product Attention Score (QK^T / sqrt(d_k))\n",
        "        raw_attentions = []\n",
        "        for layer in self.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.last_hidden_state)\n",
        "            K = layer.attention.self.key(outputs.last_hidden_state)\n",
        "            d_k = Q.shape[-1] ** 0.5  # sqrt(d_k)\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # QK^T / sqrt(d_k)\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, attention_probs  # Softmax 이전 값과 이후 값 반환\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# 입력 문장\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions = model(**inputs)\n",
        "\n",
        "# 첫 번째 레이어의 Softmax 이전 Attention Score 출력\n",
        "layer_1_raw_attention = raw_attentions[0].numpy()  # NumPy 변환\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "keaM8Y3PvqJ7",
        "outputId": "7cbebf05-2849-4eb7-df37-2a96c517e205",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 10, 10)):\n",
            "[[[-1.25852823e+00  2.66215712e-01 -8.78310561e-01 -5.46610832e-01\n",
            "   -2.88807482e-01  1.11422515e+00 -7.55868137e-01 -1.04048252e+00\n",
            "   -6.23540282e-01 -4.86584216e-01]\n",
            "  [-2.56121695e-01 -1.71548009e-01 -8.60907257e-01 -7.67546833e-01\n",
            "   -9.95912910e-01 -1.00643361e+00 -4.07447457e-01 -1.75079393e+00\n",
            "    1.79270849e-01  1.09233379e+00]\n",
            "  [-2.95971274e-01 -5.97175062e-01 -5.01220524e-01 -7.32082844e-01\n",
            "   -9.14117396e-01 -4.85211074e-01 -9.03017342e-01 -1.16841352e+00\n",
            "   -1.58572093e-01  1.26348448e+00]\n",
            "  [-1.37948975e-01 -2.04223856e-01  4.05856907e-01 -1.50166214e+00\n",
            "    5.47514558e-02  1.44970313e-01 -1.13640618e+00 -2.22163677e+00\n",
            "   -2.47296557e-01 -1.33462834e+00]\n",
            "  [ 1.01324928e+00  1.64172506e+00  6.23836458e-01  6.27645195e-01\n",
            "   -6.22797310e-01  9.15249646e-01  3.98019969e-01 -1.16255677e+00\n",
            "   -6.03965938e-01 -1.14379549e+00]\n",
            "  [ 1.11805654e+00  9.22619820e-01  1.66346371e+00  1.28638303e+00\n",
            "    3.01247567e-01 -3.35117072e-01  4.42473382e-01 -2.01341057e+00\n",
            "    1.57611266e-01 -7.06549704e-01]\n",
            "  [-2.56664723e-01  2.37522781e-01  8.96184087e-01  2.33783759e-02\n",
            "   -2.61715978e-01 -1.59865290e-01 -3.91456425e-01 -1.25633550e+00\n",
            "   -8.63685906e-02 -5.29619396e-01]\n",
            "  [-4.56178546e-01 -1.40805280e+00 -1.01764131e+00 -1.13802481e+00\n",
            "   -4.46542889e-01  1.36807829e-01 -9.18115318e-01 -1.72494113e+00\n",
            "    1.12401016e-01 -7.55020678e-01]\n",
            "  [-1.68190569e-01  6.50996327e-01 -4.09294933e-01  1.49280071e-01\n",
            "   -6.98003054e-01  1.38944983e+00  8.27238634e-02 -2.14583308e-01\n",
            "    8.28214407e-01  7.93602645e-01]\n",
            "  [-1.48121583e+00 -4.18758541e-02 -2.22063810e-03 -8.71774971e-01\n",
            "   -1.92896914e+00 -1.38735354e+00 -1.09499991e+00 -8.92453134e-01\n",
            "   -5.12685597e-01  1.16958547e+00]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 Head 수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        raw_attentions = []\n",
        "        for layer in self.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.last_hidden_state)  # (1, 10, 768)\n",
        "            K = layer.attention.self.key(outputs.last_hidden_state)  # (1, 10, 768)\n",
        "\n",
        "            # 🚀 **멀티헤드 형태로 변환 (12개 헤드 고려)**\n",
        "            Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, head_dim)\n",
        "            K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, head_dim)\n",
        "\n",
        "            # Softmax 이전 Attention Score (1, 12, 10, 10)\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, outputs.attentions  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# 입력 문장\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions = model(**inputs)\n",
        "\n",
        "#  Softmax 이전 값의 shape이 (1, 12, 10, 10)\n",
        "layer_1_raw_attention = raw_attentions[0].numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "6c_PDcdAuBHP",
        "outputId": "cc21fafc-d25a-4599-ad0c-35a6dc4ede2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[-0.16330126  0.74665904  0.5046175  ...  0.1053734  -0.3517992\n",
            "    -0.82628703]\n",
            "   [-0.85504246 -0.8495395   0.27420458 ... -0.7120759  -0.6404201\n",
            "    -0.7213575 ]\n",
            "   [-0.33850312 -0.49887422 -1.0850958  ... -0.41751945 -0.6837665\n",
            "     0.12196846]\n",
            "   ...\n",
            "   [ 0.04038128 -1.5239407  -0.4461439  ... -0.8514781  -0.62913764\n",
            "    -1.6456957 ]\n",
            "   [-0.48097274 -1.1991742  -0.16329284 ...  0.6281986  -0.76396775\n",
            "    -0.7268485 ]\n",
            "   [-0.87766147 -1.1943011  -0.7693224  ... -1.3699665  -1.3390534\n",
            "    -1.2797705 ]]\n",
            "\n",
            "  [[-1.5912344   0.20777252 -0.43285406 ... -0.1675356  -0.7102615\n",
            "    -1.2166344 ]\n",
            "   [-0.7868527  -1.6073718  -0.392333   ... -0.75894797 -0.4079647\n",
            "    -1.2190759 ]\n",
            "   [-0.8922362  -1.5154754  -0.5177639  ... -1.1458592   0.04225418\n",
            "    -0.81918186]\n",
            "   ...\n",
            "   [-0.91656446 -1.0473183  -1.0032847  ... -1.8697616  -0.1359748\n",
            "    -1.1439781 ]\n",
            "   [-1.0975006   0.37157917 -0.00895183 ... -0.17786475 -0.4199428\n",
            "    -0.6056418 ]\n",
            "   [-1.0515333  -1.0735983  -0.05120684 ...  0.6294587  -0.54036653\n",
            "    -1.3968381 ]]\n",
            "\n",
            "  [[-1.3334383   0.52438104 -0.77032316 ... -1.5920824  -0.6231944\n",
            "     0.6344059 ]\n",
            "   [ 0.60698706  0.8066657  -0.67015445 ... -1.5112193  -0.23542288\n",
            "     1.3105445 ]\n",
            "   [ 0.1526948   0.43083888 -0.17596313 ... -1.0903219   0.08325759\n",
            "     1.6672667 ]\n",
            "   ...\n",
            "   [-1.329351   -0.46315804 -0.77565247 ... -1.8013197  -0.62225544\n",
            "     0.04331292]\n",
            "   [-1.354799    0.23697038 -0.7694026  ... -1.0223584  -0.39240664\n",
            "     1.1857013 ]\n",
            "   [-0.77541286  1.3453577   0.29122424 ... -0.58102393  0.17997822\n",
            "     2.177164  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.63773     0.58566344  0.02071998 ...  0.6568019  -0.00503088\n",
            "     0.5775351 ]\n",
            "   [ 0.78469926  0.7234775   0.37324268 ...  0.569415    1.1611848\n",
            "     0.6611439 ]\n",
            "   [ 0.3827159  -0.38354316 -0.5915842  ...  0.07002717  0.5606207\n",
            "     0.02549144]\n",
            "   ...\n",
            "   [ 1.7375914   0.74641496  1.1182951  ...  1.1461586   0.9258757\n",
            "     1.1023892 ]\n",
            "   [ 1.1071512   1.3260292   0.03723068 ...  0.7178233   0.57782423\n",
            "     1.2720349 ]\n",
            "   [ 0.3825344   0.2458191  -0.4766403  ... -0.06924211  0.1440097\n",
            "     0.67922354]]\n",
            "\n",
            "  [[-0.3283248  -0.4531534  -0.86989236 ... -1.0598785  -0.37491632\n",
            "     0.2130923 ]\n",
            "   [-0.4929133  -1.5774691  -1.8541327  ... -1.1291902  -0.08987184\n",
            "     0.23253548]\n",
            "   [-0.4946392  -1.7031145  -2.267106   ... -1.085547   -0.52221733\n",
            "     0.45331928]\n",
            "   ...\n",
            "   [-0.7060982  -0.8856094  -0.4371871  ... -1.617462   -0.37426627\n",
            "     0.09161048]\n",
            "   [-0.5336012  -0.49941093  0.12769873 ... -0.99562484 -0.21031216\n",
            "     0.80872864]\n",
            "   [-1.1588708  -0.64251643 -1.3979228  ... -0.06940307 -1.1459157\n",
            "    -1.1483954 ]]\n",
            "\n",
            "  [[ 1.9371294   1.6769056   0.6644526  ...  1.3235898   0.4470895\n",
            "     0.93524164]\n",
            "   [ 1.2109681   4.041701    1.0350982  ...  0.7575122   0.9619884\n",
            "     2.167085  ]\n",
            "   [ 0.8685935   2.0647922   4.160913   ...  0.98664516  0.39813486\n",
            "     1.0062088 ]\n",
            "   ...\n",
            "   [ 1.6321392   1.4402163   1.1636865  ...  4.4765925   1.1307021\n",
            "     0.8986397 ]\n",
            "   [ 1.3424951   0.9187418   0.57245266 ...  1.02316     2.328365\n",
            "     1.0132259 ]\n",
            "   [ 0.4674242   1.5584285   0.5007494  ...  0.0055076   0.7250677\n",
            "     3.1158278 ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#아무래도 진짜..코드 위에선  outputs.last_hidden_state 로 써서 12번째 레이어의 값으로 KQV 계산했을 수 있다.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertWithRawAttention(BertModel):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=False, return_dict=True):\n",
        "        # BERT 모델의 기본 동작 수행\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,  # 어텐션 값 반환 활성화\n",
        "            output_hidden_states=True,  # 히든 스테이트 반환 활성화\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # 모델 설정값 가져오기\n",
        "        num_heads = self.config.num_attention_heads  # KLUE-BERT의 멀티헤드 개수 (12)\n",
        "        hidden_dim = self.config.hidden_size  # BERT의 Hidden Dimension (768)\n",
        "        head_dim = hidden_dim // num_heads  # 각 Head의 크기 (64)\n",
        "        d_k = head_dim ** 0.5  # sqrt(d_k)\n",
        "\n",
        "        # === 첫 번째 Transformer 레이어에서 Query (Q), Key (K) 직접 가져오기 ===\n",
        "        first_layer = self.encoder.layer[0]  # 첫 번째 Transformer 레이어\n",
        "        input_tensor = outputs.hidden_states[0]  # 첫 번째 레이어 입력 (Embedding 후 결과)\n",
        "\n",
        "        # Query, Key 생성\n",
        "        Q = first_layer.attention.self.query(input_tensor)  # (1, 10, 768)\n",
        "        K = first_layer.attention.self.key(input_tensor)  # (1, 10, 768)\n",
        "\n",
        "        # === Multi-Head 형태로 변환 ===\n",
        "        # Query, Key의 shape을 (batch_size, num_heads, sequence_length, head_dim)로 변환\n",
        "        Q = Q.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "        K = K.view(1, 10, num_heads, head_dim).transpose(1, 2)  # (1, 12, 10, 64)\n",
        "\n",
        "        # === Softmax 이전 Attention Score 계산 ===\n",
        "        raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k  # (1, 12, 10, 10)\n",
        "\n",
        "        return raw_attention, outputs.attentions[0]  # Softmax 이전 & 이후 값 반환\n",
        "\n",
        "# === 모델 로드 ===\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name)\n",
        "\n",
        "# === 입력 문장 ===\n",
        "text = \"BERT 모델이 잘 동작하는지 확인합니다.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=10)\n",
        "\n",
        "# === 모델 실행 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attention, softmax_attention = model(**inputs)\n",
        "\n",
        "# === 첫 번째 레이어의 Softmax 이전 Attention Score 확인 ===\n",
        "layer_1_raw_attention = raw_attention.numpy()\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {layer_1_raw_attention.shape}):\")\n",
        "print(layer_1_raw_attention)\n"
      ],
      "metadata": {
        "id": "_beDp4MY8Ib_",
        "outputId": "12e9ad16-c03c-4058-a2d9-b6a72501a768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: (1, 12, 10, 10)):\n",
            "[[[[ 3.479377    0.1171443   0.58569705 ...  0.49772385  2.06176\n",
            "     1.4053445 ]\n",
            "   [ 1.6703308   3.3466516   5.7931113  ...  2.388606    1.5484267\n",
            "     1.9099065 ]\n",
            "   [ 3.3168163   4.502995    3.8073645  ...  1.6874913   2.6028965\n",
            "     1.5656486 ]\n",
            "   ...\n",
            "   [ 1.6387084   1.7666456   2.1017816  ...  2.9609554   3.9101956\n",
            "     4.5376897 ]\n",
            "   [ 3.3072975   1.26182     2.3654344  ...  4.363251    3.5291743\n",
            "     5.749544  ]\n",
            "   [ 4.5703974   3.1162214   2.4864209  ...  4.4660215   6.6182046\n",
            "     5.148362  ]]\n",
            "\n",
            "  [[-1.0886635   0.02555746  0.31114915 ... -0.46038565 -0.68037045\n",
            "     0.9627845 ]\n",
            "   [-1.7430699  -0.5790166   0.73016    ... -0.7375136  -0.68991894\n",
            "     0.9723423 ]\n",
            "   [-0.4329701  -0.3477663  -0.61825114 ... -0.05859011 -1.3146529\n",
            "     1.1253307 ]\n",
            "   ...\n",
            "   [-0.3597892   0.09166003  0.4224084  ... -0.3363082  -0.5691451\n",
            "     0.9960096 ]\n",
            "   [-0.96181613  0.22939442  0.14909385 ...  0.6880507  -0.33433586\n",
            "     0.44172966]\n",
            "   [-0.6064538  -0.35795176  0.4738743  ... -0.10441232 -0.4639737\n",
            "     0.8191131 ]]\n",
            "\n",
            "  [[ 2.8996305   0.02200188 -0.74852276 ... -0.14752427  4.092835\n",
            "     2.4114072 ]\n",
            "   [ 0.5878505   3.0115817   3.9065936  ...  2.1310635  -0.09421209\n",
            "     0.9854513 ]\n",
            "   [ 0.60490626  2.234319    2.6323042  ...  1.5101193   0.5683531\n",
            "     1.3811644 ]\n",
            "   ...\n",
            "   [ 2.1231968   0.8496826   1.4300145  ...  1.5934154   1.0071484\n",
            "     2.0823562 ]\n",
            "   [ 3.2195091   0.00969239  0.5695026  ...  0.257331    1.7817798\n",
            "     2.0053062 ]\n",
            "   [ 3.9127853   0.84975827  0.38670912 ...  0.90620166  4.1586957\n",
            "     2.920747  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.7641902  -0.04179818 -0.03871066 ... -0.10111786 -0.6103709\n",
            "     1.1136796 ]\n",
            "   [ 0.63152     1.5662171   1.0136856  ...  1.0755256   0.36316216\n",
            "     1.536088  ]\n",
            "   [-0.19636309  1.3796111   0.99720216 ...  0.5310282   0.60126483\n",
            "     1.4317175 ]\n",
            "   ...\n",
            "   [-0.42347953  0.76450497  1.1695964  ...  1.8586994   1.3764336\n",
            "     1.343096  ]\n",
            "   [-0.04601977  1.031017    1.1641405  ...  0.95073164  1.0027806\n",
            "     1.6112568 ]\n",
            "   [-0.12048295  0.88819987  0.83503574 ...  0.675006    0.5101987\n",
            "     1.0522461 ]]\n",
            "\n",
            "  [[ 3.5113134   0.23125714  0.1485499  ... -0.6694763   0.04084336\n",
            "     0.70824885]\n",
            "   [ 1.7904971   2.2246802   2.8069272  ...  2.6324606   1.0418183\n",
            "     2.8195403 ]\n",
            "   [ 2.583067    2.5436697   2.678921   ...  1.4597999   1.4553257\n",
            "     3.0531595 ]\n",
            "   ...\n",
            "   [ 1.5281328   3.5719972   3.1684306  ...  3.3282528   1.6605139\n",
            "     4.1889677 ]\n",
            "   [ 3.7193847   2.3510675   2.3213775  ...  3.097043    1.2444314\n",
            "     2.0928159 ]\n",
            "   [ 5.245867    2.9236445   2.6110198  ...  3.3721251   2.8552227\n",
            "     3.1460385 ]]\n",
            "\n",
            "  [[ 1.7404835   0.20622326  0.17036499 ... -0.21828592  0.24408364\n",
            "     2.59453   ]\n",
            "   [ 2.5038111   3.8067126  -0.9152964  ... -1.4174232   0.4316581\n",
            "     1.9661092 ]\n",
            "   [ 2.3395202  -1.5124058   1.7736301  ... -1.3535221   0.9409391\n",
            "     0.73563105]\n",
            "   ...\n",
            "   [ 1.5222138  -0.8623995  -0.373424   ...  3.1788635   0.40442383\n",
            "     0.2975553 ]\n",
            "   [ 1.7944591   0.43165278 -0.35015965 ... -1.6325724  -1.2602834\n",
            "     0.9605552 ]\n",
            "   [ 1.9798659  -0.5624909  -0.7449865  ... -0.919578   -0.82357836\n",
            "     0.95598394]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# 1. 토크나이저 로드\n",
        "model_name = \"klue/bert-base\"  # 모델 이름 (학습에 사용된 것과 동일해야 함)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 2. 사전 학습된 모델 로드\n",
        "num_labels = len(label_names)  # 멀티라벨 분류를 위한 레이블 수\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "# 저장된 가중치 로드\n",
        "checkpoint_path = \"/content/model/BERT_multilabel_model.pt\"  # 저장된 모델 경로\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# 3. Attention 추출을 위해 모델 설정 변경\n",
        "model.config.output_attentions = True  # Attention 점수 출력 활성화\n",
        "model.eval()  # 평가 모드\n",
        "\n",
        "# 4. 입력 텍스트\n",
        "text = \"ㅅ발 천주교도들은 너무 말이 많아\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 5. 모델 추론\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits  # 최종 예측 값 (softmax 이전)\n",
        "    attentions = outputs.attentions  # Attention 점수\n",
        "\n",
        "# 6. Softmax 이전의 값을 출력\n",
        "print(f\"Logits (Softmax 이전 값): {logits}\")\n",
        "\n",
        "# 7. Attention 점수를 출력 (각 Layer마다 Attention 점수가 포함됨)\n",
        "for i, attention_layer in enumerate(attentions):\n",
        "    print(f\"Layer {i + 1} Attention Scores: {attention_layer.shape}\")\n",
        "\n",
        "# 각 Attention Layer의 Shape\n",
        "for i, attention in enumerate(attentions):\n",
        "    print(f\"Layer {i + 1} Attention Shape: {attention.shape}\")\n",
        "\n",
        "# 첫 번째 레이어의 Attention 값을 numpy로 변환하여 확인\n",
        "layer_1_attention = attentions[0].numpy()\n",
        "print(f\"Layer 1 Attention Scores (Shape: {layer_1_attention.shape}):\")\n",
        "print(layer_1_attention)\n"
      ],
      "metadata": {
        "id": "u9YiENTjOKK7",
        "outputId": "1fb107ae-a0f8-49f5-8083-707a93ca9ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-76-ccee9f185cc6>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits (Softmax 이전 값): tensor([[-2.4690, -4.7337, -4.9942,  2.2562, -5.2708, -4.6522, -5.1170,  1.8131,\n",
            "         -4.5230]])\n",
            "Layer 1 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 2 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 3 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 4 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 5 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 6 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 7 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 8 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 9 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 10 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 11 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 12 Attention Scores: torch.Size([1, 12, 10, 10])\n",
            "Layer 1 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 2 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 3 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 4 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 5 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 6 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 7 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 8 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 9 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 10 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 11 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 12 Attention Shape: torch.Size([1, 12, 10, 10])\n",
            "Layer 1 Attention Scores (Shape: (1, 12, 10, 10)):\n",
            "[[[[0.50276214 0.01801627 0.02399363 ... 0.0342509  0.03105909\n",
            "    0.06140413]\n",
            "   [0.28548524 0.12932299 0.11471977 ... 0.03935906 0.03413377\n",
            "    0.0462996 ]\n",
            "   [0.02393627 0.23049009 0.119009   ... 0.03462357 0.03437519\n",
            "    0.03273839]\n",
            "   ...\n",
            "   [0.07680625 0.00734722 0.00598513 ... 0.06522951 0.3043518\n",
            "    0.23911789]\n",
            "   [0.03908146 0.0087873  0.02467276 ... 0.27252406 0.04178381\n",
            "    0.42806664]\n",
            "   [0.13904521 0.01395757 0.00765489 ... 0.12952536 0.06837368\n",
            "    0.13328184]]\n",
            "\n",
            "  [[0.07985371 0.11216996 0.10060646 ... 0.10826609 0.09725763\n",
            "    0.2325552 ]\n",
            "   [0.0540519  0.01976733 0.12369999 ... 0.05865423 0.0952526\n",
            "    0.3069954 ]\n",
            "   [0.06732248 0.07314759 0.01510452 ... 0.17405728 0.11080742\n",
            "    0.3473453 ]\n",
            "   ...\n",
            "   [0.09490318 0.07963616 0.09468538 ... 0.0643936  0.0823948\n",
            "    0.34108797]\n",
            "   [0.02915837 0.1307724  0.08730808 ... 0.11512087 0.08144001\n",
            "    0.15715772]\n",
            "   [0.04625707 0.14411137 0.08635145 ... 0.16749963 0.07595401\n",
            "    0.21095937]]\n",
            "\n",
            "  [[0.19249158 0.02968404 0.00476936 ... 0.02142655 0.03418698\n",
            "    0.16786152]\n",
            "   [0.18242025 0.13631509 0.03929277 ... 0.06477983 0.03665771\n",
            "    0.17155178]\n",
            "   [0.18842699 0.07288257 0.04646761 ... 0.05176065 0.0615009\n",
            "    0.1846192 ]\n",
            "   ...\n",
            "   [0.12221343 0.16754884 0.08269276 ... 0.25251973 0.06872934\n",
            "    0.15158708]\n",
            "   [0.05153883 0.2571161  0.07073224 ... 0.07998767 0.06833493\n",
            "    0.18693537]\n",
            "   [0.41005656 0.04520131 0.00977826 ... 0.02479132 0.035253\n",
            "    0.1137526 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.10091401 0.15715222 0.10352629 ... 0.07797453 0.12888864\n",
            "    0.2592011 ]\n",
            "   [0.11257173 0.15267216 0.17494407 ... 0.04752741 0.02646148\n",
            "    0.33733252]\n",
            "   [0.02282469 0.13679282 0.3181143  ... 0.0866075  0.11079092\n",
            "    0.12702297]\n",
            "   ...\n",
            "   [0.0292747  0.07044251 0.26751333 ... 0.13342448 0.05688879\n",
            "    0.18797602]\n",
            "   [0.05979285 0.10998605 0.11743829 ... 0.15265188 0.08031254\n",
            "    0.15957834]\n",
            "   [0.06887838 0.0913663  0.20700881 ... 0.13372055 0.09142224\n",
            "    0.16873328]]\n",
            "\n",
            "  [[0.37489742 0.02933082 0.01872855 ... 0.00941682 0.02215154\n",
            "    0.05373281]\n",
            "   [0.0477233  0.07654192 0.10908442 ... 0.06884889 0.13898917\n",
            "    0.08864494]\n",
            "   [0.07779457 0.0570039  0.1138563  ... 0.05632794 0.06416035\n",
            "    0.27175546]\n",
            "   ...\n",
            "   [0.12312736 0.13339986 0.05075939 ... 0.05491564 0.07999808\n",
            "    0.20520656]\n",
            "   [0.05629834 0.1606151  0.03484033 ... 0.18163337 0.17536202\n",
            "    0.19427177]\n",
            "   [0.26320818 0.01499027 0.01506835 ... 0.02027144 0.0245714\n",
            "    0.03274287]]\n",
            "\n",
            "  [[0.18579273 0.04888129 0.05709388 ... 0.04365798 0.07530626\n",
            "    0.43601793]\n",
            "   [0.29635048 0.23618098 0.05854771 ... 0.04919232 0.04249952\n",
            "    0.07779395]\n",
            "   [0.39474365 0.00597612 0.36150783 ... 0.03503075 0.03659008\n",
            "    0.1024332 ]\n",
            "   ...\n",
            "   [0.34529865 0.01474646 0.02463462 ... 0.27073318 0.04451074\n",
            "    0.1501966 ]\n",
            "   [0.24132645 0.04245967 0.1469332  ... 0.04169809 0.2451356\n",
            "    0.16123603]\n",
            "   [0.51953447 0.02683437 0.04897838 ... 0.07776037 0.04533174\n",
            "    0.18517023]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "class BertWithRawAttention(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=True, output_hidden_states=True, return_dict=True):\n",
        "        # ✅ output_hidden_states=True 추가!\n",
        "        outputs = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,  # ✅ 여기를 추가해야 hidden_states가 출력됨!\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        # Softmax 이후의 Attention Score\n",
        "        attention_probs = outputs.attentions\n",
        "\n",
        "        # Softmax 이전 값 (QK^T / sqrt(d_k)) 추출\n",
        "        raw_attentions = []\n",
        "        for layer in self.bert.encoder.layer:\n",
        "            Q = layer.attention.self.query(outputs.hidden_states[-1])  # ✅ 이제 None이 아님!\n",
        "            K = layer.attention.self.key(outputs.hidden_states[-1])\n",
        "            d_k = Q.shape[-1] ** 0.5  # sqrt(d_k)\n",
        "\n",
        "            # Softmax 이전의 Attention Score\n",
        "            raw_attention = torch.matmul(Q, K.transpose(-2, -1)) / d_k\n",
        "            raw_attentions.append(raw_attention)\n",
        "\n",
        "        return raw_attentions, attention_probs, outputs.logits\n",
        "\n",
        "# 모델 로드\n",
        "model_name = \"klue/bert-base\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertWithRawAttention.from_pretrained(model_name, num_labels=len(label_names))\n",
        "\n",
        "# 입력 문장\n",
        "texts = [\"ㅅ발 천주교도들은 너무 말이 많아\"]\n",
        "\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=10)\n",
        "\n",
        "# 모델 실행\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    raw_attentions, softmax_attentions, logits = model(**inputs)\n",
        "\n",
        "# Softmax 이전의 Attention Score 확인\n",
        "print(f\"Layer 1 Softmax 이전 Attention Score (Shape: {raw_attentions[0].shape}):\")\n",
        "print(raw_attentions[0].numpy())\n",
        "\n",
        "# Softmax 이후의 Attention Score 확인\n",
        "print(f\"Layer 1 Softmax 이후 Attention Score (Shape: {softmax_attentions[0].shape}):\")\n",
        "print(softmax_attentions[0].numpy())\n",
        "\n",
        "# 최종 분류 logits 출력\n",
        "print(f\"Logits (분류 모델의 Softmax 이전 값): {logits}\")\n"
      ],
      "metadata": {
        "id": "BCV0QwgTxr1e",
        "outputId": "860bdb15-aebf-47cf-a375-0a4ce3dfdee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertWithRawAttention were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Softmax 이전 Attention Score (Shape: torch.Size([1, 10, 10])):\n",
            "[[[-1.25852823e+00  2.66215712e-01 -8.78310561e-01 -5.46610832e-01\n",
            "   -2.88807482e-01  1.11422515e+00 -7.55868137e-01 -1.04048252e+00\n",
            "   -6.23540282e-01 -4.86584216e-01]\n",
            "  [-2.56121695e-01 -1.71548009e-01 -8.60907257e-01 -7.67546833e-01\n",
            "   -9.95912910e-01 -1.00643361e+00 -4.07447457e-01 -1.75079393e+00\n",
            "    1.79270849e-01  1.09233379e+00]\n",
            "  [-2.95971274e-01 -5.97175062e-01 -5.01220524e-01 -7.32082844e-01\n",
            "   -9.14117396e-01 -4.85211074e-01 -9.03017342e-01 -1.16841352e+00\n",
            "   -1.58572093e-01  1.26348448e+00]\n",
            "  [-1.37948975e-01 -2.04223856e-01  4.05856907e-01 -1.50166214e+00\n",
            "    5.47514558e-02  1.44970313e-01 -1.13640618e+00 -2.22163677e+00\n",
            "   -2.47296557e-01 -1.33462834e+00]\n",
            "  [ 1.01324928e+00  1.64172506e+00  6.23836458e-01  6.27645195e-01\n",
            "   -6.22797310e-01  9.15249646e-01  3.98019969e-01 -1.16255677e+00\n",
            "   -6.03965938e-01 -1.14379549e+00]\n",
            "  [ 1.11805654e+00  9.22619820e-01  1.66346371e+00  1.28638303e+00\n",
            "    3.01247567e-01 -3.35117072e-01  4.42473382e-01 -2.01341057e+00\n",
            "    1.57611266e-01 -7.06549704e-01]\n",
            "  [-2.56664723e-01  2.37522781e-01  8.96184087e-01  2.33783759e-02\n",
            "   -2.61715978e-01 -1.59865290e-01 -3.91456425e-01 -1.25633550e+00\n",
            "   -8.63685906e-02 -5.29619396e-01]\n",
            "  [-4.56178546e-01 -1.40805280e+00 -1.01764131e+00 -1.13802481e+00\n",
            "   -4.46542889e-01  1.36807829e-01 -9.18115318e-01 -1.72494113e+00\n",
            "    1.12401016e-01 -7.55020678e-01]\n",
            "  [-1.68190569e-01  6.50996327e-01 -4.09294933e-01  1.49280071e-01\n",
            "   -6.98003054e-01  1.38944983e+00  8.27238634e-02 -2.14583308e-01\n",
            "    8.28214407e-01  7.93602645e-01]\n",
            "  [-1.48121583e+00 -4.18758541e-02 -2.22063810e-03 -8.71774971e-01\n",
            "   -1.92896914e+00 -1.38735354e+00 -1.09499991e+00 -8.92453134e-01\n",
            "   -5.12685597e-01  1.16958547e+00]]]\n",
            "Layer 1 Softmax 이후 Attention Score (Shape: torch.Size([1, 12, 10, 10])):\n",
            "[[[[0.50193053 0.01646294 0.02458053 ... 0.03021928 0.03516091\n",
            "    0.06308161]\n",
            "   [0.22571197 0.12214692 0.13914467 ... 0.03955203 0.03931026\n",
            "    0.05574832]\n",
            "   [0.00731852 0.15145266 0.11674146 ... 0.02108586 0.02430418\n",
            "    0.02280195]\n",
            "   ...\n",
            "   [0.0678239  0.00700259 0.0069513  ... 0.04489433 0.3237514\n",
            "    0.22219692]\n",
            "   [0.03092064 0.00997889 0.03502037 ... 0.2269365  0.04496774\n",
            "    0.41050157]\n",
            "   [0.0741941  0.01003211 0.01068952 ... 0.09740562 0.08451286\n",
            "    0.13224411]]\n",
            "\n",
            "  [[0.04115042 0.08926985 0.07000751 ... 0.10584227 0.1085436\n",
            "    0.3201155 ]\n",
            "   [0.05052924 0.01660708 0.09794959 ... 0.07169245 0.12102537\n",
            "    0.27986318]\n",
            "   [0.05395626 0.05563773 0.01607826 ... 0.17889246 0.10790431\n",
            "    0.3581522 ]\n",
            "   ...\n",
            "   [0.07962454 0.07294574 0.09648975 ... 0.07228429 0.08998562\n",
            "    0.3496276 ]\n",
            "   [0.0255961  0.1254367  0.08391792 ... 0.12145846 0.07797515\n",
            "    0.16491632]\n",
            "   [0.05308816 0.11393113 0.08302062 ... 0.15818529 0.0855791\n",
            "    0.22085819]]\n",
            "\n",
            "  [[0.25516987 0.03431695 0.00428409 ... 0.01912345 0.03518634\n",
            "    0.15660179]\n",
            "   [0.13680004 0.11780471 0.03900155 ... 0.06704757 0.03970232\n",
            "    0.24825518]\n",
            "   [0.11689737 0.09255069 0.05735985 ... 0.0605448  0.06487989\n",
            "    0.19065589]\n",
            "   ...\n",
            "   [0.11428072 0.20210367 0.08333405 ... 0.22817586 0.0654134\n",
            "    0.14926815]\n",
            "   [0.04288723 0.3133893  0.0878645  ... 0.06443704 0.06182248\n",
            "    0.14729889]\n",
            "   [0.3005874  0.05435768 0.01160257 ... 0.02809226 0.04214298\n",
            "    0.11146384]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.05317722 0.14274758 0.10946882 ... 0.07352181 0.10586049\n",
            "    0.3477556 ]\n",
            "   [0.11008223 0.24453689 0.18030298 ... 0.05199188 0.02249919\n",
            "    0.20538071]\n",
            "   [0.01644883 0.12896726 0.33732638 ... 0.08603207 0.10337761\n",
            "    0.09454589]\n",
            "   ...\n",
            "   [0.03143752 0.08671279 0.31751582 ... 0.10323577 0.04712138\n",
            "    0.14935142]\n",
            "   [0.04219531 0.10846445 0.13773629 ... 0.14145379 0.072102\n",
            "    0.1732167 ]\n",
            "   [0.0542199  0.09281379 0.23242326 ... 0.1167574  0.08671355\n",
            "    0.1751735 ]]\n",
            "\n",
            "  [[0.5720189  0.01799796 0.0087535  ... 0.00541417 0.01432684\n",
            "    0.03467807]\n",
            "   [0.03808249 0.07802656 0.11277841 ... 0.06981867 0.13535056\n",
            "    0.0923093 ]\n",
            "   [0.04817314 0.05937601 0.11599965 ... 0.06266043 0.06124886\n",
            "    0.29385027]\n",
            "   ...\n",
            "   [0.11173632 0.13069044 0.0493538  ... 0.0537655  0.07555193\n",
            "    0.1833624 ]\n",
            "   [0.05658199 0.16392574 0.03680176 ... 0.1664859  0.143547\n",
            "    0.19960178]\n",
            "   [0.21057622 0.00922463 0.01137071 ... 0.01278055 0.0171657\n",
            "    0.02579084]]\n",
            "\n",
            "  [[0.20086427 0.04173107 0.04344716 ... 0.03688852 0.07055343\n",
            "    0.471857  ]\n",
            "   [0.23607269 0.3755227  0.05690284 ... 0.04558486 0.02987671\n",
            "    0.06265713]\n",
            "   [0.22610003 0.00912194 0.5442027  ... 0.04248916 0.03555816\n",
            "    0.08360582]\n",
            "   ...\n",
            "   [0.3231144  0.01766624 0.0279856  ... 0.30637172 0.04468505\n",
            "    0.14027685]\n",
            "   [0.2573445  0.03987942 0.14915828 ... 0.04214596 0.23392743\n",
            "    0.16138762]\n",
            "   [0.47199497 0.03932175 0.06136924 ... 0.09315775 0.05202026\n",
            "    0.16953959]]]]\n",
            "Logits (분류 모델의 Softmax 이전 값): tensor([[-0.5414,  0.4313,  0.0370, -0.0976, -0.0870, -0.2223, -0.2459,  0.2729,\n",
            "         -0.4879]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = './model/attention_scores_2.txt'  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "Q0nZ4Onl21iB",
        "outputId": "868878ad-3db2-48fc-e23a-7f06e58611eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    0.11714409  0.5856975   0.6307755  -0.30920362  2.1947367\n",
            "  -0.14835791  0.49772462  2.0617602   1.4053444 ]\n",
            " [ 1.6703308   3.3466518   5.793112    4.621073    3.812749    2.3419719\n",
            "   1.8878778   2.3886065   1.5484276   1.9099072 ]\n",
            " [ 3.3168168   4.502995    3.8073637   5.2124023   2.3082643   3.0351076\n",
            "   2.4797425   1.6874914   2.6028967   1.5656495 ]\n",
            " [ 2.5718498   4.652975    6.7969666   3.8015726   5.3321524   2.659658\n",
            "   2.719986    2.416732    2.1785326   3.108758  ]\n",
            " [ 0.62522817  4.6419153   3.3077164   5.064213    3.339889    2.7762215\n",
            "   1.873533    3.4980125   2.023627    2.5917144 ]\n",
            " [ 3.9795005   2.6142015   2.2757936   2.9215946   3.511932    3.220555\n",
            "   3.0432897   2.8711824   4.3125715   4.3036885 ]\n",
            " [ 1.7959094   2.6852992   1.6750463   1.3191165   4.1721644   3.331105\n",
            "   2.4741642   4.5505824   2.6400094   3.1753776 ]\n",
            " [ 1.6387088   1.7666457   2.1017816   2.1071794   3.422982    3.3852067\n",
            "   4.2240024   2.9609547   3.9101954   4.537689  ]\n",
            " [ 3.3072975   1.2618201   2.365435    1.1282016   2.2333503   2.9970148\n",
            "   3.822887    4.3632503   3.529175    5.7495446 ]\n",
            " [ 4.5703983   3.1162205   2.4864216   3.426703    2.1799157   5.7463045\n",
            "   3.174025    4.4660215   6.618206    5.1483626 ]] [[-1.0886638   0.02555725  0.311149   -0.1185468  -0.07704417 -1.6976843\n",
            "  -0.04857237 -0.46038562 -0.6803706   0.9627847 ]\n",
            " [-1.7430696  -0.5790163   0.7301598   0.43518707  0.06117958 -1.1784676\n",
            "  -0.22009215 -0.7375137  -0.6899191   0.97234195]\n",
            " [-0.43296996 -0.34776625 -0.61825126 -0.5565975  -0.20672473 -1.1309534\n",
            "   0.21543759 -0.0585902  -1.3146526   1.1253307 ]\n",
            " [-0.5908074  -0.25380707  0.00024927  0.01682144  0.45576128 -0.25012723\n",
            "   0.03673334  0.14773999 -0.3354175   1.2667636 ]\n",
            " [-1.7260594  -0.03702255  0.32314226  0.09670944 -0.25472367 -1.5367095\n",
            "   0.7070519   0.6523646  -1.2064693   0.59022087]\n",
            " [-1.209122    0.15285142  0.38227442  0.2848917   0.37704596 -0.8517933\n",
            "   0.01839954  0.43778053 -0.49263728  0.7998164 ]\n",
            " [-0.2891728   0.10043441 -0.09115115  0.03625927  0.10675713 -0.83618826\n",
            "   0.2000978   0.5833909  -0.17491554  0.60655284]\n",
            " [-0.35978922  0.09165996  0.42240837  0.1125567  -0.06464243 -1.3896195\n",
            "   0.38931042 -0.33630806 -0.56914496  0.99600965]\n",
            " [-0.96181583  0.22939461  0.1490941   0.16794282  0.17030033 -0.5399121\n",
            "   0.03469593  0.6880506  -0.33433583  0.4417293 ]\n",
            " [-0.60645354 -0.3579516   0.47387433  0.27014586  0.25771543 -0.9096098\n",
            "   0.17429377 -0.10441241 -0.4639737   0.81911325]] [[ 2.8996303   0.02200214 -0.74852276  0.631462   -1.1275623   3.0894957\n",
            "   0.9280114  -0.14752409  4.0928345   2.411408  ]\n",
            " [ 0.5878507   3.011582    3.9065943   3.235908    0.50435984  0.34831482\n",
            "   0.17555894  2.1310635  -0.09421223  0.98545116]\n",
            " [ 0.6049058   2.2343197   2.6323042   2.430443    0.4869851   0.8571075\n",
            "   1.0000788   1.5101197   0.56835276  1.3811649 ]\n",
            " [ 1.430701    2.0099015   4.087019    3.0947237   0.56819826  0.75650877\n",
            "   0.33274144  1.465734   -0.30525357  0.9727164 ]\n",
            " [-0.3164355   1.5521222   3.0174787   1.4834703   2.2269187  -1.30088\n",
            "   1.1328936   3.5774622  -1.429762   -0.17385992]\n",
            " [ 3.4188118   0.62846535  0.07279523  0.71736014 -0.32747287  2.2898376\n",
            "   1.0576711   0.22138332  3.0749917   2.4532826 ]\n",
            " [ 1.9065028   0.88415587  1.2080953   0.14300826  0.593324    0.49050444\n",
            "   0.5708541   1.5033801   0.42657304  0.6549574 ]\n",
            " [ 2.1231966   0.84968215  1.4300145   1.3541062   1.0749373   1.852924\n",
            "   0.76707125  1.5934157   1.0071483   2.0823565 ]\n",
            " [ 3.2195091   0.0096926   0.56950235  0.23191671 -0.32239503  2.1220663\n",
            "   1.1799686   0.2573312   1.7817802   2.0053072 ]\n",
            " [ 3.912785    0.8497595   0.3867088   0.8289084   0.23973835  3.5320184\n",
            "   1.3169683   0.9062026   4.1586957   2.9207473 ]] [[-0.91819704 -0.73714244 -1.2835796  -1.3152801  -1.7907189  -2.3600693\n",
            "  -1.71575    -2.0585341  -0.88458973 -1.0391645 ]\n",
            " [ 0.76816994  2.8525796   0.98103195  1.0893993   1.291576   -0.3590138\n",
            "  -0.05392636  1.1377413  -1.1812421   0.5328254 ]\n",
            " [ 0.44077566  1.889281    1.394224    1.2403969   0.93400806 -0.6091448\n",
            "   0.37211862  1.1208864  -0.48069543  0.9152784 ]\n",
            " [-0.4079485   1.9117765   0.61145085  1.4986356   1.2874416  -0.2541298\n",
            "   0.17829615  0.8347929  -0.5898164   1.7898803 ]\n",
            " [ 0.5058691   1.6893194   0.8303908   0.35562584  1.9394354  -0.32631215\n",
            "  -0.15927449  1.2605628  -1.4803319   0.92400664]\n",
            " [ 0.47246826  1.049527    0.68996495  0.5756347   0.2827701   1.6729834\n",
            "   1.2482777   1.4437281   1.0102694   0.7912869 ]\n",
            " [ 1.2386009   1.133507    0.64457095  0.43742573  1.0146374  -0.527435\n",
            "   1.1386023   1.2811688  -0.267912   -0.3252511 ]\n",
            " [-0.6168757   0.9414549   0.6545312   0.44207764  1.0313237   0.28013933\n",
            "   0.6557309   1.4528047   0.10742482  2.0227776 ]\n",
            " [ 0.6610696   1.1441543   0.83005744  0.6699963   0.68824714  0.8841506\n",
            "   1.2305831   1.0789971   0.96978915  0.1847023 ]\n",
            " [ 0.48081017  0.5815153   0.65710616  0.34215644 -0.4203801  -1.0223608\n",
            "  -0.1397903   0.8336154   0.45186663 -0.02691434]] [[-0.4206367  -0.26431718 -0.8189321   0.5453431  -0.81877565  3.265758\n",
            "   1.123025   -0.45972508  3.0087957   4.069817  ]\n",
            " [ 1.711552    4.0104914   6.097168    4.062114    3.3517642   0.6797678\n",
            "   2.4742503   2.5503993   1.0404894   2.6415534 ]\n",
            " [ 1.6555488   2.8842583   3.6345613   2.4311733   2.4532597   1.8469099\n",
            "   1.1871887   2.1401596   2.593385    2.5239465 ]\n",
            " [ 2.897587    4.3002462   6.664719    2.8146844   4.007442    0.92588633\n",
            "   0.9355154   1.9416659   1.1508867   2.0899508 ]\n",
            " [ 1.4384526   4.5608745   3.7128031   3.3055158   2.5344577   0.3143406\n",
            "   2.7502472   3.773708    1.4212635   1.7340083 ]\n",
            " [-1.8715912   2.1050293   2.2834506   2.1121552   1.4853789   2.427682\n",
            "   3.0749145   1.8919368   3.9486756   4.785963  ]\n",
            " [ 0.63691103  1.810391    0.84790796  1.1583683   2.2992978   1.9338874\n",
            "   2.1868212   3.2546113   2.360936    3.5164182 ]\n",
            " [ 0.39985502  1.6061538   1.7325523   0.35841948  2.477663    1.037012\n",
            "   2.7054691   2.465773    1.360221    2.7568579 ]\n",
            " [-1.5197104   0.47858107  1.2087647   0.85278237  1.0399474   2.266237\n",
            "   3.0739172   2.0501065   2.4958704   4.687452  ]\n",
            " [ 3.000189   -0.7293791  -0.74419117  1.7917078   0.4763999   2.9361863\n",
            "   2.2864735   2.0922556   2.3336442   3.609223  ]] [[ 2.3518488  -2.4012413  -2.5848315  -2.5842254  -1.4390004  -1.3970611\n",
            "  -1.486853   -1.3146498  -1.5213429  -0.10409442]\n",
            " [-0.08029907  0.95492965  3.0861502   1.0803758   2.8016753   1.3075106\n",
            "   2.5004106   3.4115536   1.5283737   2.4000955 ]\n",
            " [-0.98470867  1.4555954   1.5423824   0.30919918  3.159526    1.3234267\n",
            "   2.0309644   3.8802829   0.77620506  2.2096994 ]\n",
            " [-1.3650285   1.9985721   3.1277943   0.9758086   3.153818    2.5558827\n",
            "   2.7993655   3.6075718   2.483896    3.5096714 ]\n",
            " [-0.53188324  2.7865634   2.933026    1.9947041   2.6538177   0.17108425\n",
            "   1.41041     3.5341537   0.09414454  2.1139412 ]\n",
            " [-0.05147918  2.960376    2.8401773   2.9880128   2.2146826   3.026591\n",
            "   2.6003537   2.4387147   3.1415412   3.8921413 ]\n",
            " [-0.9958864   2.6857972   2.583294    2.6029804   2.5345263   1.2893649\n",
            "   1.4581535   2.6380162   2.0204773   2.2150342 ]\n",
            " [ 0.04527869  2.9330308   3.2778075   2.720913    3.2038531   1.2107869\n",
            "   1.9810863   2.4970698   1.1165935   1.571423  ]\n",
            " [-0.23130603  2.2237506   2.6563025   2.6123178   2.1577914   2.2081223\n",
            "   2.521809    2.3261166   1.9723585   2.7725258 ]\n",
            " [ 0.2493442   3.188392    3.1076705   3.369534    2.6593766   3.4948716\n",
            "   2.873453    2.958899    3.7007978   5.390417  ]] [[ 1.8577769  -0.1782641  -0.8391258  -0.20157872  0.03677352  1.8336577\n",
            "  -0.5154236  -0.9360012  -0.36019903  2.0303364 ]\n",
            " [ 0.07594603  1.6416981   2.4703162   1.7014173   1.7434708   0.00997017\n",
            "   1.3008279   1.896263    1.5449183   1.616728  ]\n",
            " [ 0.6953787   2.1692429   2.1441464   1.7379965   2.1794832   0.00943146\n",
            "   1.3819319   2.406196    1.5149322   1.8323896 ]\n",
            " [ 1.5004507   2.191609    2.7665334   0.9322765   2.0782743  -0.32668146\n",
            "   1.5269834   2.6152775   1.2686868   2.566569  ]\n",
            " [-0.5223735   2.492464    1.484075    1.3629732   1.5521193  -0.75108665\n",
            "   1.1117117   2.8975577   1.2339579   0.7913337 ]\n",
            " [ 4.608461    2.6140327   1.6747181   1.5631702   1.1256423   2.156302\n",
            "   1.8067638   1.0583446   1.9421829   4.2106786 ]\n",
            " [ 2.443831    2.08211     1.7901441   1.5581807   2.1890495   1.9666604\n",
            "   1.4040198   2.1084352   1.0204064   2.4160697 ]\n",
            " [ 1.6170082   2.1157253   1.7847257   1.1339206   2.4702833   1.1112541\n",
            "   1.9466188   2.2814734   1.4104946   2.5419347 ]\n",
            " [ 2.5761323   1.8463246   1.4472572   1.2411208   1.1666892   1.2266266\n",
            "   2.137839    1.720331    1.3243217   2.4792182 ]\n",
            " [ 5.4560094   2.8533223   1.9060035   2.8041744   2.1872957   4.541738\n",
            "   2.3418133   2.6403146   3.3154905   5.353278  ]] [[-0.20872909 -0.04676584 -0.06920808  0.22612049 -0.5273356  -0.03878088\n",
            "  -0.35037673 -0.24101785 -0.03800961 -0.4477717 ]\n",
            " [ 0.39312774 -0.72015625 -0.11039566 -0.47187504 -0.6243619  -0.5550632\n",
            "  -0.06305974  0.23725607 -0.29921988  0.67517275]\n",
            " [ 0.9336121  -0.30668795 -1.2280265  -0.23901877  0.21531588 -0.02921304\n",
            "   0.18740971  0.49287453 -0.32362545  0.5395098 ]\n",
            " [ 0.44989973 -0.07840493 -0.70561624 -0.6797175  -0.32464612 -0.00245793\n",
            "   0.24341476 -0.38152987 -0.6197981   0.69756246]\n",
            " [ 0.07505149 -0.34050646 -0.20628366 -0.03507853 -2.1298897  -0.46191064\n",
            "   0.10249646 -0.23292464 -0.44878232 -0.04885465]\n",
            " [ 0.2423661   0.24130446 -0.13099633  0.29947233  0.00284321  0.18978542\n",
            "   0.3024567   0.02645526  0.03272907  0.096457  ]\n",
            " [ 0.52392596 -0.43888092  0.6062699  -0.16046394 -0.4598454  -0.40288302\n",
            "  -0.34419575 -0.3142506  -0.00332226 -0.19334584]\n",
            " [-0.56612873 -0.188554   -0.02999487 -1.3156276  -0.39713255 -0.16519366\n",
            "  -0.31032342 -2.612752   -0.6005166   0.04201785]\n",
            " [ 0.2327159   0.3471023  -0.03875374  0.0647919  -0.1906524   0.13848405\n",
            "   0.0672462  -0.08677322  0.1582894  -0.00930041]\n",
            " [ 0.2202284  -0.15427314 -0.08931216 -0.03995595  0.00104465 -0.02846966\n",
            "  -0.06644918 -0.06230865  0.05504296 -0.25045082]] [[ 0.7274816   0.11507649  0.284214   -0.4026169  -0.22948742  0.5726925\n",
            "   0.7000268   0.13661313  2.2500303   2.2188106 ]\n",
            " [ 1.4019722   3.4689038   2.3157012   2.951157    1.1965826   1.1602786\n",
            "  -0.1770497   0.6572411   0.2278574   1.8796558 ]\n",
            " [ 1.2921461   0.8905095   3.709777    2.3455753   1.0153087   1.4283334\n",
            "   0.5606777   0.47134808  1.6395503   1.9080584 ]\n",
            " [ 1.8637079   3.003888    3.8354084   4.1362057   1.2275932   2.323182\n",
            "  -0.19235559  1.0532311   1.3310231   2.590262  ]\n",
            " [ 0.54005456  0.6143206   1.7547503   1.8359743   3.094353    0.6746429\n",
            "   0.2596902   1.5248697   0.47067168  1.3008693 ]\n",
            " [-0.9338605   0.5036669   0.87460697  0.45084783  0.901352   -0.10966269\n",
            "   1.9916923   1.3448064   2.0936713   0.80160993]\n",
            " [ 0.5728401  -0.04004947  0.45082232 -0.43184328  0.9820602   0.0408671\n",
            "   1.4810711   0.40630463  0.07374337  0.5373771 ]\n",
            " [ 2.0956993   0.6018912   0.6745899   0.5275235   1.8832694   0.7081071\n",
            "   1.0816227   3.1449246   0.19390348  2.3962045 ]\n",
            " [-0.3780636   0.18745206  1.7450609   0.46006605  0.8310921   0.57361317\n",
            "   2.0125527   1.6686664   1.5488706   1.1293051 ]\n",
            " [ 0.6197194   0.2847378   0.8111273   0.29930606  0.12218147  0.633571\n",
            "   1.7020148   1.1978279   2.0720472   1.3618188 ]] [[-0.7641907  -0.04179777 -0.03871024 -0.01029287  0.10982683 -3.409261\n",
            "  -0.8519444  -0.1011171  -0.61037153  1.11368   ]\n",
            " [ 0.6315195   1.5662173   1.0136852   0.79115003  0.5027024  -0.84586865\n",
            "  -0.60011023  1.0755258   0.36316153  1.5360875 ]\n",
            " [-0.19636366  1.3796113   0.9972024   0.42479315  0.7522633  -1.2828168\n",
            "  -0.24372143  0.53102773  0.60126495  1.431718  ]\n",
            " [-0.01733678  1.2261399   0.60732824 -0.3713482   1.0066447  -1.0930486\n",
            "  -0.34242573  1.2536769  -0.01925345  0.05428234]\n",
            " [-0.6089171   0.812452    0.73339826  0.27320436  1.0981218  -0.69458455\n",
            "   0.300511    1.9441388  -0.5859628   1.1883222 ]\n",
            " [-0.3862846   0.9120517   0.6206465   0.7143033   0.49330038 -1.0343239\n",
            "  -0.31964967  0.45504218  0.87512237  1.6519731 ]\n",
            " [-0.11572167  1.118077    1.1451776   0.45498532  0.7921902  -0.8244491\n",
            "   0.13255627  1.3740886   1.5412023   1.585442  ]\n",
            " [-0.42347932  0.7645048   1.1695968   0.8649328   1.0572455  -1.3920376\n",
            "   0.06315615  1.8586993   1.3764335   1.3430959 ]\n",
            " [-0.04602024  1.0310172   1.1641402   0.830472    0.55506825 -1.4279099\n",
            "  -0.305408    0.95073116  1.0027801   1.6112568 ]\n",
            " [-0.1204833   0.88820004  0.8350356   0.46982872  0.30827308 -1.1874206\n",
            "   0.06021432  0.6750055   0.5101989   1.052246  ]] [[ 3.5113144   0.23125732  0.14855024  0.31988123 -0.34488022  1.1630836\n",
            "  -0.23730999 -0.6694767   0.04084282  0.70824903]\n",
            " [ 1.7904973   2.2246804   2.806927    2.5454693   2.600652    2.0405247\n",
            "   2.0883412   2.6324604   1.0418186   2.819541  ]\n",
            " [ 2.5830665   2.5436692   2.6789215   2.552863    1.8923868   2.387744\n",
            "   2.497571    1.4598      1.4553257   3.0531595 ]\n",
            " [ 2.0304976   3.0259213   3.0475783   2.566625    2.3083878   2.8534472\n",
            "   2.431889    3.5424695   1.5133282   3.2522182 ]\n",
            " [ 0.85365546  2.1300118   2.9776423   2.764315    1.9021384   2.261848\n",
            "   0.78977865  2.7873087   1.51449     3.4065237 ]\n",
            " [ 4.7410984   2.2832878   2.5947425   2.7378526   1.9672732   3.6375775\n",
            "   2.2509813   3.3431032   1.4767879   2.352169  ]\n",
            " [ 1.3938805   2.63342     2.7286584   1.8677042   2.9486048   1.323737\n",
            "   0.75743663  3.4104338   1.7034984   2.298728  ]\n",
            " [ 1.5281339   3.5719974   3.1684306   2.4641638   3.45946     2.1354446\n",
            "   2.2208533   3.3282526   1.6605146   4.188968  ]\n",
            " [ 3.7193854   2.3510675   2.3213775   2.3511674   2.4487157   3.718595\n",
            "   2.4170146   3.097043    1.2444317   2.0928166 ]\n",
            " [ 5.245867    2.9236443   2.6110198   2.8997252   2.7353942   4.847442\n",
            "   2.6822622   3.372125    2.8552227   3.146039  ]] [[ 1.7404832   0.20622298  0.17036484  0.14028859 -0.0875273  -0.28903437\n",
            "  -0.05346468 -0.21828583  0.24408357  2.5945306 ]\n",
            " [ 2.5038111   3.8067138  -0.9152964  -1.0867347  -0.66055036 -0.3236773\n",
            "  -0.31045496 -1.4174232   0.43165812  1.9661093 ]\n",
            " [ 2.3395207  -1.5124058   1.7736304  -0.67819226 -1.0566123   0.19052632\n",
            "  -0.78984517 -1.3535223   0.9409393   0.73563135]\n",
            " [ 1.2547673   0.34710675 -0.44897196  2.7757225  -0.33859655 -0.15644921\n",
            "  -0.6115687  -0.48662195  0.41058114  0.87479126]\n",
            " [ 0.6738987   0.4476631  -1.602245   -0.6992324   3.0947883  -0.30546984\n",
            "  -0.6876085  -0.13776019  0.14923412  0.28215185]\n",
            " [ 1.546602   -0.46327224 -1.2862829  -1.491924   -1.288245   -1.6702429\n",
            "  -0.73712903 -1.5902119  -0.9095844   1.7985494 ]\n",
            " [ 1.4186683   0.2906626  -0.9079117  -1.503863   -0.35724834 -0.79060125\n",
            "   1.2171147  -1.3592548  -0.53071135  0.48501337]\n",
            " [ 1.5222133  -0.8623995  -0.37342417 -0.85203713 -1.0658941  -0.4834577\n",
            "   0.21761012  3.1788638   0.40442356  0.29755515]\n",
            " [ 1.7944585   0.43165296 -0.3501598  -0.7924533   0.07014562 -0.5650798\n",
            "  -0.51980543 -1.6325725  -1.2602837   0.9605556 ]\n",
            " [ 1.9798651  -0.5624908  -0.7449863  -1.232003   -0.63779896 -0.6748462\n",
            "  -0.8677051  -0.9195779  -0.8235787   0.9559839 ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 각 최소 단위(10x10 행렬의 10개 값) 내림차순 정렬\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 최소 단위(10개) 값을 내림차순으로 정렬\n",
        "            sorted_attention_scores[i, j, k] = np.sort(attention_scores[i, j, k])[::-1]\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gTTz4HV13uLB",
        "outputId": "5818db24-998a-4401-bb51-ee5fa898edca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 지수 표기법 억제 (출력 시 적용됨)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"/./content/model/attention_scores.pkl\"  # 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# ✅ dtype을 float32로 유지하여 값의 정밀도를 유지\n",
        "attention_scores = attention_scores.astype(np.float32)\n",
        "\n",
        "# 2. 원본 값을 유지하면서 내림차순 정렬 (argsort 사용)\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)  # 동일한 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # ✅ 원본 값의 순서를 유지하면서 내림차순 정렬\n",
        "            indices = np.argsort(-attention_scores[i, j, k])  # 내림차순 정렬된 인덱스 가져오기\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][indices]  # 원본 값 유지\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores.astype(np.float32), f)  # ✅ 저장 시에도 float32 유지\n",
        "\n",
        "print(f\"정렬된 attention_scores가 {sorted_file_path}에 저장되었습니다! 🚀\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEeT1XRCxsN",
        "outputId": "7d6bcd46-ea5c-4d24-a79b-70ca2aed217e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores가 /./content/model/sorted_attention_scores.pkl에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_2 = []\n",
        "\n",
        "import pickle\n",
        "with open(\"/./content/model/sorted_attention_scores.pkl\", \"rb\") as f:\n",
        "    outputs_2 = pickle.load(f)\n",
        "\n",
        "print(outputs_2)"
      ],
      "metadata": {
        "id": "-vdLamvD6Vcc",
        "outputId": "ebb7c8f2-0e95-4d80-fab9-5fec8ed982d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0.50276214 0.18352194 0.07385454 ... 0.02399363 0.01801627\n",
            "    0.00693945]\n",
            "   [0.28548524 0.15781423 0.12932299 ... 0.0462996  0.03935906\n",
            "    0.03413377]\n",
            "   [0.42965856 0.23049009 0.119009   ... 0.03273839 0.02393627\n",
            "    0.01153364]\n",
            "   ...\n",
            "   [0.3043518  0.23911789 0.14382176 ... 0.02023179 0.00734722\n",
            "    0.00598513]\n",
            "   [0.42806664 0.27252406 0.0660226  ... 0.03525357 0.02467276\n",
            "    0.0087873 ]\n",
            "   [0.35068387 0.13904521 0.13328184 ... 0.01395757 0.00985229\n",
            "    0.00765489]]\n",
            "\n",
            "  [[0.2325552  0.13501358 0.11216996 ... 0.06796568 0.04669739\n",
            "    0.01961427]\n",
            "   [0.3069954  0.1544281  0.12369999 ... 0.0540519  0.03094326\n",
            "    0.01976733]\n",
            "   [0.3473453  0.17405728 0.11080742 ... 0.02729124 0.0272199\n",
            "    0.01510452]\n",
            "   ...\n",
            "   [0.34108797 0.14767179 0.09490318 ... 0.05895856 0.02201105\n",
            "    0.01425752]\n",
            "   [0.16335478 0.15715772 0.1307724  ... 0.07702713 0.06241015\n",
            "    0.02915837]\n",
            "   [0.21095937 0.16749963 0.14411137 ... 0.04625707 0.04081224\n",
            "    0.03196875]]\n",
            "\n",
            "  [[0.20825657 0.19249158 0.18383561 ... 0.02142655 0.01533512\n",
            "    0.00476936]\n",
            "   [0.24235135 0.18242025 0.17155178 ... 0.03665771 0.03388991\n",
            "    0.03156955]\n",
            "   [0.18842699 0.1846192  0.15932496 ... 0.0527045  0.05176065\n",
            "    0.04646761]\n",
            "   ...\n",
            "   [0.25251973 0.16754884 0.15158708 ... 0.03404357 0.03329607\n",
            "    0.02462847]\n",
            "   [0.2571161  0.21102408 0.18693537 ... 0.02713428 0.02467851\n",
            "    0.02251801]\n",
            "   [0.41005656 0.19873372 0.1137526  ... 0.02479132 0.01154065\n",
            "    0.00977826]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.2592011  0.15715222 0.12888864 ... 0.05018471 0.01325505\n",
            "    0.0045917 ]\n",
            "   [0.33733252 0.17494407 0.15267216 ... 0.02646148 0.01087068\n",
            "    0.00389986]\n",
            "   [0.3181143  0.13679282 0.12702297 ... 0.02282469 0.02214158\n",
            "    0.01064354]\n",
            "   ...\n",
            "   [0.26751333 0.18797602 0.13342448 ... 0.04374462 0.0292747\n",
            "    0.00853144]\n",
            "   [0.18074659 0.15957834 0.15265188 ... 0.05979285 0.03502361\n",
            "    0.01639437]\n",
            "   [0.20700881 0.16873328 0.13372055 ... 0.06887838 0.02255044\n",
            "    0.00934925]]\n",
            "\n",
            "  [[0.37489742 0.2901547  0.11512411 ... 0.02215154 0.01872855\n",
            "    0.00941682]\n",
            "   [0.18999724 0.13898917 0.12236455 ... 0.07654192 0.06884889\n",
            "    0.0477233 ]\n",
            "   [0.27175546 0.12120829 0.1138563  ... 0.0570039  0.05632794\n",
            "    0.05246266]\n",
            "   ...\n",
            "   [0.20520656 0.13339986 0.12312736 ... 0.05491564 0.05075939\n",
            "    0.03485935]\n",
            "   [0.19427177 0.18163337 0.17536202 ... 0.03484033 0.02603423\n",
            "    0.0250867 ]\n",
            "   [0.2918996  0.27665862 0.26320818 ... 0.02027144 0.01506835\n",
            "    0.01499027]]\n",
            "\n",
            "  [[0.43601793 0.18579273 0.07530626 ... 0.03807148 0.03671275\n",
            "    0.03654618]\n",
            "   [0.29635048 0.23618098 0.07779395 ... 0.05147965 0.04919232\n",
            "    0.04249952]\n",
            "   [0.39474365 0.36150783 0.1024332  ... 0.01188225 0.00715878\n",
            "    0.00597612]\n",
            "   ...\n",
            "   [0.34529865 0.27073318 0.1501966  ... 0.03340842 0.02463462\n",
            "    0.01474646]\n",
            "   [0.2451356  0.24132645 0.16123603 ... 0.02899556 0.02688335\n",
            "    0.02529364]\n",
            "   [0.51953447 0.18517023 0.07776037 ... 0.02618033 0.01927708\n",
            "    0.01510626]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "3IpQeei26iui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일을 열고 읽은 다음 내용을 출력하는 코드\n",
        "file_path = \"/./content/model/sorted_attention_scores_2.txt\"  # 읽고자 하는 파일의 경로\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "dhImdkUJ62U5",
        "outputId": "dcc9a8e2-3659-477e-fc1a-dc245a6b6edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.479377    2.1947367   2.0617602   1.4053444   0.6307755   0.5856975\n",
            "   0.49772462  0.11714409 -0.14835791 -0.30920362]\n",
            " [ 5.793112    4.621073    3.812749    3.3466518   2.3886065   2.3419719\n",
            "   1.9099072   1.8878778   1.6703308   1.5484276 ]\n",
            " [ 5.2124023   4.502995    3.8073637   3.3168168   3.0351076   2.6028967\n",
            "   2.4797425   2.3082643   1.6874914   1.5656495 ]\n",
            " [ 6.7969666   5.3321524   4.652975    3.8015726   3.108758    2.719986\n",
            "   2.659658    2.5718498   2.416732    2.1785326 ]\n",
            " [ 5.064213    4.6419153   3.4980125   3.339889    3.3077164   2.7762215\n",
            "   2.5917144   2.023627    1.873533    0.62522817]\n",
            " [ 4.3125715   4.3036885   3.9795005   3.511932    3.220555    3.0432897\n",
            "   2.9215946   2.8711824   2.6142015   2.2757936 ]\n",
            " [ 4.5505824   4.1721644   3.331105    3.1753776   2.6852992   2.6400094\n",
            "   2.4741642   1.7959094   1.6750463   1.3191165 ]\n",
            " [ 4.537689    4.2240024   3.9101954   3.422982    3.3852067   2.9609547\n",
            "   2.1071794   2.1017816   1.7666457   1.6387088 ]\n",
            " [ 5.7495446   4.3632503   3.822887    3.529175    3.3072975   2.9970148\n",
            "   2.365435    2.2333503   1.2618201   1.1282016 ]\n",
            " [ 6.618206    5.7463045   5.1483626   4.5703983   4.4660215   3.426703\n",
            "   3.174025    3.1162205   2.4864216   2.1799157 ]] [[ 0.9627847   0.311149    0.02555725 -0.04857237 -0.07704417 -0.1185468\n",
            "  -0.46038562 -0.6803706  -1.0886638  -1.6976843 ]\n",
            " [ 0.97234195  0.7301598   0.43518707  0.06117958 -0.22009215 -0.5790163\n",
            "  -0.6899191  -0.7375137  -1.1784676  -1.7430696 ]\n",
            " [ 1.1253307   0.21543759 -0.0585902  -0.20672473 -0.34776625 -0.43296996\n",
            "  -0.5565975  -0.61825126 -1.1309534  -1.3146526 ]\n",
            " [ 1.2667636   0.45576128  0.14773999  0.03673334  0.01682144  0.00024927\n",
            "  -0.25012723 -0.25380707 -0.3354175  -0.5908074 ]\n",
            " [ 0.7070519   0.6523646   0.59022087  0.32314226  0.09670944 -0.03702255\n",
            "  -0.25472367 -1.2064693  -1.5367095  -1.7260594 ]\n",
            " [ 0.7998164   0.43778053  0.38227442  0.37704596  0.2848917   0.15285142\n",
            "   0.01839954 -0.49263728 -0.8517933  -1.209122  ]\n",
            " [ 0.60655284  0.5833909   0.2000978   0.10675713  0.10043441  0.03625927\n",
            "  -0.09115115 -0.17491554 -0.2891728  -0.83618826]\n",
            " [ 0.99600965  0.42240837  0.38931042  0.1125567   0.09165996 -0.06464243\n",
            "  -0.33630806 -0.35978922 -0.56914496 -1.3896195 ]\n",
            " [ 0.6880506   0.4417293   0.22939461  0.17030033  0.16794282  0.1490941\n",
            "   0.03469593 -0.33433583 -0.5399121  -0.96181583]\n",
            " [ 0.81911325  0.47387433  0.27014586  0.25771543  0.17429377 -0.10441241\n",
            "  -0.3579516  -0.4639737  -0.60645354 -0.9096098 ]] [[ 4.0928345   3.0894957   2.8996303   2.411408    0.9280114   0.631462\n",
            "   0.02200214 -0.14752409 -0.74852276 -1.1275623 ]\n",
            " [ 3.9065943   3.235908    3.011582    2.1310635   0.98545116  0.5878507\n",
            "   0.50435984  0.34831482  0.17555894 -0.09421223]\n",
            " [ 2.6323042   2.430443    2.2343197   1.5101197   1.3811649   1.0000788\n",
            "   0.8571075   0.6049058   0.56835276  0.4869851 ]\n",
            " [ 4.087019    3.0947237   2.0099015   1.465734    1.430701    0.9727164\n",
            "   0.75650877  0.56819826  0.33274144 -0.30525357]\n",
            " [ 3.5774622   3.0174787   2.2269187   1.5521222   1.4834703   1.1328936\n",
            "  -0.17385992 -0.3164355  -1.30088    -1.429762  ]\n",
            " [ 3.4188118   3.0749917   2.4532826   2.2898376   1.0576711   0.71736014\n",
            "   0.62846535  0.22138332  0.07279523 -0.32747287]\n",
            " [ 1.9065028   1.5033801   1.2080953   0.88415587  0.6549574   0.593324\n",
            "   0.5708541   0.49050444  0.42657304  0.14300826]\n",
            " [ 2.1231966   2.0823565   1.852924    1.5934157   1.4300145   1.3541062\n",
            "   1.0749373   1.0071483   0.84968215  0.76707125]\n",
            " [ 3.2195091   2.1220663   2.0053072   1.7817802   1.1799686   0.56950235\n",
            "   0.2573312   0.23191671  0.0096926  -0.32239503]\n",
            " [ 4.1586957   3.912785    3.5320184   2.9207473   1.3169683   0.9062026\n",
            "   0.8497595   0.8289084   0.3867088   0.23973835]] [[-0.73714244 -0.88458973 -0.91819704 -1.0391645  -1.2835796  -1.3152801\n",
            "  -1.71575    -1.7907189  -2.0585341  -2.3600693 ]\n",
            " [ 2.8525796   1.291576    1.1377413   1.0893993   0.98103195  0.76816994\n",
            "   0.5328254  -0.05392636 -0.3590138  -1.1812421 ]\n",
            " [ 1.889281    1.394224    1.2403969   1.1208864   0.93400806  0.9152784\n",
            "   0.44077566  0.37211862 -0.48069543 -0.6091448 ]\n",
            " [ 1.9117765   1.7898803   1.4986356   1.2874416   0.8347929   0.61145085\n",
            "   0.17829615 -0.2541298  -0.4079485  -0.5898164 ]\n",
            " [ 1.9394354   1.6893194   1.2605628   0.92400664  0.8303908   0.5058691\n",
            "   0.35562584 -0.15927449 -0.32631215 -1.4803319 ]\n",
            " [ 1.6729834   1.4437281   1.2482777   1.049527    1.0102694   0.7912869\n",
            "   0.68996495  0.5756347   0.47246826  0.2827701 ]\n",
            " [ 1.2811688   1.2386009   1.1386023   1.133507    1.0146374   0.64457095\n",
            "   0.43742573 -0.267912   -0.3252511  -0.527435  ]\n",
            " [ 2.0227776   1.4528047   1.0313237   0.9414549   0.6557309   0.6545312\n",
            "   0.44207764  0.28013933  0.10742482 -0.6168757 ]\n",
            " [ 1.2305831   1.1441543   1.0789971   0.96978915  0.8841506   0.83005744\n",
            "   0.68824714  0.6699963   0.6610696   0.1847023 ]\n",
            " [ 0.8336154   0.65710616  0.5815153   0.48081017  0.45186663  0.34215644\n",
            "  -0.02691434 -0.1397903  -0.4203801  -1.0223608 ]] [[ 4.069817    3.265758    3.0087957   1.123025    0.5453431  -0.26431718\n",
            "  -0.4206367  -0.45972508 -0.81877565 -0.8189321 ]\n",
            " [ 6.097168    4.062114    4.0104914   3.3517642   2.6415534   2.5503993\n",
            "   2.4742503   1.711552    1.0404894   0.6797678 ]\n",
            " [ 3.6345613   2.8842583   2.593385    2.5239465   2.4532597   2.4311733\n",
            "   2.1401596   1.8469099   1.6555488   1.1871887 ]\n",
            " [ 6.664719    4.3002462   4.007442    2.897587    2.8146844   2.0899508\n",
            "   1.9416659   1.1508867   0.9355154   0.92588633]\n",
            " [ 4.5608745   3.773708    3.7128031   3.3055158   2.7502472   2.5344577\n",
            "   1.7340083   1.4384526   1.4212635   0.3143406 ]\n",
            " [ 4.785963    3.9486756   3.0749145   2.427682    2.2834506   2.1121552\n",
            "   2.1050293   1.8919368   1.4853789  -1.8715912 ]\n",
            " [ 3.5164182   3.2546113   2.360936    2.2992978   2.1868212   1.9338874\n",
            "   1.810391    1.1583683   0.84790796  0.63691103]\n",
            " [ 2.7568579   2.7054691   2.477663    2.465773    1.7325523   1.6061538\n",
            "   1.360221    1.037012    0.39985502  0.35841948]\n",
            " [ 4.687452    3.0739172   2.4958704   2.266237    2.0501065   1.2087647\n",
            "   1.0399474   0.85278237  0.47858107 -1.5197104 ]\n",
            " [ 3.609223    3.000189    2.9361863   2.3336442   2.2864735   2.0922556\n",
            "   1.7917078   0.4763999  -0.7293791  -0.74419117]] [[ 2.3518488  -0.10409442 -1.3146498  -1.3970611  -1.4390004  -1.486853\n",
            "  -1.5213429  -2.4012413  -2.5842254  -2.5848315 ]\n",
            " [ 3.4115536   3.0861502   2.8016753   2.5004106   2.4000955   1.5283737\n",
            "   1.3075106   1.0803758   0.95492965 -0.08029907]\n",
            " [ 3.8802829   3.159526    2.2096994   2.0309644   1.5423824   1.4555954\n",
            "   1.3234267   0.77620506  0.30919918 -0.98470867]\n",
            " [ 3.6075718   3.5096714   3.153818    3.1277943   2.7993655   2.5558827\n",
            "   2.483896    1.9985721   0.9758086  -1.3650285 ]\n",
            " [ 3.5341537   2.933026    2.7865634   2.6538177   2.1139412   1.9947041\n",
            "   1.41041     0.17108425  0.09414454 -0.53188324]\n",
            " [ 3.8921413   3.1415412   3.026591    2.9880128   2.960376    2.8401773\n",
            "   2.6003537   2.4387147   2.2146826  -0.05147918]\n",
            " [ 2.6857972   2.6380162   2.6029804   2.583294    2.5345263   2.2150342\n",
            "   2.0204773   1.4581535   1.2893649  -0.9958864 ]\n",
            " [ 3.2778075   3.2038531   2.9330308   2.720913    2.4970698   1.9810863\n",
            "   1.571423    1.2107869   1.1165935   0.04527869]\n",
            " [ 2.7725258   2.6563025   2.6123178   2.521809    2.3261166   2.2237506\n",
            "   2.2081223   2.1577914   1.9723585  -0.23130603]\n",
            " [ 5.390417    3.7007978   3.4948716   3.369534    3.188392    3.1076705\n",
            "   2.958899    2.873453    2.6593766   0.2493442 ]] [[ 2.0303364   1.8577769   1.8336577   0.03677352 -0.1782641  -0.20157872\n",
            "  -0.36019903 -0.5154236  -0.8391258  -0.9360012 ]\n",
            " [ 2.4703162   1.896263    1.7434708   1.7014173   1.6416981   1.616728\n",
            "   1.5449183   1.3008279   0.07594603  0.00997017]\n",
            " [ 2.406196    2.1794832   2.1692429   2.1441464   1.8323896   1.7379965\n",
            "   1.5149322   1.3819319   0.6953787   0.00943146]\n",
            " [ 2.7665334   2.6152775   2.566569    2.191609    2.0782743   1.5269834\n",
            "   1.5004507   1.2686868   0.9322765  -0.32668146]\n",
            " [ 2.8975577   2.492464    1.5521193   1.484075    1.3629732   1.2339579\n",
            "   1.1117117   0.7913337  -0.5223735  -0.75108665]\n",
            " [ 4.608461    4.2106786   2.6140327   2.156302    1.9421829   1.8067638\n",
            "   1.6747181   1.5631702   1.1256423   1.0583446 ]\n",
            " [ 2.443831    2.4160697   2.1890495   2.1084352   2.08211     1.9666604\n",
            "   1.7901441   1.5581807   1.4040198   1.0204064 ]\n",
            " [ 2.5419347   2.4702833   2.2814734   2.1157253   1.9466188   1.7847257\n",
            "   1.6170082   1.4104946   1.1339206   1.1112541 ]\n",
            " [ 2.5761323   2.4792182   2.137839    1.8463246   1.720331    1.4472572\n",
            "   1.3243217   1.2411208   1.2266266   1.1666892 ]\n",
            " [ 5.4560094   5.353278    4.541738    3.3154905   2.8533223   2.8041744\n",
            "   2.6403146   2.3418133   2.1872957   1.9060035 ]] [[ 0.22612049 -0.03800961 -0.03878088 -0.04676584 -0.06920808 -0.20872909\n",
            "  -0.24101785 -0.35037673 -0.4477717  -0.5273356 ]\n",
            " [ 0.67517275  0.39312774  0.23725607 -0.06305974 -0.11039566 -0.29921988\n",
            "  -0.47187504 -0.5550632  -0.6243619  -0.72015625]\n",
            " [ 0.9336121   0.5395098   0.49287453  0.21531588  0.18740971 -0.02921304\n",
            "  -0.23901877 -0.30668795 -0.32362545 -1.2280265 ]\n",
            " [ 0.69756246  0.44989973  0.24341476 -0.00245793 -0.07840493 -0.32464612\n",
            "  -0.38152987 -0.6197981  -0.6797175  -0.70561624]\n",
            " [ 0.10249646  0.07505149 -0.03507853 -0.04885465 -0.20628366 -0.23292464\n",
            "  -0.34050646 -0.44878232 -0.46191064 -2.1298897 ]\n",
            " [ 0.3024567   0.29947233  0.2423661   0.24130446  0.18978542  0.096457\n",
            "   0.03272907  0.02645526  0.00284321 -0.13099633]\n",
            " [ 0.6062699   0.52392596 -0.00332226 -0.16046394 -0.19334584 -0.3142506\n",
            "  -0.34419575 -0.40288302 -0.43888092 -0.4598454 ]\n",
            " [ 0.04201785 -0.02999487 -0.16519366 -0.188554   -0.31032342 -0.39713255\n",
            "  -0.56612873 -0.6005166  -1.3156276  -2.612752  ]\n",
            " [ 0.3471023   0.2327159   0.1582894   0.13848405  0.0672462   0.0647919\n",
            "  -0.00930041 -0.03875374 -0.08677322 -0.1906524 ]\n",
            " [ 0.2202284   0.05504296  0.00104465 -0.02846966 -0.03995595 -0.06230865\n",
            "  -0.06644918 -0.08931216 -0.15427314 -0.25045082]] [[ 2.2500303   2.2188106   0.7274816   0.7000268   0.5726925   0.284214\n",
            "   0.13661313  0.11507649 -0.22948742 -0.4026169 ]\n",
            " [ 3.4689038   2.951157    2.3157012   1.8796558   1.4019722   1.1965826\n",
            "   1.1602786   0.6572411   0.2278574  -0.1770497 ]\n",
            " [ 3.709777    2.3455753   1.9080584   1.6395503   1.4283334   1.2921461\n",
            "   1.0153087   0.8905095   0.5606777   0.47134808]\n",
            " [ 4.1362057   3.8354084   3.003888    2.590262    2.323182    1.8637079\n",
            "   1.3310231   1.2275932   1.0532311  -0.19235559]\n",
            " [ 3.094353    1.8359743   1.7547503   1.5248697   1.3008693   0.6746429\n",
            "   0.6143206   0.54005456  0.47067168  0.2596902 ]\n",
            " [ 2.0936713   1.9916923   1.3448064   0.901352    0.87460697  0.80160993\n",
            "   0.5036669   0.45084783 -0.10966269 -0.9338605 ]\n",
            " [ 1.4810711   0.9820602   0.5728401   0.5373771   0.45082232  0.40630463\n",
            "   0.07374337  0.0408671  -0.04004947 -0.43184328]\n",
            " [ 3.1449246   2.3962045   2.0956993   1.8832694   1.0816227   0.7081071\n",
            "   0.6745899   0.6018912   0.5275235   0.19390348]\n",
            " [ 2.0125527   1.7450609   1.6686664   1.5488706   1.1293051   0.8310921\n",
            "   0.57361317  0.46006605  0.18745206 -0.3780636 ]\n",
            " [ 2.0720472   1.7020148   1.3618188   1.1978279   0.8111273   0.633571\n",
            "   0.6197194   0.29930606  0.2847378   0.12218147]] [[ 1.11368     0.10982683 -0.01029287 -0.03871024 -0.04179777 -0.1011171\n",
            "  -0.61037153 -0.7641907  -0.8519444  -3.409261  ]\n",
            " [ 1.5662173   1.5360875   1.0755258   1.0136852   0.79115003  0.6315195\n",
            "   0.5027024   0.36316153 -0.60011023 -0.84586865]\n",
            " [ 1.431718    1.3796113   0.9972024   0.7522633   0.60126495  0.53102773\n",
            "   0.42479315 -0.19636366 -0.24372143 -1.2828168 ]\n",
            " [ 1.2536769   1.2261399   1.0066447   0.60732824  0.05428234 -0.01733678\n",
            "  -0.01925345 -0.34242573 -0.3713482  -1.0930486 ]\n",
            " [ 1.9441388   1.1883222   1.0981218   0.812452    0.73339826  0.300511\n",
            "   0.27320436 -0.5859628  -0.6089171  -0.69458455]\n",
            " [ 1.6519731   0.9120517   0.87512237  0.7143033   0.6206465   0.49330038\n",
            "   0.45504218 -0.31964967 -0.3862846  -1.0343239 ]\n",
            " [ 1.585442    1.5412023   1.3740886   1.1451776   1.118077    0.7921902\n",
            "   0.45498532  0.13255627 -0.11572167 -0.8244491 ]\n",
            " [ 1.8586993   1.3764335   1.3430959   1.1695968   1.0572455   0.8649328\n",
            "   0.7645048   0.06315615 -0.42347932 -1.3920376 ]\n",
            " [ 1.6112568   1.1641402   1.0310172   1.0027801   0.95073116  0.830472\n",
            "   0.55506825 -0.04602024 -0.305408   -1.4279099 ]\n",
            " [ 1.052246    0.88820004  0.8350356   0.6750055   0.5101989   0.46982872\n",
            "   0.30827308  0.06021432 -0.1204833  -1.1874206 ]] [[ 3.5113144   1.1630836   0.70824903  0.31988123  0.23125732  0.14855024\n",
            "   0.04084282 -0.23730999 -0.34488022 -0.6694767 ]\n",
            " [ 2.819541    2.806927    2.6324604   2.600652    2.5454693   2.2246804\n",
            "   2.0883412   2.0405247   1.7904973   1.0418186 ]\n",
            " [ 3.0531595   2.6789215   2.5830665   2.552863    2.5436692   2.497571\n",
            "   2.387744    1.8923868   1.4598      1.4553257 ]\n",
            " [ 3.5424695   3.2522182   3.0475783   3.0259213   2.8534472   2.566625\n",
            "   2.431889    2.3083878   2.0304976   1.5133282 ]\n",
            " [ 3.4065237   2.9776423   2.7873087   2.764315    2.261848    2.1300118\n",
            "   1.9021384   1.51449     0.85365546  0.78977865]\n",
            " [ 4.7410984   3.6375775   3.3431032   2.7378526   2.5947425   2.352169\n",
            "   2.2832878   2.2509813   1.9672732   1.4767879 ]\n",
            " [ 3.4104338   2.9486048   2.7286584   2.63342     2.298728    1.8677042\n",
            "   1.7034984   1.3938805   1.323737    0.75743663]\n",
            " [ 4.188968    3.5719974   3.45946     3.3282526   3.1684306   2.4641638\n",
            "   2.2208533   2.1354446   1.6605146   1.5281339 ]\n",
            " [ 3.7193854   3.718595    3.097043    2.4487157   2.4170146   2.3511674\n",
            "   2.3510675   2.3213775   2.0928166   1.2444317 ]\n",
            " [ 5.245867    4.847442    3.372125    3.146039    2.9236443   2.8997252\n",
            "   2.8552227   2.7353942   2.6822622   2.6110198 ]] [[ 2.5945306   1.7404832   0.24408357  0.20622298  0.17036484  0.14028859\n",
            "  -0.05346468 -0.0875273  -0.21828583 -0.28903437]\n",
            " [ 3.8067138   2.5038111   1.9661093   0.43165812 -0.31045496 -0.3236773\n",
            "  -0.66055036 -0.9152964  -1.0867347  -1.4174232 ]\n",
            " [ 2.3395207   1.7736304   0.9409393   0.73563135  0.19052632 -0.67819226\n",
            "  -0.78984517 -1.0566123  -1.3535223  -1.5124058 ]\n",
            " [ 2.7757225   1.2547673   0.87479126  0.41058114  0.34710675 -0.15644921\n",
            "  -0.33859655 -0.44897196 -0.48662195 -0.6115687 ]\n",
            " [ 3.0947883   0.6738987   0.4476631   0.28215185  0.14923412 -0.13776019\n",
            "  -0.30546984 -0.6876085  -0.6992324  -1.602245  ]\n",
            " [ 1.7985494   1.546602   -0.46327224 -0.73712903 -0.9095844  -1.2862829\n",
            "  -1.288245   -1.491924   -1.5902119  -1.6702429 ]\n",
            " [ 1.4186683   1.2171147   0.48501337  0.2906626  -0.35724834 -0.53071135\n",
            "  -0.79060125 -0.9079117  -1.3592548  -1.503863  ]\n",
            " [ 3.1788638   1.5222133   0.40442356  0.29755515  0.21761012 -0.37342417\n",
            "  -0.4834577  -0.85203713 -0.8623995  -1.0658941 ]\n",
            " [ 1.7944585   0.9605556   0.43165296  0.07014562 -0.3501598  -0.51980543\n",
            "  -0.5650798  -0.7924533  -1.2602837  -1.6325725 ]\n",
            " [ 1.9798651   0.9559839  -0.5624908  -0.63779896 -0.6748462  -0.7449863\n",
            "  -0.8235787  -0.8677051  -0.9195779  -1.232003  ]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path = \"./model/softmax_attention_scores.pkl\"\n",
        "with open(softmax_file_path, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax attention_scores가 {softmax_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "WUVvB7pr7RBf",
        "outputId": "b5f65e1b-76b3-429b-cd41-c8f2f15e29a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.14792055 0.09109741 0.09164357 ... 0.09258842 0.09229336\n",
            "    0.09513694]\n",
            "   [0.12004586 0.10268968 0.10120098 ... 0.09385469 0.09336554\n",
            "    0.09450836]\n",
            "   [0.09188308 0.11296417 0.10104739 ... 0.09287033 0.09284727\n",
            "    0.09269542]\n",
            "   ...\n",
            "   [0.09724706 0.09072162 0.09059814 ... 0.09612775 0.12209511\n",
            "    0.1143846 ]\n",
            "   [0.09323013 0.09044815 0.09189644 ... 0.11774409 0.09348241\n",
            "    0.13755944]\n",
            "   [0.10347308 0.09130668 0.09073301 ... 0.10249271 0.0964129\n",
            "    0.10287845]]\n",
            "\n",
            "  [[0.09785708 0.1010711  0.09990909 ... 0.1006773  0.09957507\n",
            "    0.11400125]\n",
            "   [0.09519613 0.09198768 0.10206269 ... 0.09563526 0.09920019\n",
            "    0.12259457]\n",
            "   [0.0963392  0.09690202 0.09143765 ... 0.10719077 0.10062093\n",
            "    0.12747219]\n",
            "   ...\n",
            "   [0.09908457 0.09758333 0.09906299 ... 0.0961072  0.0978529\n",
            "    0.12674263]\n",
            "   [0.09308667 0.10304288 0.09866013 ... 0.10144265 0.09808288\n",
            "    0.10579788]\n",
            "   [0.09461471 0.1043413  0.0984853  ... 0.10681042 0.09746661\n",
            "    0.11155472]]\n",
            "\n",
            "  [[0.10933199 0.09290536 0.09061925 ... 0.09214136 0.09332465\n",
            "    0.10667202]\n",
            "   [0.10829917 0.10341936 0.09385677 ... 0.09627965 0.09360978\n",
            "    0.10712849]\n",
            "   [0.10907564 0.09717342 0.0946402  ... 0.09514245 0.09607369\n",
            "    0.1086611 ]\n",
            "   ...\n",
            "   [0.10199555 0.10672598 0.09804323 ... 0.11619101 0.09668372\n",
            "    0.10503597]\n",
            "   [0.0949479  0.11661825 0.09678788 ... 0.09768786 0.09655614\n",
            "    0.10871448]\n",
            "   [0.1353592  0.0939795  0.09070874 ... 0.09208083 0.09304921\n",
            "    0.10064787]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.09984183 0.10561763 0.10010299 ... 0.09757758 0.1026743\n",
            "    0.11696494]\n",
            "   [0.10077073 0.1048938  0.1072562  ... 0.09442478 0.09245645\n",
            "    0.1261673 ]\n",
            "   [0.09222058 0.10335313 0.12389978 ... 0.09829431 0.10070038\n",
            "    0.1023483 ]\n",
            "   ...\n",
            "   [0.09290123 0.09680557 0.11789276 ... 0.10309868 0.09550235\n",
            "    0.1088791 ]\n",
            "   [0.09593145 0.10086945 0.10162396 ... 0.10526626 0.09792026\n",
            "    0.10599791]\n",
            "   [0.09677328 0.09897416 0.11110785 ... 0.10325618 0.0989797\n",
            "    0.10693549]]\n",
            "\n",
            "  [[0.13062458 0.09245858 0.0914835  ... 0.09063558 0.09179717\n",
            "    0.09474251]\n",
            "   [0.09483223 0.09760492 0.10083348 ... 0.09685693 0.10389443\n",
            "    0.09879342]\n",
            "   [0.09761009 0.09560166 0.10119431 ... 0.09553706 0.09628828\n",
            "    0.11850341]\n",
            "   ...\n",
            "   [0.10222587 0.10328139 0.09508933 ... 0.09548536 0.09791066\n",
            "    0.11097045]\n",
            "   [0.09551324 0.10601512 0.09348555 ... 0.10826695 0.1075901\n",
            "    0.10964395]\n",
            "   [0.11690799 0.09121044 0.09121756 ... 0.0916934  0.09208853\n",
            "    0.09284412]]\n",
            "\n",
            "  [[0.10810776 0.0942751  0.09505253 ... 0.09378396 0.09679952\n",
            "    0.13884439]\n",
            "   [0.12123886 0.11415911 0.09557965 ... 0.09468964 0.09405801\n",
            "    0.09743701]\n",
            "   [0.132849   0.09005725 0.12850621 ... 0.0927122  0.09285689\n",
            "    0.09917664]\n",
            "   ...\n",
            "   [0.12697606 0.0912357  0.09214232 ... 0.1178524  0.09399209\n",
            "    0.10446963]\n",
            "   [0.11475074 0.09405647 0.10441453 ... 0.09398486 0.11518867\n",
            "    0.1059187 ]\n",
            "   [0.15028572 0.09182073 0.0938767  ... 0.09661791 0.09353498\n",
            "    0.10757346]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 2]: 1.0\n",
            "Sum of softmax values in [0, 0, 3]: 1.0\n",
            "Sum of softmax values in [0, 0, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 5]: 1.0\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 1.0\n",
            "Sum of softmax values in [0, 1, 1]: 1.0\n",
            "Sum of softmax values in [0, 1, 2]: 1.0\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 1, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 7]: 1.0\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 1.0\n",
            "Sum of softmax values in [0, 2, 0]: 1.0\n",
            "Sum of softmax values in [0, 2, 1]: 1.0\n",
            "Sum of softmax values in [0, 2, 2]: 1.0\n",
            "Sum of softmax values in [0, 2, 3]: 1.0\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 6]: 1.0\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 1]: 1.0\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 5]: 1.0\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 1]: 1.0\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 1.0\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0\n",
            "Sum of softmax values in [0, 6, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 0]: 1.0\n",
            "Sum of softmax values in [0, 7, 1]: 1.0\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 4]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 1.0\n",
            "Sum of softmax values in [0, 8, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 4]: 1.0\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 1.0\n",
            "Sum of softmax values in [0, 8, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 8]: 1.0\n",
            "Sum of softmax values in [0, 8, 9]: 1.0\n",
            "Sum of softmax values in [0, 9, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 2]: 1.0\n",
            "Sum of softmax values in [0, 9, 3]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 1.0\n",
            "Sum of softmax values in [0, 9, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 7]: 1.0\n",
            "Sum of softmax values in [0, 9, 8]: 1.0\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 1]: 1.0\n",
            "Sum of softmax values in [0, 10, 2]: 1.0\n",
            "Sum of softmax values in [0, 10, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0\n",
            "Sum of softmax values in [0, 11, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 1.0\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 1.0\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0\n",
            "Sum of softmax values in [0, 11, 8]: 1.0\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax attention_scores가 ./model/softmax_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 파일 경로\n",
        "file_path = \"./model/attention_scores.pkl\"\n",
        "\n",
        "# 파일에서 데이터 로드\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(f\"Shape of attention_scores: {np.array(attention_scores).shape}\")\n"
      ],
      "metadata": {
        "id": "EvyTkAln9iH7",
        "outputId": "83609b4b-dd62-4e02-854d-d3e2d785f8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of attention_scores: (1, 12, 10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 파일 로드\n",
        "file_path = \"./model/attention_scores.pkl\"  # 기존 파일 경로\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. 정렬 및 인덱스 저장\n",
        "sorted_attention_scores = np.zeros_like(attention_scores)\n",
        "original_indices = np.zeros_like(attention_scores, dtype=int)\n",
        "\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 인덱스와 정렬된 배열 저장\n",
        "            sorted_indices = np.argsort(attention_scores[i, j, k])[::-1]  # 내림차순 인덱스\n",
        "            sorted_attention_scores[i, j, k] = attention_scores[i, j, k][sorted_indices]\n",
        "            original_indices[i, j, k] = sorted_indices  # 원래의 순서 저장\n",
        "\n",
        "# 3. 정렬된 데이터를 새로운 파일로 저장\n",
        "sorted_file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(sorted_file_path, \"wb\") as f:\n",
        "    pickle.dump(sorted_attention_scores, f)\n",
        "\n",
        "# 4. 원래 인덱스 데이터를 새로운 파일로 저장\n",
        "indices_file_path = \"./model/original_indices.pkl\"\n",
        "with open(indices_file_path, \"wb\") as f:\n",
        "    pickle.dump(original_indices, f)\n",
        "\n",
        "print(f\"정렬된 attention_scores와 원래 인덱스가 각각 {sorted_file_path}, {indices_file_path}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "eOuBuIM67wL7",
        "outputId": "979679d1-1b75-4729-b2e0-de81d1e48f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정렬된 attention_scores와 원래 인덱스가 각각 ./model/sorted_attention_scores.pkl, ./model/original_indices.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# 1. 파일에서 attention_scores 로드\n",
        "file_path = \"./model/sorted_attention_scores.pkl\"\n",
        "with open(file_path, \"rb\") as f:\n",
        "    attention_scores = pickle.load(f)\n",
        "\n",
        "# 2. Softmax 함수 정의\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Overflow 방지를 위해 x에서 최대값을 뺌\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# 3. attention_scores에 Softmax 연산 적용\n",
        "softmax_values = np.zeros_like(attention_scores)  # 원래 크기의 배열 생성\n",
        "for i in range(attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            softmax_values[i, j, k] = softmax(attention_scores[i, j, k])  # 최소 단위(10개)에 Softmax 적용\n",
        "\n",
        "# 4. Softmax 결과 확인\n",
        "print(\"Softmax 값:\")\n",
        "print(softmax_values)\n",
        "\n",
        "# 5. Softmax 값의 합 (확률 분포인지 확인)\n",
        "print(f\"Softmax 값의 합 (각 10개 묶음에서):\")\n",
        "for i in range(softmax_values.shape[0]):\n",
        "    for j in range(softmax_values.shape[1]):\n",
        "        for k in range(softmax_values.shape[2]):\n",
        "            print(f\"Sum of softmax values in [{i}, {j}, {k}]: {softmax_values[i, j, k].sum()}\")\n",
        "\n",
        "# 6. Softmax 값을 새로운 파일로 저장\n",
        "softmax_file_path2 = \"./model/softmax_sorted_attention_scores.pkl\"\n",
        "with open(softmax_file_path2, \"wb\") as f:\n",
        "    pickle.dump(softmax_values, f)\n",
        "\n",
        "print(f\"Softmax sorted_attention_scores가 {softmax_file_path2}에 저장되었습니다!\")"
      ],
      "metadata": {
        "id": "jM9BFbZ2-5sn",
        "outputId": "290534aa-6cef-4739-f55a-0f012a6139bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax 값:\n",
            "[[[[0.52837735 0.14622842 0.12802091 ... 0.01831239 0.01404232\n",
            "    0.01195596]\n",
            "   [0.59860635 0.18540917 0.08261921 ... 0.01205368 0.00969707\n",
            "    0.00858417]\n",
            "   [0.444481   0.21865617 0.10905692 ... 0.02435579 0.01309194\n",
            "    0.01159013]\n",
            "   ...\n",
            "   [0.29339513 0.21439773 0.1566519  ... 0.02567742 0.01836554\n",
            "    0.01616   ]\n",
            "   [0.57483137 0.14370805 0.08371503 ... 0.01707957 0.00646467\n",
            "    0.0056561 ]\n",
            "   [0.4939701  0.2065565  0.1135942  ... 0.01488705 0.0079303\n",
            "    0.00583681]]\n",
            "\n",
            "  [[0.27761802 0.14469248 0.10874645 ... 0.05368272 0.03568742\n",
            "    0.0194098 ]\n",
            "   [0.2604175  0.20440508 0.15219018 ... 0.0471074  0.03030995\n",
            "    0.01723382]\n",
            "   [0.33725736 0.13576876 0.1032265  ... 0.0589839  0.03532398\n",
            "    0.02939612]\n",
            "   ...\n",
            "   [0.24415724 0.13758078 0.13310163 ... 0.06292942 0.05104246\n",
            "    0.02247004]\n",
            "   [0.18009993 0.14077894 0.11384702 ... 0.06478832 0.05274922\n",
            "    0.03459278]\n",
            "   [0.20915565 0.14809291 0.12079702 ... 0.05797384 0.0502752\n",
            "    0.03712743]]\n",
            "\n",
            "  [[0.5064871  0.18570489 0.15359119 ... 0.00729464 0.00399939\n",
            "    0.00273766]\n",
            "   [0.4379279  0.22393818 0.17893854 ... 0.01247561 0.01049627\n",
            "    0.00801447]\n",
            "   [0.2603332  0.21274655 0.17485853 ... 0.03428008 0.03304966\n",
            "    0.03046695]\n",
            "   ...\n",
            "   [0.18211862 0.17483063 0.13898769 ... 0.0596569  0.05096525\n",
            "    0.04692418]\n",
            "   [0.44636634 0.14896286 0.13254699 ... 0.02250073 0.01801714\n",
            "    0.01292593]\n",
            "   [0.35479093 0.2774438  0.18958764 ... 0.01270177 0.00816243\n",
            "    0.00704678]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.3224566  0.11816897 0.104794   ... 0.04930861 0.04516601\n",
            "    0.00350093]\n",
            "   [0.20571333 0.1996078  0.12593831 ... 0.06177067 0.0235743\n",
            "    0.01843773]\n",
            "   [0.21004215 0.19937788 0.13601877 ... 0.04123254 0.03932535\n",
            "    0.0139123 ]\n",
            "   ...\n",
            "   [0.23940288 0.14780326 0.14295706 ... 0.03974978 0.02443384\n",
            "    0.00927581]\n",
            "   [0.22464605 0.1436543  0.1257488  ... 0.04283045 0.03304471\n",
            "    0.01075488]\n",
            "   [0.17417425 0.14782219 0.14016858 ... 0.06458771 0.05391061\n",
            "    0.01854851]]\n",
            "\n",
            "  [[0.7349548  0.0702162  0.0445559  ... 0.01730829 0.01554308\n",
            "    0.01123483]\n",
            "   [0.15628093 0.15432215 0.12961592 ... 0.07171063 0.05584678\n",
            "    0.02641503]\n",
            "   [0.18773966 0.12912975 0.11732686 ... 0.05880835 0.03815652\n",
            "    0.03798618]\n",
            "   ...\n",
            "   [0.29404277 0.1586586  0.14177155 ... 0.03772045 0.0234594\n",
            "    0.02055061]\n",
            "   [0.24240188 0.24221043 0.13009375 ... 0.05989481 0.04765693\n",
            "    0.02040222]\n",
            "   [0.40604976 0.27261227 0.06234816 ... 0.03298337 0.03127664\n",
            "    0.02912593]]\n",
            "\n",
            "  [[0.4896041  0.20841901 0.04667229 ... 0.03349983 0.02939372\n",
            "    0.02738602]\n",
            "   [0.653465   0.17757401 0.10371903 ... 0.00581406 0.00489807\n",
            "    0.00351892]\n",
            "   [0.43387488 0.24637781 0.10714415 ... 0.01453594 0.01080181\n",
            "    0.00921498]\n",
            "   ...\n",
            "   [0.6826025  0.13022491 0.04258376 ... 0.01212188 0.01199692\n",
            "    0.00978798]\n",
            "   [0.42847246 0.18610714 0.1096639  ... 0.03224342 0.02019599\n",
            "    0.01391817]\n",
            "   [0.5374473  0.19304991 0.04228676 ... 0.03116387 0.02958853\n",
            "    0.02164905]]]]\n",
            "Softmax 값의 합 (각 10개 묶음에서):\n",
            "Sum of softmax values in [0, 0, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 0, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 0, 4]: 1.0\n",
            "Sum of softmax values in [0, 0, 5]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 0, 6]: 1.0\n",
            "Sum of softmax values in [0, 0, 7]: 1.0\n",
            "Sum of softmax values in [0, 0, 8]: 1.0\n",
            "Sum of softmax values in [0, 0, 9]: 1.0\n",
            "Sum of softmax values in [0, 1, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 3]: 1.0\n",
            "Sum of softmax values in [0, 1, 4]: 1.0\n",
            "Sum of softmax values in [0, 1, 5]: 1.0\n",
            "Sum of softmax values in [0, 1, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 1, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 1, 8]: 1.0\n",
            "Sum of softmax values in [0, 1, 9]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 2]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 2, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 4]: 1.0\n",
            "Sum of softmax values in [0, 2, 5]: 1.0\n",
            "Sum of softmax values in [0, 2, 6]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 2, 7]: 1.0\n",
            "Sum of softmax values in [0, 2, 8]: 1.0\n",
            "Sum of softmax values in [0, 2, 9]: 1.0\n",
            "Sum of softmax values in [0, 3, 0]: 1.0\n",
            "Sum of softmax values in [0, 3, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 3, 2]: 1.0\n",
            "Sum of softmax values in [0, 3, 3]: 1.0\n",
            "Sum of softmax values in [0, 3, 4]: 1.0\n",
            "Sum of softmax values in [0, 3, 5]: 1.0\n",
            "Sum of softmax values in [0, 3, 6]: 1.0\n",
            "Sum of softmax values in [0, 3, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 3, 8]: 1.0\n",
            "Sum of softmax values in [0, 3, 9]: 1.0\n",
            "Sum of softmax values in [0, 4, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 4, 1]: 1.0\n",
            "Sum of softmax values in [0, 4, 2]: 1.0\n",
            "Sum of softmax values in [0, 4, 3]: 1.0\n",
            "Sum of softmax values in [0, 4, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 6]: 1.0\n",
            "Sum of softmax values in [0, 4, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 4, 8]: 1.0\n",
            "Sum of softmax values in [0, 4, 9]: 1.0\n",
            "Sum of softmax values in [0, 5, 0]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 5, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 5, 2]: 1.0\n",
            "Sum of softmax values in [0, 5, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 4]: 1.0\n",
            "Sum of softmax values in [0, 5, 5]: 1.0\n",
            "Sum of softmax values in [0, 5, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 5, 9]: 1.0\n",
            "Sum of softmax values in [0, 6, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 1]: 1.0\n",
            "Sum of softmax values in [0, 6, 2]: 1.0\n",
            "Sum of softmax values in [0, 6, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 6, 4]: 1.0\n",
            "Sum of softmax values in [0, 6, 5]: 1.0\n",
            "Sum of softmax values in [0, 6, 6]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 6, 7]: 1.0\n",
            "Sum of softmax values in [0, 6, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 6, 9]: 1.0\n",
            "Sum of softmax values in [0, 7, 0]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 7, 1]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 2]: 1.0\n",
            "Sum of softmax values in [0, 7, 3]: 1.0\n",
            "Sum of softmax values in [0, 7, 4]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 5]: 1.0\n",
            "Sum of softmax values in [0, 7, 6]: 1.0\n",
            "Sum of softmax values in [0, 7, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 7, 8]: 1.0\n",
            "Sum of softmax values in [0, 7, 9]: 1.0\n",
            "Sum of softmax values in [0, 8, 0]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 1]: 1.0\n",
            "Sum of softmax values in [0, 8, 2]: 1.0\n",
            "Sum of softmax values in [0, 8, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 8, 4]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 8, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 7]: 1.0\n",
            "Sum of softmax values in [0, 8, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 8, 9]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 0]: 1.0\n",
            "Sum of softmax values in [0, 9, 1]: 1.0\n",
            "Sum of softmax values in [0, 9, 2]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 3]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 9, 4]: 1.0\n",
            "Sum of softmax values in [0, 9, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 6]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 7]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 8]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 9, 9]: 1.0\n",
            "Sum of softmax values in [0, 10, 0]: 1.0\n",
            "Sum of softmax values in [0, 10, 1]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 10, 2]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 10, 3]: 1.0\n",
            "Sum of softmax values in [0, 10, 4]: 1.0\n",
            "Sum of softmax values in [0, 10, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 10, 6]: 1.0\n",
            "Sum of softmax values in [0, 10, 7]: 1.0\n",
            "Sum of softmax values in [0, 10, 8]: 1.0\n",
            "Sum of softmax values in [0, 10, 9]: 1.0\n",
            "Sum of softmax values in [0, 11, 0]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 1]: 0.9999998807907104\n",
            "Sum of softmax values in [0, 11, 2]: 1.0\n",
            "Sum of softmax values in [0, 11, 3]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 4]: 1.0\n",
            "Sum of softmax values in [0, 11, 5]: 0.9999999403953552\n",
            "Sum of softmax values in [0, 11, 6]: 1.0\n",
            "Sum of softmax values in [0, 11, 7]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 8]: 1.0000001192092896\n",
            "Sum of softmax values in [0, 11, 9]: 1.0\n",
            "Softmax sorted_attention_scores가 ./model/softmax_sorted_attention_scores.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "1Pr9O46V_Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/softmax_sorted_attention_scores.pkl\"\n",
        "text_file_path = \"/./content/model/softmax_sorted_attention_scores_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "hhRL4CRO_QSf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"/./content/model/restored_softmax.pkl\"\n",
        "text_file_path = \"/./content/model/restored_softmax_2.txt\"\n",
        "pickle_to_text(pickle_file_path, text_file_path)"
      ],
      "metadata": {
        "id": "V-oYzGDQCZvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/softmax_sorted_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "THbCGtMz_twq",
        "outputId": "112c2397-825f-4837-ce06-6a4df446ea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.10749399 0.09632882 0.0954031  0.09513693 0.09258841\n",
            "  0.09229334 0.09164356 0.0910974  0.0900939 ]\n",
            " [0.12004588 0.10565753 0.10268969 0.10120098 0.09709173 0.0958351\n",
            "  0.09575053 0.09450836 0.0938547  0.09336555]\n",
            " [0.13786007 0.11296417 0.10104739 0.09357624 0.09350549 0.09287033\n",
            "  0.09284727 0.09269542 0.09188308 0.09075052]\n",
            " [0.11074849 0.10814226 0.10393477 0.10047178 0.10030901 0.09913348\n",
            "  0.09670201 0.09443171 0.09372903 0.09239744]\n",
            " [0.1193184  0.10324923 0.10189565 0.09932904 0.09908514 0.09784093\n",
            "  0.09755905 0.0950703  0.09426644 0.09238588]\n",
            " [0.1328674  0.10326969 0.09898279 0.09854479 0.09625035 0.09615592\n",
            "  0.0958468  0.09484941 0.09185758 0.0913753 ]\n",
            " [0.11864013 0.1089671  0.10785589 0.10248473 0.09685351 0.09558748\n",
            "  0.09497281 0.09192704 0.0917357  0.0909756 ]\n",
            " [0.12209511 0.1143846  0.10398746 0.09853819 0.09724706 0.09612775\n",
            "  0.09440193 0.09189809 0.09072162 0.09059814]\n",
            " [0.13755944 0.11774409 0.09577599 0.0939422  0.09348241 0.09323013\n",
            "  0.09304722 0.09287393 0.09189644 0.09044815]\n",
            " [0.12786184 0.10347308 0.10287845 0.10249271 0.09869479 0.0964129\n",
            "  0.0952139  0.09130668 0.09093261 0.09073301]] [[0.11400125 0.1034065  0.1010711  0.1006773  0.09990909 0.09957507\n",
            "  0.09785708 0.09670063 0.09466569 0.09213626]\n",
            " [0.12259456 0.10524756 0.10206269 0.09920018 0.09916254 0.09589188\n",
            "  0.09563524 0.09519612 0.09302149 0.09198767]\n",
            " [0.12747219 0.10719077 0.10062093 0.09860631 0.09690202 0.0963392\n",
            "  0.09631989 0.09255879 0.0925522  0.09143765]\n",
            " [0.10658482 0.10630877 0.10104766 0.1003748  0.10008461 0.09871509\n",
            "  0.0979219  0.09733845 0.09657256 0.09505137]\n",
            " [0.11034425 0.10167924 0.10102019 0.10027704 0.10000083 0.09928491\n",
            "  0.09772887 0.09770507 0.09617376 0.0957859 ]\n",
            " [0.10516495 0.10368128 0.10063306 0.1006038  0.10018845 0.09995812\n",
            "  0.09989405 0.09896458 0.09562299 0.09528879]\n",
            " [0.11380466 0.10230775 0.1017336  0.10014401 0.09873901 0.09837577\n",
            "  0.09824028 0.09637209 0.09522659 0.0950562 ]\n",
            " [0.12674263 0.10445353 0.09908456 0.09906299 0.0978529  0.09758332\n",
            "  0.09610719 0.09558626 0.09211903 0.09140754]\n",
            " [0.10645555 0.10579788 0.10304288 0.10144265 0.09954634 0.09866013\n",
            "  0.09808288 0.097651   0.09623402 0.09308667]\n",
            " [0.11155472 0.10681042 0.1043413  0.10225179 0.0984853  0.09746661\n",
            "  0.09710175 0.09461471 0.09410094 0.09327243]] [[0.11106927 0.109332   0.10838971 0.10667203 0.10396456 0.09332467\n",
            "  0.09290537 0.09214137 0.09158181 0.09061927]\n",
            " [0.11498808 0.10829917 0.10712849 0.10341936 0.09627965 0.0959329\n",
            "  0.09385677 0.09360978 0.09335104 0.09313468]\n",
            " [0.10907564 0.1086611  0.10594706 0.10251999 0.09717342 0.09607369\n",
            "  0.09553417 0.09523229 0.09514245 0.0946402 ]\n",
            " [0.12777801 0.11388236 0.09597065 0.09547208 0.09541373 0.09527735\n",
            "  0.09474532 0.09463353 0.09392282 0.09290416]\n",
            " [0.11447315 0.10678963 0.10269815 0.10112287 0.10047487 0.09732886\n",
            "  0.0970234  0.09365991 0.09344386 0.09298529]\n",
            " [0.11844434 0.10639787 0.10390373 0.10112502 0.09893835 0.09716936\n",
            "  0.0958861  0.09353664 0.0925469  0.09205168]\n",
            " [0.11324795 0.10864487 0.10467929 0.10341784 0.10152826 0.09656344\n",
            "  0.09464015 0.0934985  0.09244199 0.09133781]\n",
            " [0.11619101 0.10672598 0.10503597 0.10199555 0.09804323 0.09668372\n",
            "  0.09610645 0.09338766 0.0933179  0.09251253]\n",
            " [0.11661826 0.11136508 0.10871449 0.09768787 0.09678789 0.09655615\n",
            "  0.09494792 0.09265881 0.09243154 0.09223206]\n",
            " [0.13535918 0.10957498 0.10064787 0.09704289 0.09668809 0.0939795\n",
            "  0.0930492  0.09208082 0.09086873 0.09070873]] [[0.1255899  0.10366833 0.10065787 0.09996307 0.09845075 0.09556752\n",
            "  0.09483397 0.09431619 0.09430879 0.09264354]\n",
            " [0.13242505 0.1023296  0.1009952  0.09722893 0.0965215  0.09473015\n",
            "  0.09469819 0.09453561 0.09363452 0.09290122]\n",
            " [0.10879505 0.10861369 0.10704175 0.0996678  0.09955349 0.0962432\n",
            "  0.09612511 0.09592903 0.09408776 0.09394309]\n",
            " [0.12335853 0.109509   0.10271551 0.09744254 0.09695764 0.09671901\n",
            "  0.09527482 0.09343539 0.09332724 0.09126032]\n",
            " [0.1051129  0.1042406  0.1015951  0.10096215 0.10058594 0.09961344\n",
            "  0.09938804 0.09867377 0.09613637 0.09369161]\n",
            " [0.11151089 0.10542171 0.10479862 0.10213321 0.0991762  0.09746461\n",
            "  0.09690585 0.09604911 0.09489696 0.09164282]\n",
            " [0.10953204 0.10539693 0.10379548 0.10073565 0.100105   0.09728067\n",
            "  0.09637927 0.09632144 0.09549578 0.09495777]\n",
            " [0.11535057 0.11265247 0.10442845 0.10190308 0.0975237  0.09578036\n",
            "  0.094757   0.0945795  0.09181842 0.09120651]\n",
            " [0.11083733 0.10423398 0.10382918 0.10361786 0.09832249 0.09829199\n",
            "  0.0961586  0.09549905 0.0948538  0.09435575]\n",
            " [0.12480727 0.10181123 0.1017132  0.09872679 0.09662166 0.09624251\n",
            "  0.09611325 0.09551828 0.094544   0.0939018 ]] [[0.13122697 0.11838867 0.09999187 0.09693875 0.09442222 0.0934737\n",
            "  0.09302619 0.09113406 0.09096654 0.090431  ]\n",
            " [0.11642858 0.11028487 0.10202178 0.09834425 0.09758889 0.09684826\n",
            "  0.09614606 0.0955855  0.09482107 0.09193079]\n",
            " [0.13121082 0.11401134 0.10236181 0.09529249 0.09509484 0.09347839\n",
            "  0.09292267 0.09219655 0.09185337 0.09157771]\n",
            " [0.11182034 0.11131455 0.10122852 0.09885452 0.09775028 0.09756619\n",
            "  0.0970481  0.09618475 0.09485637 0.09337639]\n",
            " [0.1190371  0.11268517 0.10337377 0.09892204 0.09817803 0.09598743\n",
            "  0.09449787 0.0939927  0.09308489 0.09024091]\n",
            " [0.1231669  0.11651503 0.10195184 0.09985358 0.09462189 0.09450209\n",
            "  0.0933025  0.09328135 0.09239239 0.09041242]\n",
            " [0.13613823 0.11589173 0.09990533 0.09561177 0.09451851 0.09313484\n",
            "  0.09205063 0.09152158 0.09145974 0.08976758]\n",
            " [0.1390204  0.11394679 0.10029403 0.09454747 0.09414111 0.09320738\n",
            "  0.09201896 0.09160782 0.0911697  0.09004641]\n",
            " [0.12268637 0.11812288 0.09949172 0.09598787 0.09570937 0.09495543\n",
            "  0.09386134 0.09341761 0.09317895 0.0925884 ]\n",
            " [0.11522201 0.10869771 0.10425299 0.10174679 0.09862161 0.09762945\n",
            "  0.09581748 0.09348565 0.0927586  0.09176765]] [[0.19221878 0.09784383 0.08963636 0.08957554 0.08923525 0.08854745\n",
            "  0.08842815 0.08823875 0.08822448 0.08805135]\n",
            " [0.11539409 0.10904791 0.10234714 0.10070689 0.09962562 0.09711855\n",
            "  0.09595603 0.09456613 0.09366652 0.09157109]\n",
            " [0.11589902 0.11491495 0.10738936 0.10107232 0.09720412 0.09633563\n",
            "  0.09241604 0.09182198 0.09179646 0.09115013]\n",
            " [0.11951818 0.10833368 0.10711588 0.09994849 0.09823545 0.09602655\n",
            "  0.09344209 0.09324856 0.09276845 0.09136264]\n",
            " [0.11600425 0.10421543 0.10398513 0.09926617 0.09877275 0.09778262\n",
            "  0.09739378 0.09617388 0.09505376 0.09135223]\n",
            " [0.11857469 0.10661126 0.1019878  0.09983031 0.09922573 0.09874775\n",
            "  0.09660321 0.09393042 0.09363413 0.09085469]\n",
            " [0.13629879 0.09932628 0.09855013 0.09824003 0.09734751 0.0959255\n",
            "  0.09526379 0.09510257 0.09359585 0.09034953]\n",
            " [0.1166717  0.10794695 0.10213608 0.10188431 0.10099822 0.09603059\n",
            "  0.09559518 0.09504844 0.09319708 0.09049152]\n",
            " [0.10728315 0.1037925  0.10343576 0.10218531 0.10196406 0.10056645\n",
            "  0.09859848 0.09630246 0.0945216  0.09135017]\n",
            " [0.18254873 0.09307522 0.09207456 0.09193303 0.09161045 0.09072111\n",
            "  0.0906655  0.08960212 0.08930827 0.08846102]] [[0.11651556 0.11437199 0.11160105 0.09936865 0.09705305 0.09333326\n",
            "  0.09255443 0.09213877 0.09158062 0.09148257]\n",
            " [0.11088444 0.10870033 0.10675944 0.10344209 0.10087191 0.09622392\n",
            "  0.09453411 0.09344795 0.09310738 0.09202842]\n",
            " [0.10944903 0.10575333 0.10088027 0.10072865 0.09912886 0.09830763\n",
            "  0.0975268  0.09695422 0.09693255 0.09433866]\n",
            " [0.10834975 0.10484561 0.10161021 0.10110388 0.10089392 0.0985859\n",
            "  0.09677326 0.09623311 0.09595081 0.0956535 ]\n",
            " [0.11836878 0.10995642 0.10637329 0.10316958 0.10050903 0.09407511\n",
            "  0.09224288 0.09195571 0.09188712 0.09146208]\n",
            " [0.11637533 0.107494   0.10246739 0.10176704 0.10082836 0.09627321\n",
            "  0.0941247  0.09410713 0.09370921 0.0928537 ]\n",
            " [0.17207588 0.10849798 0.09107385 0.09054288 0.09051681 0.08970771\n",
            "  0.08961482 0.0895204  0.08928338 0.08916631]\n",
            " [0.11313932 0.10984481 0.10417305 0.1018426  0.10149228 0.09582976\n",
            "  0.09468491 0.09335858 0.09303081 0.09260397]\n",
            " [0.12644607 0.10036467 0.10026442 0.09970112 0.09940325 0.0972826\n",
            "  0.09482437 0.09429312 0.09427355 0.09314673]\n",
            " [0.1405463  0.1159537  0.10057663 0.09612732 0.09178676 0.09127815\n",
            "  0.09113301 0.09111058 0.0908433  0.09064425]] [[0.10564238 0.10292613 0.10179431 0.10042136 0.09872103 0.09872036\n",
            "  0.09871954 0.09819727 0.09806671 0.09679093]\n",
            " [0.12064464 0.10207136 0.10152597 0.10133596 0.09803465 0.09705557\n",
            "  0.09630508 0.09615217 0.09468193 0.09219266]\n",
            " [0.10665165 0.10452332 0.10275489 0.10125034 0.10006174 0.09947256\n",
            "  0.09891605 0.097019   0.09581892 0.0935316 ]\n",
            " [0.11108197 0.1069545  0.10360119 0.10301835 0.09847432 0.09757042\n",
            "  0.09722493 0.0958219  0.09537969 0.09087261]\n",
            " [0.10333292 0.10259257 0.10245122 0.10149055 0.1004594  0.09958882\n",
            "  0.09949169 0.09887893 0.09800059 0.09371338]\n",
            " [0.10969684 0.10169461 0.10050323 0.09977714 0.09924264 0.0991381\n",
            "  0.09875637 0.09777958 0.09685702 0.09655443]\n",
            " [0.10171361 0.10146581 0.10124384 0.10099129 0.09960892 0.09923731\n",
            "  0.09916671 0.09902416 0.09887232 0.098676  ]\n",
            " [0.10602034 0.10511005 0.10080007 0.10076638 0.09995149 0.09937529\n",
            "  0.09768594 0.09724063 0.09691003 0.09613974]\n",
            " [0.10654233 0.10577352 0.10148946 0.10047438 0.10002071 0.0985586\n",
            "  0.09784236 0.09719845 0.0961601  0.09594019]\n",
            " [0.10370079 0.10097425 0.10082368 0.10058665 0.10050481 0.09954733\n",
            "  0.09918906 0.09886386 0.09817427 0.0976353 ]] [[0.13101614 0.10155541 0.09949803 0.09879939 0.09736524 0.09523892\n",
            "  0.09497467 0.09472965 0.0946505  0.09217209]\n",
            " [0.16043125 0.09743757 0.09690606 0.09600316 0.09286897 0.09224714\n",
            "  0.09165689 0.09157068 0.09061959 0.09025875]\n",
            " [0.12229677 0.10795741 0.09818567 0.09794795 0.09757593 0.09644455\n",
            "  0.0955545  0.09544124 0.09520435 0.09339152]\n",
            " [0.14856924 0.10204253 0.10037015 0.09949326 0.09272838 0.09220155\n",
            "  0.09164988 0.09154554 0.09090395 0.0904955 ]\n",
            " [0.13742623 0.10216511 0.10204151 0.09627024 0.0957383  0.09423456\n",
            "  0.09366982 0.09324936 0.09266366 0.09254126]\n",
            " [0.10827874 0.10729821 0.10317886 0.10045856 0.09872456 0.09777663\n",
            "  0.09749199 0.09618194 0.09610833 0.09450217]\n",
            " [0.13456634 0.10423085 0.10157086 0.09865664 0.09621219 0.09613518\n",
            "  0.09293942 0.09284518 0.09169888 0.0911445 ]\n",
            " [0.15805185 0.09799827 0.09751602 0.09492274 0.09333222 0.09234674\n",
            "  0.0920763  0.0920596  0.09175216 0.0899441 ]\n",
            " [0.15166666 0.10440575 0.09550705 0.09392787 0.0938193  0.09349321\n",
            "  0.09203372 0.0918356  0.09167873 0.09163215]\n",
            " [0.10974686 0.10353356 0.10199118 0.10157139 0.10014214 0.09902046\n",
            "  0.09866758 0.09735171 0.09568052 0.09229465]] [[0.11696494 0.10561763 0.1026743  0.10018165 0.10010299 0.09984183\n",
            "  0.09757758 0.09490325 0.09146243 0.09067347]\n",
            " [0.12616728 0.10725618 0.10489378 0.10077072 0.09898864 0.09442478\n",
            "  0.09362216 0.09245644 0.09102614 0.09039382]\n",
            " [0.12389978 0.10335313 0.1023483  0.10156903 0.10070038 0.09829431\n",
            "  0.09435275 0.09222058 0.09215761 0.09110405]\n",
            " [0.13135895 0.11509195 0.09834989 0.09702215 0.09552077 0.09462588\n",
            "  0.09443802 0.09247658 0.09081339 0.09030242]\n",
            " [0.11786105 0.10425267 0.10283441 0.10009396 0.0991247  0.098704\n",
            "  0.09789151 0.09510923 0.09314692 0.09098157]\n",
            " [0.11120586 0.11066937 0.10239101 0.1016436  0.09920651 0.09874985\n",
            "  0.09706905 0.09613745 0.0918766  0.09105068]\n",
            " [0.11243922 0.11034236 0.1020238  0.10166942 0.09871032 0.09781794\n",
            "  0.0956016  0.09512395 0.09494527 0.09132624]\n",
            " [0.11789278 0.10887911 0.1030987  0.10161806 0.09805292 0.09680559\n",
            "  0.09550236 0.09425528 0.09290124 0.09099401]\n",
            " [0.10826562 0.10599791 0.10526626 0.10162396 0.10086945 0.09868338\n",
            "  0.09792026 0.09593145 0.09358449 0.09185722]\n",
            " [0.11110785 0.10693549 0.10325618 0.10216829 0.0989797  0.09897416\n",
            "  0.09823224 0.09677328 0.09239224 0.09118057]] [[0.13062459 0.12001117 0.10074113 0.09474252 0.09386603 0.09363971\n",
            "  0.09245858 0.09179718 0.0914835  0.09063558]\n",
            " [0.10933135 0.10389441 0.10218149 0.10083347 0.0987934  0.09805172\n",
            "  0.09762    0.09760492 0.09685692 0.09483222]\n",
            " [0.11850341 0.10194103 0.10119431 0.09937377 0.09878195 0.09761009\n",
            "  0.09628828 0.09560166 0.09553706 0.09516849]\n",
            " [0.1064885  0.10433034 0.10290188 0.10156679 0.1006103  0.09858835\n",
            "  0.09808301 0.09728806 0.09667599 0.09346682]\n",
            " [0.11237273 0.10942037 0.10832172 0.0995042  0.09650969 0.0957105\n",
            "  0.09499046 0.09493661 0.09430388 0.09392986]\n",
            " [0.10560665 0.10434524 0.10314914 0.10254232 0.1011281  0.09828933\n",
            "  0.09727395 0.09697267 0.09606361 0.094629  ]\n",
            " [0.12966645 0.11357925 0.11246008 0.09314593 0.09302556 0.09259983\n",
            "  0.09171455 0.09159797 0.091246   0.09096438]\n",
            " [0.11097045 0.10328139 0.10222587 0.10110361 0.10058366 0.09976029\n",
            "  0.09791066 0.09548536 0.09508933 0.09358936]\n",
            " [0.10964395 0.10826695 0.1075901  0.10601512 0.09815793 0.0960831\n",
            "  0.09551324 0.09348555 0.09266593 0.09257816]\n",
            " [0.12031083 0.11849108 0.11690799 0.09304062 0.09284412 0.09219547\n",
            "  0.09208853 0.0916934  0.09121756 0.09121044]] [[0.13884439 0.10810776 0.09679952 0.09505253 0.0942751  0.09378396\n",
            "  0.09362106 0.0932615  0.09313487 0.09311935]\n",
            " [0.12123885 0.11415909 0.097437   0.09722511 0.09567007 0.09557963\n",
            "  0.09503611 0.09490646 0.09468962 0.09405799]\n",
            " [0.132849   0.12850621 0.09917664 0.09285689 0.0927122  0.0919118\n",
            "  0.09117553 0.0905907  0.09016381 0.09005725]\n",
            " [0.1297989  0.12024375 0.1006963  0.09401721 0.09367883 0.09252627\n",
            "  0.09244621 0.09233411 0.09221454 0.09204385]\n",
            " [0.12638246 0.12465423 0.099479   0.09614468 0.09545842 0.09220749\n",
            "  0.09193899 0.09154938 0.0913196  0.09086577]\n",
            " [0.13141826 0.12846188 0.09653927 0.09354375 0.09281931 0.09193935\n",
            "  0.09180678 0.09180298 0.09110983 0.09055864]\n",
            " [0.1273724  0.11926056 0.09824953 0.09632255 0.09553046 0.09303466\n",
            "  0.09287931 0.09279443 0.09237044 0.09218565]\n",
            " [0.12697604 0.1178524  0.10446963 0.09399208 0.09357508 0.09352376\n",
            "  0.09327863 0.09295432 0.09214232 0.0912357 ]\n",
            " [0.11518867 0.11475074 0.1059187  0.10441453 0.09405647 0.09398486\n",
            "  0.09382902 0.09279858 0.09260277 0.09245568]\n",
            " [0.15028572 0.10757346 0.09661791 0.0938767  0.09353498 0.09265015\n",
            "  0.09182073 0.09176069 0.09112944 0.09075014]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open( \"/./content/model/softmax_attention_scores_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "xhGzU2ZG_t3b",
        "outputId": "54c8137e-eff2-4565-b7b1-e1c1542b0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792055 0.09109741 0.09164357 0.09009392 0.09632883 0.09540311\n",
            "  0.107494   0.09258842 0.09229336 0.09513694]\n",
            " [0.12004586 0.10268968 0.10120098 0.09575053 0.09583508 0.09709172\n",
            "  0.10565752 0.09385469 0.09336554 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185757 0.09137529 0.09854478 0.09584679 0.0948494\n",
            "  0.09615591 0.13286738 0.09898278 0.10326968]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519613 0.09198768 0.10206269 0.10524758 0.0930215  0.09916256\n",
            "  0.09589189 0.09563526 0.09920019 0.12259457]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.09578589 0.0992849  0.10167923 0.10000082 0.09617375 0.10027704\n",
            "  0.09772886 0.09770505 0.10102018 0.11034424]\n",
            " [0.09562298 0.09995811 0.10516494 0.10018844 0.09989404 0.10063305\n",
            "  0.10060379 0.09528878 0.10368127 0.09896457]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908457 0.09758333 0.09906299 0.10445354 0.09140754 0.09558626\n",
            "  0.09211904 0.0961072  0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.10933199 0.09290536 0.09061925 0.0915818  0.1083897  0.10396454\n",
            "  0.11106926 0.09214136 0.09332465 0.10667202]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639788 0.09716938 0.10112503 0.09205169 0.09254691\n",
            "  0.09353665 0.11844435 0.09588612 0.09893835]\n",
            " [0.11324794 0.09464014 0.0913378  0.09244198 0.10467927 0.10152824\n",
            "  0.10341783 0.09349848 0.09656344 0.10864485]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.0949479  0.11661825 0.09678788 0.11136506 0.0926588  0.09223205\n",
            "  0.09243153 0.09768786 0.09655614 0.10871448]\n",
            " [0.1353592  0.0939795  0.09070874 0.09086874 0.0966881  0.0970429\n",
            "  0.10957499 0.09208083 0.09304921 0.10064787]] [[0.09431619 0.09845076 0.10366833 0.09264354 0.10065788 0.09556752\n",
            "  0.0943088  0.09483398 0.09996308 0.12558992]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113407 0.09302621 0.09096655 0.09999189 0.09347371\n",
            "  0.11838868 0.09693877 0.09442223 0.13122699]\n",
            " [0.11642858 0.09614605 0.11028486 0.09684824 0.09834424 0.09758888\n",
            "  0.10202176 0.09558548 0.09193078 0.09482107]\n",
            " [0.09292267 0.1023618  0.13121082 0.11401133 0.0915777  0.09347839\n",
            "  0.09219654 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024093 0.0939927  0.09598744 0.09817804 0.09449788 0.09892205\n",
            "  0.10337377 0.11268519 0.0930849  0.11903711]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152159 0.09205063 0.09145974 0.09561178 0.09990533\n",
            "  0.09451851 0.11589174 0.09313484 0.13613825]\n",
            " [0.09160781 0.09116969 0.09004641 0.09201896 0.09454746 0.0941411\n",
            "  0.10029402 0.11394678 0.09320737 0.13902038]\n",
            " [0.09258841 0.09495544 0.09341762 0.09949172 0.09386135 0.09570938\n",
            "  0.09598789 0.11812289 0.09317896 0.12268639]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.0904915  0.10794695 0.10099821 0.09559517 0.1166717  0.10213607\n",
            "  0.1018843  0.09319707 0.09603058 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912887 0.10944904 0.09433867 0.10088028 0.09830764 0.0975268\n",
            "  0.10072865 0.09693256 0.09695423 0.10575334]\n",
            " [0.10161023 0.09677327 0.10834976 0.10484561 0.10110389 0.09623312\n",
            "  0.0985859  0.0956535  0.09595082 0.10089393]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246737 0.10176703 0.09412469 0.10082835 0.0937092  0.09410712\n",
            "  0.0928537  0.11637531 0.0962732  0.10749398]\n",
            " [0.17207587 0.08952039 0.08916631 0.0897077  0.09107384 0.08961482\n",
            "  0.0905168  0.09054288 0.08928337 0.10849796]\n",
            " [0.1098448  0.10417304 0.0930308  0.0946849  0.09335857 0.09582975\n",
            "  0.09260397 0.10184258 0.10149226 0.11313931]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.14054629 0.09064424 0.09111057 0.0908433  0.09612731 0.09127814\n",
            "  0.10057662 0.09178675 0.091133   0.11595369]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665164 0.10275488 0.09353159 0.10125034 0.09947255 0.10006173\n",
            "  0.09701899 0.09581891 0.09891603 0.10452331]\n",
            " [0.11108198 0.09722494 0.09757043 0.09087262 0.09847433 0.10360121\n",
            "  0.09582192 0.10695451 0.0953797  0.10301836]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654232 0.1000207  0.09855858 0.09616009 0.10047437 0.09784234\n",
            "  0.09719844 0.10148945 0.09594018 0.1057735 ]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743756 0.16043124 0.09025874 0.09600315 0.09286896 0.09061958\n",
            "  0.09224714 0.09157067 0.09165689 0.09690605]\n",
            " [0.12229678 0.09520435 0.10795742 0.09818569 0.09339153 0.09644455\n",
            "  0.09794796 0.09544125 0.09757594 0.09555452]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872455 0.09450217 0.09777661 0.10317885 0.09749197 0.09618193\n",
            "  0.09610832 0.10827873 0.10045855 0.1072982 ]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.08994411 0.09333223 0.09175216 0.09207631\n",
            "  0.09234674 0.15805186 0.09799828 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077073 0.1048938  0.1072562  0.09898866 0.09102615 0.09362218\n",
            "  0.09039383 0.09442478 0.09245645 0.1261673 ]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135894 0.09834988 0.09081338 0.09247658\n",
            "  0.09030242 0.09443802 0.09552076 0.11509194]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290123 0.09680557 0.11789276 0.10161805 0.09425527 0.0980529\n",
            "  0.090994   0.10309868 0.09550235 0.1088791 ]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062458 0.09245858 0.0914835  0.09386603 0.10074112 0.09363971\n",
            "  0.12001116 0.09063558 0.09179717 0.09474251]\n",
            " [0.09483223 0.09760492 0.10083348 0.10933136 0.1021815  0.09805173\n",
            "  0.09762    0.09685693 0.10389443 0.09879342]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123886 0.11415911 0.09557965 0.09490647 0.09503613 0.09567008\n",
            "  0.09722512 0.09468964 0.09405801 0.09743701]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024376 0.09221455 0.09204386 0.12979892 0.09252628 0.09244622\n",
            "  0.09233411 0.09401721 0.09367883 0.10069631]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.0928193  0.09193934 0.09055864 0.09180677 0.09110983\n",
            "  0.09180297 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697606 0.0912357  0.09214232 0.09352377 0.09357508 0.09295433\n",
            "  0.09327864 0.1178524  0.09399209 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# 1. 정렬된 데이터와 원래 인덱스 로드\n",
        "sorted_file_path3 = \"./model/sorted_attention_scores.pkl\"\n",
        "indices_file_path3 = \"./model/original_indices.pkl\"\n",
        "restored_file_path3 = \"./model/restored_softmax.pkl\"\n",
        "\n",
        "with open(sorted_file_path3, \"rb\") as f:\n",
        "    sorted_attention_scores = pickle.load(f)\n",
        "\n",
        "with open(indices_file_path3, \"rb\") as f:\n",
        "    original_indices = pickle.load(f)\n",
        "\n",
        "# 2. 원래 순서로 복원\n",
        "restored_attention_scores = np.zeros_like(sorted_attention_scores)\n",
        "for i in range(sorted_attention_scores.shape[0]):  # 첫 번째 차원 순회\n",
        "    for j in range(sorted_attention_scores.shape[1]):  # 두 번째 차원 순회\n",
        "        for k in range(sorted_attention_scores.shape[2]):  # 세 번째 차원 순회\n",
        "            # 원래 순서로 복원\n",
        "            inverse_indices = np.argsort(original_indices[i, j, k])  # 원래 순서 찾기\n",
        "            restored_attention_scores[i, j, k] = sorted_attention_scores[i, j, k][inverse_indices]\n",
        "\n",
        "# 3. 복원된 결과를 새로운 파일에 저장\n",
        "with open(restored_file_path3, \"wb\") as f:\n",
        "    pickle.dump(restored_attention_scores, f)\n",
        "\n",
        "print(f\"복원된 softmax attention_scores가 {restored_file_path3}에 저장되었습니다!\")\n"
      ],
      "metadata": {
        "id": "MIofHJFRCG0b",
        "outputId": "ea3b115a-5c7c-49f1-89e6-6715fa22bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복원된 softmax attention_scores가 ./model/restored_softmax.pkl에 저장되었습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/restored_softmax_2.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "BIQ4u34qCk1E",
        "outputId": "b31e641a-a68a-4c58-f0ea-68cecc2a221f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14792053 0.0910974  0.09164356 0.0900939  0.09632882 0.0954031\n",
            "  0.10749399 0.09258841 0.09229334 0.09513693]\n",
            " [0.12004588 0.10268969 0.10120098 0.09575053 0.0958351  0.09709173\n",
            "  0.10565753 0.0938547  0.09336555 0.09450836]\n",
            " [0.09188308 0.11296417 0.10104739 0.13786007 0.09357624 0.09350549\n",
            "  0.09075052 0.09287033 0.09284727 0.09269542]\n",
            " [0.11074849 0.10814226 0.10393477 0.09670201 0.09913348 0.10047178\n",
            "  0.10030901 0.09443171 0.09239744 0.09372903]\n",
            " [0.09755905 0.09238588 0.09932904 0.10189565 0.09426644 0.1193184\n",
            "  0.09908514 0.09784093 0.0950703  0.10324923]\n",
            " [0.09625035 0.09185758 0.0913753  0.09854479 0.0958468  0.09484941\n",
            "  0.09615592 0.1328674  0.09898279 0.10326969]\n",
            " [0.10248473 0.0909756  0.09192704 0.0917357  0.09685351 0.10785589\n",
            "  0.09497281 0.1089671  0.09558748 0.11864013]\n",
            " [0.09724706 0.09072162 0.09059814 0.09189809 0.09440193 0.09853819\n",
            "  0.10398746 0.09612775 0.12209511 0.1143846 ]\n",
            " [0.09323013 0.09044815 0.09189644 0.09287393 0.09304722 0.0939422\n",
            "  0.09577599 0.11774409 0.09348241 0.13755944]\n",
            " [0.10347308 0.09130668 0.09073301 0.09093261 0.0952139  0.09869479\n",
            "  0.12786184 0.10249271 0.0964129  0.10287845]] [[0.09785708 0.1010711  0.09990909 0.1034065  0.09213626 0.09670063\n",
            "  0.09466569 0.1006773  0.09957507 0.11400125]\n",
            " [0.09519612 0.09198767 0.10206269 0.10524756 0.09302149 0.09916254\n",
            "  0.09589188 0.09563524 0.09920018 0.12259456]\n",
            " [0.0963392  0.09690202 0.09143765 0.09631989 0.09255879 0.09860631\n",
            "  0.0925522  0.10719077 0.10062093 0.12747219]\n",
            " [0.09505137 0.10658482 0.10008461 0.10104766 0.09871509 0.0979219\n",
            "  0.09657256 0.09733845 0.10630877 0.1003748 ]\n",
            " [0.0957859  0.09928491 0.10167924 0.10000083 0.09617376 0.10027704\n",
            "  0.09772887 0.09770507 0.10102019 0.11034425]\n",
            " [0.09562299 0.09995812 0.10516495 0.10018845 0.09989405 0.10063306\n",
            "  0.1006038  0.09528879 0.10368128 0.09896458]\n",
            " [0.0950562  0.10014401 0.09873901 0.10230775 0.09522659 0.09824028\n",
            "  0.09637209 0.1017336  0.09837577 0.11380466]\n",
            " [0.09908456 0.09758332 0.09906299 0.10445353 0.09140754 0.09558626\n",
            "  0.09211903 0.09610719 0.0978529  0.12674263]\n",
            " [0.09308667 0.10304288 0.09866013 0.10645555 0.09623402 0.09954634\n",
            "  0.097651   0.10144265 0.09808288 0.10579788]\n",
            " [0.09461471 0.1043413  0.0984853  0.10225179 0.09410094 0.09710175\n",
            "  0.09327243 0.10681042 0.09746661 0.11155472]] [[0.109332   0.09290537 0.09061927 0.09158181 0.10838971 0.10396456\n",
            "  0.11106927 0.09214137 0.09332467 0.10667203]\n",
            " [0.10829917 0.10341936 0.09385677 0.11498808 0.09313468 0.09335104\n",
            "  0.0959329  0.09627965 0.09360978 0.10712849]\n",
            " [0.10907564 0.09717342 0.0946402  0.10594706 0.09523229 0.09553417\n",
            "  0.10251999 0.09514245 0.09607369 0.1086611 ]\n",
            " [0.09547208 0.09474532 0.09392282 0.12777801 0.09541373 0.09527735\n",
            "  0.09597065 0.09463353 0.09290416 0.11388236]\n",
            " [0.11447315 0.10112287 0.09298529 0.09344386 0.09365991 0.0970234\n",
            "  0.10269815 0.09732886 0.10047487 0.10678963]\n",
            " [0.10390373 0.10639787 0.09716936 0.10112502 0.09205168 0.0925469\n",
            "  0.09353664 0.11844434 0.0958861  0.09893835]\n",
            " [0.11324795 0.09464015 0.09133781 0.09244199 0.10467929 0.10152826\n",
            "  0.10341784 0.0934985  0.09656344 0.10864487]\n",
            " [0.10199555 0.10672598 0.09804323 0.09610645 0.09338766 0.0933179\n",
            "  0.09251253 0.11619101 0.09668372 0.10503597]\n",
            " [0.09494792 0.11661826 0.09678789 0.11136508 0.09265881 0.09223206\n",
            "  0.09243154 0.09768787 0.09655615 0.10871449]\n",
            " [0.13535918 0.0939795  0.09070873 0.09086873 0.09668809 0.09704289\n",
            "  0.10957498 0.09208082 0.0930492  0.10064787]] [[0.09431619 0.09845075 0.10366833 0.09264354 0.10065787 0.09556752\n",
            "  0.09430879 0.09483397 0.09996307 0.1255899 ]\n",
            " [0.09473015 0.13242505 0.09722893 0.0965215  0.1023296  0.09363452\n",
            "  0.09290122 0.09469819 0.09453561 0.1009952 ]\n",
            " [0.0962432  0.10704175 0.10861369 0.10879505 0.0996678  0.09592903\n",
            "  0.09394309 0.09955349 0.09612511 0.09408776]\n",
            " [0.09671901 0.109509   0.09744254 0.12335853 0.09332724 0.09695764\n",
            "  0.09126032 0.09527482 0.10271551 0.09343539]\n",
            " [0.1015951  0.1042406  0.10058594 0.1051129  0.09938804 0.09961344\n",
            "  0.09613637 0.10096215 0.09867377 0.09369161]\n",
            " [0.0991762  0.11151089 0.10213321 0.10542171 0.09604911 0.09690585\n",
            "  0.09164282 0.09489696 0.10479862 0.09746461]\n",
            " [0.09728067 0.10539693 0.09495777 0.10379548 0.10073565 0.09632144\n",
            "  0.10953204 0.100105   0.09549578 0.09637927]\n",
            " [0.11535057 0.0945795  0.0975237  0.09578036 0.094757   0.10442845\n",
            "  0.09120651 0.10190308 0.11265247 0.09181842]\n",
            " [0.0948538  0.11083733 0.09435575 0.10382918 0.09829199 0.09549905\n",
            "  0.0961586  0.10423398 0.10361786 0.09832249]\n",
            " [0.09872679 0.12480727 0.1017132  0.094544   0.09611325 0.09662166\n",
            "  0.0939018  0.09551828 0.10181123 0.09624251]] [[0.090431   0.09113406 0.09302619 0.09096654 0.09999187 0.0934737\n",
            "  0.11838867 0.09693875 0.09442222 0.13122697]\n",
            " [0.11642858 0.09614606 0.11028487 0.09684826 0.09834425 0.09758889\n",
            "  0.10202178 0.0955855  0.09193079 0.09482107]\n",
            " [0.09292267 0.10236181 0.13121082 0.11401134 0.09157771 0.09347839\n",
            "  0.09219655 0.09529249 0.09509484 0.09185337]\n",
            " [0.11131455 0.09775028 0.09337639 0.0970481  0.09756619 0.09618475\n",
            "  0.10122852 0.09885452 0.09485637 0.11182034]\n",
            " [0.09024091 0.0939927  0.09598743 0.09817803 0.09449787 0.09892204\n",
            "  0.10337377 0.11268517 0.09308489 0.1190371 ]\n",
            " [0.09041242 0.0933025  0.09328135 0.10195184 0.09450209 0.09239239\n",
            "  0.09985358 0.11651503 0.09462189 0.1231669 ]\n",
            " [0.08976758 0.09152158 0.09205063 0.09145974 0.09561177 0.09990533\n",
            "  0.09451851 0.11589173 0.09313484 0.13613823]\n",
            " [0.09160782 0.0911697  0.09004641 0.09201896 0.09454747 0.09414111\n",
            "  0.10029403 0.11394679 0.09320738 0.1390204 ]\n",
            " [0.0925884  0.09495543 0.09341761 0.09949172 0.09386134 0.09570937\n",
            "  0.09598787 0.11812288 0.09317895 0.12268637]\n",
            " [0.11522201 0.0927586  0.09176765 0.09581748 0.09348565 0.09762945\n",
            "  0.10174679 0.10425299 0.09862161 0.10869771]] [[0.19221878 0.08923525 0.08822448 0.08957554 0.08805135 0.08823875\n",
            "  0.08842815 0.08854745 0.08963636 0.09784383]\n",
            " [0.09157109 0.09962562 0.09456613 0.10070689 0.09366652 0.09711855\n",
            "  0.10234714 0.10904791 0.09595603 0.11539409]\n",
            " [0.09115013 0.10107232 0.09241604 0.11589902 0.09182198 0.09720412\n",
            "  0.09179646 0.10738936 0.09633563 0.11491495]\n",
            " [0.09136264 0.11951818 0.09602655 0.10833368 0.09344209 0.09324856\n",
            "  0.09994849 0.09823545 0.09276845 0.10711588]\n",
            " [0.09135223 0.10398513 0.09778262 0.09739378 0.09505376 0.09926617\n",
            "  0.09877275 0.10421543 0.09617388 0.11600425]\n",
            " [0.09085469 0.11857469 0.09922573 0.09660321 0.09874775 0.09393042\n",
            "  0.1019878  0.09983031 0.09363413 0.10661126]\n",
            " [0.09034953 0.0959255  0.09359585 0.09510257 0.09526379 0.09932628\n",
            "  0.09824003 0.09855013 0.09734751 0.13629879]\n",
            " [0.09049152 0.10794695 0.10099822 0.09559518 0.1166717  0.10213608\n",
            "  0.10188431 0.09319708 0.09603059 0.09504844]\n",
            " [0.09135017 0.10343576 0.1037925  0.09630246 0.10218531 0.10728315\n",
            "  0.10056645 0.09859848 0.0945216  0.10196406]\n",
            " [0.08846102 0.09161045 0.08960212 0.09193303 0.08930827 0.09072111\n",
            "  0.09307522 0.09207456 0.0906655  0.18254873]] [[0.11437199 0.09213877 0.09333326 0.11160105 0.09705305 0.09255443\n",
            "  0.09936865 0.09158062 0.09148257 0.11651556]\n",
            " [0.10087191 0.10870033 0.09622392 0.10675944 0.09310738 0.09202842\n",
            "  0.09453411 0.10344209 0.09344795 0.11088444]\n",
            " [0.09912886 0.10944903 0.09433866 0.10088027 0.09830763 0.0975268\n",
            "  0.10072865 0.09693255 0.09695422 0.10575333]\n",
            " [0.10161021 0.09677326 0.10834975 0.10484561 0.10110388 0.09623311\n",
            "  0.0985859  0.0956535  0.09595081 0.10089392]\n",
            " [0.11836878 0.10050903 0.09188712 0.10637329 0.09146208 0.09224288\n",
            "  0.09195571 0.10995642 0.09407511 0.10316958]\n",
            " [0.10246739 0.10176704 0.0941247  0.10082836 0.09370921 0.09410713\n",
            "  0.0928537  0.11637533 0.09627321 0.107494  ]\n",
            " [0.17207588 0.0895204  0.08916631 0.08970771 0.09107385 0.08961482\n",
            "  0.09051681 0.09054288 0.08928338 0.10849798]\n",
            " [0.10984481 0.10417305 0.09303081 0.09468491 0.09335858 0.09582976\n",
            "  0.09260397 0.1018426  0.10149228 0.11313932]\n",
            " [0.09970112 0.10026442 0.09429312 0.0972826  0.09482437 0.09940325\n",
            "  0.09314673 0.12644607 0.09427355 0.10036467]\n",
            " [0.1405463  0.09064425 0.09111058 0.0908433  0.09612732 0.09127815\n",
            "  0.10057663 0.09178676 0.09113301 0.1159537 ]] [[0.09679093 0.10292613 0.10179431 0.09806671 0.09872036 0.10042136\n",
            "  0.09819727 0.10564238 0.09871954 0.09872103]\n",
            " [0.10133596 0.09219266 0.09615217 0.10207136 0.09803465 0.09705557\n",
            "  0.09468193 0.10152597 0.09630508 0.12064464]\n",
            " [0.10665165 0.10275489 0.0935316  0.10125034 0.09947256 0.10006174\n",
            "  0.097019   0.09581892 0.09891605 0.10452332]\n",
            " [0.11108197 0.09722493 0.09757042 0.09087261 0.09847432 0.10360119\n",
            "  0.0958219  0.1069545  0.09537969 0.10301835]\n",
            " [0.10333292 0.09800059 0.09958882 0.09371338 0.1004594  0.09949169\n",
            "  0.09887893 0.10259257 0.10149055 0.10245122]\n",
            " [0.09977714 0.10050323 0.10169461 0.09655443 0.0991381  0.09777958\n",
            "  0.09685702 0.09924264 0.09875637 0.10969684]\n",
            " [0.10099129 0.09902416 0.09960892 0.098676   0.10171361 0.09923731\n",
            "  0.10146581 0.09916671 0.10124384 0.09887232]\n",
            " [0.10511005 0.09995149 0.09937529 0.10080007 0.09724063 0.10076638\n",
            "  0.09691003 0.09613974 0.09768594 0.10602034]\n",
            " [0.10654233 0.10002071 0.0985586  0.0961601  0.10047438 0.09784236\n",
            "  0.09719845 0.10148946 0.09594019 0.10577352]\n",
            " [0.10370079 0.10082368 0.10097425 0.09918906 0.09954733 0.10058665\n",
            "  0.09817427 0.09886386 0.10050481 0.0976353 ]] [[0.09472965 0.09949803 0.09217209 0.09736524 0.09879939 0.09523892\n",
            "  0.10155541 0.0946505  0.09497467 0.13101614]\n",
            " [0.09743757 0.16043125 0.09025875 0.09600316 0.09286897 0.09061959\n",
            "  0.09224714 0.09157068 0.09165689 0.09690606]\n",
            " [0.12229677 0.09520435 0.10795741 0.09818567 0.09339152 0.09644455\n",
            "  0.09794795 0.09544124 0.09757593 0.0955545 ]\n",
            " [0.10037015 0.09949326 0.09220155 0.14856924 0.09090395 0.09164988\n",
            "  0.09272838 0.0904955  0.09154554 0.10204253]\n",
            " [0.09254126 0.09266366 0.09423456 0.09366982 0.09324936 0.10204151\n",
            "  0.0957383  0.13742623 0.10216511 0.09627024]\n",
            " [0.09872456 0.09450217 0.09777663 0.10317886 0.09749199 0.09618194\n",
            "  0.09610833 0.10827874 0.10045856 0.10729821]\n",
            " [0.0911445  0.09284518 0.09613518 0.09169888 0.09621219 0.10423085\n",
            "  0.09293942 0.13456634 0.10157086 0.09865664]\n",
            " [0.09492274 0.0920596  0.0899441  0.09333222 0.09175216 0.0920763\n",
            "  0.09234674 0.15805185 0.09799827 0.09751602]\n",
            " [0.09349321 0.0938193  0.0918356  0.09392787 0.09163215 0.09167873\n",
            "  0.09203372 0.10440575 0.15166666 0.09550705]\n",
            " [0.09568052 0.09735171 0.09229465 0.09866758 0.10014214 0.09902046\n",
            "  0.10199118 0.10974686 0.10157139 0.10353356]] [[0.09984183 0.10561763 0.10010299 0.10018165 0.09146243 0.09490325\n",
            "  0.09067347 0.09757758 0.1026743  0.11696494]\n",
            " [0.10077072 0.10489378 0.10725618 0.09898864 0.09102614 0.09362216\n",
            "  0.09039382 0.09442478 0.09245644 0.12616728]\n",
            " [0.09222058 0.10335313 0.12389978 0.10156903 0.09215761 0.09435275\n",
            "  0.09110405 0.09829431 0.10070038 0.1023483 ]\n",
            " [0.09702215 0.09462588 0.13135895 0.09834989 0.09081339 0.09247658\n",
            "  0.09030242 0.09443802 0.09552077 0.11509195]\n",
            " [0.09510923 0.09789151 0.10425267 0.098704   0.09314692 0.0991247\n",
            "  0.09098157 0.10283441 0.10009396 0.11786105]\n",
            " [0.09874985 0.09706905 0.11120586 0.09920651 0.0918766  0.09613745\n",
            "  0.09105068 0.10239101 0.1016436  0.11066937]\n",
            " [0.09512395 0.09494527 0.10166942 0.09871032 0.0956016  0.1020238\n",
            "  0.09132624 0.11243922 0.09781794 0.11034236]\n",
            " [0.09290124 0.09680559 0.11789278 0.10161806 0.09425528 0.09805292\n",
            "  0.09099401 0.1030987  0.09550236 0.10887911]\n",
            " [0.09593145 0.10086945 0.10162396 0.09868338 0.09358449 0.10826562\n",
            "  0.09185722 0.10526626 0.09792026 0.10599791]\n",
            " [0.09677328 0.09897416 0.11110785 0.10216829 0.09239224 0.09823224\n",
            "  0.09118057 0.10325618 0.0989797  0.10693549]] [[0.13062459 0.09245858 0.0914835  0.09386603 0.10074113 0.09363971\n",
            "  0.12001117 0.09063558 0.09179718 0.09474252]\n",
            " [0.09483222 0.09760492 0.10083347 0.10933135 0.10218149 0.09805172\n",
            "  0.09762    0.09685692 0.10389441 0.0987934 ]\n",
            " [0.09761009 0.09560166 0.10119431 0.10194103 0.09937377 0.09878195\n",
            "  0.09516849 0.09553706 0.09628828 0.11850341]\n",
            " [0.09667599 0.10156679 0.1006103  0.10290188 0.1064885  0.09808301\n",
            "  0.09858835 0.09728806 0.09346682 0.10433034]\n",
            " [0.11237273 0.09493661 0.09392986 0.0957105  0.10832172 0.09499046\n",
            "  0.10942037 0.0995042  0.09430388 0.09650969]\n",
            " [0.10560665 0.09727395 0.09828933 0.10254232 0.1011281  0.094629\n",
            "  0.09697267 0.10434524 0.09606361 0.10314914]\n",
            " [0.12966645 0.09096438 0.091246   0.09302556 0.11357925 0.09314593\n",
            "  0.11246008 0.09171455 0.09259983 0.09159797]\n",
            " [0.10222587 0.10328139 0.09508933 0.10058366 0.10110361 0.09976029\n",
            "  0.09358936 0.09548536 0.09791066 0.11097045]\n",
            " [0.09551324 0.10601512 0.09348555 0.09815793 0.09257816 0.0960831\n",
            "  0.09266593 0.10826695 0.1075901  0.10964395]\n",
            " [0.11690799 0.09121044 0.09121756 0.09219547 0.12031083 0.09304062\n",
            "  0.11849108 0.0916934  0.09208853 0.09284412]] [[0.10810776 0.0942751  0.09505253 0.09311935 0.09313487 0.09362106\n",
            "  0.0932615  0.09378396 0.09679952 0.13884439]\n",
            " [0.12123885 0.11415909 0.09557963 0.09490646 0.09503611 0.09567007\n",
            "  0.09722511 0.09468962 0.09405799 0.097437  ]\n",
            " [0.132849   0.09005725 0.12850621 0.09016381 0.0905907  0.0919118\n",
            "  0.09117553 0.0927122  0.09285689 0.09917664]\n",
            " [0.12024375 0.09221454 0.09204385 0.1297989  0.09252627 0.09244621\n",
            "  0.09233411 0.09401721 0.09367883 0.1006963 ]\n",
            " [0.12638246 0.09086577 0.09614468 0.0913196  0.09154938 0.09220749\n",
            "  0.09193899 0.09545842 0.099479   0.12465423]\n",
            " [0.13141826 0.09281931 0.09193935 0.09055864 0.09180678 0.09110983\n",
            "  0.09180298 0.09354375 0.09653927 0.12846188]\n",
            " [0.11926056 0.09287931 0.09632255 0.09237044 0.09279443 0.09303466\n",
            "  0.09218565 0.09553046 0.09824953 0.1273724 ]\n",
            " [0.12697604 0.0912357  0.09214232 0.09352376 0.09357508 0.09295432\n",
            "  0.09327863 0.1178524  0.09399208 0.10446963]\n",
            " [0.11475074 0.09405647 0.10441453 0.09245568 0.09279858 0.09382902\n",
            "  0.09260277 0.09398486 0.11518867 0.1059187 ]\n",
            " [0.15028572 0.09182073 0.0938767  0.09075014 0.09176069 0.09265015\n",
            "  0.09112944 0.09661791 0.09353498 0.10757346]] \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def parse_text_file(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    # 데이터 전처리: 불필요한 문자 제거 및 정리\n",
        "    data = data.replace(\"\\n\", \" \")  # 줄바꿈 제거\n",
        "    data = data.replace(\"[\", \"\").replace(\"]\", \"\")  # 대괄호 제거\n",
        "    data = data.split()  # 공백 기준으로 나눔\n",
        "\n",
        "    # 문자열을 float으로 변환\n",
        "    try:\n",
        "        data_list = [float(value) for value in data]\n",
        "        return np.array(data_list)  # numpy 배열로 변환\n",
        "    except ValueError as e:\n",
        "        print(f\"데이터 변환 중 오류 발생: {e}\")\n",
        "        raise\n",
        "\n",
        "# 두 파일의 데이터 읽기\n",
        "try:\n",
        "    restored_data = parse_text_file('./model/restored_softmax_2.txt')\n",
        "    original_data = parse_text_file('./model/attention_scores_2.txt')\n",
        "\n",
        "    # 데이터 형태 확인\n",
        "    print(f\"Restored data shape: {restored_data.shape}\")\n",
        "    print(f\"Original data shape: {original_data.shape}\")\n",
        "\n",
        "    # 데이터 값 하나하나 비교\n",
        "    if np.array_equal(restored_data, original_data):\n",
        "        print(\"두 데이터는 형태와 값이 모두 동일합니다.\")\n",
        "    else:\n",
        "        print(\"데이터에 차이가 있습니다.\")\n",
        "\n",
        "        # 값이 다를 경우, 차이를 확인\n",
        "        differences = np.where(restored_data != original_data)\n",
        "        print(f\"값이 다른 위치: {differences}\")\n",
        "        print(f\"Restored data at differences: {restored_data[differences]}\")\n",
        "        print(f\"Original data at differences: {original_data[differences]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"파일 처리 중 오류 발생: {e}\")\n"
      ],
      "metadata": {
        "id": "NqnBhDHgkSWH",
        "outputId": "5b70cbcc-752c-49ec-fba2-149541753efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored data shape: (1200,)\n",
            "Original data shape: (1200,)\n",
            "두 데이터는 형태와 값이 모두 동일합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    음수의 경우 정수부를 내림하여 변환하고, 남은 값을 소수부로 변환.\n",
        "    \"\"\"\n",
        "    max_int_value = 2**(int_bits - 1) - 1  # 7비트 최대값 (63)\n",
        "    min_int_value = -2**(int_bits - 1)     # 7비트 최소값 (-64)\n",
        "    max_frac_value = 2**frac_bits           # 13비트 정밀도 (8192)\n",
        "\n",
        "    # ✅ 정수부 조정 (floor 적용하여 내림)\n",
        "    int_part = int(np.floor(value))\n",
        "    frac_part = abs(value - int_part)\n",
        "\n",
        "    # ✅ 정수부 범위 확인\n",
        "    if int_part < min_int_value or int_part > max_int_value:\n",
        "        raise ValueError(f\"정수부 {int_part}가 {min_int_value} ~ {max_int_value} 범위를 벗어남!\")\n",
        "\n",
        "    # ✅ 2의 보수 변환 (정수부 7비트)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 앞 12비트는 항상 0 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트, 항상 양수)\n",
        "    frac_binary = format(int(round(frac_part * max_frac_value)), f'0{frac_bits}b')\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "id": "gNlyfcx-D_Mi",
        "outputId": "b8518686-a8ed-42f1-9cf9-d367777b8fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    return fixed_binary\n",
        "\n",
        "def process_txt_file(input_file, output_file):\n",
        "    \"\"\"\n",
        "    TXT 파일을 읽어서 Fixed-Point 변환 후 새로운 파일에 저장하는 함수.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    converted_data = []\n",
        "\n",
        "    for line in data:\n",
        "        line = line.strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "        try:\n",
        "            numbers = list(map(float, line.split()))  # 파일에서 숫자 읽어오기\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ 변환 오류 발생: {line}\")\n",
        "            continue\n",
        "\n",
        "        # ✅ 32비트 Fixed-Point 변환 수행\n",
        "        converted_numbers = [float_to_fixed_point(num) for num in numbers]\n",
        "        converted_data.append(\" \".join(converted_numbers))\n",
        "\n",
        "    # 결과를 출력 파일로 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"\\n\".join(converted_data))\n",
        "\n",
        "# ✅ 입력 파일과 출력 파일 경로 설정\n",
        "input_file = './model/sorted_attention_scores_2.txt'  # 원본 파일 경로\n",
        "output_file = './model/output.txt'  # 변환된 파일 저장 경로\n",
        "\n",
        "# ✅ TXT 파일 변환 실행\n",
        "process_txt_file(input_file, output_file)\n",
        "print(f\"✅ 파일이 성공적으로 변환되어 {output_file}에 저장되었습니다! 🚀\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjoyAYqcE8Rj",
        "outputId": "dc3df0de-d3f6-4394-8f74-fbdc33a322b3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 파일이 성공적으로 변환되어 ./model/output.txt에 저장되었습니다! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(\"/./content/model/output.txt\", 'r') as file:  # 파일을 읽기 모드로 열기\n",
        "        content = file.read()  # 파일의 내용을 전체 읽기\n",
        "    print(content)  # 읽은 내용 출력\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file {file_path} does not exist.\")  # 파일이 존재하지 않을 경우 에러 메시지 출력"
      ],
      "metadata": {
        "id": "y9gvMWCUC7wz",
        "outputId": "3a16bf05-17e6-4d04-a637-1e1a3ecbff30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00000000000000000001000000010110 00000000000000000000010111011111 00000000000000000000001001011100 00000000000000000000001000001101 00000000000000000000000111110110 00000000000000000000000100011000\n",
            "00000000000000000000000011111110 00000000000000000000000011000100 00000000000000000000000010010011 00000000000000000000000000111000\n",
            "00000000000000000000100100100010 00000000000000000000010100001100 00000000000000000000010000100011 00000000000000000000001110101011 00000000000000000000001001011000 00000000000000000000000111101101\n",
            "00000000000000000000000111100110 00000000000000000000000101111011 00000000000000000000000101000010 00000000000000000000000100010111\n",
            "00000000000000000000110110111111 00000000000000000000011101011111 00000000000000000000001111001110 00000000000000000000000101011001 00000000000000000000000101010011 00000000000000000000000100011011\n",
            "00000000000000000000000100011001 00000000000000000000000100001100 00000000000000000000000011000100 00000000000000000000000001011110\n",
            "00000000000000000000011010000100 00000000000000000000010111000001 00000000000000000000010001111100 00000000000000000000001101100111 00000000000000000000001101011001 00000000000000000000001011111001\n",
            "00000000000000000000001000101110 00000000000000000000000101101011 00000000000000000000000100101110 00000000000000000000000010111001\n",
            "00000000000000000000100011101101 00000000000000000000010001001100 00000000000000000000001111100000 00000000000000000000001100001111 00000000000000000000001011111011 00000000000000000000001010010011\n",
            "00000000000000000000001001111100 00000000000000000000000110101000 00000000000000000000000101100011 00000000000000000000000010111101\n",
            "00000000000000000000110001111001 00000000000000000000010001101000 00000000000000000000001100001101 00000000000000000000001011101001 00000000000000000000001000101000 00000000000000000000001000100000\n",
            "00000000000000000000001000000101 00000000000000000000000110110000 00000000000000000000000010101001 00000000000000000000000001111110\n",
            "00000000000000000000100011001001 00000000000000000000011000010000 00000000000000000000010110111100 00000000000000000000010000011010 00000000000000000000001001001011 00000000000000000000000111011111\n",
            "00000000000000000000000110101010 00000000000000000000000010011111 00000000000000000000000010001110 00000000000000000000000001001010\n",
            "00000000000000000000100110111100 00000000000000000000011110100110 00000000000000000000010010011010 00000000000000000000001011100001 00000000000000000000001001110101 00000000000000000000001000010110\n",
            "00000000000000000000000110000001 00000000000000000000000010100101 00000000000000000000000000111100 00000000000000000000000000110001\n",
            "00000000000000000000110110110010 00000000000000000000100010111000 00000000000000000000001000011100 00000000000000000000000101111110 00000000000000000000000101010110 00000000000000000000000101000000\n",
            "00000000000000000000000100110000 00000000000000000000000100100000 00000000000000000000000011001010 00000000000000000000000001000111\n",
            "00000000000000000000101100111000 00000000000000000000010001110010 00000000000000000000010001000011 00000000000000000000010000100100 00000000000000000000001011101111 00000000000000000000001000110000\n",
            "00000000000000000000000111001001 00000000000000000000000001110010 00000000000000000000000001010000 00000000000000000000000000111110 00000000000000000000011101110000 00000000000000000000010001010001 00000000000000000000001110010110 00000000000000000000001101110110 00000000000000000000001100111000 00000000000000000000001100011100\n",
            "00000000000000000000001010001110 00000000000000000000001000101100 00000000000000000000000101111110 00000000000000000000000010100000\n",
            "00000000000000000000100111010010 00000000000000000000010011110000 00000000000000000000001111110101 00000000000000000000001100001100 00000000000000000000001100001001 00000000000000000000000111110110\n",
            "00000000000000000000000111100000 00000000000000000000000110111010 00000000000000000000000011111101 00000000000000000000000010100001\n",
            "00000000000000000000101100011101 00000000000000000000010110010001 00000000000000000000001110001011 00000000000000000000001011100101 00000000000000000000001001010111 00000000000000000000001000100111\n",
            "00000000000000000000001000100101 00000000000000000000000011011111 00000000000000000000000011011110 00000000000000000000000001111011\n",
            "00000000000000000000010101000010 00000000000000000000010100101101 00000000000000000000001110001101 00000000000000000000001101010111 00000000000000000000001100111111 00000000000000000000001011001110\n",
            "00000000000000000000001010001100 00000000000000000000001001011011 00000000000000000000001000011010 00000000000000000000000110011000\n",
            "00000000000000000000011001011111 00000000000000000000001111000001 00000000000000000000001110001100 00000000000000000000001101001111 00000000000000000000001100111001 00000000000000000000001011111110\n",
            "00000000000000000000001001111101 00000000000000000000001001111011 00000000000000000000000111111001 00000000000000000000000111011000\n",
            "00000000000000000000010011010011 00000000000000000000010001011110 00000000000000000000001101101010 00000000000000000000001101100111 00000000000000000000001101000101 00000000000000000000001100110011\n",
            "00000000000000000000001100101101 00000000000000000000001011100001 00000000000000000000000111000111 00000000000000000000000110101011\n",
            "00000000000000000000011101100000 00000000000000000000001111111000 00000000000000000000001111001010 00000000000000000000001101001001 00000000000000000000001011010101 00000000000000000000001010110111\n",
            "00000000000000000000001010101100 00000000000000000000001000001110 00000000000000000000000110101100 00000000000000000000000110011110\n",
            "00000000000000000000101011101001 00000000000000000000010010111001 00000000000000000000001100001001 00000000000000000000001100000111 00000000000000000000001010100010 00000000000000000000001010001100\n",
            "00000000000000000000001000001111 00000000000000000000000111100010 00000000000000000000000010110100 00000000000000000000000001110100\n",
            "00000000000000000000010100111010 00000000000000000000010100000111 00000000000000000000010000101111 00000000000000000000001110101110 00000000000000000000001100010100 00000000000000000000001011001011\n",
            "00000000000000000000001010011011 00000000000000000000001001110110 00000000000000000000000111111111 00000000000000000000000011101110\n",
            "00000000000000000000011010111111 00000000000000000000010101011011 00000000000000000000010010011100 00000000000000000000001111110110 00000000000000000000001011000011 00000000000000000000001001101110\n",
            "00000000000000000000001001001111 00000000000000000000000101111010 00000000000000000000000101001110 00000000000000000000000100000101 00000000000000000000011010101001 00000000000000000000011000101000 00000000000000000000010111100001 00000000000000000000010101011110 00000000000000000000010010001100 00000000000000000000000100011000\n",
            "00000000000000000000000011110011 00000000000000000000000010101111 00000000000000000000000001111101 00000000000000000000000000100111\n",
            "00000000000000000000011111000001 00000000000000000000010111010110 00000000000000000000010101111101 00000000000000000000010001011100 00000000000000000000001000010010 00000000000000000000000111110101\n",
            "00000000000000000000000101000001 00000000000000000000000100101100 00000000000000000000000100010101 00000000000000000000000100000010\n",
            "00000000000000000000011000000111 00000000000000000000010111101000 00000000000000000000010100011001 00000000000000000000010000001011 00000000000000000000001001010100 00000000000000000000000111110111\n",
            "00000000000000000000000111001001 00000000000000000000000110101111 00000000000000000000000110100111 00000000000000000000000101111100\n",
            "00000000000000000000101100110110 00000000000000000000011110000111 00000000000000000000001000001101 00000000000000000000000111100011 00000000000000000000000111011110 00000000000000000000000111010010\n",
            "00000000000000000000000110100100 00000000000000000000000110011010 00000000000000000000000101011101 00000000000000000000000100000011\n",
            "00000000000000000000011110010110 00000000000000000000010101011101 00000000000000000000010000011101 00000000000000000000001110011110 00000000000000000000001101101010 00000000000000000000001001100101\n",
            "00000000000000000000001001001011 00000000000000000000000100101010 00000000000000000000000100011000 00000000000000000000000011101111\n",
            "00000000000000000000100010110100 00000000000000000000010101000101 00000000000000000000010010000011 00000000000000000000001110100101 00000000000000000000001011110010 00000000000000000000001001011110\n",
            "00000000000000000000000111110001 00000000000000000000000100100110 00000000000000000000000011001111 00000000000000000000000010100011\n",
            "00000000000000000000011101000010 00000000000000000000010111101110 00000000000000000000010010111101 00000000000000000000010001011010 00000000000000000000001111000011 00000000000000000000001000101000\n",
            "00000000000000000000000110000100 00000000000000000000000100100000 00000000000000000000000011000011 00000000000000000000000001100001\n",
            "00000000000000000000100000010100 00000000000000000000010101011100 00000000000000000000010011011001 00000000000000000000001111101001 00000000000000000000001010100101 00000000000000000000001000110010\n",
            "00000000000000000000001000000001 00000000000000000000000100010110 00000000000000000000000100010000 00000000000000000000000011001001\n",
            "00000000000000000000100000111010 00000000000000000000011011000000 00000000000000000000010111111011 00000000000000000000001010001111 00000000000000000000001001000011 00000000000000000000001000101111\n",
            "00000000000000000000000110100110 00000000000000000000000011011110 00000000000000000000000011001010 00000000000000000000000010111000\n",
            "00000000000000000000110100011110 00000000000000000000011001011011 00000000000000000000001110100011 00000000000000000000001001111000 00000000000000000000001001011010 00000000000000000000000101110010\n",
            "00000000000000000000000100100000 00000000000000000000000011001011 00000000000000000000000001011110 00000000000000000000000001010000 00000000000000000000101010011100 00000000000000000000010001111000 00000000000000000000001110000111 00000000000000000000001101001110 00000000000000000000001011010001 00000000000000000000000111011110\n",
            "00000000000000000000000110011111 00000000000000000000000101110010 00000000000000000000000101110001 00000000000000000000000011011111\n",
            "00000000000000000000110001011011 00000000000000000000010000011011 00000000000000000000001110110000 00000000000000000000001001111001 00000000000000000000001000111101 00000000000000000000000110100011\n",
            "00000000000000000000000110100001 00000000000000000000000110010010 00000000000000000000000101000100 00000000000000000000000100000100\n",
            "00000000000000000000010111110010 00000000000000000000010111100100 00000000000000000000010101101101 00000000000000000000001100100100 00000000000000000000001100011011 00000000000000000000001000000110\n",
            "00000000000000000000000111111100 00000000000000000000000111101011 00000000000000000000000101001100 00000000000000000000000101000000\n",
            "00000000000000000000101000001010 00000000000000000000011000111011 00000000000000000000010000101110 00000000000000000000001001111111 00000000000000000000001001010110 00000000000000000000001001000010\n",
            "00000000000000000000000111000110 00000000000000000000000100100111 00000000000000000000000100011101 00000000000000000000000001100110\n",
            "00000000000000000000010011001111 00000000000000000000010010001011 00000000000000000000001110111001 00000000000000000000001110000101 00000000000000000000001101100111 00000000000000000000001100010111\n",
            "00000000000000000000001100000101 00000000000000000000001011001010 00000000000000000000000111110100 00000000000000000000000100100001\n",
            "00000000000000000000011010111100 00000000000000000000010011110000 00000000000000000000010010111111 00000000000000000000001111101100 00000000000000000000001011111100 00000000000000000000001001101101\n",
            "00000000000000000000001000111110 00000000000000000000000111110101 00000000000000000000000110010010 00000000000000000000000001110101\n",
            "00000000000000000000011000100101 00000000000000000000010011101010 00000000000000000000010001101100 00000000000000000000001101110111 00000000000000000000001101000100 00000000000000000000001001011001\n",
            "00000000000000000000001000001101 00000000000000000000001000001000 00000000000000000000000111000010 00000000000000000000000110010011\n",
            "00000000000000000000011111011110 00000000000000000000011100011100 00000000000000000000010010101111 00000000000000000000001111100110 00000000000000000000001001111111 00000000000000000000000111101011\n",
            "00000000000000000000000110010011 00000000000000000000000110000100 00000000000000000000000010010001 00000000000000000000000001011010\n",
            "00000000000000000000011010001000 00000000000000000000010010010001 00000000000000000000010001110001 00000000000000000000010001100000 00000000000000000000001010110011 00000000000000000000001010110000\n",
            "00000000000000000000000111111100 00000000000000000000000111000100 00000000000000000000000110001100 00000000000000000000000101100001\n",
            "00000000000000000000101001100101 00000000000000000000001111100001 00000000000000000000001111011001 00000000000000000000001011100101 00000000000000000000001000110101 00000000000000000000001000010100\n",
            "00000000000000000000001000001001 00000000000000000000000111010110 00000000000000000000000110000010 00000000000000000000000101001011 00000000000000000000110000100011 00000000000000000000100011010111 00000000000000000000001101110000 00000000000000000000001001110010 00000000000000000000000110011011 00000000000000000000000101001000\n",
            "00000000000000000000000100100001 00000000000000000000000001111000 00000000000000000000000001101001 00000000000000000000000000111001\n",
            "00000000000000000000100000100101 00000000000000000000011001101001 00000000000000000000001111101011 00000000000000000000001010111110 00000000000000000000001001111111 00000000000000000000001001000001\n",
            "00000000000000000000001000000101 00000000000000000000000111010101 00000000000000000000000110010011 00000000000000000000000010010110\n",
            "00000000000000000000110000011011 00000000000000000000011110011100 00000000000000000000010000101001 00000000000000000000000111011111 00000000000000000000000111001110 00000000000000000000000101000001\n",
            "00000000000000000000000100010001 00000000000000000000000011010000 00000000000000000000000010110010 00000000000000000000000010011001\n",
            "00000000000000000000011011010100 00000000000000000000011010101111 00000000000000000000001110100101 00000000000000000000001011100011 00000000000000000000001010000111 00000000000000000000001001111000\n",
            "00000000000000000000001001001100 00000000000000000000001000000011 00000000000000000000000110010001 00000000000000000000000100010000\n",
            "00000000000000000000100011100100 00000000000000000000011100100010 00000000000000000000010001100000 00000000000000000000001011110111 00000000000000000000001010111010 00000000000000000000001000000001\n",
            "00000000000000000000000110000001 00000000000000000000000101010101 00000000000000000000000100000101 00000000000000000000000000000111\n",
            "00000000000000000000101000001000 00000000000000000000100001000001 00000000000000000000001111111011 00000000000000000000001101010001 00000000000000000000000110011000 00000000000000000000000110001110\n",
            "00000000000000000000000100100101 00000000000000000000000100100011 00000000000000000000000011010101 00000000000000000000000000100011\n",
            "00000000000000000000110101011000 00000000000000000000100000110001 00000000000000000000001101110001 00000000000000000000001000001001 00000000000000000000000110101011 00000000000000000000000100110010\n",
            "00000000000000000000000011010011 00000000000000000000000010100011 00000000000000000000000010011110 00000000000000000000000000000101\n",
            "00000000000000000000111000001000 00000000000000000000011110101011 00000000000000000000001110010110 00000000000000000000000110110011 00000000000000000000000110001111 00000000000000000000000100111110\n",
            "00000000000000000000000011010101 00000000000000000000000010110000 00000000000000000000000010001001 00000000000000000000000000100011\n",
            "00000000000000000000100111100110 00000000000000000000100010110000 00000000000000000000001100110010 00000000000000000000001000001100 00000000000000000000000111110100 00000000000000000000000110110011\n",
            "00000000000000000000000101010100 00000000000000000000000100101110 00000000000000000000000100011001 00000000000000000000000011100101\n",
            "00000000000000000000011111010000 00000000000000000000010111110010 00000000000000000000010010011100 00000000000000000000001111010101 00000000000000000000001011010101 00000000000000000000001010000011\n",
            "00000000000000000000000111101001 00000000000000000000000100011111 00000000000000000000000011011111 00000000000000000000000010000111 00000000000000000001100100100101 00000000000000000000001110001001 00000000000000000000000010111100 00000000000000000000000010110110 00000000000000000000000010010111 00000000000000000000000001011000\n",
            "00000000000000000000000001001101 00000000000000000000000000111011 00000000000000000000000000111010 00000000000000000000000000101010\n",
            "00000000000000000000011111011011 00000000000000000000011000001011 00000000000000000000010000000100 00000000000000000000001110000000 00000000000000000000001100100111 00000000000000000000001001010110\n",
            "00000000000000000000000111110100 00000000000000000000000101111100 00000000000000000000000100101110 00000000000000000000000001110101\n",
            "00000000000000000000100000001100 00000000000000000000011111000110 00000000000000000000010110011011 00000000000000000000001110101010 00000000000000000000001001101011 00000000000000000000001000100001\n",
            "00000000000000000000000011001101 00000000000000000000000010011000 00000000000000000000000010010110 00000000000000000000000001011100\n",
            "00000000000000000000100100000100 00000000000000000000010111011111 00000000000000000000010110000010 00000000000000000000001101001011 00000000000000000000001010111101 00000000000000000000001000000011\n",
            "00000000000000000000000100100100 00000000000000000000000100010011 00000000000000000000000011101000 00000000000000000000000001101011\n",
            "00000000000000000000100000000011 00000000000000000000010010010101 00000000000000000000010010000011 00000000000000000000001100000111 00000000000000000000001011011110 00000000000000000000001010001011\n",
            "00000000000000000000001001101011 00000000000000000000001000000011 00000000000000000000000110100011 00000000000000000000000001011110\n",
            "00000000000000000000100010111100 00000000000000000000010101010101 00000000000000000000001111101010 00000000000000000000001100111011 00000000000000000000001100001001 00000000000000000000001011100001\n",
            "00000000000000000000001000101110 00000000000000000000000101001000 00000000000000000000000100101110 00000000000000000000000000110111\n",
            "00000000000000000000110101010000 00000000000000000000001100110000 00000000000000000000001011110000 00000000000000000000001011010110 00000000000000000000001010001011 00000000000000000000001000010011\n",
            "00000000000000000000000111011010 00000000000000000000000111001100 00000000000000000000000101001001 00000000000000000000000000101000\n",
            "00000000000000000000100000110111 00000000000000000000010110111011 00000000000000000000001111110101 00000000000000000000001111100001 00000000000000000000001110011010 00000000000000000000000111111100\n",
            "00000000000000000000000111010111 00000000000000000000000110101000 00000000000000000000000100000111 00000000000000000000000000010110\n",
            "00000000000000000000010101111011 00000000000000000000010001101100 00000000000000000000010001010000 00000000000000000000001111101100 00000000000000000000001111011011 00000000000000000000001101101010\n",
            "00000000000000000000001011001000 00000000000000000000001000000111 00000000000000000000000101101110 00000000000000000000000001010110\n",
            "00000000000000000001011101001101 00000000000000000000000111000000 00000000000000000000000101100111 00000000000000000000000101011011 00000000000000000000000100111110 00000000000000000000000011101110\n",
            "00000000000000000000000011101001 00000000000000000000000010001000 00000000000000000000000001101110 00000000000000000000000000011111 00000000000000000000100000111011 00000000000000000000011110100011 00000000000000000000011011011010 00000000000000000000001100100011 00000000000000000000001001100010 00000000000000000000000100100010\n",
            "00000000000000000000000011011101 00000000000000000000000010111000 00000000000000000000000010000111 00000000000000000000000001111110\n",
            "00000000000000000000011010010011 00000000000000000000010111110000 00000000000000000000010101011101 00000000000000000000010001011010 00000000000000000000001110001100 00000000000000000000001000001010\n",
            "00000000000000000000000101111000 00000000000000000000000100011010 00000000000000000000000011111100 00000000000000000000000010011100\n",
            "00000000000000000000011000011110 00000000000000000000010100000100 00000000000000000000001110000010 00000000000000000000001101110101 00000000000000000000001011110010 00000000000000000000001010101110\n",
            "00000000000000000000001001101101 00000000000000000000001000111101 00000000000000000000001000111011 00000000000000000000000101011101\n",
            "00000000000000000000010111001010 00000000000000000000010010111101 00000000000000000000001110111100 00000000000000000000001110010011 00000000000000000000001110000010 00000000000000000000001011000100\n",
            "00000000000000000000001000101100 00000000000000000000000111111111 00000000000000000000000111100110 00000000000000000000000111001101\n",
            "00000000000000000000100010110111 00000000000000000000011001011011 00000000000000000000010101001100 00000000000000000000010001010001 00000000000000000000001101111011 00000000000000000000000101011101\n",
            "00000000000000000000000010111100 00000000000000000000000010100011 00000000000000000000000010011101 00000000000000000000000001110111\n",
            "00000000000000000000100000100001 00000000000000000000010110010110 00000000000000000000010000001110 00000000000000000000001111010110 00000000000000000000001110001010 00000000000000000000001000001111\n",
            "00000000000000000000000101010111 00000000000000000000000101010101 00000000000000000000000100110010 00000000000000000000000011100111\n",
            "00000000000000000001010101001001 00000000000000000000011010000111 00000000000000000000000011101101 00000000000000000000000010111101 00000000000000000000000010111011 00000000000000000000000001110001\n",
            "00000000000000000000000001101001 00000000000000000000000001100000 00000000000000000000000001001011 00000000000000000000000001000000\n",
            "00000000000000000000011100111001 00000000000000000000011001000111 00000000000000000000010010010101 00000000000000000000001111011100 00000000000000000000001110111111 00000000000000000000000111101001\n",
            "00000000000000000000000110000111 00000000000000000000000100010011 00000000000000000000000011110110 00000000000000000000000011010001\n",
            "00000000000000000000101011010011 00000000000000000000001101101111 00000000000000000000001101100111 00000000000000000000001100111001 00000000000000000000001100100000 00000000000000000000001001110000\n",
            "00000000000000000000000110011110 00000000000000000000000101110000 00000000000000000000000101101110 00000000000000000000000100001100\n",
            "00000000000000000000111001101011 00000000000000000000100001000011 00000000000000000000001110110110 00000000000000000000001001000011 00000000000000000000000011001001 00000000000000000000000010011011\n",
            "00000000000000000000000010001110 00000000000000000000000010001100 00000000000000000000000001110100 00000000000000000000000001100010 00000000000000000000010011110111 00000000000000000000010000100010 00000000000000000000001111000111 00000000000000000000001101011000 00000000000000000000001011001100 00000000000000000000001011001100\n",
            "00000000000000000000001011001100 00000000000000000000001010100000 00000000000000000000001010010101 00000000000000000000001000101010\n",
            "00000000000000000000100101001001 00000000000000000000001111110000 00000000000000000000001111000100 00000000000000000000001110110101 00000000000000000000001010100101 00000000000000000000001001010011\n",
            "00000000000000000000001000010011 00000000000000000000001000000110 00000000000000000000000110001000 00000000000000000000000010101110\n",
            "00000000000000000000010101001000 00000000000000000000010010100011 00000000000000000000010000010111 00000000000000000000001110011110 00000000000000000000001100111110 00000000000000000000001100001101\n",
            "00000000000000000000001011011111 00000000000000000000001001000001 00000000000000000000000111011011 00000000000000000000000100010101\n",
            "00000000000000000000011010011101 00000000000000000000010101100111 00000000000000000000010001100010 00000000000000000000010000110100 00000000000000000000001011000010 00000000000000000000001001110111\n",
            "00000000000000000000001001011001 00000000000000000000000111100010 00000000000000000000000110111101 00000000000000000000000000110000\n",
            "00000000000000000000010001000010 00000000000000000000010000000111 00000000000000000000001111111100 00000000000000000000001110101111 00000000000000000000001101011011 00000000000000000000001100010100\n",
            "00000000000000000000001100001100 00000000000000000000001011011001 00000000000000000000001010010000 00000000000000000000000100100010\n",
            "00000000000000000000011000101110 00000000000000000000001111000001 00000000000000000000001101100001 00000000000000000000001100100101 00000000000000000000001011111001 00000000000000000000001011110001\n",
            "00000000000000000000001011010001 00000000000000000000001010000000 00000000000000000000001000110010 00000000000000000000001000011000\n",
            "00000000000000000000001110111110 00000000000000000000001110101010 00000000000000000000001110011000 00000000000000000000001110000100 00000000000000000000001100010011 00000000000000000000001011110100\n",
            "00000000000000000000001011101111 00000000000000000000001011100011 00000000000000000000001011010110 00000000000000000000001011000110\n",
            "00000000000000000000010100010110 00000000000000000000010011001111 00000000000000000000001101111000 00000000000000000000001101110101 00000000000000000000001100110011 00000000000000000000001100000011\n",
            "00000000000000000000001001110111 00000000000000000000001001010001 00000000000000000000001000110110 00000000000000000000000111110100\n",
            "00000000000000000000010100111111 00000000000000000000010100000011 00000000000000000000001110110001 00000000000000000000001101011110 00000000000000000000001100111001 00000000000000000000001011000001\n",
            "00000000000000000000001010000101 00000000000000000000001001001111 00000000000000000000000111110111 00000000000000000000000111100100\n",
            "00000000000000000000010001011101 00000000000000000000001110000011 00000000000000000000001101110111 00000000000000000000001101100100 00000000000000000000001101011101 00000000000000000000001100001111\n",
            "00000000000000000000001011110001 00000000000000000000001011010110 00000000000000000000001010011101 00000000000000000000001001110000 00000000000000000000110000000000 00000000000000000000001111011001 00000000000000000000001100110010 00000000000000000000001011111000 00000000000000000000001010000000 00000000000000000000000111001011\n",
            "00000000000000000000000110110101 00000000000000000000000110011111 00000000000000000000000110011001 00000000000000000000000010111111\n",
            "00000000000000000001001011010010 00000000000000000000001011011110 00000000000000000000001010110001 00000000000000000000001001100101 00000000000000000000000101010101 00000000000000000000000100011110\n",
            "00000000000000000000000011101001 00000000000000000000000011100001 00000000000000000000000010001100 00000000000000000000000001101011\n",
            "00000000000000000000100110111101 00000000000000000000010111000000 00000000000000000000001010110110 00000000000000000000001010100011 00000000000000000000001010000011 00000000000000000000001000100100\n",
            "00000000000000000000000111011000 00000000000000000000000111001110 00000000000000000000000110111010 00000000000000000000000100011100\n",
            "00000000000000000001000000111010 00000000000000000000010000110101 00000000000000000000001110101101 00000000000000000000001101100101 00000000000000000000000100100101 00000000000000000000000011110110\n",
            "00000000000000000000000011000101 00000000000000000000000010111011 00000000000000000000000010000010 00000000000000000000000001011101\n",
            "00000000000000000000110110011000 00000000000000000000010000011100 00000000000000000000010000010010 00000000000000000000001000110101 00000000000000000000001000001000 00000000000000000000000110000110\n",
            "00000000000000000000000101010101 00000000000000000000000100110000 00000000000000000000000011111100 00000000000000000000000011110001\n",
            "00000000000000000000010111000110 00000000000000000000010101111100 00000000000000000000010000111011 00000000000000000000001101100000 00000000000000000000001011010010 00000000000000000000001010000011\n",
            "00000000000000000000001001101011 00000000000000000000000111111100 00000000000000000000000111110110 00000000000000000000000101101100\n",
            "00000000000000000000110011100111 00000000000000000000010010111011 00000000000000000000001111100111 00000000000000000000001011111001 00000000000000000000001000101011 00000000000000000000001000100101\n",
            "00000000000000000000000100010000 00000000000000000000000100000111 00000000000000000000000010100010 00000000000000000000000001110000\n",
            "00000000000000000001001001001111 00000000000000000000001100000100 00000000000000000000001011011100 00000000000000000000000111111111 00000000000000000000000101110101 00000000000000000000000100011110\n",
            "00000000000000000000000100000110 00000000000000000000000100000100 00000000000000000000000011101001 00000000000000000000000001000110\n",
            "00000000000000000001000011101011 00000000000000000000010011111000 00000000000000000000001000011110 00000000000000000000000110010110 00000000000000000000000110001100 00000000000000000000000101110000\n",
            "00000000000000000000000011101111 00000000000000000000000011011101 00000000000000000000000011001111 00000000000000000000000011001011\n",
            "00000000000000000000011000110101 00000000000000000000010001010111 00000000000000000000001111011100 00000000000000000000001110111010 00000000000000000000001101000110 00000000000000000000001011101010\n",
            "00000000000000000000001011001101 00000000000000000000001001011111 00000000000000000000000111010001 00000000000000000000000010101010 00000000000000000000100001001011 00000000000000000000010100000111 00000000000000000000010000011111 00000000000000000000001101010110 00000000000000000000001101001111 00000000000000000000001100111010\n",
            "00000000000000000000001001111110 00000000000000000000000110011011 00000000000000000000000001101100 00000000000000000000000000100101\n",
            "00000000000000000000101011001011 00000000000000000000010110011000 00000000000000000000010011100010 00000000000000000000001110011010 00000000000000000000001100000111 00000000000000000000000110000101\n",
            "00000000000000000000000100111111 00000000000000000000000011011000 00000000000000000000000001011001 00000000000000000000000000011111\n",
            "00000000000000000000101000101101 00000000000000000000010001100000 00000000000000000000010000010000 00000000000000000000001111010001 00000000000000000000001110001011 00000000000000000000001011000101\n",
            "00000000000000000000000101110110 00000000000000000000000010111010 00000000000000000000000010110101 00000000000000000000000001010111\n",
            "00000000000000000000110000100101 00000000000000000000011111101010 00000000000000000000001011100010 00000000000000000000001001110011 00000000000000000000000111110011 00000000000000000000000110100110\n",
            "00000000000000000000000110010110 00000000000000000000000011101010 00000000000000000000000001010101 00000000000000000000000000100111\n",
            "00000000000000000000100010001000 00000000000000000000010010011011 00000000000000000000010000101011 00000000000000000000001101001110 00000000000000000000001011111110 00000000000000000000001011011011\n",
            "00000000000000000000001010011000 00000000000000000000000110101011 00000000000000000000000100000001 00000000000000000000000001000000\n",
            "00000000000000000000011010101001 00000000000000000000011010000010 00000000000000000000010000000101 00000000000000000000001111001001 00000000000000000000001100000010 00000000000000000000001011011100\n",
            "00000000000000000000001001010000 00000000000000000000001000000001 00000000000000000000000010001110 00000000000000000000000001000100\n",
            "00000000000000000000011100000100 00000000000000000000011001101001 00000000000000000000001111100111 00000000000000000000001111001011 00000000000000000000001011011001 00000000000000000000001010001111\n",
            "00000000000000000000000111010011 00000000000000000000000110101010 00000000000000000000000110011010 00000000000000000000000001011100\n",
            "00000000000000000000100010001111 00000000000000000000011000000011 00000000000000000000010001000100 00000000000000000000001111001110 00000000000000000000001010101001 00000000000000000000001001000000\n",
            "00000000000000000000000111010001 00000000000000000000000101100110 00000000000000000000000011101111 00000000000000000000000001000101\n",
            "00000000000000000000010111001000 00000000000000000000010100011011 00000000000000000000010011100010 00000000000000000000001111000001 00000000000000000000001110000100 00000000000000000000001011010001\n",
            "00000000000000000000001010010001 00000000000000000000000111101001 00000000000000000000000100011110 00000000000000000000000010000110\n",
            "00000000000000000000011010011111 00000000000000000000010101100110 00000000000000000000010001000111 00000000000000000000001111110000 00000000000000000000001011101100 00000000000000000000001011101100\n",
            "00000000000000000000001010101110 00000000000000000000001000110100 00000000000000000000000010111000 00000000000000000000000001001100 00000000000000000000101111111110 00000000000000000000100101001000 00000000000000000000001110101110 00000000000000000000000110111000 00000000000000000000000101101011 00000000000000000000000101011000\n",
            "00000000000000000000000011110000 00000000000000000000000010110101 00000000000000000000000010011001 00000000000000000000000001001101\n",
            "00000000000000000000011000010100 00000000000000000000010001110010 00000000000000000000001111101010 00000000000000000000001101111101 00000000000000000000001011010110 00000000000000000000001010011000\n",
            "00000000000000000000001001110100 00000000000000000000001001110010 00000000000000000000001000110011 00000000000000000000000110000110\n",
            "00000000000000000000100010110001 00000000000000000000001111100000 00000000000000000000001110100100 00000000000000000000001100001111 00000000000000000000001011011110 00000000000000000000001001111101\n",
            "00000000000000000000001000001101 00000000000000000000000111010010 00000000000000000000000111001101 00000000000000000000000110101101\n",
            "00000000000000000000010100111011 00000000000000000000010010010100 00000000000000000000010000100011 00000000000000000000001110111000 00000000000000000000001101101010 00000000000000000000001011000100\n",
            "00000000000000000000001010011010 00000000000000000000001001010111 00000000000000000000001000100011 00000000000000000000000100001111\n",
            "00000000000000000000011100000000 00000000000000000000011000100110 00000000000000000000010111010100 00000000000000000000001100011100 00000000000000000000001000100010 00000000000000000000000111011110\n",
            "00000000000000000000000110100000 00000000000000000000000110011011 00000000000000000000000101100101 00000000000000000000000101000100\n",
            "00000000000000000000010011110111 00000000000000000000010010010100 00000000000000000000010000110110 00000000000000000000010000000110 00000000000000000000001110010100 00000000000000000000001010101011\n",
            "00000000000000000000001001010110 00000000000000000000001000111100 00000000000000000000000111101111 00000000000000000000000101110100\n",
            "00000000000000000000101111000001 00000000000000000000011110000100 00000000000000000000011100110011 00000000000000000000000100101011 00000000000000000000000100100001 00000000000000000000000011111011\n",
            "00000000000000000000000010101101 00000000000000000000000010100010 00000000000000000000000010000011 00000000000000000000000001101001\n",
            "00000000000000000000011010010000 00000000000000000000010001000100 00000000000000000000001111110000 00000000000000000000001110010110 00000000000000000000001101101011 00000000000000000000001100101000\n",
            "00000000000000000000001010001111 00000000000000000000000111000001 00000000000000000000000110011111 00000000000000000000000100011101\n",
            "00000000000000000000011000110111 00000000000000000000010111001111 00000000000000000000010110011100 00000000000000000000010100100011 00000000000000000000001010101100 00000000000000000000000111111101\n",
            "00000000000000000000000111001101 00000000000000000000000100011101 00000000000000000000000011010101 00000000000000000000000011001101\n",
            "00000000000000000000100101010110 00000000000000000000100011011010 00000000000000000000100001101011 00000000000000000000000100011101 00000000000000000000000100001100 00000000000000000000000011010010\n",
            "00000000000000000000000011001001 00000000000000000000000010100110 00000000000000000000000001111011 00000000000000000000000001111010 00000000000000000000110111110011 00000000000000000000010111110001 00000000000000000000001001101000 00000000000000000000000111010011 00000000000000000000000110010000 00000000000000000000000101100101\n",
            "00000000000000000000000101010111 00000000000000000000000100110111 00000000000000000000000100101100 00000000000000000000000100101011\n",
            "00000000000000000000100101111011 00000000000000000000011110001110 00000000000000000000001001111101 00000000000000000000001001101011 00000000000000000000000111100111 00000000000000000000000111011111\n",
            "00000000000000000000000110110000 00000000000000000000000110100101 00000000000000000000000110010010 00000000000000000000000101011100\n",
            "00000000000000000000110010100001 00000000000000000000101110010001 00000000000000000000001101000111 00000000000000000000000100101011 00000000000000000000000100011110 00000000000000000000000011010111\n",
            "00000000000000000000000010010110 00000000000000000000000001100001 00000000000000000000000000111010 00000000000000000000000000110000\n",
            "00000000000000000000101111001000 00000000000000000000100101010110 00000000000000000000001110101001 00000000000000000000000101110111 00000000000000000000000101011001 00000000000000000000000011110100\n",
            "00000000000000000000000011101101 00000000000000000000000011100011 00000000000000000000000011011000 00000000000000000000000011001001\n",
            "00000000000000000000101011101111 00000000000000000000101001111110 00000000000000000000001101000111 00000000000000000000001000101111 00000000000000000000000111110101 00000000000000000000000011011001\n",
            "00000000000000000000000011000001 00000000000000000000000010011110 00000000000000000000000010001010 00000000000000000000000001100001\n",
            "00000000000000000000110001000011 00000000000000000000101110001000 00000000000000000000001001100100 00000000000000000000000101100010 00000000000000000000000100100010 00000000000000000000000011010100\n",
            "00000000000000000000000011001000 00000000000000000000000011001000 00000000000000000000000010001010 00000000000000000000000001011000\n",
            "00000000000000000000101100100101 00000000000000000000100100001010 00000000000000000000001011010111 00000000000000000000001000110100 00000000000000000000000111110001 00000000000000000000000100011000\n",
            "00000000000000000000000100001010 00000000000000000000000100000011 00000000000000000000000011011101 00000000000000000000000011001101\n",
            "00000000000000000000101100001100 00000000000000000000100010101001 00000000000000000000010011001110 00000000000000000000000101101100 00000000000000000000000101001000 00000000000000000000000101000011\n",
            "00000000000000000000000100101110 00000000000000000000000100010001 00000000000000000000000011001001 00000000000000000000000001111000\n",
            "00000000000000000000011111010111 00000000000000000000011110111000 00000000000000000000010100101000 00000000000000000000010010110011 00000000000000000000000101011011 00000000000000000000000101010101\n",
            "00000000000000000000000101000111 00000000000000000000000011101101 00000000000000000000000011011100 00000000000000000000000011001111\n",
            "00000000000000000001000010011111 00000000000000000000010111101100 00000000000000000000001001111100 00000000000000000000000110010001 00000000000000000000000101110011 00000000000000000000000100100101\n",
            "00000000000000000000000011011011 00000000000000000000000011010110 00000000000000000000000010011101 00000000000000000000000001111011\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_from_txt(input_file, output_file):\n",
        "    # 템플릿 형식\n",
        "    template = \"Xil_Out32(XPAR_AXI_BRAM_CTRL_0_S_AXI_BASEADDR + (4 * {index}), 0b{binary_value});\"\n",
        "\n",
        "    # txt 파일 읽기 및 값 분리\n",
        "    with open(input_file, 'r') as f:\n",
        "        content = f.read()  # 파일 전체 내용을 읽음\n",
        "        binary_values = content.split()  # 스페이스와 줄바꿈을 기준으로 값을 분리\n",
        "\n",
        "    # 새로운 파일 작성\n",
        "    with open(output_file, 'w') as f:\n",
        "        for i, binary_value in enumerate(binary_values):\n",
        "            # 줄 생성\n",
        "            line = template.format(index=i + 9, binary_value=binary_value)  # index는 9부터 시작\n",
        "            f.write(line + \"\\n\")  # 줄바꿈 포함\n",
        "\n",
        "# 입력 파일과 출력 파일 경로 설정\n",
        "input_txt_file = './model/output.txt'  # 입력 파일 경로 (값들이 스페이스/줄바꿈으로 구별됨)\n",
        "output_code_file = './model/generated_code.txt'  # 생성할 코드 파일 경로\n",
        "\n",
        "# 코드 생성 함수 호출\n",
        "generate_code_from_txt(input_txt_file, output_code_file)\n",
        "print(f\"코드가 성공적으로 생성되어 {output_code_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "bBrrgb7-GxN3",
        "outputId": "9bc39fe5-49d6-4bcb-cb8f-30fa5e3e72bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코드가 성공적으로 생성되어 ./model/generated_code.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_hex_to_16bit_binary(input_file, output_file):\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일 내용 읽기 및 분리 (스페이스 및 줄바꿈 기준)\n",
        "        hex_values = f.read().split()\n",
        "\n",
        "    # 16진수 -> 16비트 2진수 변환\n",
        "    binary_values = [format(int(hex_value, 16), '016b') for hex_value in hex_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for binary_value in binary_values:\n",
        "            f.write(binary_value + \"\\n\")  # 각 값을 줄바꿈으로 저장\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/cordic_result2.txt'  # 16진수 값이 저장된 입력 파일\n",
        "output_txt_file = './model/binary_values2.txt'  # 변환된 16비트 2진수를 저장할 출력 파일https://github.com/MMujtabaRoohani/RISC-V-Processor/blob/master/PipelinedProcessor/Control_Unit.v\n",
        "# 함수 호출\n",
        "convert_hex_to_16bit_binary(input_txt_file, output_txt_file)\n",
        "print(f\"16진수 값이 16비트 2진수로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "cCw_Fb3iL9zA",
        "outputId": "500aa7a0-adb0-465e-82d6-3ce66ecd6f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16진수 값이 16비트 2진수로 변환되어 ./model/binary_values2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary_to_decimal(input_file, output_file):\n",
        "    def binary_to_decimal(binary_str):\n",
        "        # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "        int_part = int(binary_str[:3], 2)  # 정수부\n",
        "        frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "        return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 16비트 바이너리 값 읽기\n",
        "        binary_values = f.read().splitlines()\n",
        "\n",
        "    # 16비트 이진수를 10진수로 변환\n",
        "    decimal_values = [binary_to_decimal(binary) for binary in binary_values]\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for decimal in decimal_values:\n",
        "            f.write(f\"{decimal:.10f}\\n\")  # 소수점 10자리까지 출력\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/binary_values2.txt'  # 16비트 바이너리 입력 파일\n",
        "output_txt_file = './model/cordic_dec_val2.txt'  # 변환된 10진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "convert_binary_to_decimal(input_txt_file, output_txt_file)\n",
        "print(f\"16비트 바이너리 값이 10진수 소수점 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "6YmJ4ZPhM_Nb",
        "outputId": "f5b6937d-3e9f-4b03-9a42-3dd8c13cac3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16비트 바이너리 값이 10진수 소수점 값으로 변환되어 ./model/cordic_dec_val2.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_fixed_point_hex(input_file, output_file):\n",
        "    def float_to_fixed_point(value):\n",
        "        \"\"\"\n",
        "        10진수 소수를 16비트 고정소수점 표현으로 변환:\n",
        "        - 앞 3비트: 정수부 (0~7)\n",
        "        - 뒤 13비트: 소수부\n",
        "        \"\"\"\n",
        "        # 정수부: value의 정수 부분 (0~7 사이 값)\n",
        "        int_part = int(value)\n",
        "        if int_part > 7:\n",
        "            raise ValueError(f\"정수부가 3비트를 초과했습니다: {value}\")\n",
        "\n",
        "        # 소수부: value의 소수 부분을 13비트로 표현\n",
        "        frac_part = value - int_part\n",
        "        frac_binary = int(round(frac_part * (2 ** 13)))  # 소수부를 2^13로 스케일링\n",
        "\n",
        "        # 16비트 바이너리 표현\n",
        "        binary_value = f\"{int_part:03b}{frac_binary:013b}\"\n",
        "        return binary_value\n",
        "\n",
        "    def binary_to_hex(binary_str):\n",
        "        \"\"\"\n",
        "        16비트 바이너리를 16진수(hex)로 변환.\n",
        "        \"\"\"\n",
        "        return f\"0x{int(binary_str, 2):04X}\"\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        # 파일에서 10진수 소수점 값 읽기 (불필요한 문자 제거)\n",
        "        raw_data = f.read()\n",
        "        cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "        decimal_values = [float(value) for value in cleaned_data.split()]\n",
        "\n",
        "    # 10진수를 16비트 고정소수점 -> 16진수로 변환\n",
        "    hex_values = []\n",
        "    for value in decimal_values:\n",
        "        binary_value = float_to_fixed_point(value)  # 16비트 바이너리 변환\n",
        "        hex_value = binary_to_hex(binary_value)  # 16진수 변환\n",
        "        hex_values.append(hex_value)\n",
        "\n",
        "    # 결과를 새 파일에 저장\n",
        "    with open(output_file, 'w') as f:\n",
        "        for hex_value in hex_values:\n",
        "            f.write(f\"{hex_value}\\n\")\n",
        "\n",
        "# 입력 및 출력 파일 경로\n",
        "input_txt_file = './model/softmax_sorted_attention_scores_2.txt'  # 입력 파일\n",
        "output_txt_file = './model/converted_fixed_point_hex.txt'  # 변환된 16진수 값을 저장할 출력 파일\n",
        "\n",
        "# 함수 호출\n",
        "decimal_to_fixed_point_hex(input_txt_file, output_txt_file)\n",
        "print(f\"소수점 값이 16비트 16진수 값으로 변환되어 {output_txt_file}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "jaDSmkz7Rmej",
        "outputId": "1be6d348-7a2d-4fe4-b519-52be78856cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소수점 값이 16비트 16진수 값으로 변환되어 ./model/converted_fixed_point_hex.txt에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차율, 평균 오차율, 최대 오차율 및 해당 위치를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로\n",
        "    file2: 두 번째 텍스트 파일 경로\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 오차율 리스트\n",
        "    - 전체 평균 오차율\n",
        "    - 최대 오차율 및 해당 위치(인덱스)\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)\n",
        "    values2 = read_file(file2)\n",
        "\n",
        "    # 데이터 길이 확인\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 길이에 맞춰 비교\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # 1대1 오차율 계산: |값1 - 값2| / |값1| * 100\n",
        "    error_rates = np.abs(values1 - values2) / np.abs(values1) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차율 계산\n",
        "    mean_error_rate = np.mean(error_rates)\n",
        "\n",
        "    # ✅ 최대 오차율 및 해당 위치 찾기\n",
        "    max_error = np.max(error_rates)\n",
        "    max_error_index = np.argmax(error_rates)  # 최대 오차율을 가지는 인덱스\n",
        "\n",
        "    return error_rates, mean_error_rate, max_error, max_error_index\n",
        "\n",
        "# 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 첫 번째 파일\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 두 번째 파일\n",
        "\n",
        "# 함수 호출 (1200개 값 비교)\n",
        "error_rates, mean_error_rate, max_error, max_error_index = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"각 값의 오차율 (퍼센트):\\n{error_rates}\")\n",
        "print(f\"전체 평균 오차율 (퍼센트): {mean_error_rate:.6f}\")\n",
        "print(f\"최대 오차율 (퍼센트): {max_error:.6f} (위치: {max_error_index})\")\n"
      ],
      "metadata": {
        "id": "ubtP_IPwR_KR",
        "outputId": "da0acc02-3cc9-4c01-a749-de3902a3c405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 오차율 (퍼센트):\n",
            "[1.30099331 0.52132794 1.15643086 ... 0.57155869 1.26821387 1.6914753 ]\n",
            "전체 평균 오차율 (퍼센트): 0.801867\n",
            "최대 오차율 (퍼센트): 3.703725 (위치: 739)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_error_metrics(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여\n",
        "    1대1 오차 및 평균 오차를 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - 전체 평균 오차\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ 오차율 계산 (음수값 유지)\n",
        "    error_rates = (differences / np.abs(values1)) * 100\n",
        "\n",
        "    # ✅ 전체 평균 오차 계산\n",
        "    mean_error = np.mean(np.abs(differences))  # 전체 차이 평균\n",
        "\n",
        "    return differences, mean_error\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, mean_error = calculate_error_metrics(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"전체 평균 차이: {mean_error:.6f}\")\n"
      ],
      "metadata": {
        "id": "OrQuhc19gboQ",
        "outputId": "8ad31a67-9ee8-4715-f49c-70cd629d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "전체 평균 차이: 0.000800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(file1, file2):\n",
        "    \"\"\"\n",
        "    두 파일에서 데이터를 비교하여 RMSE(Root Mean Squared Error) 계산.\n",
        "\n",
        "    Args:\n",
        "    file1: 첫 번째 텍스트 파일 경로 (정확한 기준값)\n",
        "    file2: 두 번째 텍스트 파일 경로 (비교 대상)\n",
        "\n",
        "    Returns:\n",
        "    - 각 값의 차이 리스트\n",
        "    - RMSE 값\n",
        "    \"\"\"\n",
        "    # 파일에서 데이터를 읽어오기\n",
        "    def read_file(file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            raw_data = f.read()\n",
        "            # 불필요한 문자 제거 및 숫자 리스트로 변환\n",
        "            cleaned_data = raw_data.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").strip()\n",
        "            return np.array([float(value) for value in cleaned_data.split()])\n",
        "\n",
        "    # 두 파일의 데이터를 읽어오기\n",
        "    values1 = read_file(file1)  # 기준 값 (Softmax 정렬 값)\n",
        "    values2 = read_file(file2)  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "    # ✅ 두 파일에서 비교할 수 있는 최대 개수(1200개 기준)로 제한\n",
        "    num_values = min(len(values1), len(values2))  # 가장 짧은 데이터 길이에 맞춤\n",
        "    values1 = values1[:num_values]\n",
        "    values2 = values2[:num_values]\n",
        "\n",
        "    # ✅ 데이터 길이 확인 (1200개 비교)\n",
        "    if len(values1) != len(values2):\n",
        "        raise ValueError(f\"비교할 데이터 길이가 다릅니다: {len(values1)} vs {len(values2)}\")\n",
        "\n",
        "    # ✅ 오차 계산: file2_path - file1_path\n",
        "    differences = values2 - values1  # 오차 (file2 - file1)\n",
        "\n",
        "    # ✅ RMSE 계산\n",
        "    rmse = np.sqrt(np.mean(differences ** 2))  # (차이 제곱 → 평균 → 루트)\n",
        "\n",
        "    return differences, rmse\n",
        "\n",
        "# ✅ 파일 경로 설정\n",
        "file1_path = './model/softmax_sorted_attention_scores_2.txt'  # 기준 값 (Softmax 정렬 값)\n",
        "file2_path = './model/cordic_dec_val2.txt'  # 비교 대상 (CORDIC 결과 값)\n",
        "\n",
        "# ✅ 함수 호출 (1200개 값 비교)\n",
        "differences, rmse = calculate_rmse(file1_path, file2_path)\n",
        "\n",
        "# ✅ 결과 출력\n",
        "print(f\"각 값의 차이:\\n{differences}\")\n",
        "print(f\"✅ RMSE (Root Mean Squared Error): {rmse:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JGwrIV7NNw",
        "outputId": "9118d0f8-b468-41d8-d5e1-317c4db2cbd0"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 값의 차이:\n",
            "[-0.00192444 -0.0005604  -0.00111398 ...  0.00052447  0.00115572\n",
            "  0.00153502]\n",
            "✅ RMSE (Root Mean Squared Error): 0.001001\n"
          ]
        }
      ]
    }
  ]
}