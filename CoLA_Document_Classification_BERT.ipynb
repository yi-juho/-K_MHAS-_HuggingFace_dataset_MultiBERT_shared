{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21647f650e8642afaa150c4a31a9f56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2e51646d0724c6b84e4cc3047ed3e0e",
              "IPY_MODEL_1bea68bb306748c3abe9a1a7951d3cf8",
              "IPY_MODEL_4057fad4547546399720164e21c94721"
            ],
            "layout": "IPY_MODEL_ec42f719294c425ca1a8b63582a0b117"
          }
        },
        "f2e51646d0724c6b84e4cc3047ed3e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5cc5a7810248fdb02d3757e8342a47",
            "placeholder": "​",
            "style": "IPY_MODEL_d97b55b02c6349e5a75226385923daa9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1bea68bb306748c3abe9a1a7951d3cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da9a9c6d4d7e404f95c408db13f49de1",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb13b3ed78ee4fb5989a9733be32cc8c",
            "value": 48
          }
        },
        "4057fad4547546399720164e21c94721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0893228bcb3424f854491fc4582c20f",
            "placeholder": "​",
            "style": "IPY_MODEL_c249737b8f524e3885269bb49b9693f3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.11kB/s]"
          }
        },
        "ec42f719294c425ca1a8b63582a0b117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5cc5a7810248fdb02d3757e8342a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97b55b02c6349e5a75226385923daa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da9a9c6d4d7e404f95c408db13f49de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb13b3ed78ee4fb5989a9733be32cc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0893228bcb3424f854491fc4582c20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c249737b8f524e3885269bb49b9693f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9f222533264388bf7eef8e7cf8f23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_297bb25e012c4c09942f882920f8cf8b",
              "IPY_MODEL_f7e65943daac40b3825e73ed57048a2f",
              "IPY_MODEL_23da79cb7a8045a2869af10cdf206175"
            ],
            "layout": "IPY_MODEL_a3a4deffe3a64e6aa3c894badfa07e31"
          }
        },
        "297bb25e012c4c09942f882920f8cf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595e071b805b4b1b9d89feb6b57082ee",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa9d4590bb94ccdbfbdb9ad33613c43",
            "value": "vocab.txt: 100%"
          }
        },
        "f7e65943daac40b3825e73ed57048a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867f2b9ef2bb4749bd543b6949013c39",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4688741ae333403585031546f91449a4",
            "value": 231508
          }
        },
        "23da79cb7a8045a2869af10cdf206175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6f9cc78548427cac3b632bacc7058d",
            "placeholder": "​",
            "style": "IPY_MODEL_956fb7a85f2648fe95d92ae89ab7fa51",
            "value": " 232k/232k [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "a3a4deffe3a64e6aa3c894badfa07e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595e071b805b4b1b9d89feb6b57082ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa9d4590bb94ccdbfbdb9ad33613c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867f2b9ef2bb4749bd543b6949013c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4688741ae333403585031546f91449a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de6f9cc78548427cac3b632bacc7058d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956fb7a85f2648fe95d92ae89ab7fa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d71fa82b4804f888a17feb29c3da915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc22f02bba374f35bc9224c6e8043628",
              "IPY_MODEL_f88c4f08a90745e6957099c79a0ce55a",
              "IPY_MODEL_89b9427dce014ef784debe3a476afb38"
            ],
            "layout": "IPY_MODEL_b2fbcafba6d344e0ba465a7b94ac4075"
          }
        },
        "fc22f02bba374f35bc9224c6e8043628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9e647e17314008bdef689dfc806d99",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b92019c1bb4b15bdcabca6ea46fef7",
            "value": "tokenizer.json: 100%"
          }
        },
        "f88c4f08a90745e6957099c79a0ce55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64cfd6a45214e79a11d190950de1da7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b6d57e400c948efae7d8b39bbd3b1a3",
            "value": 466062
          }
        },
        "89b9427dce014ef784debe3a476afb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccacbcc6fc5d4bbd8270ebd73e1c9eaa",
            "placeholder": "​",
            "style": "IPY_MODEL_e563e154deac4398804263303a046083",
            "value": " 466k/466k [00:00&lt;00:00, 42.8MB/s]"
          }
        },
        "b2fbcafba6d344e0ba465a7b94ac4075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9e647e17314008bdef689dfc806d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b92019c1bb4b15bdcabca6ea46fef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64cfd6a45214e79a11d190950de1da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6d57e400c948efae7d8b39bbd3b1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccacbcc6fc5d4bbd8270ebd73e1c9eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e563e154deac4398804263303a046083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51466319aeb748c99a39a40240cad178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffd094ec7f5e43a9b42eca730cc10c5e",
              "IPY_MODEL_5ab71a52aa0442d09e20e2a88b73113b",
              "IPY_MODEL_ad5ea0b1b46749008d1d415156d5d38b"
            ],
            "layout": "IPY_MODEL_b4ef36bca9a649cfaa85fb4743b0a23d"
          }
        },
        "ffd094ec7f5e43a9b42eca730cc10c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ecaba034ea4aa18424ebf59caccf45",
            "placeholder": "​",
            "style": "IPY_MODEL_614278161a054032844b3b0918bac1f3",
            "value": "config.json: 100%"
          }
        },
        "5ab71a52aa0442d09e20e2a88b73113b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55db5ffe7c8143138cc1d25fce57cb9e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_229c75c52d564ecfa718ad70261a43b8",
            "value": 570
          }
        },
        "ad5ea0b1b46749008d1d415156d5d38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca9f2deb9254ab88e5efc018da79a84",
            "placeholder": "​",
            "style": "IPY_MODEL_b11d538b51c442e4af7b404b8f8a5367",
            "value": " 570/570 [00:00&lt;00:00, 74.6kB/s]"
          }
        },
        "b4ef36bca9a649cfaa85fb4743b0a23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ecaba034ea4aa18424ebf59caccf45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614278161a054032844b3b0918bac1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55db5ffe7c8143138cc1d25fce57cb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229c75c52d564ecfa718ad70261a43b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca9f2deb9254ab88e5efc018da79a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11d538b51c442e4af7b404b8f8a5367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ba5169307c45508f5847f1daeb76d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f81394a29604411a0e01e7affead432",
              "IPY_MODEL_39722a94be4f4a14af1ddaf63e6639b7",
              "IPY_MODEL_cbe94b0dd40a4ae8abf89d5e7202d506"
            ],
            "layout": "IPY_MODEL_c2fbf7998e9b44cdbdf148cef0c1ebae"
          }
        },
        "7f81394a29604411a0e01e7affead432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89c19f933d24a6c8c6ece0495078a13",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0e64e34f864657965c20c781b9eeeb",
            "value": "model.safetensors: 100%"
          }
        },
        "39722a94be4f4a14af1ddaf63e6639b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68eaac5671b64634ab7d55f728f43b99",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43435ed194974628ada06eb473fb46b2",
            "value": 440449768
          }
        },
        "cbe94b0dd40a4ae8abf89d5e7202d506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54c1c33d0fd438ab2f7274dd8a8304a",
            "placeholder": "​",
            "style": "IPY_MODEL_9726a149fcb44b0882884c346a3cdf8a",
            "value": " 440M/440M [00:01&lt;00:00, 256MB/s]"
          }
        },
        "c2fbf7998e9b44cdbdf148cef0c1ebae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89c19f933d24a6c8c6ece0495078a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0e64e34f864657965c20c781b9eeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68eaac5671b64634ab7d55f728f43b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43435ed194974628ada06eb473fb46b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f54c1c33d0fd438ab2f7274dd8a8304a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9726a149fcb44b0882884c346a3cdf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2e6ad076da4890b6c650c7857725e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19ffeab4996644f3b69c9f7a47c933af",
              "IPY_MODEL_8d1afc99a12f4814bf314250cc7aaae8",
              "IPY_MODEL_cdc021052eba4401a96c94d70213b7da"
            ],
            "layout": "IPY_MODEL_a8a26fe559fe4fa5b07809c18f5367f7"
          }
        },
        "19ffeab4996644f3b69c9f7a47c933af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ab6f4dcf7c47b3af8b2f1360acad42",
            "placeholder": "​",
            "style": "IPY_MODEL_c9985c73150041699cf8d3d55a8e41ce",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8d1afc99a12f4814bf314250cc7aaae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554f4bfc60e44e9dbc328a850db13afb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7a2347416b44350abc8c88bb8cdc18e",
            "value": 48
          }
        },
        "cdc021052eba4401a96c94d70213b7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_582dc42978ed47859ae9693579499b25",
            "placeholder": "​",
            "style": "IPY_MODEL_2ad87c39060d45478d2276ce484719c5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.84kB/s]"
          }
        },
        "a8a26fe559fe4fa5b07809c18f5367f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ab6f4dcf7c47b3af8b2f1360acad42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9985c73150041699cf8d3d55a8e41ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "554f4bfc60e44e9dbc328a850db13afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a2347416b44350abc8c88bb8cdc18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "582dc42978ed47859ae9693579499b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad87c39060d45478d2276ce484719c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c90ea080b1640eb9a20f4836bec9f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf65057bf8134c9690e362c39c09965a",
              "IPY_MODEL_72f5af19cd134f9d9974a164c91b5125",
              "IPY_MODEL_f56624ff29db4733b97b84ecb024fae1"
            ],
            "layout": "IPY_MODEL_3776b140bb21417990aaeab1afa9bf5c"
          }
        },
        "cf65057bf8134c9690e362c39c09965a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d9d7aa96b614836b98b16bb455e9117",
            "placeholder": "​",
            "style": "IPY_MODEL_4a402830b0e2489d824726181ba9951a",
            "value": "vocab.txt: 100%"
          }
        },
        "72f5af19cd134f9d9974a164c91b5125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347e5d3a6d864596bf9a47e7656a77e1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9476b97685724f61b0ed589312286084",
            "value": 231508
          }
        },
        "f56624ff29db4733b97b84ecb024fae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91630a154804e399b9a2f0668f9d754",
            "placeholder": "​",
            "style": "IPY_MODEL_952047b4b3a64ea3b47bcf946817c0b9",
            "value": " 232k/232k [00:00&lt;00:00, 22.2MB/s]"
          }
        },
        "3776b140bb21417990aaeab1afa9bf5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d9d7aa96b614836b98b16bb455e9117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a402830b0e2489d824726181ba9951a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "347e5d3a6d864596bf9a47e7656a77e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9476b97685724f61b0ed589312286084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a91630a154804e399b9a2f0668f9d754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952047b4b3a64ea3b47bcf946817c0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159521f292e647a082f4cbe8aca634c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86fb9d0142b04a63b6a22271c05ba089",
              "IPY_MODEL_27cc59f4d8474e22a3e572f1e401d26d",
              "IPY_MODEL_4539202c02814b77b0a8dd03b2acdf29"
            ],
            "layout": "IPY_MODEL_027fdc06cc46489687f5f3de7c04731d"
          }
        },
        "86fb9d0142b04a63b6a22271c05ba089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81803aca4ebd4c05b5915b09d10159ed",
            "placeholder": "​",
            "style": "IPY_MODEL_71bd9252889e4789a604a1ea18567f11",
            "value": "tokenizer.json: 100%"
          }
        },
        "27cc59f4d8474e22a3e572f1e401d26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586b604fe7cc49348e7e5734c8991088",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9dc3da122e94a7f9e31aa4e580b37f2",
            "value": 466062
          }
        },
        "4539202c02814b77b0a8dd03b2acdf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad4cc183f5642c68be992ba77690bb8",
            "placeholder": "​",
            "style": "IPY_MODEL_cb4587fe8569404fbf1c849c0b5265c6",
            "value": " 466k/466k [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "027fdc06cc46489687f5f3de7c04731d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81803aca4ebd4c05b5915b09d10159ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71bd9252889e4789a604a1ea18567f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "586b604fe7cc49348e7e5734c8991088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9dc3da122e94a7f9e31aa4e580b37f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fad4cc183f5642c68be992ba77690bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4587fe8569404fbf1c849c0b5265c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31f2b76691d4b3890be874e26f72074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05d3df7d7c6e4fc79effd41c912651d2",
              "IPY_MODEL_e1166087e0ea43c0b88dd754f1fd8cdb",
              "IPY_MODEL_73ae64ddd8ef41c9805f35e2e53f8c97"
            ],
            "layout": "IPY_MODEL_adc34631f7584078adc0946014b2c544"
          }
        },
        "05d3df7d7c6e4fc79effd41c912651d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b01e720e269148bfbcb564902e6cfcbd",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c19a551dfc44449ad28742280d5ac3",
            "value": "config.json: 100%"
          }
        },
        "e1166087e0ea43c0b88dd754f1fd8cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444eda94d0ae4bb3b74b49b1a415e228",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d85c971b26d4184a846de2cf3b27082",
            "value": 570
          }
        },
        "73ae64ddd8ef41c9805f35e2e53f8c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f45cabbc084bcda09d7b2194747b82",
            "placeholder": "​",
            "style": "IPY_MODEL_34a79d2d965948b5b26c0f04195edf21",
            "value": " 570/570 [00:00&lt;00:00, 69.9kB/s]"
          }
        },
        "adc34631f7584078adc0946014b2c544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b01e720e269148bfbcb564902e6cfcbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c19a551dfc44449ad28742280d5ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444eda94d0ae4bb3b74b49b1a415e228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d85c971b26d4184a846de2cf3b27082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f45cabbc084bcda09d7b2194747b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a79d2d965948b5b26c0f04195edf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0725c75a174cdcb9105b621dd8021a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d3af3c44f0e465dac22a1636c851d1f",
              "IPY_MODEL_0bc3eb2ba77b48998ad0085d93a268f9",
              "IPY_MODEL_e567f86373344169b97e8f5c7fe85d67"
            ],
            "layout": "IPY_MODEL_f32f48795b2243feb0a6eb088ae05cb4"
          }
        },
        "1d3af3c44f0e465dac22a1636c851d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f23edbc30174a0b853fe381d0132ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_75920eeb27314dedbf2cfd9359949cdf",
            "value": "README.md: 100%"
          }
        },
        "0bc3eb2ba77b48998ad0085d93a268f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ea84e6e2694e46a40e0af53386dc41",
            "max": 35296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bff5a431b6424f38acd2acf715f6e04a",
            "value": 35296
          }
        },
        "e567f86373344169b97e8f5c7fe85d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1cbd83b628452097cdc8676291af38",
            "placeholder": "​",
            "style": "IPY_MODEL_f1df9f7a30664458bde5a5161728c1bc",
            "value": " 35.3k/35.3k [00:00&lt;00:00, 4.08MB/s]"
          }
        },
        "f32f48795b2243feb0a6eb088ae05cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f23edbc30174a0b853fe381d0132ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75920eeb27314dedbf2cfd9359949cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47ea84e6e2694e46a40e0af53386dc41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff5a431b6424f38acd2acf715f6e04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d1cbd83b628452097cdc8676291af38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1df9f7a30664458bde5a5161728c1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5817f83cd3a4ff1ad5060de4f2a78a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73b53f037b80484f9b43d01b3040ea98",
              "IPY_MODEL_a0a1e77a1f1a4f3c808fdb44a6a4fcf1",
              "IPY_MODEL_982ae8572b6e4d34b428fb0512432691"
            ],
            "layout": "IPY_MODEL_17c2f0fe362b46e9b6b93c00a9cced20"
          }
        },
        "73b53f037b80484f9b43d01b3040ea98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2432b508700c4149a9ecf0d9447715dc",
            "placeholder": "​",
            "style": "IPY_MODEL_baf6f259c4a24eb6949bf59ab86dda1f",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "a0a1e77a1f1a4f3c808fdb44a6a4fcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32afee2832ab44b98983e4d27bcc7f1a",
            "max": 3110468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8159e540caaa4397a03be4c5d8275b59",
            "value": 3110468
          }
        },
        "982ae8572b6e4d34b428fb0512432691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0918295773842119971247aefdc0c32",
            "placeholder": "​",
            "style": "IPY_MODEL_473b0752c2b14c0caf19ca7aa79cf414",
            "value": " 3.11M/3.11M [00:00&lt;00:00, 138MB/s]"
          }
        },
        "17c2f0fe362b46e9b6b93c00a9cced20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2432b508700c4149a9ecf0d9447715dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf6f259c4a24eb6949bf59ab86dda1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32afee2832ab44b98983e4d27bcc7f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8159e540caaa4397a03be4c5d8275b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0918295773842119971247aefdc0c32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473b0752c2b14c0caf19ca7aa79cf414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aec7445e2094675b2c22257a3bf059b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56fe9a6d3f9e4cf7acd9fb4b06808937",
              "IPY_MODEL_3390b88cb84c4578a89234bb2b6dfe1a",
              "IPY_MODEL_d0037ee21ed44a6a9e4f95a655d288da"
            ],
            "layout": "IPY_MODEL_db173055bc954fe5a657e699172c0c8f"
          }
        },
        "56fe9a6d3f9e4cf7acd9fb4b06808937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f83f81d70d14cf294b1adef7a778dee",
            "placeholder": "​",
            "style": "IPY_MODEL_39f565d9f0134ac08068d548c521e706",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "3390b88cb84c4578a89234bb2b6dfe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_953d7ac7ec6f4c89a34be7f8e2261099",
            "max": 72819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4036f1b2f82b40ee86d2a51ad5ad31db",
            "value": 72819
          }
        },
        "d0037ee21ed44a6a9e4f95a655d288da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8bec5f556740c8ba733e38178ea615",
            "placeholder": "​",
            "style": "IPY_MODEL_874f0fe4a83f4d9cbe6f4143466a6765",
            "value": " 72.8k/72.8k [00:00&lt;00:00, 8.46MB/s]"
          }
        },
        "db173055bc954fe5a657e699172c0c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f83f81d70d14cf294b1adef7a778dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f565d9f0134ac08068d548c521e706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "953d7ac7ec6f4c89a34be7f8e2261099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4036f1b2f82b40ee86d2a51ad5ad31db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b8bec5f556740c8ba733e38178ea615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874f0fe4a83f4d9cbe6f4143466a6765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed6d8a5673ac408ba61862c9ca643d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2bf3bd05abd4f8c9ab391ee3f368c02",
              "IPY_MODEL_28285800ae7c4d7baa9b99cf0429ab5b",
              "IPY_MODEL_f33c6e30c69a4a52b1bfb6379b789d3d"
            ],
            "layout": "IPY_MODEL_f65ef88562de4fb8839c5262bb25fde0"
          }
        },
        "d2bf3bd05abd4f8c9ab391ee3f368c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e92af041414a66a8619cbe36956736",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb22d34b37143748d418337aafcfe72",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "28285800ae7c4d7baa9b99cf0429ab5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab26b138bd334596931de39b0e797336",
            "max": 147793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42ae0eb4ea8c4a3585f495fa10e1db09",
            "value": 147793
          }
        },
        "f33c6e30c69a4a52b1bfb6379b789d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccadea40a2c74070aadafbfdfd06e063",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d74ab506c640f9af6ab957bae85117",
            "value": " 148k/148k [00:00&lt;00:00, 16.6MB/s]"
          }
        },
        "f65ef88562de4fb8839c5262bb25fde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e92af041414a66a8619cbe36956736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb22d34b37143748d418337aafcfe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab26b138bd334596931de39b0e797336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ae0eb4ea8c4a3585f495fa10e1db09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccadea40a2c74070aadafbfdfd06e063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d74ab506c640f9af6ab957bae85117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8044d14bd2c43eea429f995e9899774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcdaed45afc74d5b825510140b594b91",
              "IPY_MODEL_f768228fc5024f6c813e86e82f3a3705",
              "IPY_MODEL_20ba488f7e0a466c8414904bb4702253"
            ],
            "layout": "IPY_MODEL_4a8e069016d2495a861296813cf418f4"
          }
        },
        "fcdaed45afc74d5b825510140b594b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c859f30bd1b49da8e52812e00aec443",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff1f47124f2468f99df5f4fe4b03960",
            "value": "Generating train split: 100%"
          }
        },
        "f768228fc5024f6c813e86e82f3a3705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0098582d9bc94b0e91e4faef023392fb",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baab82f0c48e460da69de86f9098c25d",
            "value": 67349
          }
        },
        "20ba488f7e0a466c8414904bb4702253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a4b789ff5a44859b60048d7d7aa2a00",
            "placeholder": "​",
            "style": "IPY_MODEL_dd600a12ae594dc7a7e068eb5f02c649",
            "value": " 67349/67349 [00:00&lt;00:00, 879614.94 examples/s]"
          }
        },
        "4a8e069016d2495a861296813cf418f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c859f30bd1b49da8e52812e00aec443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff1f47124f2468f99df5f4fe4b03960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0098582d9bc94b0e91e4faef023392fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baab82f0c48e460da69de86f9098c25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a4b789ff5a44859b60048d7d7aa2a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd600a12ae594dc7a7e068eb5f02c649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfaf6e447e434bbeb38176c8a7cace32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f3d606dd41045718d5bb62bf82130b4",
              "IPY_MODEL_12f484d91145409b8a04b3843a6f0126",
              "IPY_MODEL_9760b37e6cd546babac5d4e7439f320b"
            ],
            "layout": "IPY_MODEL_d113ef1e4aaa4175b4c55fec44acef49"
          }
        },
        "9f3d606dd41045718d5bb62bf82130b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddbf67699f384346b8051d12395e665a",
            "placeholder": "​",
            "style": "IPY_MODEL_86c787254b4742ae910181bf05daca82",
            "value": "Generating validation split: 100%"
          }
        },
        "12f484d91145409b8a04b3843a6f0126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517ad4f0b73149ba9632e967889db768",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89cff491c21c494287df03883ab2d05a",
            "value": 872
          }
        },
        "9760b37e6cd546babac5d4e7439f320b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc8154060ea472aa682a77308a2b537",
            "placeholder": "​",
            "style": "IPY_MODEL_5211949776a84a639150b2c4992decba",
            "value": " 872/872 [00:00&lt;00:00, 71675.02 examples/s]"
          }
        },
        "d113ef1e4aaa4175b4c55fec44acef49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbf67699f384346b8051d12395e665a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c787254b4742ae910181bf05daca82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "517ad4f0b73149ba9632e967889db768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89cff491c21c494287df03883ab2d05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fc8154060ea472aa682a77308a2b537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5211949776a84a639150b2c4992decba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "669ba151a72f444eb09ceb59d422a07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8104f7eeb70d416c891ae7dcc8bd2a2e",
              "IPY_MODEL_dcc51e2ec4144ce8b646aeb67b415115",
              "IPY_MODEL_1e0a84a482bc44789a2ce788477d3124"
            ],
            "layout": "IPY_MODEL_3a514567c1c243fcb38ac37eba3f0644"
          }
        },
        "8104f7eeb70d416c891ae7dcc8bd2a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270421cab3104900b3978b839aacc680",
            "placeholder": "​",
            "style": "IPY_MODEL_7f30693ea39b44deb857480044c22321",
            "value": "Generating test split: 100%"
          }
        },
        "dcc51e2ec4144ce8b646aeb67b415115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea255922c77c4f7aaf057e953938111c",
            "max": 1821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0736bd135d624d64a3f76d0570d311c5",
            "value": 1821
          }
        },
        "1e0a84a482bc44789a2ce788477d3124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6024844f9e8b412cb21a9bceb200e6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_b045ee4b9e2a45b2b8603b1ac50f86ff",
            "value": " 1821/1821 [00:00&lt;00:00, 147317.59 examples/s]"
          }
        },
        "3a514567c1c243fcb38ac37eba3f0644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270421cab3104900b3978b839aacc680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f30693ea39b44deb857480044c22321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea255922c77c4f7aaf057e953938111c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0736bd135d624d64a3f76d0570d311c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6024844f9e8b412cb21a9bceb200e6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b045ee4b9e2a45b2b8603b1ac50f86ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1168caceab643aeb6b8816a27ca8244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16da427ff681433fb077081f890b7089",
              "IPY_MODEL_a99f03b1e2be4325804a357039435e6a",
              "IPY_MODEL_5371a45778994b4a825017787aa89a3d"
            ],
            "layout": "IPY_MODEL_b07d2337b7664253959ff9ea768f0d16"
          }
        },
        "16da427ff681433fb077081f890b7089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b35013521b48759fb8c8e18ea2ae72",
            "placeholder": "​",
            "style": "IPY_MODEL_f8e22bc86a3541839712e9bb59228ed9",
            "value": "model.safetensors: 100%"
          }
        },
        "a99f03b1e2be4325804a357039435e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa5554d67eb40feaa549394c830ef95",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f39c132a7c1141079ae838605a01d0eb",
            "value": 440449768
          }
        },
        "5371a45778994b4a825017787aa89a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15153ca406f74fa78d76cf9a34faab5f",
            "placeholder": "​",
            "style": "IPY_MODEL_dc90848a125d4e66a30ad0e71c6112bd",
            "value": " 440M/440M [00:01&lt;00:00, 339MB/s]"
          }
        },
        "b07d2337b7664253959ff9ea768f0d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b35013521b48759fb8c8e18ea2ae72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e22bc86a3541839712e9bb59228ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fa5554d67eb40feaa549394c830ef95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f39c132a7c1141079ae838605a01d0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15153ca406f74fa78d76cf9a34faab5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc90848a125d4e66a30ad0e71c6112bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c247134ebd8b4087be8906b1a113645e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10e4e0df17244c0890623da94c6c2d28",
              "IPY_MODEL_baaa36739ced47c18b55a4a0485284f7",
              "IPY_MODEL_58ec4fefccc04c0cb893226f7557d304"
            ],
            "layout": "IPY_MODEL_5433d77215b7439bb0ad31b82eff7da3"
          }
        },
        "10e4e0df17244c0890623da94c6c2d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005248a8a1984ced9d2bda47760bfdba",
            "placeholder": "​",
            "style": "IPY_MODEL_2cdf1771553e40b089c5b3ab9944eeae",
            "value": "Map: 100%"
          }
        },
        "baaa36739ced47c18b55a4a0485284f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_251a141e8e5a484fb0da25c706d24183",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddabd03e49954f8389da2d4826468fb1",
            "value": 872
          }
        },
        "58ec4fefccc04c0cb893226f7557d304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b473f1b04f57489a8f6441f5089043b7",
            "placeholder": "​",
            "style": "IPY_MODEL_2462422285e14563a676c0b43e8c74a1",
            "value": " 872/872 [00:00&lt;00:00, 9625.58 examples/s]"
          }
        },
        "5433d77215b7439bb0ad31b82eff7da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "005248a8a1984ced9d2bda47760bfdba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cdf1771553e40b089c5b3ab9944eeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251a141e8e5a484fb0da25c706d24183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddabd03e49954f8389da2d4826468fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b473f1b04f57489a8f6441f5089043b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2462422285e14563a676c0b43e8c74a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bcfe257ad8a46d0a6ba4bbb4a67e91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64a434022a614a8da6fd19d1d59ef55b",
              "IPY_MODEL_b3c3011bc9b540e78ec0e9d67e3f1eb3",
              "IPY_MODEL_8c3466c637d449aab43a921e21b2e19d"
            ],
            "layout": "IPY_MODEL_78796feccd1b48c4987e5a72b6615318"
          }
        },
        "64a434022a614a8da6fd19d1d59ef55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71717822f528491b9d052cb58278febc",
            "placeholder": "​",
            "style": "IPY_MODEL_87375f6f5c1e44e985cfa68bbb4069eb",
            "value": "Map: 100%"
          }
        },
        "b3c3011bc9b540e78ec0e9d67e3f1eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c241c9423e7e4446afd98f38d293f764",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97eb5b3f258b46fda3678aca83699a79",
            "value": 67349
          }
        },
        "8c3466c637d449aab43a921e21b2e19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9020c66142f48f79bdb46bf2210deff",
            "placeholder": "​",
            "style": "IPY_MODEL_1b3c68dc12034f73ac6e23127635b2a3",
            "value": " 67349/67349 [00:06&lt;00:00, 11256.79 examples/s]"
          }
        },
        "78796feccd1b48c4987e5a72b6615318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71717822f528491b9d052cb58278febc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87375f6f5c1e44e985cfa68bbb4069eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c241c9423e7e4446afd98f38d293f764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97eb5b3f258b46fda3678aca83699a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9020c66142f48f79bdb46bf2210deff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3c68dc12034f73ac6e23127635b2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification BERT [CoLA]\n",
        "\n",
        "*   항목 추가\n",
        "*   항목 추가\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SGcOaw5P769d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "Pg-qog2IyzCc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic"
      ],
      "metadata": {
        "id": "x6iTkvfbQ6Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores, dim=-1):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    \"\"\"\n",
        "    chunk_size = len(attention_scores) // dim\n",
        "    data_list = [attention_scores[i * chunk_size:(i + 1) * chunk_size] for i in range(120)]\n",
        "\n",
        "    # 120개의 결과 리스트 생성\n",
        "    result_arrays = []\n",
        "\n",
        "    # 각 10개씩 top 함수에 전달\n",
        "    for i in range(120):\n",
        "        result = top(*data_list[i])  # 리스트를 개별 인자로 풀어서 전달\n",
        "        result_arrays.append(result)  # 결과 저장\n",
        "\n",
        "    return result_arrays\n",
        "\n",
        "\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    fixed_binary_int = int(fixed_binary, 2)\n",
        "    lower_20_bits = fixed_binary_int & 0xFFFFF\n",
        "    return lower_20_bits\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "        #print(int_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "   #return int_values\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "\n",
        "    # 7비트 마스크\n",
        "    mask = (1 << 7) - 1  # 0b1111111\n",
        "\n",
        "    # 1) 각 값 → signed int\n",
        "    for i in range(10):\n",
        "        # 순수 이진문자열 생성\n",
        "        binary_str      = format(data_list[i] & mask, '07b')\n",
        "        data_to_int[i]  = signed_binary_to_int(binary_str)\n",
        "\n",
        "    # 2) offset 계산 (0b0001011 = 11)\n",
        "    i_max      = max(data_to_int)\n",
        "    offset_val = 0b0001011 - i_max           # 정수 차 계산\n",
        "    # 마찬가지로 format + mask 로 2진문자열\n",
        "    binary_off = format(offset_val & mask, '07b')\n",
        "    offset     = signed_binary_to_int(binary_off)\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    # 이진수의 길이\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 방법으로 음수 변환\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수는 그냥 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "        #print(hex(exp_fraction[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "'''\n",
        "top(\n",
        "    0b00000011000110001110,  # 첫 번째 data_in 값\n",
        "    0b00000100010011110000,  # 두 번째 data_in 값\n",
        "    0b00000000010011111010,  # 세 번째 data_in 값\n",
        "    0b00000010101101111100,  # 네 번째 data_in 값\n",
        "    0b00000111000110011000,  # 다섯 번째 data_in 값\n",
        "    0b00000100010100001101,  # 여섯 번째 data_in 값\n",
        "    0b11111100110100100011,  # 일곱 번째 data_in 값\n",
        "    0b11111111100000001011,  # 여덟 번째 data_in 값\n",
        "    0b00000011010101100100,  # 아홉 번째 data_in 값\n",
        "    0b11111010100111110111   # 열 번째 data_in 값\n",
        ")\n",
        "'''\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ✅ 기존 Softmax -> Sigmoid Normalization 적용\n",
        "        attention_probs = top(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "HM1AXhHcQ04X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구조 적용,, 재시작"
      ],
      "metadata": {
        "id": "eA7KlC3ftQ-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) Query/Key/Value 계산 (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) Attention score 계산 & scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ---------------------------------------------------\n",
        "        # 3) CORDIC-Softmax: top()을 120번 자동 호출\n",
        "        #    attention_scores.shape == [B, H, L, L] with L=10\n",
        "        # ---------------------------------------------------\n",
        "        B, H, L, _ = attention_scores.size()             # B=1, H=12, L=10\n",
        "        flat = attention_scores.view(-1, L)              # shape = [B*H, 10]\n",
        "        rows = []\n",
        "        for row in flat:                                 # 자동으로 1*12 = 12 행 × 10 쿼리 = 120 호출\n",
        "            # row.tolist() → Python float 리스트 길이 10\n",
        "            top_out = top(*row.tolist())                 # 여러분의 top(data1…data10)\n",
        "            # 다시 tensor 로 만들 때, dtype/device 일치시키기\n",
        "            rows.append(torch.tensor(\n",
        "                top_out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows)              # shape = [B*H, 10]\n",
        "        attention_probs = attention_probs.view(B, H, L, L)\n",
        "        # ---------------------------------------------------\n",
        "\n",
        "        # 4) Dropout & Context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "zfSHmJVQtUqh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. 1,12,10,10\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            #row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "        # ─────────────────────────────────────────────\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "JxoOuCl6wyU6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    # Modified 모듈 생성\n",
        "    mod = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 로드\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n"
      ],
      "metadata": {
        "id": "peAPhZdDvZzN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "# → BertForSequenceClassificationCordic 이어야 함\n",
        "\n",
        "# 2) forward 메서드가 서브클래스에서 정의된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "# → BertForSequenceClassificationCordic.forward 여야 함\n",
        "\n",
        "# 3) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)"
      ],
      "metadata": {
        "id": "huL4Du0TtzwD",
        "outputId": "25e420aa-ecad-4715-c22f-825e2b431b82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 마지막 레이어 확률만 꺼내기\n",
        "all_attentions = outputs.attentions    # tuple of length 12, each is [B, H, L, L]\n",
        "attention_probs = all_attentions[-1]   # 마지막 레이어의 [B, H, L, L] 텐서\n",
        "\n",
        "# 3) 마지막 축(키 방향)으로 합이 1인지 확인\n",
        "sums = attention_probs.sum(dim=-1)     # shape = [B, H, L]\n",
        "print(\"어텐션 확률 합:\", sums)\n"
      ],
      "metadata": {
        "id": "m2Fs1SMmxKoy",
        "outputId": "15f5a9b8-6e07-49cc-9103-f5777675c42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어텐션 확률 합: tensor([[[0.9990, 0.9897, 0.9912, 0.9973, 0.9907, 0.9900, 0.9814, 0.9922,\n",
            "          0.9905, 0.9912],\n",
            "         [0.9980, 0.9878, 0.9729, 0.9846, 0.9734, 0.9851, 0.9924, 0.9775,\n",
            "          0.9900, 0.9971],\n",
            "         [1.0000, 0.9961, 0.9966, 0.9905, 0.9985, 0.9963, 0.9976, 0.9827,\n",
            "          1.0007, 0.9995],\n",
            "         [0.9966, 0.9888, 0.9866, 0.9902, 0.9912, 0.9868, 0.9922, 0.9922,\n",
            "          0.9829, 1.0005],\n",
            "         [0.9978, 0.9958, 0.9927, 0.9919, 0.9895, 0.9971, 0.9829, 0.9829,\n",
            "          0.9905, 0.9907],\n",
            "         [0.9966, 0.9976, 0.9963, 0.9985, 0.9883, 0.9927, 0.9988, 0.9773,\n",
            "          0.9963, 0.9968],\n",
            "         [0.9980, 0.9922, 0.9905, 0.9939, 0.9978, 0.9958, 0.9890, 0.9861,\n",
            "          0.9988, 0.9902],\n",
            "         [0.9895, 0.9753, 0.9871, 0.9949, 0.9871, 0.9832, 0.9910, 0.9910,\n",
            "          0.9978, 0.9951],\n",
            "         [0.9927, 0.9980, 0.9929, 0.9980, 0.9973, 1.0042, 0.9973, 0.9893,\n",
            "          1.0012, 0.9998],\n",
            "         [0.9980, 1.0005, 0.9968, 0.9961, 0.9973, 0.9932, 0.9905, 0.9871,\n",
            "          0.9976, 0.9971],\n",
            "         [0.9990, 0.9927, 0.9956, 0.9980, 0.9861, 0.9885, 0.9761, 0.9871,\n",
            "          0.9951, 0.9976],\n",
            "         [0.9866, 0.9941, 0.9829, 0.9890, 0.9905, 0.9827, 0.9946, 0.9900,\n",
            "          0.9888, 0.9851]],\n",
            "\n",
            "        [[0.9990, 0.9983, 0.9968, 0.9990, 0.9973, 0.9983, 0.9993, 0.9976,\n",
            "          0.9976, 0.9983],\n",
            "         [0.9990, 0.9963, 0.9983, 0.9980, 0.9988, 0.9966, 0.9985, 0.9968,\n",
            "          1.0012, 0.9973],\n",
            "         [0.9993, 0.9993, 0.9956, 0.9980, 0.9978, 0.9988, 0.9978, 0.9988,\n",
            "          0.9995, 0.9993],\n",
            "         [0.9995, 1.0007, 0.9988, 0.9988, 1.0000, 0.9973, 0.9968, 0.9988,\n",
            "          0.9985, 0.9995],\n",
            "         [0.9985, 0.9988, 0.9973, 0.9988, 0.9988, 0.9976, 0.9954, 0.9983,\n",
            "          1.0002, 0.9958],\n",
            "         [0.9956, 0.9985, 0.9939, 0.9963, 0.9963, 0.9932, 0.9985, 0.9966,\n",
            "          0.9993, 0.9978],\n",
            "         [0.9980, 0.9988, 0.9971, 0.9988, 0.9993, 0.9976, 0.9966, 1.0012,\n",
            "          0.9990, 0.9958],\n",
            "         [0.9980, 0.9961, 0.9973, 0.9976, 0.9971, 0.9993, 0.9988, 0.9949,\n",
            "          0.9956, 0.9985],\n",
            "         [0.9985, 0.9951, 0.9985, 0.9868, 0.9993, 0.9810, 0.9971, 0.9893,\n",
            "          0.9912, 0.9990],\n",
            "         [0.9993, 0.9985, 0.9968, 0.9993, 0.9983, 0.9961, 0.9944, 0.9966,\n",
            "          1.0005, 0.9993],\n",
            "         [0.9990, 0.9998, 0.9985, 0.9990, 0.9968, 1.0002, 0.9976, 0.9988,\n",
            "          1.0000, 0.9990],\n",
            "         [0.9988, 0.9978, 0.9980, 0.9983, 0.9946, 0.9978, 0.9956, 0.9968,\n",
            "          0.9958, 0.9990]],\n",
            "\n",
            "        [[0.9993, 0.9988, 0.9968, 0.9973, 0.9995, 1.0012, 0.9990, 1.0010,\n",
            "          0.9976, 0.9985],\n",
            "         [0.9983, 0.9961, 1.0002, 0.9985, 0.9973, 0.9993, 0.9978, 0.9966,\n",
            "          0.9978, 0.9978],\n",
            "         [0.9961, 1.0000, 0.9985, 1.0002, 0.9995, 1.0000, 0.9988, 0.9980,\n",
            "          0.9944, 0.9988],\n",
            "         [1.0007, 0.9995, 0.9998, 0.9993, 1.0000, 0.9973, 0.9983, 0.9988,\n",
            "          1.0007, 0.9988],\n",
            "         [0.9993, 0.9954, 0.9990, 0.9993, 0.9988, 0.9988, 0.9968, 0.9971,\n",
            "          0.9963, 0.9973],\n",
            "         [0.9988, 0.9983, 0.9988, 0.9971, 0.9978, 0.9946, 0.9944, 0.9988,\n",
            "          0.9985, 0.9978],\n",
            "         [0.9978, 0.9980, 0.9949, 0.9973, 0.9980, 0.9983, 0.9973, 0.9971,\n",
            "          0.9951, 0.9937],\n",
            "         [0.9980, 0.9980, 0.9978, 0.9985, 0.9963, 0.9978, 0.9973, 0.9946,\n",
            "          0.9949, 0.9985],\n",
            "         [0.9973, 0.9978, 0.9917, 0.9888, 0.9976, 0.9922, 0.9958, 0.9973,\n",
            "          0.9976, 0.9993],\n",
            "         [0.9976, 0.9990, 0.9971, 1.0000, 0.9963, 0.9985, 0.9988, 0.9988,\n",
            "          0.9963, 0.9988],\n",
            "         [1.0015, 0.9980, 1.0002, 0.9966, 0.9993, 0.9985, 0.9995, 0.9983,\n",
            "          0.9995, 0.9966],\n",
            "         [0.9956, 0.9958, 0.9937, 0.9966, 0.9968, 0.9929, 0.9990, 0.9993,\n",
            "          0.9946, 0.9990]],\n",
            "\n",
            "        [[0.9956, 0.9963, 0.9883, 0.9968, 0.9934, 0.9932, 0.9924, 0.9832,\n",
            "          1.0002, 0.9985],\n",
            "         [0.9973, 0.9980, 0.9927, 0.9939, 0.9937, 1.0000, 0.9973, 0.9844,\n",
            "          0.9954, 0.9998],\n",
            "         [0.9978, 0.9951, 0.9976, 0.9978, 0.9998, 0.9946, 0.9954, 1.0056,\n",
            "          0.9998, 0.9958],\n",
            "         [0.9976, 0.9978, 0.9849, 0.9731, 0.9971, 0.9944, 0.9961, 0.9971,\n",
            "          0.9956, 0.9995],\n",
            "         [0.9980, 0.9978, 0.9990, 0.9995, 0.9988, 0.9993, 0.9993, 0.9807,\n",
            "          0.9980, 0.9983],\n",
            "         [0.9988, 0.9983, 0.9980, 0.9963, 0.9976, 0.9946, 0.9973, 0.9885,\n",
            "          0.9985, 0.9983],\n",
            "         [0.9988, 1.0015, 0.9949, 0.9988, 0.9849, 0.9919, 0.9910, 0.9807,\n",
            "          0.9968, 0.9990],\n",
            "         [0.9902, 0.9951, 0.9941, 0.9939, 0.9966, 0.9939, 0.9905, 0.9902,\n",
            "          0.9937, 0.9976],\n",
            "         [0.9937, 0.9995, 0.9968, 0.9829, 1.0000, 0.9812, 0.9927, 0.9973,\n",
            "          0.9980, 0.9973],\n",
            "         [0.9978, 1.0000, 0.9993, 0.9990, 0.9968, 0.9976, 0.9990, 1.0000,\n",
            "          0.9993, 1.0005],\n",
            "         [0.9988, 1.0000, 0.9998, 0.9990, 0.9968, 0.9968, 0.9785, 0.9946,\n",
            "          0.9968, 0.9956],\n",
            "         [1.0005, 0.9944, 0.9934, 0.9951, 0.9944, 0.9971, 0.9927, 0.9805,\n",
            "          0.9973, 1.0005]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "    model.eval()\n",
        "    eval_accuracy = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            # 배치를 GPU로\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            #logits만 얻기\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # CPU로 내리고 numpy 변환\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            # 배치별 정확도 계산\n",
        "            batch_acc = flat_accuracy(logits, label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.2f}\")\n",
        "    print(f\"Validation Time   : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return avg_accuracy\n",
        "\n",
        "avg_acc = run_validation(model, validation_dataloader, device)"
      ],
      "metadata": {
        "id": "r3GHXPFAyqKm",
        "outputId": "c8901a25-8078-4233-efc5-bd5ebb47d6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1576223b15c7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-1576223b15c7>\u001b[0m in \u001b[0;36mrun_validation\u001b[0;34m(model, validation_dataloader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#logits만 얻기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             outputs = model(\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c86f7e7a9655>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# (4) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             rows.append(torch.tensor(\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    # 2) 준비\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_accuracy = 0.0\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            # Forward pass (logits 얻기)\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]              # [B, 2]\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = criterion(logits, b_labels)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            #probs_tensor = torch.softmax(logits, dim=1)               # [B,2]\n",
        "            #pos_probs = probs_tensor[:, 1].detach().cpu().numpy()     # positive 클래스 확률\n",
        "            #threshold = 0.6                                           # 원하는 임계치\n",
        "            #preds = (pos_probs > threshold).astype(int)               # 0.6 초과면 1, 아니면 0\n",
        "            label_ids = b_labels.detach().cpu().numpy()\n",
        "            batch_acc = np.sum(preds == label_ids) / len(label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "\n",
        "            # 저장\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(label_ids.tolist())\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    # 3) 평균 지표 계산\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_loss     = eval_loss / nb_eval_steps\n",
        "    mcc          = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # 4) 결과 출력\n",
        "    print(f\"Validation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision / Recall / F1: {precision:.4f} / {recall:.4f} / {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": avg_accuracy,\n",
        "        \"loss\": avg_loss,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5cgFqujvRRb",
        "outputId": "9d860b2c-f132-4277-f682-6b2baf8d0ee9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n",
            "Validation Loss    : 0.5975\n",
            "Validation Accuracy: 0.7971\n",
            "Matthews CorrCoef  : 0.4921\n",
            "Precision / Recall / F1: 0.8056 / 0.9307 / 0.8636\n",
            "Confusion Matrix:\n",
            " [[131 133]\n",
            " [ 41 551]]\n",
            "Validation Time    : 0:06:40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ."
      ],
      "metadata": {
        "id": "cSd2dA-wQ94T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de556c0f-d18c-4c7d-a7aa-e1da60adabe8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32049856-b723-472c-b366-c66a84f00f57"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7436408c-8cd4-4e4b-9307-114f0a5341d3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c26184-022f-4eaa-f2b6-6923b9a56d5a"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=02bba3e6582c978cdde3e2a7cc44ef47a39ab8b784f7d57a719753fab2b0c94e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7baf8c3c-44eb-4e48-fb0d-ebbef55e7281"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cc7151-6f9b-48b6-d37a-152745871909"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e6e8a116-8a64-4265-cb8a-c242fce8a920"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "6090            c_13      1         NaN   \n",
              "2851            l-93      1         NaN   \n",
              "7009          sgww85      1         NaN   \n",
              "2883            l-93      1         NaN   \n",
              "4639            ks08      1         NaN   \n",
              "6189            c_13      1         NaN   \n",
              "1188            r-67      1         NaN   \n",
              "3581            ks08      1         NaN   \n",
              "7890            ad03      1         NaN   \n",
              "8200            ad03      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "6090                       I do not love peanut butter.  \n",
              "2851                            Carol cut at the bread.  \n",
              "7009                          Dana was quite competent.  \n",
              "2883                 Harriet interconnected the pieces.  \n",
              "4639                            The car will be driven.  \n",
              "6189                 How do you think John bought what?  \n",
              "1188       I read a statement which was about that man.  \n",
              "3581  I know I should go to the dentist's, but I jus...  \n",
              "7890                  Hera tried to appear to be happy.  \n",
              "8200                             They kicked themselves  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-725b7f6e-913a-4c99-8577-3dea593e5f7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I do not love peanut butter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carol cut at the bread.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7009</th>\n",
              "      <td>sgww85</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dana was quite competent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2883</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Harriet interconnected the pieces.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4639</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The car will be driven.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>How do you think John bought what?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I read a statement which was about that man.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I know I should go to the dentist's, but I jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7890</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hera tried to appear to be happy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8200</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They kicked themselves</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-725b7f6e-913a-4c99-8577-3dea593e5f7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-725b7f6e-913a-4c99-8577-3dea593e5f7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-725b7f6e-913a-4c99-8577-3dea593e5f7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ce2a49ea-6669-4835-862c-e28db6d9abb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce2a49ea-6669-4835-862c-e28db6d9abb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ce2a49ea-6669-4835-862c-e28db6d9abb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "601a1abe-d6c0-4d91-a286-a66adc6f9c1b"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             sentence  label\n",
              "2317                         Bill married with Kathy.      0\n",
              "4301  Stephen persuaded the cat to be out of the bag.      0\n",
              "2803                                   The fence hit.      0\n",
              "2358                  I sought for game in the woods.      0\n",
              "2354                 We rummaged the desk for papers.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b392803-aa20-41db-998e-f0b027c00468\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2317</th>\n",
              "      <td>Bill married with Kathy.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4301</th>\n",
              "      <td>Stephen persuaded the cat to be out of the bag.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2803</th>\n",
              "      <td>The fence hit.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2358</th>\n",
              "      <td>I sought for game in the woods.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2354</th>\n",
              "      <td>We rummaged the desk for papers.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b392803-aa20-41db-998e-f0b027c00468')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b392803-aa20-41db-998e-f0b027c00468 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b392803-aa20-41db-998e-f0b027c00468');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b29f4d53-7f33-4352-9517-b5a905dc9e39\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b29f4d53-7f33-4352-9517-b5a905dc9e39')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b29f4d53-7f33-4352-9517-b5a905dc9e39 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Stephen persuaded the cat to be out of the bag.\",\n          \"We rummaged the desk for papers.\",\n          \"The fence hit.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "21647f650e8642afaa150c4a31a9f56c",
            "f2e51646d0724c6b84e4cc3047ed3e0e",
            "1bea68bb306748c3abe9a1a7951d3cf8",
            "4057fad4547546399720164e21c94721",
            "ec42f719294c425ca1a8b63582a0b117",
            "2e5cc5a7810248fdb02d3757e8342a47",
            "d97b55b02c6349e5a75226385923daa9",
            "da9a9c6d4d7e404f95c408db13f49de1",
            "bb13b3ed78ee4fb5989a9733be32cc8c",
            "f0893228bcb3424f854491fc4582c20f",
            "c249737b8f524e3885269bb49b9693f3",
            "2c9f222533264388bf7eef8e7cf8f23f",
            "297bb25e012c4c09942f882920f8cf8b",
            "f7e65943daac40b3825e73ed57048a2f",
            "23da79cb7a8045a2869af10cdf206175",
            "a3a4deffe3a64e6aa3c894badfa07e31",
            "595e071b805b4b1b9d89feb6b57082ee",
            "3aa9d4590bb94ccdbfbdb9ad33613c43",
            "867f2b9ef2bb4749bd543b6949013c39",
            "4688741ae333403585031546f91449a4",
            "de6f9cc78548427cac3b632bacc7058d",
            "956fb7a85f2648fe95d92ae89ab7fa51",
            "5d71fa82b4804f888a17feb29c3da915",
            "fc22f02bba374f35bc9224c6e8043628",
            "f88c4f08a90745e6957099c79a0ce55a",
            "89b9427dce014ef784debe3a476afb38",
            "b2fbcafba6d344e0ba465a7b94ac4075",
            "ef9e647e17314008bdef689dfc806d99",
            "b7b92019c1bb4b15bdcabca6ea46fef7",
            "c64cfd6a45214e79a11d190950de1da7",
            "5b6d57e400c948efae7d8b39bbd3b1a3",
            "ccacbcc6fc5d4bbd8270ebd73e1c9eaa",
            "e563e154deac4398804263303a046083",
            "51466319aeb748c99a39a40240cad178",
            "ffd094ec7f5e43a9b42eca730cc10c5e",
            "5ab71a52aa0442d09e20e2a88b73113b",
            "ad5ea0b1b46749008d1d415156d5d38b",
            "b4ef36bca9a649cfaa85fb4743b0a23d",
            "e5ecaba034ea4aa18424ebf59caccf45",
            "614278161a054032844b3b0918bac1f3",
            "55db5ffe7c8143138cc1d25fce57cb9e",
            "229c75c52d564ecfa718ad70261a43b8",
            "8ca9f2deb9254ab88e5efc018da79a84",
            "b11d538b51c442e4af7b404b8f8a5367"
          ]
        },
        "outputId": "7b777a36-989a-419f-fc47-e3afae9c7d2a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21647f650e8642afaa150c4a31a9f56c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c9f222533264388bf7eef8e7cf8f23f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d71fa82b4804f888a17feb29c3da915"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51466319aeb748c99a39a40240cad178"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797249ad-f6be-4b75-e172-b5800cfa6b04"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2247b1c3-5963-4b63-f6fc-d88f3f272726"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf23724-4295-42d2-f90b-a29b620fdee2"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86471e3c-c89e-4a8c-eab7-269cd57d36e7"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d5ba5169307c45508f5847f1daeb76d3",
            "7f81394a29604411a0e01e7affead432",
            "39722a94be4f4a14af1ddaf63e6639b7",
            "cbe94b0dd40a4ae8abf89d5e7202d506",
            "c2fbf7998e9b44cdbdf148cef0c1ebae",
            "d89c19f933d24a6c8c6ece0495078a13",
            "1e0e64e34f864657965c20c781b9eeeb",
            "68eaac5671b64634ab7d55f728f43b99",
            "43435ed194974628ada06eb473fb46b2",
            "f54c1c33d0fd438ab2f7274dd8a8304a",
            "9726a149fcb44b0882884c346a3cdf8a"
          ]
        },
        "outputId": "0c24e029-78e1-46b7-c90a-f2ecbb29b9af"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5ba5169307c45508f5847f1daeb76d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20b783d-8a7b-4629-c509-311be3b2b9fe"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3"
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6842c23c-055e-40c9-f924-1cdf70c473a7"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:04.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:07.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:10.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:16.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "38fd451e-17d5-47e7-bca4-1d902351ef68"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9fe64ec-0654-4bbf-d2ba-19e9de695aac"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204e560f-09eb-44ca-86c2-4fc01c18ae04"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d069ca1e-e575-469f-c67b-4edeb287fbcb"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b0a467-0c69-4c0b-ed07-61ff047b5e69"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58429f2f-d2c8-4cba-e0d2-d8dad3c8620a"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.21713222235566895),\n",
              " 0.0,\n",
              " np.float64(0.34500484066310094),\n",
              " np.float64(0.4127594582445936),\n",
              " np.float64(0.21867346044008387),\n",
              " np.float64(0.6979824404521128),\n",
              " np.float64(0.12403473458920847),\n",
              " 0.0,\n",
              " np.float64(0.9165151389911681),\n",
              " np.float64(0.6659416347320276),\n",
              " np.float64(0.7679476477883045),\n",
              " np.float64(0.5673665146135802),\n",
              " np.float64(0.8749672939989046),\n",
              " np.float64(0.7141684885491869),\n",
              " np.float64(0.23372319715296222),\n",
              " np.float64(0.4252964776724258),\n",
              " np.float64(-0.3333333333333333)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c867fe-c85a-4c52-d927-ac1cf0972787"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 코드"
      ],
      "metadata": {
        "id": "xd5BzXwU8HM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MAX_LEN = 10\n",
        "\n",
        "def predict_with_cordic(model, tokenizer, sentence, device):\n",
        "    \"\"\"\n",
        "    CORDIC-Softmax 패치된 model + tokenizer를 이용해\n",
        "    단일 문장(sentence)에 대해 CoLA 예측을 수행합니다.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 토크나이징 + 패딩\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # GPU/CPU 동일하게 맞추기\n",
        "    inputs = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "    # 순전파만 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs.get(\"token_type_ids\", None)\n",
        "        )\n",
        "        # HuggingFace 버전 따라 .logits 또는 [0]\n",
        "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
        "\n",
        "    # CORDIC-Softmax로 이미 변환된 attention을 쓰므로\n",
        "    # classification head 출력만 softmax\n",
        "    probs = torch.softmax(logits, dim=-1)    # [1, 2]\n",
        "    pred  = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    return pred, probs.cpu().numpy().flatten()\n",
        "\n",
        "\n",
        "# — 사용 예시 —\n",
        "sentence = \"Here is a sample sentence to test CORDIC inference.\"\n",
        "pred, probs = predict_with_cordic(model, tokenizer, sentence, device)\n",
        "\n",
        "label_name = \"acceptable\" if pred == 1 else \"unacceptable\"\n",
        "print(f\"Sentence        : {sentence}\")\n",
        "print(f\"Predicted label : {pred} ({label_name})\")\n",
        "print(f\"Probabilities   : [0]={probs[0]:.4f}, [1]={probs[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "ddIcD3HipFSO",
        "outputId": "f0bead73-a2f3-40b3-8781-7ebb1136d030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cordic_softmax_2way' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# — 사용 예시 —\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Here is a sample sentence to test CORDIC inference.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_cordic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"acceptable\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"unacceptable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36mpredict_with_cordic\u001b[0;34m(model, tokenizer, sentence, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 순전파만 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-cfef15f4be3a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 2) CORDIC-Softmax으로 대체 (num_labels=2라면 top_2 입력 함수 필요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 여기서는 예시로 두 값에 대한 지수→분모→나눗셈을 직접 호출한다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcordic_softmax_2way\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# logits.shape == [B,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cordic_softmax_2way' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d731a4d-adf9-475b-a709-34946ac56710"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# 1. 모델 및 토크나이저 로드 (예: 'bert-base-uncased' 사용)\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()               # GPU로 이동\n",
        "model.eval()               # 평가 모드로 전환\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# 2. 추론할 영어 문장 예시\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "\n",
        "# 3. 문장 토큰화 및 인코딩\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,      # [CLS]와 [SEP] 토큰 추가\n",
        "    max_length=10,                # 최대 길이 설정\n",
        "    padding=\"max_length\",         # 최대 길이에 맞춰 패딩\n",
        "    truncation=True,              # 길면 잘라냄\n",
        "    return_tensors=\"pt\"           # 파이토치 텐서 반환\n",
        ")\n",
        "\n",
        "# 4. 텐서를 GPU로 이동\n",
        "inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "\n",
        "# 5. 추론 (forward pass)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs[0]  # 모델의 출력은 튜플이며, 첫 번째 요소가 로짓입니다.\n",
        "\n",
        "# 6. Softmax 적용 (선택 사항) 및 예측 클래스 결정\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "# 7. 결과 출력\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", predicted_class.item())\n",
        "print(\"예측 확률:\", probs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: tensor([[0.7347, 0.2653]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    입력된 문장에 대해 학습된 모델을 사용하여 예측을 수행합니다.\n",
        "    Returns:\n",
        "        predicted_class: 예측된 클래스 (예: 0 또는 1)\n",
        "        probs: 각 클래스의 확률 (numpy 배열)\n",
        "    \"\"\"\n",
        "    # 문장을 토큰화하고 encode_plus를 통해 [CLS], [SEP] 토큰을 추가하며, 패딩/자르기 적용\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,      # [CLS]와 [SEP] 추가\n",
        "        max_length=max_length,        # 최대 길이\n",
        "        padding=\"max_length\",         # 최대 길이에 맞게 패딩\n",
        "        truncation=True,              # 길면 자르기\n",
        "        return_tensors=\"pt\"           # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # GPU로 텐서를 전송\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # 모델을 평가 모드로 전환하고, 추론 시에는 기울기를 계산하지 않도록 설정\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # 모델의 출력은 튜플 형태로, 첫 번째 요소가 logits입니다.\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 사용\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PITHYJKhPHD",
        "outputId": "c1e48647-320b-42aa-d562-a50a05b01a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.73471546 0.26528448]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic 코드"
      ],
      "metadata": {
        "id": "oK0EdSFZjeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    결과는 원본 형태 (1, 12, 10, 10)로 반환\n",
        "    \"\"\"\n",
        "    if isinstance(attention_scores, torch.Tensor):\n",
        "        attention_scores = attention_scores.detach().cpu().numpy()  # ✅ detach() 추가\n",
        "\n",
        "    batch_size, num_heads, seq_length, _ = attention_scores.shape\n",
        "    result_arrays = np.zeros((batch_size, num_heads, seq_length, seq_length))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        for row in range(seq_length):\n",
        "            for col in range(seq_length // 10):\n",
        "                input_values = attention_scores[0, head, row, col * 10:(col + 1) * 10]\n",
        "                result = top(*input_values)\n",
        "                result_arrays[0, head, row, col * 10:(col + 1) * 10] = result\n",
        "\n",
        "    # ✅ numpy -> torch 변환할 때 `.to(device)` 추가\n",
        "    return torch.tensor(result_arrays, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 정수부는 7비트 (Signed, 2의 보수)\n",
        "    - 소수부는 13비트 (항상 양수)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ PyTorch Tensor 처리\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        value = value.detach().cpu().numpy()\n",
        "\n",
        "    # ✅ NaN 또는 Inf 값 체크 후 예외 처리\n",
        "    if np.isnan(value) or np.isinf(value):\n",
        "        raise ValueError(f\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\")\n",
        "\n",
        "    # ✅ **최대/최소 값 제한 (7비트 표현 범위)**\n",
        "    value = max(min(value, 63), -64)\n",
        "\n",
        "    # ✅ 정수부와 소수부 분리\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수 부분\n",
        "\n",
        "    # ✅ 2의 보수 변환 (음수 처리)\n",
        "    if int_part < 0:\n",
        "        int_part = (1 << int_bits) + int_part\n",
        "\n",
        "    int_binary = format(int_part, f'0{int_bits}b')\n",
        "\n",
        "    # ✅ 12비트 0 추가 (BERT 출력 형식 유지)\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트)\n",
        "    frac_binary = \"\"\n",
        "    for _ in range(frac_bits):\n",
        "        frac_part *= 2\n",
        "        if frac_part >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_part -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 문자열 생성\n",
        "    binary_string = int_binary + frac_binary\n",
        "\n",
        "    # ✅ `binary_string`이 음수 값을 포함하는지 확인 후 처리\n",
        "    if \"-\" in binary_string:\n",
        "        raise ValueError(f\"[ERROR] 잘못된 바이너리 문자열 변환 감지: {binary_string}\")\n",
        "\n",
        "    # ✅ 20비트 정수 변환 (부호 처리)\n",
        "    fixed_binary = int(binary_string, 2)\n",
        "    if value < 0:\n",
        "        fixed_binary = (1 << 20) - fixed_binary  # 2의 보수 변환\n",
        "\n",
        "    lower_20_bits = fixed_binary & 0xFFFFF  # 20비트 마스킹\n",
        "\n",
        "    return lower_20_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    \"\"\"\n",
        "    2의 보수 표현된 이진수를 정수로 변환하는 함수.\n",
        "    \"\"\"\n",
        "    # ✅ \"0b\" 제거\n",
        "    binary_str = binary_str.replace(\"0b\", \"\")\n",
        "\n",
        "    # ✅ 이진수 길이 확인\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # ✅ 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 변환 (음수)\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JuXVpD_Fjj7q",
        "outputId": "92b4e0a7-8f92-4fb4-e9da-9a1ba0f0b8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0528564453125,\n",
              " 0.0977783203125,\n",
              " 0.0128173828125,\n",
              " 0.0438232421875,\n",
              " 0.3963623046875,\n",
              " 0.0980224609375,\n",
              " 0.0552978515625,\n",
              " 0.0140380859375,\n",
              " 0.0599365234375,\n",
              " 0.1666259765625)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 수정 및 적용 코드"
      ],
      "metadata": {
        "id": "o19OXrVjjoaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# … (BertSelfAttentionModified / BertEncoderModified / BertWithModifiedAttentionForClassification 정의부는 그대로) …\n",
        "\n",
        "# 4. 모델 생성\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "\n",
        "# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\n",
        "checkpoint = torch.load(\"./model/CoLA.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "# 이후 GPU 이동·평가 모드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 예시 추론 함수 (변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=device):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred  = torch.argmax(probs, dim=1).item()\n",
        "    return pred, probs.cpu().numpy()\n",
        "\n",
        "# 테스트\n",
        "sentence = \"This is a grammatically acceptable sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sXS8S2bXX17u",
        "outputId": "8e8a0084-48e7-458f-db5a-5450af90ce01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e186ff2ff0d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/CoLA.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                     warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "scMdkDy7tAqU",
        "outputId": "8e4b9b79-2fec-49f1-addb-5207366623b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassificationModified(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Softmax 대신 CORDIC을 적용\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "XySJ0nStsisx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # 여기서 원래 softmax를 적용하는 대신 CORDIC 기반 함수를 사용합니다.\n",
        "        # 예를 들어, top_1200_input(attention_scores)를 사용하여 softmax 결과를 근사합니다.\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        # 만약 반환된 결과가 numpy 형태라면, torch.tensor로 변환해주어야 합니다.\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 원래 출력은 (context_layer, attention_probs) 또는 (context_layer,)인데,\n",
        "        # 필요에 따라 raw attention scores도 반환하도록 할 수 있습니다.\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "# 만약 학습된 가중치를 로드해야 한다면 로드합니다.\n",
        "# model.load_state_dict(torch.load(\"your_checkpoint.pt\"), strict=False)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# 이제 이 모델은 CoLA나 다른 영어 문장 분류 작업에 사용할 수 있습니다.\n",
        "# 예시 추론 함수:\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 문장으로 테스트\n",
        "sentence = \"This is a grammatically acceptable for sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "itlqawMcjmJ3",
        "outputId": "11d60001-ac23-433a-cb2d-a279facb7a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is a grammatically acceptable for sentence.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.5131679  0.48683208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 encoder 내 각 레이어의 self-attention 모듈 타입을 출력하여\n",
        "# 수정된 BertSelfAttentionModified가 적용되었는지 확인합니다.\n",
        "print(\"수정된 Attention Layers 확인:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn_layer = layer.attention.self\n",
        "    print(f\"Layer {i} self-attention layer type: {type(attn_layer)}\")\n"
      ],
      "metadata": {
        "id": "8WUtGKLuoW2z",
        "outputId": "fa8009ef-7082-49b3-ea5a-13e2553196a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정된 Attention Layers 확인:\n",
            "Layer 0 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 1 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 2 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 3 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 4 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 5 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 6 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 7 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 8 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 9 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 10 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 11 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디버깅용 잡동사니코드"
      ],
      "metadata": {
        "id": "H5iP5hhyJuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print(f\"[TOP] exp_fraction_output[{i}] = {exp_fraction_output[i]}\")\n",
        "    print(f\"[TOP] exp_int_output[{i}] = {exp_int_output[i]}\")\n",
        "    print(f\"[TOP] exp_whole[{i}] = {exp_whole[i]}\")\n",
        "    print(f\"[TOP] exp_trunc[{i}] = {exp_trunc[i]}\")\n",
        "    print(f\"[TOP] exp_accum_input[{i}] = {exp_accum_input[i]}\")\n",
        "    print(f\"[TOP] x_divider = {x_divider[0]}\")\n",
        "    print(f\"[TOP] y_dividend = {y_dividend[i]}\")\n",
        "    print(f\"[TOP] data_out[{i}] = {data_out[i]}\")"
      ],
      "metadata": {
        "id": "rAamcoXWSjnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # ✅ 디버깅용 Q, K 체크\n",
        "        with torch.no_grad():\n",
        "            h = hidden_states.detach().cpu().numpy()\n",
        "            print(\"=== Hidden States 디버깅 ===\")\n",
        "            print(\"min:\", np.min(h), \"max:\", np.max(h))\n",
        "            print(\"NaN 수:\", np.isnan(h).sum(), \"Inf 수:\", np.isinf(h).sum())\n",
        "            q = query_layer.detach().cpu().numpy()\n",
        "            k = key_layer.detach().cpu().numpy()\n",
        "            print(\"=== Q, K 디버깅 ===\")\n",
        "            print(\"Q min/max:\", np.min(q), np.max(q))\n",
        "            print(\"K min/max:\", np.min(k), np.max(k))\n",
        "            print(\"Q NaN 수:\", np.isnan(q).sum(), \"K NaN 수:\", np.isnan(k).sum())\n",
        "            print(\"Q Inf 수:\", np.isinf(q).sum(), \"K Inf 수:\", np.isinf(k).sum())\n",
        "\n",
        "        # attention score 계산 후 clamp\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 계산 직후 ===\")\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item(), \"Inf 수:\", torch.isinf(attention_scores).sum().item())\n",
        "        attention_scores = torch.clamp(attention_scores, min=-10.0, max=10.0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 예시 ===\")\n",
        "            print(attention_scores[0, 0, 0, :10])\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item())\n",
        "        # CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "\n",
        "# 2. BertLayerWithNaNCheck: layer 0 내부 모듈 NaN 추적\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n",
        "\n",
        "\n",
        "# 3. BertEncoderModified\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "        self.layer[0] = BertLayerWithNaNCheck(self.layer[0])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_values=None, use_cache=False, output_attentions=False,\n",
        "                output_hidden_states=False, return_dict=True):\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            with torch.no_grad():\n",
        "                hs = hidden_states.detach().cpu().numpy()\n",
        "                if np.isnan(hs).sum() > 0:\n",
        "                    print(f\"[NaN DETECTED] ❌ in hidden_states BEFORE layer {i}\")\n",
        "                else:\n",
        "                    print(f\"[OK] ✅ hidden_states BEFORE layer {i}\")\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask[i] if head_mask is not None else None,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_values[i] if past_key_values is not None else None,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "        return (hidden_states,)\n",
        "\n",
        "\n",
        "# 4. BertWithModifiedAttentionForClassification\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 5. Load config and model\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dTD-BGlHKAh5",
        "outputId": "383af56c-e173-4f09-db40-610c833f616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayerWithNaNCheck(\n",
              "          (layer): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttentionModified(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_class = np.argmax(probs)\n",
        "\n",
        "    return pred_class, probs\n"
      ],
      "metadata": {
        "id": "sgc6czs9DqMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_nan(module, input, output):\n",
        "    if isinstance(output, torch.Tensor):\n",
        "        if torch.isnan(output).any():\n",
        "            print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "    elif isinstance(output, (tuple, list)):\n",
        "        for o in output:\n",
        "            if torch.is_tensor(o) and torch.isnan(o).any():\n",
        "                print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    module.register_forward_hook(check_for_nan)\n"
      ],
      "metadata": {
        "id": "2QHFLakIFV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        # Attention\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        # Intermediate\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        # Output\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n"
      ],
      "metadata": {
        "id": "gAA7SyorIaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sentence = \"The cat is sitting on the mat.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "\n",
        "print(\"문장:\", sentence)\n",
        "print(\"예측 클래스:\", pred_class)\n",
        "print(\"클래스별 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "yv0VeRUlDpLp",
        "outputId": "1cd74ea5-ca18-4524-d57c-bed12d1b5f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ✅ hidden_states BEFORE layer 0\n",
            "=== [Layer 0] BEFORE ===\n",
            "min: -4.571415901184082 max: 3.8990025520324707\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Hidden States 디버깅 ===\n",
            "min: -4.571416 max: 3.8990026\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: -2.1867194 2.275151\n",
            "K min/max: -2.4105966 2.2897592\n",
            "Q NaN 수: 0 K NaN 수: 0\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([ 0.4173, -0.1602, -0.0771,  0.3595,  0.1112, -0.1229, -0.2256, -0.0283,\n",
            "        -0.1147, -0.0984], device='cuda:0')\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0\n",
            "[NaN DETECTED] ❌ after Attention in Layer 0\n",
            "[NaN DETECTED] ❌ after Intermediate in Layer 0\n",
            "[NaN DETECTED] ❌ after Output in Layer 0\n",
            "=== [Layer 0] AFTER ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "[NaN DETECTED] ❌ in hidden_states BEFORE layer 1\n",
            "=== Hidden States 디버깅 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: nan nan\n",
            "K min/max: nan nan\n",
            "Q NaN 수: 49152 K NaN 수: 49152\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
            "min: nan max: nan\n",
            "NaN 수: 49152\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8b7cffed0231>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The cat is sitting on the mat.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-c78350183b4c>\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(model, tokenizer, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[OK] ✅ hidden_states BEFORE layer {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN 수:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        batch_size, num_heads, seq_len, _ = attention_scores.shape\n",
        "        for b in range(batch_size):\n",
        "          for h in range(num_heads):\n",
        "            for row in range(seq_len):\n",
        "              float_row = attention_scores[b, h, row, :10].detach().cpu().numpy().tolist()\n",
        "\n",
        "              if any(np.isnan(f) for f in float_row):\n",
        "                print(f\"[NaN] b={b}, head={h}, row={row} - 입력에 NaN 있음! ❌\")\n",
        "                continue  # 이건 skip하고 다음으로\n",
        "              try:\n",
        "                cordic_attention = top(*float_row)\n",
        "              except Exception as e:\n",
        "                print(f\"[ERROR] top() 실패: {e}\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "          sample_row = attention_scores[0, 0, 0, :10]  # [10개 float]\n",
        "          float_row = sample_row.detach().cpu().numpy().tolist()\n",
        "          print(\"[DEBUG] top 입력값:\", float_row)\n",
        "\n",
        "          try:\n",
        "            top_result = top(*float_row)\n",
        "            print(\"[DEBUG] top 출력값:\", top_result)\n",
        "          except Exception as e:\n",
        "            print(\"[ERROR] top에서 예외 발생:\", e)\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top(*float_row)\n",
        "\n",
        "        if any(np.isnan(c) for c in cordic_attention):\n",
        "          print(f\"[NaN DETECTED] ❌ top() 결과에 NaN 존재! input: {float_row}\")\n",
        "\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # ⚠️ 먼저 너의 원본 문장 리스트가 있어야 해!\n",
        "# 예: dataset_sentences = [\"문장1\", \"문장2\", ..., \"문장N\"]\n",
        "        # 🧪 validation_dataloader에서 원문 문장 추출 (예시)\n",
        "        dataset_sentences = []\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "          input_ids = batch[0]\n",
        "          for ids in input_ids:\n",
        "            text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "            dataset_sentences.append(text)\n",
        "\n",
        "        for i, sentence in enumerate(dataset_sentences):\n",
        "          try:\n",
        "            pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "          except Exception as e:\n",
        "            print(f\"[❌ NaN 발생] 문장 index = {i}\")\n",
        "            print(\"문장 내용:\", sentence)\n",
        "            print(\"에러 메시지:\", e)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "_dPquKTIGbOE",
        "outputId": "54615d57-7130-49f1-b469-d5b229ca4e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적용 모델 validation"
      ],
      "metadata": {
        "id": "JSRL23_d7voR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "h4m08g6HohMF",
        "outputId": "214cd12b-e10a-47d1-a737-bad6e12eb38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b8146705381d>:34: RuntimeWarning: invalid value encountered in cast\n",
            "  int_part = np.floor(value).astype(int)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e22c35b96d8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The documentation for this `model` function is here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-50e5032ce9fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# (2) CORDIC-Softmax 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# (3) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             rows.append(torch.tensor(\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdata_66\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mdata_77\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata_88\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdata_99\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdata_1010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ✅ 5. 최종 32비트 바이너리 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mfixed_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_binary\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrac_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlower_20_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFFFFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlower_20_bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장 및 로드 코드.\n",
        "path = '/content/model/'\n",
        "torch.save(model.state_dict(), path+\"CoLA.pt\")\n",
        "model.load_state_dict(torch.load(path + \"CoLA.pt\", map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6f3ddQs0x7V-",
        "outputId": "fcf8bd39-919f-468d-918c-5bcdf78d3e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST-2"
      ],
      "metadata": {
        "id": "wT4suA2WBNIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpQOdhi1DbYn",
        "outputId": "40e166c0-29b2-412c-d7b4-d7e2fbd3d80f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JY--dvwDgyY",
        "outputId": "15916bf8-3c28-463c-bfbf-43a5621cc2fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install wget\n",
        "!pip install datasets\n",
        "!pip install scikit-learn\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFsfCKWNDhY4",
        "outputId": "e0c2590e-73cf-48f1-9574-5cc7178b5510"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=e13dfd6962ae25951d29c225c473db597aa50f8560adccfc9caa63d00c8f2a57\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import time, datetime\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "id": "1NvOu43oDwo5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Downloading SST-2 dataset...')\n",
        "\n",
        "# SST-2 데이터셋 ZIP 파일 URL\n",
        "url = 'https://dl.fbaipublicfiles.com/glue/data/SST-2.zip'\n",
        "\n",
        "# 아직 다운로드되지 않았다면 저장\n",
        "if not os.path.exists('./SST-2.zip'):\n",
        "    wget.download(url, './SST-2.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbV5qPoxFfwm",
        "outputId": "534eec67-93ac-4b3b-c2fd-50d009c0777b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading SST-2 dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the SST-2 dataset (if we haven't already)\n",
        "if not os.path.exists('./SST-2/'):\n",
        "    !unzip SST-2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWhLDGo6FzEK",
        "outputId": "e9e15bb4-2cc8-4d90-a75b-985b8b3c6848"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the SST-2 training set into a pandas DataFrame.\n",
        "# The SST-2 zip unpacks to a folder “SST-2” containing “train.tsv”, which has a header.\n",
        "df = pd.read_csv(\"./SST-2/train.tsv\", sep='\\t')\n",
        "\n",
        "# Report the number of training sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Z_CIPSWDGnM9",
        "outputId": "1b1d2643-86d8-4c3b-aea1-cb2cfdb65581"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 67,349\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sentence  label\n",
              "53276              visually engrossing , seldom hammy ,       1\n",
              "28695                                       whole thing       1\n",
              "25281  maid in manhattan proves that it 's easier to ...      0\n",
              "11145            to seek and strike just the right tone       1\n",
              "9808                                            trapped       0\n",
              "46139  can argue that the debate it joins is a necess...      1\n",
              "21184  an entertaining , if somewhat standardized , a...      1\n",
              "7959   with inventive cinematic tricks and an ironica...      1\n",
              "46422                                          huge fan       1\n",
              "41534  attempt to bring cohesion to pamela 's emotion...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f971d39-b1f2-4104-bc1f-8da5e5f34976\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53276</th>\n",
              "      <td>visually engrossing , seldom hammy ,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28695</th>\n",
              "      <td>whole thing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25281</th>\n",
              "      <td>maid in manhattan proves that it 's easier to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11145</th>\n",
              "      <td>to seek and strike just the right tone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9808</th>\n",
              "      <td>trapped</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46139</th>\n",
              "      <td>can argue that the debate it joins is a necess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21184</th>\n",
              "      <td>an entertaining , if somewhat standardized , a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7959</th>\n",
              "      <td>with inventive cinematic tricks and an ironica...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46422</th>\n",
              "      <td>huge fan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41534</th>\n",
              "      <td>attempt to bring cohesion to pamela 's emotion...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f971d39-b1f2-4104-bc1f-8da5e5f34976')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f971d39-b1f2-4104-bc1f-8da5e5f34976 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f971d39-b1f2-4104-bc1f-8da5e5f34976');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1277c89c-c115-4477-b208-650173679da4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1277c89c-c115-4477-b208-650173679da4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1277c89c-c115-4477-b208-650173679da4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"huge fan \",\n          \"whole thing \",\n          \"can argue that the debate it joins is a necessary and timely one \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예: 레이블 샘플 5개 보기\n",
        "df.loc[df.label == 1].sample(5)[['sentence', 'label']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l1q4zLamGqVW",
        "outputId": "416073b0-d1c2-4dcf-f0fc-d040f3103b82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sentence  label\n",
              "39498  say for plenty of movies that flow through the...      1\n",
              "41283               it 's a quirky , off-beat project .       1\n",
              "62985                                 is a real charmer       1\n",
              "59628  the film has an infectious enthusiasm and we '...      1\n",
              "42572                                 a high water mark       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e9cf778-efd5-4d85-8ba3-9b92f5e19c04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39498</th>\n",
              "      <td>say for plenty of movies that flow through the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41283</th>\n",
              "      <td>it 's a quirky , off-beat project .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62985</th>\n",
              "      <td>is a real charmer</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59628</th>\n",
              "      <td>the film has an infectious enthusiasm and we '...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42572</th>\n",
              "      <td>a high water mark</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e9cf778-efd5-4d85-8ba3-9b92f5e19c04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e9cf778-efd5-4d85-8ba3-9b92f5e19c04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e9cf778-efd5-4d85-8ba3-9b92f5e19c04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3190b6c2-777c-4b4f-9bd8-53d7a9e418be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3190b6c2-777c-4b4f-9bd8-53d7a9e418be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3190b6c2-777c-4b4f-9bd8-53d7a9e418be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"it 's a quirky , off-beat project . \",\n          \"a high water mark \",\n          \"is a real charmer \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels    = df.label.values"
      ],
      "metadata": {
        "id": "kT4z61RMG0q3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "2f2e6ad076da4890b6c650c7857725e5",
            "19ffeab4996644f3b69c9f7a47c933af",
            "8d1afc99a12f4814bf314250cc7aaae8",
            "cdc021052eba4401a96c94d70213b7da",
            "a8a26fe559fe4fa5b07809c18f5367f7",
            "00ab6f4dcf7c47b3af8b2f1360acad42",
            "c9985c73150041699cf8d3d55a8e41ce",
            "554f4bfc60e44e9dbc328a850db13afb",
            "d7a2347416b44350abc8c88bb8cdc18e",
            "582dc42978ed47859ae9693579499b25",
            "2ad87c39060d45478d2276ce484719c5",
            "5c90ea080b1640eb9a20f4836bec9f34",
            "cf65057bf8134c9690e362c39c09965a",
            "72f5af19cd134f9d9974a164c91b5125",
            "f56624ff29db4733b97b84ecb024fae1",
            "3776b140bb21417990aaeab1afa9bf5c",
            "4d9d7aa96b614836b98b16bb455e9117",
            "4a402830b0e2489d824726181ba9951a",
            "347e5d3a6d864596bf9a47e7656a77e1",
            "9476b97685724f61b0ed589312286084",
            "a91630a154804e399b9a2f0668f9d754",
            "952047b4b3a64ea3b47bcf946817c0b9",
            "159521f292e647a082f4cbe8aca634c2",
            "86fb9d0142b04a63b6a22271c05ba089",
            "27cc59f4d8474e22a3e572f1e401d26d",
            "4539202c02814b77b0a8dd03b2acdf29",
            "027fdc06cc46489687f5f3de7c04731d",
            "81803aca4ebd4c05b5915b09d10159ed",
            "71bd9252889e4789a604a1ea18567f11",
            "586b604fe7cc49348e7e5734c8991088",
            "e9dc3da122e94a7f9e31aa4e580b37f2",
            "fad4cc183f5642c68be992ba77690bb8",
            "cb4587fe8569404fbf1c849c0b5265c6",
            "f31f2b76691d4b3890be874e26f72074",
            "05d3df7d7c6e4fc79effd41c912651d2",
            "e1166087e0ea43c0b88dd754f1fd8cdb",
            "73ae64ddd8ef41c9805f35e2e53f8c97",
            "adc34631f7584078adc0946014b2c544",
            "b01e720e269148bfbcb564902e6cfcbd",
            "a2c19a551dfc44449ad28742280d5ac3",
            "444eda94d0ae4bb3b74b49b1a415e228",
            "8d85c971b26d4184a846de2cf3b27082",
            "b4f45cabbc084bcda09d7b2194747b82",
            "34a79d2d965948b5b26c0f04195edf21"
          ]
        },
        "id": "u4bhqC5EHshE",
        "outputId": "b4159334-3385-46ba-e253-399cf3039b0b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2e6ad076da4890b6c650c7857725e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c90ea080b1640eb9a20f4836bec9f34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159521f292e647a082f4cbe8aca634c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f31f2b76691d4b3890be874e26f72074"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original SST-2 sentence.\n",
        "print('Original SST-2 sentence:', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized:', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token IDs.\n",
        "print('Token IDs:', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2ZKSndRID6r",
        "outputId": "6407d008-22a4-45f6-9541-f01b6b2f8d8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SST-2 sentence: hide new secretions from the parental units \n",
            "Tokenized: ['hide', 'new', 'secret', '##ions', 'from', 'the', 'parental', 'units']\n",
            "Token IDs: [5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SST-2 문장들을 토크나이징하고 각 토큰을 ID로 매핑합니다.\n",
        "input_ids = []\n",
        "\n",
        "# 모든 문장에 대해…\n",
        "for sent in sentences:\n",
        "    # `encode`는 다음을 수행합니다:\n",
        "    #   (1) 문장 토크나이징\n",
        "    #   (2) 맨 앞에 `[CLS]` 토큰 추가\n",
        "    #   (3) 문장 끝에 `[SEP]` 토큰 추가\n",
        "    #   (4) 토큰을 ID로 변환\n",
        "    encoded_sent = tokenizer.encode(\n",
        "        sent,                      # 인코딩할 SST-2 문장\n",
        "        add_special_tokens=True,   # '[CLS]'와 '[SEP]' 추가\n",
        "        # (padding/truncation은 이후 단계에서 처리합니다)\n",
        "    )\n",
        "\n",
        "    # 인코딩된 문장을 리스트에 추가\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# 문장 0과 그에 대응하는 토큰 ID를 출력\n",
        "print('Original SST-2 sentence:', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-rZnnGIIIrN",
        "outputId": "bd96ef34-e016-47eb-9791-364dfac19e4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SST-2 sentence: hide new secretions from the parental units \n",
            "Token IDs: [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max sentence length:', max(len(sen) for sen in input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaCjedW6IRyC",
        "outputId": "23d157f9-db13-488c-8069-43cf6f9ca84f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# typical SST-2 sentence length...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence.\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=MAX_LEN,\n",
        "    dtype=\"long\",\n",
        "    value=0,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqLIqsOUInIx",
        "outputId": "37c16cf6-2c60-49b1-88ab-04769d27ae84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks for SST-2\n",
        "attention_masks = []\n",
        "\n",
        "# For each tokenized sentence...\n",
        "for sent in input_ids:\n",
        "    #  - If token ID == 0, it's padding → mask 0\n",
        "    #  - If token ID >  0, it's a real token → mask 1\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "7XuRLEimIouw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1) SST-2 데이터 불러오기 (train / validation / test 분할 포함)\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# 2) pandas DataFrame으로 변환\n",
        "df_train = pd.DataFrame(raw_datasets[\"train\"])\n",
        "df_val   = pd.DataFrame(raw_datasets[\"validation\"])\n",
        "\n",
        "# 3) 문장과 레이블 리스트 생성\n",
        "sentences_train = df_train[\"sentence\"].values\n",
        "labels_train    = df_train[\"label\"].values\n",
        "\n",
        "sentences_val = df_val[\"sentence\"].values\n",
        "labels_val    = df_val[\"label\"].values\n",
        "\n",
        "# 4) 토크나이저 로드(변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "# 5) 토큰화 & 인코딩 (train/val 각각)\n",
        "def encode_sentences(sentences, tokenizer):\n",
        "    input_ids = []\n",
        "    for sent in sentences:\n",
        "        encoded = tokenizer.encode(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "        )\n",
        "        input_ids.append(encoded)\n",
        "    return input_ids\n",
        "\n",
        "train_ids = encode_sentences(sentences_train, tokenizer)\n",
        "val_ids   = encode_sentences(sentences_val, tokenizer)\n",
        "\n",
        "# 6) MAX_LEN을 SST-2 특성에 맞춰 늘리기 (예: 64)\n",
        "MAX_LEN = 10\n",
        "\n",
        "# 7) 패딩/트렁케이트\n",
        "train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=tokenizer.pad_token_id,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "val_ids   = pad_sequences(val_ids,   maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=tokenizer.pad_token_id,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# 8) 어텐션 마스크 생성\n",
        "def make_masks(input_ids):\n",
        "    return [[int(tok_id != tokenizer.pad_token_id) for tok_id in seq]\n",
        "            for seq in input_ids]\n",
        "\n",
        "train_masks = make_masks(train_ids)\n",
        "val_masks   = make_masks(val_ids)\n",
        "\n",
        "# 9) 텐서로 변환\n",
        "train_inputs      = torch.tensor(train_ids)\n",
        "train_labels      = torch.tensor(labels_train)\n",
        "train_attention  = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(val_ids)\n",
        "validation_labels = torch.tensor(labels_val)\n",
        "validation_attention = torch.tensor(val_masks)\n",
        "\n",
        "# 10) DataLoader 준비 (batch_size 등은 SST-2에 맞춰 조정)\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_attention, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(validation_inputs, validation_attention, validation_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "validation_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "1d0725c75a174cdcb9105b621dd8021a",
            "1d3af3c44f0e465dac22a1636c851d1f",
            "0bc3eb2ba77b48998ad0085d93a268f9",
            "e567f86373344169b97e8f5c7fe85d67",
            "f32f48795b2243feb0a6eb088ae05cb4",
            "0f23edbc30174a0b853fe381d0132ffa",
            "75920eeb27314dedbf2cfd9359949cdf",
            "47ea84e6e2694e46a40e0af53386dc41",
            "bff5a431b6424f38acd2acf715f6e04a",
            "5d1cbd83b628452097cdc8676291af38",
            "f1df9f7a30664458bde5a5161728c1bc",
            "e5817f83cd3a4ff1ad5060de4f2a78a3",
            "73b53f037b80484f9b43d01b3040ea98",
            "a0a1e77a1f1a4f3c808fdb44a6a4fcf1",
            "982ae8572b6e4d34b428fb0512432691",
            "17c2f0fe362b46e9b6b93c00a9cced20",
            "2432b508700c4149a9ecf0d9447715dc",
            "baf6f259c4a24eb6949bf59ab86dda1f",
            "32afee2832ab44b98983e4d27bcc7f1a",
            "8159e540caaa4397a03be4c5d8275b59",
            "f0918295773842119971247aefdc0c32",
            "473b0752c2b14c0caf19ca7aa79cf414",
            "7aec7445e2094675b2c22257a3bf059b",
            "56fe9a6d3f9e4cf7acd9fb4b06808937",
            "3390b88cb84c4578a89234bb2b6dfe1a",
            "d0037ee21ed44a6a9e4f95a655d288da",
            "db173055bc954fe5a657e699172c0c8f",
            "4f83f81d70d14cf294b1adef7a778dee",
            "39f565d9f0134ac08068d548c521e706",
            "953d7ac7ec6f4c89a34be7f8e2261099",
            "4036f1b2f82b40ee86d2a51ad5ad31db",
            "7b8bec5f556740c8ba733e38178ea615",
            "874f0fe4a83f4d9cbe6f4143466a6765",
            "ed6d8a5673ac408ba61862c9ca643d57",
            "d2bf3bd05abd4f8c9ab391ee3f368c02",
            "28285800ae7c4d7baa9b99cf0429ab5b",
            "f33c6e30c69a4a52b1bfb6379b789d3d",
            "f65ef88562de4fb8839c5262bb25fde0",
            "84e92af041414a66a8619cbe36956736",
            "0bb22d34b37143748d418337aafcfe72",
            "ab26b138bd334596931de39b0e797336",
            "42ae0eb4ea8c4a3585f495fa10e1db09",
            "ccadea40a2c74070aadafbfdfd06e063",
            "f8d74ab506c640f9af6ab957bae85117",
            "e8044d14bd2c43eea429f995e9899774",
            "fcdaed45afc74d5b825510140b594b91",
            "f768228fc5024f6c813e86e82f3a3705",
            "20ba488f7e0a466c8414904bb4702253",
            "4a8e069016d2495a861296813cf418f4",
            "9c859f30bd1b49da8e52812e00aec443",
            "9ff1f47124f2468f99df5f4fe4b03960",
            "0098582d9bc94b0e91e4faef023392fb",
            "baab82f0c48e460da69de86f9098c25d",
            "3a4b789ff5a44859b60048d7d7aa2a00",
            "dd600a12ae594dc7a7e068eb5f02c649",
            "bfaf6e447e434bbeb38176c8a7cace32",
            "9f3d606dd41045718d5bb62bf82130b4",
            "12f484d91145409b8a04b3843a6f0126",
            "9760b37e6cd546babac5d4e7439f320b",
            "d113ef1e4aaa4175b4c55fec44acef49",
            "ddbf67699f384346b8051d12395e665a",
            "86c787254b4742ae910181bf05daca82",
            "517ad4f0b73149ba9632e967889db768",
            "89cff491c21c494287df03883ab2d05a",
            "8fc8154060ea472aa682a77308a2b537",
            "5211949776a84a639150b2c4992decba",
            "669ba151a72f444eb09ceb59d422a07d",
            "8104f7eeb70d416c891ae7dcc8bd2a2e",
            "dcc51e2ec4144ce8b646aeb67b415115",
            "1e0a84a482bc44789a2ce788477d3124",
            "3a514567c1c243fcb38ac37eba3f0644",
            "270421cab3104900b3978b839aacc680",
            "7f30693ea39b44deb857480044c22321",
            "ea255922c77c4f7aaf057e953938111c",
            "0736bd135d624d64a3f76d0570d311c5",
            "6024844f9e8b412cb21a9bceb200e6ec",
            "b045ee4b9e2a45b2b8603b1ac50f86ff"
          ]
        },
        "id": "EkzyM2DAJGPf",
        "outputId": "bce46778-10ab-456b-b91b-a2f734d0929b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d0725c75a174cdcb9105b621dd8021a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5817f83cd3a4ff1ad5060de4f2a78a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aec7445e2094675b2c22257a3bf059b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed6d8a5673ac408ba61862c9ca643d57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8044d14bd2c43eea429f995e9899774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfaf6e447e434bbeb38176c8a7cace32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "669ba151a72f444eb09ceb59d422a07d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",   # 12-layer BERT, uncased vocab\n",
        "    num_labels=2,          # SST-2 is binary (positive / negative)\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "# Move the model to GPU for training/inference\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973,
          "referenced_widgets": [
            "d1168caceab643aeb6b8816a27ca8244",
            "16da427ff681433fb077081f890b7089",
            "a99f03b1e2be4325804a357039435e6a",
            "5371a45778994b4a825017787aa89a3d",
            "b07d2337b7664253959ff9ea768f0d16",
            "01b35013521b48759fb8c8e18ea2ae72",
            "f8e22bc86a3541839712e9bb59228ed9",
            "2fa5554d67eb40feaa549394c830ef95",
            "f39c132a7c1141079ae838605a01d0eb",
            "15153ca406f74fa78d76cf9a34faab5f",
            "dc90848a125d4e66a30ad0e71c6112bd"
          ]
        },
        "id": "XvdsETdaKLrY",
        "outputId": "ee645989-d59c-41d8-ded5-3776eeaa34f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1168caceab643aeb6b8816a27ca8244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-fetch params to be sure\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print(f\"The SST-2 fine-tuned BERT model has {len(params)} named parameters.\\n\")\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for name, tensor in params[0:5]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")\n",
        "\n",
        "print('\\n==== First Transformer Layer ====\\n')\n",
        "for name, tensor in params[5:21]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for name, tensor in params[-4:]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwHACT1RKb5z",
        "outputId": "ac9395f6-f78f-45ff-e68f-aa26a0cdb077"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The SST-2 fine-tuned BERT model has 201 named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer Layer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for fine-tuning on SST-2.\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,   # learning rate commonly used for SST-2 fine-tuning\n",
        "    eps=1e-8   # Adam epsilon\n",
        ")"
      ],
      "metadata": {
        "id": "dTbHb8NeKhfo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs for SST-2 (authors recommend ~3)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,         # run_glue.py 기본값\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "-0__rGtHLJ9I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our SST-2 predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "UZdM1oxQLxMW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    \"\"\"\n",
        "    소요 시간을 초 단위로 받아서 'hh:mm:ss' 형식의 문자열로 반환합니다.\n",
        "    SST-2 GLUE 미세조정(training/evaluation) 로그 출력에 사용하세요.\n",
        "    \"\"\"\n",
        "    # 초 단위로 반올림\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    # 'hh:mm:ss' 포맷으로 변환\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "ABNueEAPL-25"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 재현 가능성을 위해 시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 에폭별 평균 손실 기록용\n",
        "loss_values = []\n",
        "\n",
        "# 에폭 수는 앞서 설정한 epochs 변수 사용\n",
        "for epoch_i in range(epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training (SST-2)\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(f'======== SST-2 Epoch {epoch_i+1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and step != 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'  Batch {step:>5,} of {len(train_dataloader):>5,}. Elapsed: {elapsed}')\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass (SST-2는 binary label)\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(f\"  Training epoch took: {format_time(time.time() - t0)}\")\n",
        "\n",
        "    # ========================================\n",
        "    #             Validation (SST-2)\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "            logits = outputs[0].detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            preds = np.argmax(logits, axis=1)\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(label_ids)\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"  Validation took: {format_time(time.time() - t0)}\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"SST-2 fine-tuning complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPBQtpWdMa-T",
        "outputId": "0f896e12-b549-4516-9a78-d7a5cca4724b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== SST-2 Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:04\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:07\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:10\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:13\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:16\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:18\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:21\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:24\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:27\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:30\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:33\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:36\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:39\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:42\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:44\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:47\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:50\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:53\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:56\n",
            "  Batch   800 of 2,105. Elapsed: 0:00:59\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:02\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:05\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:08\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:10\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:13\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:16\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:19\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:22\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:25\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:28\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:31\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:34\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:36\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:39\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:42\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:45\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:48\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:51\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:54\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:01:57\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:02:00\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:02\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:05\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:08\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:11\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:14\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:17\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:20\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:23\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:25\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:28\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:02:33\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7890\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== SST-2 Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:03\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:06\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:09\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:12\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:14\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:17\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:20\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:23\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:26\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:29\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:32\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:35\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:38\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:40\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:43\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:46\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:49\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:52\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:55\n",
            "  Batch   800 of 2,105. Elapsed: 0:00:58\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:01\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:04\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:06\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:09\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:12\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:15\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:18\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:21\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:24\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:27\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:30\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:32\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:35\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:38\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:41\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:44\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:47\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:50\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:53\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:01:56\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:01:58\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:01\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:04\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:07\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:10\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:13\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:16\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:19\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:22\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:24\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:27\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:30\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:02:32\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7810\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== SST-2 Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:03\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:06\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:09\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:12\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:14\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:17\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:20\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:23\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:26\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:29\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:32\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:35\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:38\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:40\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:43\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:46\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:49\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:52\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:55\n",
            "  Batch   800 of 2,105. Elapsed: 0:00:58\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:01\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:04\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:06\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:09\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:12\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:15\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:18\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:21\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:24\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:27\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:30\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:32\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:35\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:38\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:41\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:44\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:47\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:50\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:53\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:01:56\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:01:58\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:01\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:04\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:07\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:10\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:13\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:16\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:19\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:22\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:24\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:27\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:30\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 0:02:32\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7878\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "SST-2 fine-tuning complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 스타일 설정 (Seaborn)\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# SST-2 학습 손실 곡선 그리기\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# 축 레이블 및 제목\n",
        "plt.title(\"SST-2 Fine-tuning Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Epoch 번호 표시\n",
        "plt.xticks(range(1, len(loss_values) + 1))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "awFGag7vOW9s",
        "outputId": "6e283321-3114-4100-9ba2-dcae931c7ac1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, SequentialSampler, DataLoader\n",
        "\n",
        "# SST-2 validation split을 pandas DataFrame으로 변환\n",
        "df = pd.DataFrame(raw_datasets['validation'])\n",
        "\n",
        "# 문장 수 출력\n",
        "print('Number of validation sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# 문장과 레이블 리스트 생성\n",
        "sentences = df['sentence'].values\n",
        "labels    = df['label'].values\n",
        "\n",
        "# 토크나이징 및 ID 매핑\n",
        "input_ids = []\n",
        "for sent in sentences:\n",
        "    encoded = tokenizer.encode(\n",
        "        sent,\n",
        "        add_special_tokens=True  # [CLS], [SEP] 추가\n",
        "    )\n",
        "    input_ids.append(encoded)\n",
        "\n",
        "# 패딩/트렁케이팅\n",
        "input_ids = pad_sequences(\n",
        "    input_ids, maxlen=MAX_LEN,\n",
        "    dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        ")\n",
        "\n",
        "# Attention mask 생성 (0=패딩, 1=실제 토큰)\n",
        "attention_masks = [\n",
        "    [float(i > 0) for i in seq]\n",
        "    for seq in input_ids\n",
        "]\n",
        "\n",
        "# 텐서로 변환\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks  = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# DataLoader 구성\n",
        "batch_size = 32\n",
        "prediction_data    = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, sampler=prediction_sampler, batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPGXVkwrOzeu",
        "outputId": "2b9f1bc5-6e39-42a8-de0c-de6ac966fe3d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation sentences: 872\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SST-2 검증(validation) 셋에 대한 예측 수행\n",
        "print('Predicting labels for {:,} validation sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# 모델을 평가 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 예측값과 실젯값 저장용\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "# 배치 단위로 예측 수행\n",
        "for batch in prediction_dataloader:\n",
        "    # GPU로 배치 옮기기\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # 그래디언트 계산 하지 않음\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            token_type_ids=None,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 옮기고 numpy로 변환\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 저장\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7G8bwDMO17R",
        "outputId": "ce450687-8769-426e-97e1-bcabfdc5bc81"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 872 validation sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = df.label.sum()\n",
        "total = len(df)\n",
        "pct = pos / total * 100.0\n",
        "\n",
        "print('Positive samples: %d of %d (%.2f%%)' % (pos, total, pct))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKW1ZX9O4Sm",
        "outputId": "e8b1edfc-15a8-440a-f9e1-50ddabe713cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 444 of 872 (50.92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "import numpy as np\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# SST-2 테스트 배치별 Matthews 상관계수 계산\n",
        "print('Calculating Matthews Corr. Coef. for each SST-2 test batch...')\n",
        "\n",
        "# predictions: 리스트 of ndarray [batch_size, 2], true_labels: 리스트 of ndarray [batch_size]\n",
        "for i in range(len(true_labels)):\n",
        "    # logits에서 가장 큰 클래스를 예측 레이블로 선택\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    # 해당 배치의 MCC 계산\n",
        "    mcc = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "    matthews_set.append(mcc)\n",
        "\n",
        "# 결과 출력\n",
        "print('Batch-wise MCCs:', ['{:.4f}'.format(m) for m in matthews_set])\n",
        "print('Average MCC       : {:.4f}'.format(np.mean(matthews_set)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuh9uwiyO7hr",
        "outputId": "b6a793cd-7ec1-4e39-811d-e813878f2781"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each SST-2 test batch...\n",
            "Batch-wise MCCs: ['0.5602', '0.7490', '0.3907', '0.5040', '0.5040', '0.3830', '0.6256', '0.6113', '0.4454', '0.6218', '0.6455', '0.6256', '0.5220', '0.8076', '0.7460', '0.7984', '0.5727', '0.6386', '0.4732', '0.6299', '0.7559', '0.4606', '0.5068', '0.2793', '0.5068', '0.6953', '0.5040', '0.7746']\n",
            "Average MCC       : 0.5835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# … (위에서 matthews_set을 계산한 뒤)\n",
        "\n",
        "# SST-2 배치별 MCC 출력\n",
        "print(\"배치별 Matthews CorrCoef:\", [\"{:.4f}\".format(m) for m in matthews_set])\n",
        "\n",
        "# 평균 MCC 계산 및 출력\n",
        "avg_mcc = np.mean(matthews_set)\n",
        "print(\"평균 Matthews CorrCoef : {:.4f}\".format(avg_mcc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1u4UaBaO9si",
        "outputId": "e41bbfcf-ad46-4261-956e-3b8361382155"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "배치별 Matthews CorrCoef: ['0.5602', '0.7490', '0.3907', '0.5040', '0.5040', '0.3830', '0.6256', '0.6113', '0.4454', '0.6218', '0.6455', '0.6256', '0.5220', '0.8076', '0.7460', '0.7984', '0.5727', '0.6386', '0.4732', '0.6299', '0.7559', '0.4606', '0.5068', '0.2793', '0.5068', '0.6953', '0.5040', '0.7746']\n",
            "평균 Matthews CorrCoef : 0.5835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# 1) 모든 배치의 logits를 하나의 배열로 합치고, 각 샘플의 예측 라벨(0 또는 1) 생성\n",
        "all_logits = np.vstack(predictions)               # shape = [num_batches*batch_size, 2]\n",
        "flat_predictions = np.argmax(all_logits, axis=1)  # [num_samples]\n",
        "\n",
        "# 2) 모든 배치의 실제 레이블을 하나의 배열로 합치기\n",
        "flat_true_labels = np.concatenate(true_labels)    # [num_samples]\n",
        "\n",
        "# 3) SST-2 테스트 세트에 대한 MCC 계산 및 출력\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "print(f\"SST-2 Test MCC: {mcc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3ZE1-FqO_1A",
        "outputId": "2d5f6bd0-6ff1-4bb0-f52c-869d86db7901"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST-2 Test MCC: 0.577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST-2 _ 2번째"
      ],
      "metadata": {
        "id": "lZWWYC0LlVaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 필수 라이브러리 설치/업그레이드\n",
        "!pip install --upgrade --quiet transformers datasets evaluate\n",
        "\n",
        "# 2) 임포트\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "# 3) 데이터셋 로드 & 토크나이저 준비\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
        "checkpoint    = \"bert-base-uncased\"\n",
        "tokenizer     = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# 4) 토크나이징 함수 정의\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"sentence\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # optional: 고정 길이 패딩\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# 5) 데이터 전처리 (map → remove → rename → set_format 분리)\n",
        "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")  # ← in-place, 반환값이 None이 아님\n",
        "\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "eval_dataset  = tokenized_datasets[\"validation\"]\n",
        "\n",
        "# 6) 평가 메트릭 정의\n",
        "metric = evaluate.load(\"glue\", \"sst2\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "# 7) 모델 로드\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint, num_labels=2\n",
        ")\n",
        "\n",
        "# 8) TrainingArguments 설정 (구버전 호환)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"sst2-output\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=500,\n",
        "    eval_steps=500,\n",
        "    logging_dir=\"logs\",\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "# 9) Trainer 생성\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 10) 학습 및 평가\n",
        "trainer.train()\n",
        "results = trainer.evaluate()\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c247134ebd8b4087be8906b1a113645e",
            "10e4e0df17244c0890623da94c6c2d28",
            "baaa36739ced47c18b55a4a0485284f7",
            "58ec4fefccc04c0cb893226f7557d304",
            "5433d77215b7439bb0ad31b82eff7da3",
            "005248a8a1984ced9d2bda47760bfdba",
            "2cdf1771553e40b089c5b3ab9944eeae",
            "251a141e8e5a484fb0da25c706d24183",
            "ddabd03e49954f8389da2d4826468fb1",
            "b473f1b04f57489a8f6441f5089043b7",
            "2462422285e14563a676c0b43e8c74a1"
          ]
        },
        "id": "DcamudZsgs6W",
        "outputId": "4b25a8d0-c42f-4854-949d-659bd276f59b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c247134ebd8b4087be8906b1a113645e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-3-f3a8b77761f3>:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12630' max='12630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12630/12630 35:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.332900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.226100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.210700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.185200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.142400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.122300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.119200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.109200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.082200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28/28 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.3760058283805847, 'eval_accuracy': 0.9220183486238532, 'eval_runtime': 2.8612, 'eval_samples_per_second': 304.766, 'eval_steps_per_second': 9.786, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) Trainer.evaluate() 와 비슷하지만, predict() 는 예측값(predictions)도 같이 반환합니다.\n",
        "pred_output = trainer.predict(eval_dataset)\n",
        "\n",
        "# pred_output 는 PredictionOutput(predictions, label_ids, metrics) 형태입니다.\n",
        "logits    = pred_output.predictions      # shape: (num_examples, num_labels)\n",
        "labels    = pred_output.label_ids         # shape: (num_examples,)\n",
        "metrics   = pred_output.metrics          # accuracy 등\n",
        "\n",
        "# (2) 예측 라벨로 변환\n",
        "import numpy as np\n",
        "preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "# (3) 결과 출력\n",
        "print(f\"Accuracy: {metrics['test_accuracy']:.4f}\")  # SST-2 기준\n",
        "print(f\"Loss:     {metrics['test_loss']:.4f}\")\n"
      ],
      "metadata": {
        "id": "qe-PR73ms0Fd",
        "outputId": "04dee4bb-0c93-4c1d-e846-c15fed1a9bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9106\n",
            "Loss:     0.2456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"sentence\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # 문장이 짧으면 뒤를 0(tokenizer.pad_token_id)로 패딩\n",
        "        max_length=128  # 최대 10토큰\n",
        "    )\n",
        "\n",
        "# 2) 데이터셋 재맵핑\n",
        "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "eval_dataset  = tokenized_datasets[\"validation\"]\n"
      ],
      "metadata": {
        "id": "OGK_7OBIsq2B",
        "outputId": "bb671500-94da-4e38-d5d3-f593afa2beb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9bcfe257ad8a46d0a6ba4bbb4a67e91e",
            "64a434022a614a8da6fd19d1d59ef55b",
            "b3c3011bc9b540e78ec0e9d67e3f1eb3",
            "8c3466c637d449aab43a921e21b2e19d",
            "78796feccd1b48c4987e5a72b6615318",
            "71717822f528491b9d052cb58278febc",
            "87375f6f5c1e44e985cfa68bbb4069eb",
            "c241c9423e7e4446afd98f38d293f764",
            "97eb5b3f258b46fda3678aca83699a79",
            "c9020c66142f48f79bdb46bf2210deff",
            "1b3c68dc12034f73ac6e23127635b2a3"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bcfe257ad8a46d0a6ba4bbb4a67e91e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST - 2  적용"
      ],
      "metadata": {
        "id": "YvtIdiYRP9QG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "# 1) CORDIC-Softmax이 적용된 SelfAttention 정의\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. [B,12,L,L]\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            # row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n",
        "\n",
        "# 2) SST-2용 BERT 모델 로드 (이미 fine-tuned 체크포인트가 있다면 그걸로)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",  # 또는 ./sst2_output 같은 로컬 경로\n",
        "    num_labels=2\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 3) 각 레이어의 self-attention을 패치\n",
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    mod  = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 그대로 복사\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n",
        "\n",
        "print(\"Self-Attention modules after patch:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    print(f\" Layer {i:2d}: {layer.attention.self.__class__.__name__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpUxcH-AP8LF",
        "outputId": "56c3daa3-a970-422a-af84-7f2e5b22f52b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-Attention modules after patch:\n",
            " Layer  0: BertSelfAttentionModified\n",
            " Layer  1: BertSelfAttentionModified\n",
            " Layer  2: BertSelfAttentionModified\n",
            " Layer  3: BertSelfAttentionModified\n",
            " Layer  4: BertSelfAttentionModified\n",
            " Layer  5: BertSelfAttentionModified\n",
            " Layer  6: BertSelfAttentionModified\n",
            " Layer  7: BertSelfAttentionModified\n",
            " Layer  8: BertSelfAttentionModified\n",
            " Layer  9: BertSelfAttentionModified\n",
            " Layer 10: BertSelfAttentionModified\n",
            " Layer 11: BertSelfAttentionModified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "# 1) 각 레이어의 Self-Attention 모듈 클래스 확인\n",
        "print(\"== Self-Attention Modules ==\")\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "print(\"=============================\\n\")\n",
        "\n",
        "# 2) 모델 클래스 이름 확인 (Cordic 패치된 SST-2용 버전이어야 함)\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "#    → 예: BertForSequenceClassificationCordic\n",
        "\n",
        "# 3) forward 메서드가 서브클래스에서 오버라이드된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "#    → 예: BertForSequenceClassificationCordic.forward\n",
        "\n",
        "# 4) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH1ZcdEZQUO8",
        "outputId": "c05e0cee-97ee-4da0-9dd1-b8ad3630f624"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "=============================\n",
            "\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass: 마지막 레이어 어텐션 가중치까지 출력하도록 설정\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,                # SST-2 validation batch의 input_ids\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True      # 모든 레이어의 attention_probs를 리턴\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 12번째(=마지막) 레이어의 attention_probs만 꺼내기\n",
        "all_attentions = outputs.attentions    # 길이 12인 tuple, each is [B, H, L, L]\n",
        "last_layer_probs = all_attentions[-1]  # [B, H, L, L]\n",
        "\n",
        "# 3) “키” 차원(L)에 대해 합이 1인지 검사\n",
        "#    sums.shape == [B, H, L]\n",
        "sums = last_layer_probs.sum(dim=-1)\n",
        "print(\"마지막 레이어 어텐션 확률 합 (shape={}):\\n{}\".format(sums.shape, sums))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "6lQtyK9YQWtY",
        "outputId": "2fdc4d03-28a9-4ac2-c5bc-77038861967f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'b_input_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fd4845bcbc6c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     outputs = model(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0;31m# SST-2 validation batch의 input_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m      \u001b[0;31m# 모든 레이어의 attention_probs를 리턴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b_input_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation_sst2(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "    # tqdm으로 진행 상황 표시\n",
        "    for batch in tqdm(validation_dataloader, desc=\"Validating\"):\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "        # forward\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "        logits = outputs[0]            # [B, 2]\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(logits, b_labels)\n",
        "        eval_loss += loss.item()\n",
        "\n",
        "        # preds & labels\n",
        "        preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "        labels = b_labels.detach().cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # 평균 지표\n",
        "    avg_loss    = eval_loss / nb_eval_steps\n",
        "    avg_acc     = np.mean(np.array(all_preds) == np.array(all_labels))  # 0~1\n",
        "    mcc         = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # positive 비율\n",
        "    pos_pred_ratio = 100.0 * np.sum(all_preds) / len(all_preds)\n",
        "    pos_true_ratio = 100.0 * np.sum(all_labels) / len(all_labels)\n",
        "\n",
        "    # 출력\n",
        "    print(f\"\\nValidation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision          : {precision*100:.2f}%\")\n",
        "    print(f\"Recall             : {recall*100:.2f}%\")\n",
        "    print(f\"F1-score           : {f1*100:.2f}%\")\n",
        "    print(f\"Predicted Positive 비율: {pos_pred_ratio:.2f}%\")\n",
        "    print(f\"Actual   Positive 비율: {pos_true_ratio:.2f}%\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"accuracy\": avg_acc,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"pred_pos_ratio\": pos_pred_ratio,\n",
        "        \"true_pos_ratio\": pos_true_ratio,\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation_sst2(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "ucbY_j5UQnGi",
        "outputId": "cea3cdd1-589d-4ee5-bb81-1e5f63c59c8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'validation_dataloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f3faa474590f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# 사용 예시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation_sst2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_dataloader' is not defined"
          ]
        }
      ]
    }
  ]
}