{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21647f650e8642afaa150c4a31a9f56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2e51646d0724c6b84e4cc3047ed3e0e",
              "IPY_MODEL_1bea68bb306748c3abe9a1a7951d3cf8",
              "IPY_MODEL_4057fad4547546399720164e21c94721"
            ],
            "layout": "IPY_MODEL_ec42f719294c425ca1a8b63582a0b117"
          }
        },
        "f2e51646d0724c6b84e4cc3047ed3e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5cc5a7810248fdb02d3757e8342a47",
            "placeholder": "​",
            "style": "IPY_MODEL_d97b55b02c6349e5a75226385923daa9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1bea68bb306748c3abe9a1a7951d3cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da9a9c6d4d7e404f95c408db13f49de1",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb13b3ed78ee4fb5989a9733be32cc8c",
            "value": 48
          }
        },
        "4057fad4547546399720164e21c94721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0893228bcb3424f854491fc4582c20f",
            "placeholder": "​",
            "style": "IPY_MODEL_c249737b8f524e3885269bb49b9693f3",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.11kB/s]"
          }
        },
        "ec42f719294c425ca1a8b63582a0b117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5cc5a7810248fdb02d3757e8342a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97b55b02c6349e5a75226385923daa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da9a9c6d4d7e404f95c408db13f49de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb13b3ed78ee4fb5989a9733be32cc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0893228bcb3424f854491fc4582c20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c249737b8f524e3885269bb49b9693f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9f222533264388bf7eef8e7cf8f23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_297bb25e012c4c09942f882920f8cf8b",
              "IPY_MODEL_f7e65943daac40b3825e73ed57048a2f",
              "IPY_MODEL_23da79cb7a8045a2869af10cdf206175"
            ],
            "layout": "IPY_MODEL_a3a4deffe3a64e6aa3c894badfa07e31"
          }
        },
        "297bb25e012c4c09942f882920f8cf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595e071b805b4b1b9d89feb6b57082ee",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa9d4590bb94ccdbfbdb9ad33613c43",
            "value": "vocab.txt: 100%"
          }
        },
        "f7e65943daac40b3825e73ed57048a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_867f2b9ef2bb4749bd543b6949013c39",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4688741ae333403585031546f91449a4",
            "value": 231508
          }
        },
        "23da79cb7a8045a2869af10cdf206175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6f9cc78548427cac3b632bacc7058d",
            "placeholder": "​",
            "style": "IPY_MODEL_956fb7a85f2648fe95d92ae89ab7fa51",
            "value": " 232k/232k [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "a3a4deffe3a64e6aa3c894badfa07e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595e071b805b4b1b9d89feb6b57082ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa9d4590bb94ccdbfbdb9ad33613c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867f2b9ef2bb4749bd543b6949013c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4688741ae333403585031546f91449a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de6f9cc78548427cac3b632bacc7058d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956fb7a85f2648fe95d92ae89ab7fa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d71fa82b4804f888a17feb29c3da915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc22f02bba374f35bc9224c6e8043628",
              "IPY_MODEL_f88c4f08a90745e6957099c79a0ce55a",
              "IPY_MODEL_89b9427dce014ef784debe3a476afb38"
            ],
            "layout": "IPY_MODEL_b2fbcafba6d344e0ba465a7b94ac4075"
          }
        },
        "fc22f02bba374f35bc9224c6e8043628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9e647e17314008bdef689dfc806d99",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b92019c1bb4b15bdcabca6ea46fef7",
            "value": "tokenizer.json: 100%"
          }
        },
        "f88c4f08a90745e6957099c79a0ce55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64cfd6a45214e79a11d190950de1da7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b6d57e400c948efae7d8b39bbd3b1a3",
            "value": 466062
          }
        },
        "89b9427dce014ef784debe3a476afb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccacbcc6fc5d4bbd8270ebd73e1c9eaa",
            "placeholder": "​",
            "style": "IPY_MODEL_e563e154deac4398804263303a046083",
            "value": " 466k/466k [00:00&lt;00:00, 42.8MB/s]"
          }
        },
        "b2fbcafba6d344e0ba465a7b94ac4075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9e647e17314008bdef689dfc806d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b92019c1bb4b15bdcabca6ea46fef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64cfd6a45214e79a11d190950de1da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6d57e400c948efae7d8b39bbd3b1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccacbcc6fc5d4bbd8270ebd73e1c9eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e563e154deac4398804263303a046083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51466319aeb748c99a39a40240cad178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffd094ec7f5e43a9b42eca730cc10c5e",
              "IPY_MODEL_5ab71a52aa0442d09e20e2a88b73113b",
              "IPY_MODEL_ad5ea0b1b46749008d1d415156d5d38b"
            ],
            "layout": "IPY_MODEL_b4ef36bca9a649cfaa85fb4743b0a23d"
          }
        },
        "ffd094ec7f5e43a9b42eca730cc10c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ecaba034ea4aa18424ebf59caccf45",
            "placeholder": "​",
            "style": "IPY_MODEL_614278161a054032844b3b0918bac1f3",
            "value": "config.json: 100%"
          }
        },
        "5ab71a52aa0442d09e20e2a88b73113b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55db5ffe7c8143138cc1d25fce57cb9e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_229c75c52d564ecfa718ad70261a43b8",
            "value": 570
          }
        },
        "ad5ea0b1b46749008d1d415156d5d38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca9f2deb9254ab88e5efc018da79a84",
            "placeholder": "​",
            "style": "IPY_MODEL_b11d538b51c442e4af7b404b8f8a5367",
            "value": " 570/570 [00:00&lt;00:00, 74.6kB/s]"
          }
        },
        "b4ef36bca9a649cfaa85fb4743b0a23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ecaba034ea4aa18424ebf59caccf45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614278161a054032844b3b0918bac1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55db5ffe7c8143138cc1d25fce57cb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229c75c52d564ecfa718ad70261a43b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca9f2deb9254ab88e5efc018da79a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11d538b51c442e4af7b404b8f8a5367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ba5169307c45508f5847f1daeb76d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f81394a29604411a0e01e7affead432",
              "IPY_MODEL_39722a94be4f4a14af1ddaf63e6639b7",
              "IPY_MODEL_cbe94b0dd40a4ae8abf89d5e7202d506"
            ],
            "layout": "IPY_MODEL_c2fbf7998e9b44cdbdf148cef0c1ebae"
          }
        },
        "7f81394a29604411a0e01e7affead432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89c19f933d24a6c8c6ece0495078a13",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0e64e34f864657965c20c781b9eeeb",
            "value": "model.safetensors: 100%"
          }
        },
        "39722a94be4f4a14af1ddaf63e6639b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68eaac5671b64634ab7d55f728f43b99",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43435ed194974628ada06eb473fb46b2",
            "value": 440449768
          }
        },
        "cbe94b0dd40a4ae8abf89d5e7202d506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54c1c33d0fd438ab2f7274dd8a8304a",
            "placeholder": "​",
            "style": "IPY_MODEL_9726a149fcb44b0882884c346a3cdf8a",
            "value": " 440M/440M [00:01&lt;00:00, 256MB/s]"
          }
        },
        "c2fbf7998e9b44cdbdf148cef0c1ebae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89c19f933d24a6c8c6ece0495078a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0e64e34f864657965c20c781b9eeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68eaac5671b64634ab7d55f728f43b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43435ed194974628ada06eb473fb46b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f54c1c33d0fd438ab2f7274dd8a8304a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9726a149fcb44b0882884c346a3cdf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db021d937c514dabaf2daede273b247c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_865d6210566a4efb83203585d12f3816",
              "IPY_MODEL_3f71cc4a0bb44b4e95c31ff3a2bbd227",
              "IPY_MODEL_06dc2e48fc394c94ace9299835e37642"
            ],
            "layout": "IPY_MODEL_2e88994e249048a6b20be16828491201"
          }
        },
        "865d6210566a4efb83203585d12f3816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4832a2a48fbc4a9ba030b68ecdc3c1f8",
            "placeholder": "​",
            "style": "IPY_MODEL_1e1dadb5518448359b4feb3254c39a39",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3f71cc4a0bb44b4e95c31ff3a2bbd227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b8dcd67aaf457493b008554489d4e7",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22f345b309944bbe82e6b1028b79c9ae",
            "value": 48
          }
        },
        "06dc2e48fc394c94ace9299835e37642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_437571621f7b4c3688a746c801eb5225",
            "placeholder": "​",
            "style": "IPY_MODEL_c97f03d542fb476897322ece560c79d2",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.41kB/s]"
          }
        },
        "2e88994e249048a6b20be16828491201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4832a2a48fbc4a9ba030b68ecdc3c1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1dadb5518448359b4feb3254c39a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b8dcd67aaf457493b008554489d4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f345b309944bbe82e6b1028b79c9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "437571621f7b4c3688a746c801eb5225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97f03d542fb476897322ece560c79d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb7c130287f43958c479930d7a71801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fed72dc0b8744c681bc1631646ffebf",
              "IPY_MODEL_3a78229810704aa2ab59f0fb6db9edee",
              "IPY_MODEL_707224129a724fe0a52bca2603bdd18a"
            ],
            "layout": "IPY_MODEL_ae5bb9fac9344b2b8904d2fd435abe29"
          }
        },
        "7fed72dc0b8744c681bc1631646ffebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0a11d9fffb472cb309044744b86130",
            "placeholder": "​",
            "style": "IPY_MODEL_e46194ee37a84452b0268c61589c740d",
            "value": "vocab.txt: 100%"
          }
        },
        "3a78229810704aa2ab59f0fb6db9edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804f6624d6ff4ee4ab370c446714e7f0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89fa207ed5574863a3ba26d48fe5539b",
            "value": 231508
          }
        },
        "707224129a724fe0a52bca2603bdd18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_216b3f9768c247cdb896001a58373473",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa3b5abbbc54073922c3bd23fc9d14b",
            "value": " 232k/232k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "ae5bb9fac9344b2b8904d2fd435abe29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0a11d9fffb472cb309044744b86130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46194ee37a84452b0268c61589c740d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "804f6624d6ff4ee4ab370c446714e7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fa207ed5574863a3ba26d48fe5539b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "216b3f9768c247cdb896001a58373473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa3b5abbbc54073922c3bd23fc9d14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d9b3bb7b55d4f43982f5479843a0e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_363817c3578043fc962cece775f34dd1",
              "IPY_MODEL_561e41f7d4184524be1244890f618506",
              "IPY_MODEL_171adea36b7c488fb59ede737ee75b24"
            ],
            "layout": "IPY_MODEL_3a917229e9854c66bfaa2bff4265f219"
          }
        },
        "363817c3578043fc962cece775f34dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab7047752874943b5ac4d1b89a06647",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ca552323734ceabef0666b95f8bdec",
            "value": "tokenizer.json: 100%"
          }
        },
        "561e41f7d4184524be1244890f618506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835572a66ddc4f729bb9d696c8118955",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bc9ab062bd74ed79ff861e303ec1677",
            "value": 466062
          }
        },
        "171adea36b7c488fb59ede737ee75b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8261622693e4b9f8b55f85944b5421c",
            "placeholder": "​",
            "style": "IPY_MODEL_556768f9f5734b1e9aaa6743344bd6ab",
            "value": " 466k/466k [00:00&lt;00:00, 723kB/s]"
          }
        },
        "3a917229e9854c66bfaa2bff4265f219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab7047752874943b5ac4d1b89a06647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ca552323734ceabef0666b95f8bdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835572a66ddc4f729bb9d696c8118955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc9ab062bd74ed79ff861e303ec1677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8261622693e4b9f8b55f85944b5421c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556768f9f5734b1e9aaa6743344bd6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a65373e47c421bb3a0050251089278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_443f0a71356648c8b9a79415c0f1a3bf",
              "IPY_MODEL_4c54365bd6e24486a841770ab9ab93df",
              "IPY_MODEL_f98a539f0e2448bca778740a52669c04"
            ],
            "layout": "IPY_MODEL_78f78ead30d34016936329073bfcfff3"
          }
        },
        "443f0a71356648c8b9a79415c0f1a3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41443af6da3346dcb5f53e0e426b70ca",
            "placeholder": "​",
            "style": "IPY_MODEL_a84b8d83e8c34cfca3271b96ce90fb25",
            "value": "config.json: 100%"
          }
        },
        "4c54365bd6e24486a841770ab9ab93df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4795324fae4e71a1e3d50e878c8b12",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2c8a0615004423db97131065abfb8c7",
            "value": 570
          }
        },
        "f98a539f0e2448bca778740a52669c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111839d773924095a897cf17ff1463d9",
            "placeholder": "​",
            "style": "IPY_MODEL_b76f4b90a9524408be7c5cedac4934bb",
            "value": " 570/570 [00:00&lt;00:00, 69.8kB/s]"
          }
        },
        "78f78ead30d34016936329073bfcfff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41443af6da3346dcb5f53e0e426b70ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84b8d83e8c34cfca3271b96ce90fb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad4795324fae4e71a1e3d50e878c8b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c8a0615004423db97131065abfb8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "111839d773924095a897cf17ff1463d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76f4b90a9524408be7c5cedac4934bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a5840e2df6348eca02447bfedea0649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99ca06b117eb4c6dad415965568cdcf6",
              "IPY_MODEL_83220f19b635412eab682cab5bc720ae",
              "IPY_MODEL_c5497ed0fcf04257a2726a9ee2bc3733"
            ],
            "layout": "IPY_MODEL_cd356a7de7574d358e12140ed24c13a3"
          }
        },
        "99ca06b117eb4c6dad415965568cdcf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf342b938a64f85b1961a0ee38d5ff3",
            "placeholder": "​",
            "style": "IPY_MODEL_9bed66be81a94fe6a3e54ad07ae0d230",
            "value": "README.md: 100%"
          }
        },
        "83220f19b635412eab682cab5bc720ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b849200754c542c4a07cc2aa9541684d",
            "max": 35296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a604f1a88da04b7f89e81ec650474b4d",
            "value": 35296
          }
        },
        "c5497ed0fcf04257a2726a9ee2bc3733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92986ddb08b45cd8111e737e8c2e8f2",
            "placeholder": "​",
            "style": "IPY_MODEL_5ab4c768da444e47b9f0cd3870c61482",
            "value": " 35.3k/35.3k [00:00&lt;00:00, 4.25MB/s]"
          }
        },
        "cd356a7de7574d358e12140ed24c13a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf342b938a64f85b1961a0ee38d5ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bed66be81a94fe6a3e54ad07ae0d230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b849200754c542c4a07cc2aa9541684d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a604f1a88da04b7f89e81ec650474b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d92986ddb08b45cd8111e737e8c2e8f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab4c768da444e47b9f0cd3870c61482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6aa31d2b4f4443b0a2fcb95bef0638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_417f83983a7f4e8686b219014ba681d8",
              "IPY_MODEL_9e234e3a448140b38652178278fe6dd9",
              "IPY_MODEL_9f0605d2083e443791e57a9019f186c9"
            ],
            "layout": "IPY_MODEL_f3ff5873e76e42cabf94e3e85a75da0a"
          }
        },
        "417f83983a7f4e8686b219014ba681d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160e87ba3479427385ce87c98afc1110",
            "placeholder": "​",
            "style": "IPY_MODEL_00bf30774c98423a857639c2b0a6b014",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "9e234e3a448140b38652178278fe6dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e218a9050ca94de2ad05f7c148a09871",
            "max": 3110468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_444d93f64e8845dab6e1c6608dc7eb22",
            "value": 3110468
          }
        },
        "9f0605d2083e443791e57a9019f186c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42ef029a158c479f9467151d18fdc3d0",
            "placeholder": "​",
            "style": "IPY_MODEL_41bc09022acb46cc801934cbb561c703",
            "value": " 3.11M/3.11M [00:00&lt;00:00, 99.8MB/s]"
          }
        },
        "f3ff5873e76e42cabf94e3e85a75da0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160e87ba3479427385ce87c98afc1110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00bf30774c98423a857639c2b0a6b014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e218a9050ca94de2ad05f7c148a09871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444d93f64e8845dab6e1c6608dc7eb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42ef029a158c479f9467151d18fdc3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bc09022acb46cc801934cbb561c703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab664ecc8ab483fa07277c82e74eec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca81668fb22f4a43b821d002e5753e08",
              "IPY_MODEL_410a8c52d526421cb0afe57c6bd4a41a",
              "IPY_MODEL_fe12f25534a74dd8856378f0fb0fb71b"
            ],
            "layout": "IPY_MODEL_6f20a96100a64a578f7cac3da14a7775"
          }
        },
        "ca81668fb22f4a43b821d002e5753e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59ec14eac0b4865a6cb934978072678",
            "placeholder": "​",
            "style": "IPY_MODEL_8655ce3293e741f9af9400606c57d17f",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "410a8c52d526421cb0afe57c6bd4a41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a001929b6d4df18177de6d952c5767",
            "max": 72819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_394f8096276d4284a8ff5521914c3c63",
            "value": 72819
          }
        },
        "fe12f25534a74dd8856378f0fb0fb71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1f79a6cc8542ceb7a3f3e3fbef1fac",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c52edee3fe4be38dad81272fccb104",
            "value": " 72.8k/72.8k [00:00&lt;00:00, 7.73MB/s]"
          }
        },
        "6f20a96100a64a578f7cac3da14a7775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59ec14eac0b4865a6cb934978072678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8655ce3293e741f9af9400606c57d17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59a001929b6d4df18177de6d952c5767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394f8096276d4284a8ff5521914c3c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f1f79a6cc8542ceb7a3f3e3fbef1fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c52edee3fe4be38dad81272fccb104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ba04a175c8445f2add4a3b647dcb456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc0ec4ff5d5940fbb338b3c3d8ed8cad",
              "IPY_MODEL_c270d57d1072451aa00f5e03e919ee2f",
              "IPY_MODEL_d74f555fa02f4acbbaf93001d362f20e"
            ],
            "layout": "IPY_MODEL_3d22d4036e6c45d68ece655dd2f4a0cc"
          }
        },
        "fc0ec4ff5d5940fbb338b3c3d8ed8cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873f43914a2249799d3ef2f8f828ddbd",
            "placeholder": "​",
            "style": "IPY_MODEL_baaae265e0d84a3791ae0632493d0ccc",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "c270d57d1072451aa00f5e03e919ee2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75243ba07134a36bc0e0d267274883f",
            "max": 147793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18dfe4d7248547e8aeb06e6103f35b78",
            "value": 147793
          }
        },
        "d74f555fa02f4acbbaf93001d362f20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdfc38648dd842f88fa85fa6ecd4a6a5",
            "placeholder": "​",
            "style": "IPY_MODEL_7611fdc79c004561bc29703777425ccf",
            "value": " 148k/148k [00:00&lt;00:00, 16.6MB/s]"
          }
        },
        "3d22d4036e6c45d68ece655dd2f4a0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873f43914a2249799d3ef2f8f828ddbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baaae265e0d84a3791ae0632493d0ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75243ba07134a36bc0e0d267274883f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18dfe4d7248547e8aeb06e6103f35b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdfc38648dd842f88fa85fa6ecd4a6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7611fdc79c004561bc29703777425ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1896fd4e05f64530a0bf21ac5a0af439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86d94d3d8dd04669ad535230d7083622",
              "IPY_MODEL_5b214fb6c29444bf97a9b97d98a158ab",
              "IPY_MODEL_56fdb426dff842b9aba18c38c0af5757"
            ],
            "layout": "IPY_MODEL_f237a42965904188b958f800e226c880"
          }
        },
        "86d94d3d8dd04669ad535230d7083622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567e56ed9b704ef8b393822650aaf62c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e23b89404a640a09bc68e3633153243",
            "value": "Generating train split: 100%"
          }
        },
        "5b214fb6c29444bf97a9b97d98a158ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d3b89111384c64ab2130e89eb2c232",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2d1b27dd45f469397963e4e4bb935f7",
            "value": 67349
          }
        },
        "56fdb426dff842b9aba18c38c0af5757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ff6e3eebca429c852e837550e94990",
            "placeholder": "​",
            "style": "IPY_MODEL_80a3d74e93dd491ca1b3e500edeb36b6",
            "value": " 67349/67349 [00:00&lt;00:00, 805093.01 examples/s]"
          }
        },
        "f237a42965904188b958f800e226c880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567e56ed9b704ef8b393822650aaf62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e23b89404a640a09bc68e3633153243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d3b89111384c64ab2130e89eb2c232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d1b27dd45f469397963e4e4bb935f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27ff6e3eebca429c852e837550e94990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a3d74e93dd491ca1b3e500edeb36b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "621a4f42fdad49da9eddd152c029785b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db82352ec4564c42add70792f0744cdb",
              "IPY_MODEL_5ac05e34cfdb4e7fb03c849a1c61101e",
              "IPY_MODEL_20fce077f1d04fd39e249b542fd77e26"
            ],
            "layout": "IPY_MODEL_61034abc604242b79202771b40f0b9fe"
          }
        },
        "db82352ec4564c42add70792f0744cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31f15f9616234ff785c1312c1d2a0ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_f7093cc42f7a4b7c83e9da99a20d3583",
            "value": "Generating validation split: 100%"
          }
        },
        "5ac05e34cfdb4e7fb03c849a1c61101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813c55fd435b4082af3a077f88231993",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c15de209f4554309ab2bb96b276778e3",
            "value": 872
          }
        },
        "20fce077f1d04fd39e249b542fd77e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e79dd427c324d19b588753e97caf007",
            "placeholder": "​",
            "style": "IPY_MODEL_e0df0ff0599a4f588e08e074730cb5f4",
            "value": " 872/872 [00:00&lt;00:00, 75410.99 examples/s]"
          }
        },
        "61034abc604242b79202771b40f0b9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f15f9616234ff785c1312c1d2a0ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7093cc42f7a4b7c83e9da99a20d3583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "813c55fd435b4082af3a077f88231993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15de209f4554309ab2bb96b276778e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e79dd427c324d19b588753e97caf007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0df0ff0599a4f588e08e074730cb5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "992775a8a69b4130abff8878b3129939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a2be34b7f934b37adc623da7d63fd53",
              "IPY_MODEL_2b8984e98113473bb8c7477d65a7b354",
              "IPY_MODEL_44e0b63cb46147c7a9e8a2e142a870d6"
            ],
            "layout": "IPY_MODEL_206caa5ed7d3432d93f63c9e79088f19"
          }
        },
        "7a2be34b7f934b37adc623da7d63fd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326b8cf85bfc47dab93e0f4ba888086d",
            "placeholder": "​",
            "style": "IPY_MODEL_5e305fd542f341519f6dfdb8bf2ea794",
            "value": "Generating test split: 100%"
          }
        },
        "2b8984e98113473bb8c7477d65a7b354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_086a59d4ec5a4db6a67f10ed4afc2305",
            "max": 1821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30b0379d35ca45d6ba0b298fc26a7bbe",
            "value": 1821
          }
        },
        "44e0b63cb46147c7a9e8a2e142a870d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_209ff1d8406249b7bc8aebdd153c1c13",
            "placeholder": "​",
            "style": "IPY_MODEL_1124b19f1de64c6a9250f0a7bee3f93d",
            "value": " 1821/1821 [00:00&lt;00:00, 139325.57 examples/s]"
          }
        },
        "206caa5ed7d3432d93f63c9e79088f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326b8cf85bfc47dab93e0f4ba888086d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e305fd542f341519f6dfdb8bf2ea794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "086a59d4ec5a4db6a67f10ed4afc2305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b0379d35ca45d6ba0b298fc26a7bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "209ff1d8406249b7bc8aebdd153c1c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1124b19f1de64c6a9250f0a7bee3f93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c21638f71d4165a022b6fd0f697a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78e4746f75cc44f2b4e27122fe2bada8",
              "IPY_MODEL_1f794bc9fc5c41d3901c2da6ed59dccf",
              "IPY_MODEL_03455df901b446f4bf7e34932b94fd4e"
            ],
            "layout": "IPY_MODEL_72d3be86354a4d40a945eb952633375a"
          }
        },
        "78e4746f75cc44f2b4e27122fe2bada8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4a582c5a07247de8d485d81f9bc81ac",
            "placeholder": "​",
            "style": "IPY_MODEL_9946ba66145f4262a2bea29205a80bbb",
            "value": "model.safetensors: 100%"
          }
        },
        "1f794bc9fc5c41d3901c2da6ed59dccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc919824bea944b280b44a5605174542",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29cbdc77708d415598827c4f78009cc8",
            "value": 440449768
          }
        },
        "03455df901b446f4bf7e34932b94fd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0e47cd84ce4cd6a5292fbf16d54264",
            "placeholder": "​",
            "style": "IPY_MODEL_b0203731c3b6412785569019b5f53371",
            "value": " 440M/440M [00:01&lt;00:00, 298MB/s]"
          }
        },
        "72d3be86354a4d40a945eb952633375a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a582c5a07247de8d485d81f9bc81ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9946ba66145f4262a2bea29205a80bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc919824bea944b280b44a5605174542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cbdc77708d415598827c4f78009cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd0e47cd84ce4cd6a5292fbf16d54264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0203731c3b6412785569019b5f53371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ba9397e1dcb4824b6e25f1cfb336086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdc389897586466ea9359812a7952ab2",
              "IPY_MODEL_eb93787249a247d5bd5c1c67fe2849bb",
              "IPY_MODEL_c53688db978247b585d9894d5b4299f2"
            ],
            "layout": "IPY_MODEL_3ed05f10e62a482d87fc60cf7f82d900"
          }
        },
        "bdc389897586466ea9359812a7952ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47856a92429c4dd28e5427f7d3878d09",
            "placeholder": "​",
            "style": "IPY_MODEL_2e202efe0ad744bc851c208c089e127d",
            "value": "Validating:  11%"
          }
        },
        "eb93787249a247d5bd5c1c67fe2849bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ec1269f4edc4776ad4ffb30af60bb9b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76fbd476b354463a8ef5b16a087a59e8",
            "value": 3
          }
        },
        "c53688db978247b585d9894d5b4299f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0865ab9f3e4c28883c2ddcb61671ab",
            "placeholder": "​",
            "style": "IPY_MODEL_236d869cd8394948b76d197566d54783",
            "value": " 3/28 [00:45&lt;06:12, 14.89s/it]"
          }
        },
        "3ed05f10e62a482d87fc60cf7f82d900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47856a92429c4dd28e5427f7d3878d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e202efe0ad744bc851c208c089e127d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ec1269f4edc4776ad4ffb30af60bb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76fbd476b354463a8ef5b16a087a59e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef0865ab9f3e4c28883c2ddcb61671ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236d869cd8394948b76d197566d54783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification BERT [CoLA]\n",
        "\n",
        "*   항목 추가\n",
        "*   항목 추가\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SGcOaw5P769d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "id": "Pg-qog2IyzCc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic"
      ],
      "metadata": {
        "id": "x6iTkvfbQ6Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores, dim=-1):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    \"\"\"\n",
        "    chunk_size = len(attention_scores) // dim\n",
        "    data_list = [attention_scores[i * chunk_size:(i + 1) * chunk_size] for i in range(120)]\n",
        "\n",
        "    # 120개의 결과 리스트 생성\n",
        "    result_arrays = []\n",
        "\n",
        "    # 각 10개씩 top 함수에 전달\n",
        "    for i in range(120):\n",
        "        result = top(*data_list[i])  # 리스트를 개별 인자로 풀어서 전달\n",
        "        result_arrays.append(result)  # 결과 저장\n",
        "\n",
        "    return result_arrays\n",
        "\n",
        "\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    fixed_binary_int = int(fixed_binary, 2)\n",
        "    lower_20_bits = fixed_binary_int & 0xFFFFF\n",
        "    return lower_20_bits\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "        #print(int_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "   #return int_values\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "\n",
        "    # 7비트 마스크\n",
        "    mask = (1 << 7) - 1  # 0b1111111\n",
        "\n",
        "    # 1) 각 값 → signed int\n",
        "    for i in range(10):\n",
        "        # 순수 이진문자열 생성\n",
        "        binary_str      = format(data_list[i] & mask, '07b')\n",
        "        data_to_int[i]  = signed_binary_to_int(binary_str)\n",
        "\n",
        "    # 2) offset 계산 (0b0001011 = 11)\n",
        "    i_max      = max(data_to_int)\n",
        "    offset_val = 0b0001011 - i_max           # 정수 차 계산\n",
        "    # 마찬가지로 format + mask 로 2진문자열\n",
        "    binary_off = format(offset_val & mask, '07b')\n",
        "    offset     = signed_binary_to_int(binary_off)\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    # 이진수의 길이\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 방법으로 음수 변환\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수는 그냥 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "        #print(hex(exp_fraction[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "'''\n",
        "top(\n",
        "    0b00000011000110001110,  # 첫 번째 data_in 값\n",
        "    0b00000100010011110000,  # 두 번째 data_in 값\n",
        "    0b00000000010011111010,  # 세 번째 data_in 값\n",
        "    0b00000010101101111100,  # 네 번째 data_in 값\n",
        "    0b00000111000110011000,  # 다섯 번째 data_in 값\n",
        "    0b00000100010100001101,  # 여섯 번째 data_in 값\n",
        "    0b11111100110100100011,  # 일곱 번째 data_in 값\n",
        "    0b11111111100000001011,  # 여덟 번째 data_in 값\n",
        "    0b00000011010101100100,  # 아홉 번째 data_in 값\n",
        "    0b11111010100111110111   # 열 번째 data_in 값\n",
        ")\n",
        "'''\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ✅ 기존 Softmax -> Sigmoid Normalization 적용\n",
        "        attention_probs = top(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "HM1AXhHcQ04X"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구조 적용,, 재시작"
      ],
      "metadata": {
        "id": "eA7KlC3ftQ-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) Query/Key/Value 계산 (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) Attention score 계산 & scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ---------------------------------------------------\n",
        "        # 3) CORDIC-Softmax: top()을 120번 자동 호출\n",
        "        #    attention_scores.shape == [B, H, L, L] with L=10\n",
        "        # ---------------------------------------------------\n",
        "        B, H, L, _ = attention_scores.size()             # B=1, H=12, L=10\n",
        "        flat = attention_scores.view(-1, L)              # shape = [B*H, 10]\n",
        "        rows = []\n",
        "        for row in flat:                                 # 자동으로 1*12 = 12 행 × 10 쿼리 = 120 호출\n",
        "            # row.tolist() → Python float 리스트 길이 10\n",
        "            top_out = top(*row.tolist())                 # 여러분의 top(data1…data10)\n",
        "            # 다시 tensor 로 만들 때, dtype/device 일치시키기\n",
        "            rows.append(torch.tensor(\n",
        "                top_out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows)              # shape = [B*H, 10]\n",
        "        attention_probs = attention_probs.view(B, H, L, L)\n",
        "        # ---------------------------------------------------\n",
        "\n",
        "        # 4) Dropout & Context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "zfSHmJVQtUqh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. 1,12,10,10\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            #row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "        # ─────────────────────────────────────────────\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "JxoOuCl6wyU6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    # Modified 모듈 생성\n",
        "    mod = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 로드\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n"
      ],
      "metadata": {
        "id": "peAPhZdDvZzN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "# → BertForSequenceClassificationCordic 이어야 함\n",
        "\n",
        "# 2) forward 메서드가 서브클래스에서 정의된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "# → BertForSequenceClassificationCordic.forward 여야 함\n",
        "\n",
        "# 3) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)"
      ],
      "metadata": {
        "id": "huL4Du0TtzwD",
        "outputId": "25e420aa-ecad-4715-c22f-825e2b431b82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 마지막 레이어 확률만 꺼내기\n",
        "all_attentions = outputs.attentions    # tuple of length 12, each is [B, H, L, L]\n",
        "attention_probs = all_attentions[-1]   # 마지막 레이어의 [B, H, L, L] 텐서\n",
        "\n",
        "# 3) 마지막 축(키 방향)으로 합이 1인지 확인\n",
        "sums = attention_probs.sum(dim=-1)     # shape = [B, H, L]\n",
        "print(\"어텐션 확률 합:\", sums)\n"
      ],
      "metadata": {
        "id": "m2Fs1SMmxKoy",
        "outputId": "15f5a9b8-6e07-49cc-9103-f5777675c42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어텐션 확률 합: tensor([[[0.9990, 0.9897, 0.9912, 0.9973, 0.9907, 0.9900, 0.9814, 0.9922,\n",
            "          0.9905, 0.9912],\n",
            "         [0.9980, 0.9878, 0.9729, 0.9846, 0.9734, 0.9851, 0.9924, 0.9775,\n",
            "          0.9900, 0.9971],\n",
            "         [1.0000, 0.9961, 0.9966, 0.9905, 0.9985, 0.9963, 0.9976, 0.9827,\n",
            "          1.0007, 0.9995],\n",
            "         [0.9966, 0.9888, 0.9866, 0.9902, 0.9912, 0.9868, 0.9922, 0.9922,\n",
            "          0.9829, 1.0005],\n",
            "         [0.9978, 0.9958, 0.9927, 0.9919, 0.9895, 0.9971, 0.9829, 0.9829,\n",
            "          0.9905, 0.9907],\n",
            "         [0.9966, 0.9976, 0.9963, 0.9985, 0.9883, 0.9927, 0.9988, 0.9773,\n",
            "          0.9963, 0.9968],\n",
            "         [0.9980, 0.9922, 0.9905, 0.9939, 0.9978, 0.9958, 0.9890, 0.9861,\n",
            "          0.9988, 0.9902],\n",
            "         [0.9895, 0.9753, 0.9871, 0.9949, 0.9871, 0.9832, 0.9910, 0.9910,\n",
            "          0.9978, 0.9951],\n",
            "         [0.9927, 0.9980, 0.9929, 0.9980, 0.9973, 1.0042, 0.9973, 0.9893,\n",
            "          1.0012, 0.9998],\n",
            "         [0.9980, 1.0005, 0.9968, 0.9961, 0.9973, 0.9932, 0.9905, 0.9871,\n",
            "          0.9976, 0.9971],\n",
            "         [0.9990, 0.9927, 0.9956, 0.9980, 0.9861, 0.9885, 0.9761, 0.9871,\n",
            "          0.9951, 0.9976],\n",
            "         [0.9866, 0.9941, 0.9829, 0.9890, 0.9905, 0.9827, 0.9946, 0.9900,\n",
            "          0.9888, 0.9851]],\n",
            "\n",
            "        [[0.9990, 0.9983, 0.9968, 0.9990, 0.9973, 0.9983, 0.9993, 0.9976,\n",
            "          0.9976, 0.9983],\n",
            "         [0.9990, 0.9963, 0.9983, 0.9980, 0.9988, 0.9966, 0.9985, 0.9968,\n",
            "          1.0012, 0.9973],\n",
            "         [0.9993, 0.9993, 0.9956, 0.9980, 0.9978, 0.9988, 0.9978, 0.9988,\n",
            "          0.9995, 0.9993],\n",
            "         [0.9995, 1.0007, 0.9988, 0.9988, 1.0000, 0.9973, 0.9968, 0.9988,\n",
            "          0.9985, 0.9995],\n",
            "         [0.9985, 0.9988, 0.9973, 0.9988, 0.9988, 0.9976, 0.9954, 0.9983,\n",
            "          1.0002, 0.9958],\n",
            "         [0.9956, 0.9985, 0.9939, 0.9963, 0.9963, 0.9932, 0.9985, 0.9966,\n",
            "          0.9993, 0.9978],\n",
            "         [0.9980, 0.9988, 0.9971, 0.9988, 0.9993, 0.9976, 0.9966, 1.0012,\n",
            "          0.9990, 0.9958],\n",
            "         [0.9980, 0.9961, 0.9973, 0.9976, 0.9971, 0.9993, 0.9988, 0.9949,\n",
            "          0.9956, 0.9985],\n",
            "         [0.9985, 0.9951, 0.9985, 0.9868, 0.9993, 0.9810, 0.9971, 0.9893,\n",
            "          0.9912, 0.9990],\n",
            "         [0.9993, 0.9985, 0.9968, 0.9993, 0.9983, 0.9961, 0.9944, 0.9966,\n",
            "          1.0005, 0.9993],\n",
            "         [0.9990, 0.9998, 0.9985, 0.9990, 0.9968, 1.0002, 0.9976, 0.9988,\n",
            "          1.0000, 0.9990],\n",
            "         [0.9988, 0.9978, 0.9980, 0.9983, 0.9946, 0.9978, 0.9956, 0.9968,\n",
            "          0.9958, 0.9990]],\n",
            "\n",
            "        [[0.9993, 0.9988, 0.9968, 0.9973, 0.9995, 1.0012, 0.9990, 1.0010,\n",
            "          0.9976, 0.9985],\n",
            "         [0.9983, 0.9961, 1.0002, 0.9985, 0.9973, 0.9993, 0.9978, 0.9966,\n",
            "          0.9978, 0.9978],\n",
            "         [0.9961, 1.0000, 0.9985, 1.0002, 0.9995, 1.0000, 0.9988, 0.9980,\n",
            "          0.9944, 0.9988],\n",
            "         [1.0007, 0.9995, 0.9998, 0.9993, 1.0000, 0.9973, 0.9983, 0.9988,\n",
            "          1.0007, 0.9988],\n",
            "         [0.9993, 0.9954, 0.9990, 0.9993, 0.9988, 0.9988, 0.9968, 0.9971,\n",
            "          0.9963, 0.9973],\n",
            "         [0.9988, 0.9983, 0.9988, 0.9971, 0.9978, 0.9946, 0.9944, 0.9988,\n",
            "          0.9985, 0.9978],\n",
            "         [0.9978, 0.9980, 0.9949, 0.9973, 0.9980, 0.9983, 0.9973, 0.9971,\n",
            "          0.9951, 0.9937],\n",
            "         [0.9980, 0.9980, 0.9978, 0.9985, 0.9963, 0.9978, 0.9973, 0.9946,\n",
            "          0.9949, 0.9985],\n",
            "         [0.9973, 0.9978, 0.9917, 0.9888, 0.9976, 0.9922, 0.9958, 0.9973,\n",
            "          0.9976, 0.9993],\n",
            "         [0.9976, 0.9990, 0.9971, 1.0000, 0.9963, 0.9985, 0.9988, 0.9988,\n",
            "          0.9963, 0.9988],\n",
            "         [1.0015, 0.9980, 1.0002, 0.9966, 0.9993, 0.9985, 0.9995, 0.9983,\n",
            "          0.9995, 0.9966],\n",
            "         [0.9956, 0.9958, 0.9937, 0.9966, 0.9968, 0.9929, 0.9990, 0.9993,\n",
            "          0.9946, 0.9990]],\n",
            "\n",
            "        [[0.9956, 0.9963, 0.9883, 0.9968, 0.9934, 0.9932, 0.9924, 0.9832,\n",
            "          1.0002, 0.9985],\n",
            "         [0.9973, 0.9980, 0.9927, 0.9939, 0.9937, 1.0000, 0.9973, 0.9844,\n",
            "          0.9954, 0.9998],\n",
            "         [0.9978, 0.9951, 0.9976, 0.9978, 0.9998, 0.9946, 0.9954, 1.0056,\n",
            "          0.9998, 0.9958],\n",
            "         [0.9976, 0.9978, 0.9849, 0.9731, 0.9971, 0.9944, 0.9961, 0.9971,\n",
            "          0.9956, 0.9995],\n",
            "         [0.9980, 0.9978, 0.9990, 0.9995, 0.9988, 0.9993, 0.9993, 0.9807,\n",
            "          0.9980, 0.9983],\n",
            "         [0.9988, 0.9983, 0.9980, 0.9963, 0.9976, 0.9946, 0.9973, 0.9885,\n",
            "          0.9985, 0.9983],\n",
            "         [0.9988, 1.0015, 0.9949, 0.9988, 0.9849, 0.9919, 0.9910, 0.9807,\n",
            "          0.9968, 0.9990],\n",
            "         [0.9902, 0.9951, 0.9941, 0.9939, 0.9966, 0.9939, 0.9905, 0.9902,\n",
            "          0.9937, 0.9976],\n",
            "         [0.9937, 0.9995, 0.9968, 0.9829, 1.0000, 0.9812, 0.9927, 0.9973,\n",
            "          0.9980, 0.9973],\n",
            "         [0.9978, 1.0000, 0.9993, 0.9990, 0.9968, 0.9976, 0.9990, 1.0000,\n",
            "          0.9993, 1.0005],\n",
            "         [0.9988, 1.0000, 0.9998, 0.9990, 0.9968, 0.9968, 0.9785, 0.9946,\n",
            "          0.9968, 0.9956],\n",
            "         [1.0005, 0.9944, 0.9934, 0.9951, 0.9944, 0.9971, 0.9927, 0.9805,\n",
            "          0.9973, 1.0005]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "    model.eval()\n",
        "    eval_accuracy = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            # 배치를 GPU로\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            #logits만 얻기\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # CPU로 내리고 numpy 변환\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            # 배치별 정확도 계산\n",
        "            batch_acc = flat_accuracy(logits, label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.2f}\")\n",
        "    print(f\"Validation Time   : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return avg_accuracy\n",
        "\n",
        "avg_acc = run_validation(model, validation_dataloader, device)"
      ],
      "metadata": {
        "id": "r3GHXPFAyqKm",
        "outputId": "c8901a25-8078-4233-efc5-bd5ebb47d6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1576223b15c7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-1576223b15c7>\u001b[0m in \u001b[0;36mrun_validation\u001b[0;34m(model, validation_dataloader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#logits만 얻기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             outputs = model(\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c86f7e7a9655>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# (4) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             rows.append(torch.tensor(\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    # 2) 준비\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_accuracy = 0.0\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            # Forward pass (logits 얻기)\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]              # [B, 2]\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = criterion(logits, b_labels)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            #probs_tensor = torch.softmax(logits, dim=1)               # [B,2]\n",
        "            #pos_probs = probs_tensor[:, 1].detach().cpu().numpy()     # positive 클래스 확률\n",
        "            #threshold = 0.6                                           # 원하는 임계치\n",
        "            #preds = (pos_probs > threshold).astype(int)               # 0.6 초과면 1, 아니면 0\n",
        "            label_ids = b_labels.detach().cpu().numpy()\n",
        "            batch_acc = np.sum(preds == label_ids) / len(label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "\n",
        "            # 저장\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(label_ids.tolist())\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    # 3) 평균 지표 계산\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_loss     = eval_loss / nb_eval_steps\n",
        "    mcc          = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # 4) 결과 출력\n",
        "    print(f\"Validation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision / Recall / F1: {precision:.4f} / {recall:.4f} / {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": avg_accuracy,\n",
        "        \"loss\": avg_loss,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5cgFqujvRRb",
        "outputId": "9d860b2c-f132-4277-f682-6b2baf8d0ee9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n",
            "Validation Loss    : 0.5975\n",
            "Validation Accuracy: 0.7971\n",
            "Matthews CorrCoef  : 0.4921\n",
            "Precision / Recall / F1: 0.8056 / 0.9307 / 0.8636\n",
            "Confusion Matrix:\n",
            " [[131 133]\n",
            " [ 41 551]]\n",
            "Validation Time    : 0:06:40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ."
      ],
      "metadata": {
        "id": "cSd2dA-wQ94T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de556c0f-d18c-4c7d-a7aa-e1da60adabe8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32049856-b723-472c-b366-c66a84f00f57"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7436408c-8cd4-4e4b-9307-114f0a5341d3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c26184-022f-4eaa-f2b6-6923b9a56d5a"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=02bba3e6582c978cdde3e2a7cc44ef47a39ab8b784f7d57a719753fab2b0c94e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7baf8c3c-44eb-4e48-fb0d-ebbef55e7281"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cc7151-6f9b-48b6-d37a-152745871909"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "e6e8a116-8a64-4265-cb8a-c242fce8a920"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "6090            c_13      1         NaN   \n",
              "2851            l-93      1         NaN   \n",
              "7009          sgww85      1         NaN   \n",
              "2883            l-93      1         NaN   \n",
              "4639            ks08      1         NaN   \n",
              "6189            c_13      1         NaN   \n",
              "1188            r-67      1         NaN   \n",
              "3581            ks08      1         NaN   \n",
              "7890            ad03      1         NaN   \n",
              "8200            ad03      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "6090                       I do not love peanut butter.  \n",
              "2851                            Carol cut at the bread.  \n",
              "7009                          Dana was quite competent.  \n",
              "2883                 Harriet interconnected the pieces.  \n",
              "4639                            The car will be driven.  \n",
              "6189                 How do you think John bought what?  \n",
              "1188       I read a statement which was about that man.  \n",
              "3581  I know I should go to the dentist's, but I jus...  \n",
              "7890                  Hera tried to appear to be happy.  \n",
              "8200                             They kicked themselves  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-725b7f6e-913a-4c99-8577-3dea593e5f7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6090</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I do not love peanut butter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carol cut at the bread.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7009</th>\n",
              "      <td>sgww85</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dana was quite competent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2883</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Harriet interconnected the pieces.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4639</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The car will be driven.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>How do you think John bought what?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I read a statement which was about that man.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I know I should go to the dentist's, but I jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7890</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hera tried to appear to be happy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8200</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They kicked themselves</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-725b7f6e-913a-4c99-8577-3dea593e5f7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-725b7f6e-913a-4c99-8577-3dea593e5f7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-725b7f6e-913a-4c99-8577-3dea593e5f7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ce2a49ea-6669-4835-862c-e28db6d9abb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce2a49ea-6669-4835-862c-e28db6d9abb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ce2a49ea-6669-4835-862c-e28db6d9abb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "601a1abe-d6c0-4d91-a286-a66adc6f9c1b"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             sentence  label\n",
              "2317                         Bill married with Kathy.      0\n",
              "4301  Stephen persuaded the cat to be out of the bag.      0\n",
              "2803                                   The fence hit.      0\n",
              "2358                  I sought for game in the woods.      0\n",
              "2354                 We rummaged the desk for papers.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b392803-aa20-41db-998e-f0b027c00468\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2317</th>\n",
              "      <td>Bill married with Kathy.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4301</th>\n",
              "      <td>Stephen persuaded the cat to be out of the bag.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2803</th>\n",
              "      <td>The fence hit.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2358</th>\n",
              "      <td>I sought for game in the woods.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2354</th>\n",
              "      <td>We rummaged the desk for papers.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b392803-aa20-41db-998e-f0b027c00468')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b392803-aa20-41db-998e-f0b027c00468 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b392803-aa20-41db-998e-f0b027c00468');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b29f4d53-7f33-4352-9517-b5a905dc9e39\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b29f4d53-7f33-4352-9517-b5a905dc9e39')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b29f4d53-7f33-4352-9517-b5a905dc9e39 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Stephen persuaded the cat to be out of the bag.\",\n          \"We rummaged the desk for papers.\",\n          \"The fence hit.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "21647f650e8642afaa150c4a31a9f56c",
            "f2e51646d0724c6b84e4cc3047ed3e0e",
            "1bea68bb306748c3abe9a1a7951d3cf8",
            "4057fad4547546399720164e21c94721",
            "ec42f719294c425ca1a8b63582a0b117",
            "2e5cc5a7810248fdb02d3757e8342a47",
            "d97b55b02c6349e5a75226385923daa9",
            "da9a9c6d4d7e404f95c408db13f49de1",
            "bb13b3ed78ee4fb5989a9733be32cc8c",
            "f0893228bcb3424f854491fc4582c20f",
            "c249737b8f524e3885269bb49b9693f3",
            "2c9f222533264388bf7eef8e7cf8f23f",
            "297bb25e012c4c09942f882920f8cf8b",
            "f7e65943daac40b3825e73ed57048a2f",
            "23da79cb7a8045a2869af10cdf206175",
            "a3a4deffe3a64e6aa3c894badfa07e31",
            "595e071b805b4b1b9d89feb6b57082ee",
            "3aa9d4590bb94ccdbfbdb9ad33613c43",
            "867f2b9ef2bb4749bd543b6949013c39",
            "4688741ae333403585031546f91449a4",
            "de6f9cc78548427cac3b632bacc7058d",
            "956fb7a85f2648fe95d92ae89ab7fa51",
            "5d71fa82b4804f888a17feb29c3da915",
            "fc22f02bba374f35bc9224c6e8043628",
            "f88c4f08a90745e6957099c79a0ce55a",
            "89b9427dce014ef784debe3a476afb38",
            "b2fbcafba6d344e0ba465a7b94ac4075",
            "ef9e647e17314008bdef689dfc806d99",
            "b7b92019c1bb4b15bdcabca6ea46fef7",
            "c64cfd6a45214e79a11d190950de1da7",
            "5b6d57e400c948efae7d8b39bbd3b1a3",
            "ccacbcc6fc5d4bbd8270ebd73e1c9eaa",
            "e563e154deac4398804263303a046083",
            "51466319aeb748c99a39a40240cad178",
            "ffd094ec7f5e43a9b42eca730cc10c5e",
            "5ab71a52aa0442d09e20e2a88b73113b",
            "ad5ea0b1b46749008d1d415156d5d38b",
            "b4ef36bca9a649cfaa85fb4743b0a23d",
            "e5ecaba034ea4aa18424ebf59caccf45",
            "614278161a054032844b3b0918bac1f3",
            "55db5ffe7c8143138cc1d25fce57cb9e",
            "229c75c52d564ecfa718ad70261a43b8",
            "8ca9f2deb9254ab88e5efc018da79a84",
            "b11d538b51c442e4af7b404b8f8a5367"
          ]
        },
        "outputId": "7b777a36-989a-419f-fc47-e3afae9c7d2a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21647f650e8642afaa150c4a31a9f56c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c9f222533264388bf7eef8e7cf8f23f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d71fa82b4804f888a17feb29c3da915"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51466319aeb748c99a39a40240cad178"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797249ad-f6be-4b75-e172-b5800cfa6b04"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2247b1c3-5963-4b63-f6fc-d88f3f272726"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf23724-4295-42d2-f90b-a29b620fdee2"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86471e3c-c89e-4a8c-eab7-269cd57d36e7"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969,
          "referenced_widgets": [
            "d5ba5169307c45508f5847f1daeb76d3",
            "7f81394a29604411a0e01e7affead432",
            "39722a94be4f4a14af1ddaf63e6639b7",
            "cbe94b0dd40a4ae8abf89d5e7202d506",
            "c2fbf7998e9b44cdbdf148cef0c1ebae",
            "d89c19f933d24a6c8c6ece0495078a13",
            "1e0e64e34f864657965c20c781b9eeeb",
            "68eaac5671b64634ab7d55f728f43b99",
            "43435ed194974628ada06eb473fb46b2",
            "f54c1c33d0fd438ab2f7274dd8a8304a",
            "9726a149fcb44b0882884c346a3cdf8a"
          ]
        },
        "outputId": "0c24e029-78e1-46b7-c90a-f2ecbb29b9af"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5ba5169307c45508f5847f1daeb76d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20b783d-8a7b-4629-c509-311be3b2b9fe"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3"
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6842c23c-055e-40c9-f924-1cdf70c473a7"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:04.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:07.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:10.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:16.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "38fd451e-17d5-47e7-bca4-1d902351ef68"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9fe64ec-0654-4bbf-d2ba-19e9de695aac"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204e560f-09eb-44ca-86c2-4fc01c18ae04"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d069ca1e-e575-469f-c67b-4edeb287fbcb"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b0a467-0c69-4c0b-ed07-61ff047b5e69"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58429f2f-d2c8-4cba-e0d2-d8dad3c8620a"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.21713222235566895),\n",
              " 0.0,\n",
              " np.float64(0.34500484066310094),\n",
              " np.float64(0.4127594582445936),\n",
              " np.float64(0.21867346044008387),\n",
              " np.float64(0.6979824404521128),\n",
              " np.float64(0.12403473458920847),\n",
              " 0.0,\n",
              " np.float64(0.9165151389911681),\n",
              " np.float64(0.6659416347320276),\n",
              " np.float64(0.7679476477883045),\n",
              " np.float64(0.5673665146135802),\n",
              " np.float64(0.8749672939989046),\n",
              " np.float64(0.7141684885491869),\n",
              " np.float64(0.23372319715296222),\n",
              " np.float64(0.4252964776724258),\n",
              " np.float64(-0.3333333333333333)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c867fe-c85a-4c52-d927-ac1cf0972787"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 코드"
      ],
      "metadata": {
        "id": "xd5BzXwU8HM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MAX_LEN = 10\n",
        "\n",
        "def predict_with_cordic(model, tokenizer, sentence, device):\n",
        "    \"\"\"\n",
        "    CORDIC-Softmax 패치된 model + tokenizer를 이용해\n",
        "    단일 문장(sentence)에 대해 CoLA 예측을 수행합니다.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 토크나이징 + 패딩\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # GPU/CPU 동일하게 맞추기\n",
        "    inputs = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "    # 순전파만 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs.get(\"token_type_ids\", None)\n",
        "        )\n",
        "        # HuggingFace 버전 따라 .logits 또는 [0]\n",
        "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
        "\n",
        "    # CORDIC-Softmax로 이미 변환된 attention을 쓰므로\n",
        "    # classification head 출력만 softmax\n",
        "    probs = torch.softmax(logits, dim=-1)    # [1, 2]\n",
        "    pred  = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    return pred, probs.cpu().numpy().flatten()\n",
        "\n",
        "\n",
        "# — 사용 예시 —\n",
        "sentence = \"Here is a sample sentence to test CORDIC inference.\"\n",
        "pred, probs = predict_with_cordic(model, tokenizer, sentence, device)\n",
        "\n",
        "label_name = \"acceptable\" if pred == 1 else \"unacceptable\"\n",
        "print(f\"Sentence        : {sentence}\")\n",
        "print(f\"Predicted label : {pred} ({label_name})\")\n",
        "print(f\"Probabilities   : [0]={probs[0]:.4f}, [1]={probs[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "ddIcD3HipFSO",
        "outputId": "f0bead73-a2f3-40b3-8781-7ebb1136d030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cordic_softmax_2way' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# — 사용 예시 —\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Here is a sample sentence to test CORDIC inference.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_cordic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"acceptable\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"unacceptable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36mpredict_with_cordic\u001b[0;34m(model, tokenizer, sentence, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 순전파만 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-cfef15f4be3a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 2) CORDIC-Softmax으로 대체 (num_labels=2라면 top_2 입력 함수 필요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 여기서는 예시로 두 값에 대한 지수→분모→나눗셈을 직접 호출한다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcordic_softmax_2way\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# logits.shape == [B,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cordic_softmax_2way' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d731a4d-adf9-475b-a709-34946ac56710"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# 1. 모델 및 토크나이저 로드 (예: 'bert-base-uncased' 사용)\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()               # GPU로 이동\n",
        "model.eval()               # 평가 모드로 전환\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# 2. 추론할 영어 문장 예시\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "\n",
        "# 3. 문장 토큰화 및 인코딩\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,      # [CLS]와 [SEP] 토큰 추가\n",
        "    max_length=10,                # 최대 길이 설정\n",
        "    padding=\"max_length\",         # 최대 길이에 맞춰 패딩\n",
        "    truncation=True,              # 길면 잘라냄\n",
        "    return_tensors=\"pt\"           # 파이토치 텐서 반환\n",
        ")\n",
        "\n",
        "# 4. 텐서를 GPU로 이동\n",
        "inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "\n",
        "# 5. 추론 (forward pass)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs[0]  # 모델의 출력은 튜플이며, 첫 번째 요소가 로짓입니다.\n",
        "\n",
        "# 6. Softmax 적용 (선택 사항) 및 예측 클래스 결정\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "# 7. 결과 출력\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", predicted_class.item())\n",
        "print(\"예측 확률:\", probs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: tensor([[0.7347, 0.2653]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    입력된 문장에 대해 학습된 모델을 사용하여 예측을 수행합니다.\n",
        "    Returns:\n",
        "        predicted_class: 예측된 클래스 (예: 0 또는 1)\n",
        "        probs: 각 클래스의 확률 (numpy 배열)\n",
        "    \"\"\"\n",
        "    # 문장을 토큰화하고 encode_plus를 통해 [CLS], [SEP] 토큰을 추가하며, 패딩/자르기 적용\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,      # [CLS]와 [SEP] 추가\n",
        "        max_length=max_length,        # 최대 길이\n",
        "        padding=\"max_length\",         # 최대 길이에 맞게 패딩\n",
        "        truncation=True,              # 길면 자르기\n",
        "        return_tensors=\"pt\"           # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # GPU로 텐서를 전송\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # 모델을 평가 모드로 전환하고, 추론 시에는 기울기를 계산하지 않도록 설정\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # 모델의 출력은 튜플 형태로, 첫 번째 요소가 logits입니다.\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 사용\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PITHYJKhPHD",
        "outputId": "c1e48647-320b-42aa-d562-a50a05b01a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.73471546 0.26528448]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic 코드"
      ],
      "metadata": {
        "id": "oK0EdSFZjeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    결과는 원본 형태 (1, 12, 10, 10)로 반환\n",
        "    \"\"\"\n",
        "    if isinstance(attention_scores, torch.Tensor):\n",
        "        attention_scores = attention_scores.detach().cpu().numpy()  # ✅ detach() 추가\n",
        "\n",
        "    batch_size, num_heads, seq_length, _ = attention_scores.shape\n",
        "    result_arrays = np.zeros((batch_size, num_heads, seq_length, seq_length))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        for row in range(seq_length):\n",
        "            for col in range(seq_length // 10):\n",
        "                input_values = attention_scores[0, head, row, col * 10:(col + 1) * 10]\n",
        "                result = top(*input_values)\n",
        "                result_arrays[0, head, row, col * 10:(col + 1) * 10] = result\n",
        "\n",
        "    # ✅ numpy -> torch 변환할 때 `.to(device)` 추가\n",
        "    return torch.tensor(result_arrays, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 정수부는 7비트 (Signed, 2의 보수)\n",
        "    - 소수부는 13비트 (항상 양수)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ PyTorch Tensor 처리\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        value = value.detach().cpu().numpy()\n",
        "\n",
        "    # ✅ NaN 또는 Inf 값 체크 후 예외 처리\n",
        "    if np.isnan(value) or np.isinf(value):\n",
        "        raise ValueError(f\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\")\n",
        "\n",
        "    # ✅ **최대/최소 값 제한 (7비트 표현 범위)**\n",
        "    value = max(min(value, 63), -64)\n",
        "\n",
        "    # ✅ 정수부와 소수부 분리\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수 부분\n",
        "\n",
        "    # ✅ 2의 보수 변환 (음수 처리)\n",
        "    if int_part < 0:\n",
        "        int_part = (1 << int_bits) + int_part\n",
        "\n",
        "    int_binary = format(int_part, f'0{int_bits}b')\n",
        "\n",
        "    # ✅ 12비트 0 추가 (BERT 출력 형식 유지)\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트)\n",
        "    frac_binary = \"\"\n",
        "    for _ in range(frac_bits):\n",
        "        frac_part *= 2\n",
        "        if frac_part >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_part -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 문자열 생성\n",
        "    binary_string = int_binary + frac_binary\n",
        "\n",
        "    # ✅ `binary_string`이 음수 값을 포함하는지 확인 후 처리\n",
        "    if \"-\" in binary_string:\n",
        "        raise ValueError(f\"[ERROR] 잘못된 바이너리 문자열 변환 감지: {binary_string}\")\n",
        "\n",
        "    # ✅ 20비트 정수 변환 (부호 처리)\n",
        "    fixed_binary = int(binary_string, 2)\n",
        "    if value < 0:\n",
        "        fixed_binary = (1 << 20) - fixed_binary  # 2의 보수 변환\n",
        "\n",
        "    lower_20_bits = fixed_binary & 0xFFFFF  # 20비트 마스킹\n",
        "\n",
        "    return lower_20_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    \"\"\"\n",
        "    2의 보수 표현된 이진수를 정수로 변환하는 함수.\n",
        "    \"\"\"\n",
        "    # ✅ \"0b\" 제거\n",
        "    binary_str = binary_str.replace(\"0b\", \"\")\n",
        "\n",
        "    # ✅ 이진수 길이 확인\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # ✅ 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 변환 (음수)\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JuXVpD_Fjj7q",
        "outputId": "92b4e0a7-8f92-4fb4-e9da-9a1ba0f0b8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0528564453125,\n",
              " 0.0977783203125,\n",
              " 0.0128173828125,\n",
              " 0.0438232421875,\n",
              " 0.3963623046875,\n",
              " 0.0980224609375,\n",
              " 0.0552978515625,\n",
              " 0.0140380859375,\n",
              " 0.0599365234375,\n",
              " 0.1666259765625)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 수정 및 적용 코드"
      ],
      "metadata": {
        "id": "o19OXrVjjoaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# … (BertSelfAttentionModified / BertEncoderModified / BertWithModifiedAttentionForClassification 정의부는 그대로) …\n",
        "\n",
        "# 4. 모델 생성\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "\n",
        "# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\n",
        "checkpoint = torch.load(\"./model/CoLA.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "# 이후 GPU 이동·평가 모드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 예시 추론 함수 (변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=device):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred  = torch.argmax(probs, dim=1).item()\n",
        "    return pred, probs.cpu().numpy()\n",
        "\n",
        "# 테스트\n",
        "sentence = \"This is a grammatically acceptable sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sXS8S2bXX17u",
        "outputId": "8e8a0084-48e7-458f-db5a-5450af90ce01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e186ff2ff0d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/CoLA.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                     warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "scMdkDy7tAqU",
        "outputId": "8e4b9b79-2fec-49f1-addb-5207366623b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassificationModified(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Softmax 대신 CORDIC을 적용\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "XySJ0nStsisx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # 여기서 원래 softmax를 적용하는 대신 CORDIC 기반 함수를 사용합니다.\n",
        "        # 예를 들어, top_1200_input(attention_scores)를 사용하여 softmax 결과를 근사합니다.\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        # 만약 반환된 결과가 numpy 형태라면, torch.tensor로 변환해주어야 합니다.\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 원래 출력은 (context_layer, attention_probs) 또는 (context_layer,)인데,\n",
        "        # 필요에 따라 raw attention scores도 반환하도록 할 수 있습니다.\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "# 만약 학습된 가중치를 로드해야 한다면 로드합니다.\n",
        "# model.load_state_dict(torch.load(\"your_checkpoint.pt\"), strict=False)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# 이제 이 모델은 CoLA나 다른 영어 문장 분류 작업에 사용할 수 있습니다.\n",
        "# 예시 추론 함수:\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 문장으로 테스트\n",
        "sentence = \"This is a grammatically acceptable for sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "itlqawMcjmJ3",
        "outputId": "11d60001-ac23-433a-cb2d-a279facb7a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is a grammatically acceptable for sentence.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.5131679  0.48683208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 encoder 내 각 레이어의 self-attention 모듈 타입을 출력하여\n",
        "# 수정된 BertSelfAttentionModified가 적용되었는지 확인합니다.\n",
        "print(\"수정된 Attention Layers 확인:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn_layer = layer.attention.self\n",
        "    print(f\"Layer {i} self-attention layer type: {type(attn_layer)}\")\n"
      ],
      "metadata": {
        "id": "8WUtGKLuoW2z",
        "outputId": "fa8009ef-7082-49b3-ea5a-13e2553196a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정된 Attention Layers 확인:\n",
            "Layer 0 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 1 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 2 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 3 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 4 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 5 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 6 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 7 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 8 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 9 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 10 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 11 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디버깅용 잡동사니코드"
      ],
      "metadata": {
        "id": "H5iP5hhyJuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print(f\"[TOP] exp_fraction_output[{i}] = {exp_fraction_output[i]}\")\n",
        "    print(f\"[TOP] exp_int_output[{i}] = {exp_int_output[i]}\")\n",
        "    print(f\"[TOP] exp_whole[{i}] = {exp_whole[i]}\")\n",
        "    print(f\"[TOP] exp_trunc[{i}] = {exp_trunc[i]}\")\n",
        "    print(f\"[TOP] exp_accum_input[{i}] = {exp_accum_input[i]}\")\n",
        "    print(f\"[TOP] x_divider = {x_divider[0]}\")\n",
        "    print(f\"[TOP] y_dividend = {y_dividend[i]}\")\n",
        "    print(f\"[TOP] data_out[{i}] = {data_out[i]}\")"
      ],
      "metadata": {
        "id": "rAamcoXWSjnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # ✅ 디버깅용 Q, K 체크\n",
        "        with torch.no_grad():\n",
        "            h = hidden_states.detach().cpu().numpy()\n",
        "            print(\"=== Hidden States 디버깅 ===\")\n",
        "            print(\"min:\", np.min(h), \"max:\", np.max(h))\n",
        "            print(\"NaN 수:\", np.isnan(h).sum(), \"Inf 수:\", np.isinf(h).sum())\n",
        "            q = query_layer.detach().cpu().numpy()\n",
        "            k = key_layer.detach().cpu().numpy()\n",
        "            print(\"=== Q, K 디버깅 ===\")\n",
        "            print(\"Q min/max:\", np.min(q), np.max(q))\n",
        "            print(\"K min/max:\", np.min(k), np.max(k))\n",
        "            print(\"Q NaN 수:\", np.isnan(q).sum(), \"K NaN 수:\", np.isnan(k).sum())\n",
        "            print(\"Q Inf 수:\", np.isinf(q).sum(), \"K Inf 수:\", np.isinf(k).sum())\n",
        "\n",
        "        # attention score 계산 후 clamp\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 계산 직후 ===\")\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item(), \"Inf 수:\", torch.isinf(attention_scores).sum().item())\n",
        "        attention_scores = torch.clamp(attention_scores, min=-10.0, max=10.0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 예시 ===\")\n",
        "            print(attention_scores[0, 0, 0, :10])\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item())\n",
        "        # CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "\n",
        "# 2. BertLayerWithNaNCheck: layer 0 내부 모듈 NaN 추적\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n",
        "\n",
        "\n",
        "# 3. BertEncoderModified\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "        self.layer[0] = BertLayerWithNaNCheck(self.layer[0])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_values=None, use_cache=False, output_attentions=False,\n",
        "                output_hidden_states=False, return_dict=True):\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            with torch.no_grad():\n",
        "                hs = hidden_states.detach().cpu().numpy()\n",
        "                if np.isnan(hs).sum() > 0:\n",
        "                    print(f\"[NaN DETECTED] ❌ in hidden_states BEFORE layer {i}\")\n",
        "                else:\n",
        "                    print(f\"[OK] ✅ hidden_states BEFORE layer {i}\")\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask[i] if head_mask is not None else None,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_values[i] if past_key_values is not None else None,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "        return (hidden_states,)\n",
        "\n",
        "\n",
        "# 4. BertWithModifiedAttentionForClassification\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 5. Load config and model\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dTD-BGlHKAh5",
        "outputId": "383af56c-e173-4f09-db40-610c833f616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayerWithNaNCheck(\n",
              "          (layer): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttentionModified(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_class = np.argmax(probs)\n",
        "\n",
        "    return pred_class, probs\n"
      ],
      "metadata": {
        "id": "sgc6czs9DqMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_nan(module, input, output):\n",
        "    if isinstance(output, torch.Tensor):\n",
        "        if torch.isnan(output).any():\n",
        "            print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "    elif isinstance(output, (tuple, list)):\n",
        "        for o in output:\n",
        "            if torch.is_tensor(o) and torch.isnan(o).any():\n",
        "                print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    module.register_forward_hook(check_for_nan)\n"
      ],
      "metadata": {
        "id": "2QHFLakIFV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        # Attention\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        # Intermediate\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        # Output\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n"
      ],
      "metadata": {
        "id": "gAA7SyorIaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sentence = \"The cat is sitting on the mat.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "\n",
        "print(\"문장:\", sentence)\n",
        "print(\"예측 클래스:\", pred_class)\n",
        "print(\"클래스별 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "yv0VeRUlDpLp",
        "outputId": "1cd74ea5-ca18-4524-d57c-bed12d1b5f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ✅ hidden_states BEFORE layer 0\n",
            "=== [Layer 0] BEFORE ===\n",
            "min: -4.571415901184082 max: 3.8990025520324707\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Hidden States 디버깅 ===\n",
            "min: -4.571416 max: 3.8990026\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: -2.1867194 2.275151\n",
            "K min/max: -2.4105966 2.2897592\n",
            "Q NaN 수: 0 K NaN 수: 0\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([ 0.4173, -0.1602, -0.0771,  0.3595,  0.1112, -0.1229, -0.2256, -0.0283,\n",
            "        -0.1147, -0.0984], device='cuda:0')\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0\n",
            "[NaN DETECTED] ❌ after Attention in Layer 0\n",
            "[NaN DETECTED] ❌ after Intermediate in Layer 0\n",
            "[NaN DETECTED] ❌ after Output in Layer 0\n",
            "=== [Layer 0] AFTER ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "[NaN DETECTED] ❌ in hidden_states BEFORE layer 1\n",
            "=== Hidden States 디버깅 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: nan nan\n",
            "K min/max: nan nan\n",
            "Q NaN 수: 49152 K NaN 수: 49152\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
            "min: nan max: nan\n",
            "NaN 수: 49152\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8b7cffed0231>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The cat is sitting on the mat.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-c78350183b4c>\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(model, tokenizer, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[OK] ✅ hidden_states BEFORE layer {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN 수:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        batch_size, num_heads, seq_len, _ = attention_scores.shape\n",
        "        for b in range(batch_size):\n",
        "          for h in range(num_heads):\n",
        "            for row in range(seq_len):\n",
        "              float_row = attention_scores[b, h, row, :10].detach().cpu().numpy().tolist()\n",
        "\n",
        "              if any(np.isnan(f) for f in float_row):\n",
        "                print(f\"[NaN] b={b}, head={h}, row={row} - 입력에 NaN 있음! ❌\")\n",
        "                continue  # 이건 skip하고 다음으로\n",
        "              try:\n",
        "                cordic_attention = top(*float_row)\n",
        "              except Exception as e:\n",
        "                print(f\"[ERROR] top() 실패: {e}\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "          sample_row = attention_scores[0, 0, 0, :10]  # [10개 float]\n",
        "          float_row = sample_row.detach().cpu().numpy().tolist()\n",
        "          print(\"[DEBUG] top 입력값:\", float_row)\n",
        "\n",
        "          try:\n",
        "            top_result = top(*float_row)\n",
        "            print(\"[DEBUG] top 출력값:\", top_result)\n",
        "          except Exception as e:\n",
        "            print(\"[ERROR] top에서 예외 발생:\", e)\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top(*float_row)\n",
        "\n",
        "        if any(np.isnan(c) for c in cordic_attention):\n",
        "          print(f\"[NaN DETECTED] ❌ top() 결과에 NaN 존재! input: {float_row}\")\n",
        "\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # ⚠️ 먼저 너의 원본 문장 리스트가 있어야 해!\n",
        "# 예: dataset_sentences = [\"문장1\", \"문장2\", ..., \"문장N\"]\n",
        "        # 🧪 validation_dataloader에서 원문 문장 추출 (예시)\n",
        "        dataset_sentences = []\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "          input_ids = batch[0]\n",
        "          for ids in input_ids:\n",
        "            text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "            dataset_sentences.append(text)\n",
        "\n",
        "        for i, sentence in enumerate(dataset_sentences):\n",
        "          try:\n",
        "            pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "          except Exception as e:\n",
        "            print(f\"[❌ NaN 발생] 문장 index = {i}\")\n",
        "            print(\"문장 내용:\", sentence)\n",
        "            print(\"에러 메시지:\", e)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "_dPquKTIGbOE",
        "outputId": "54615d57-7130-49f1-b469-d5b229ca4e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적용 모델 validation"
      ],
      "metadata": {
        "id": "JSRL23_d7voR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "h4m08g6HohMF",
        "outputId": "214cd12b-e10a-47d1-a737-bad6e12eb38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b8146705381d>:34: RuntimeWarning: invalid value encountered in cast\n",
            "  int_part = np.floor(value).astype(int)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e22c35b96d8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The documentation for this `model` function is here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-50e5032ce9fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# (2) CORDIC-Softmax 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# (3) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             rows.append(torch.tensor(\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdata_66\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mdata_77\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata_88\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdata_99\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdata_1010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ✅ 5. 최종 32비트 바이너리 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mfixed_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_binary\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrac_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlower_20_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFFFFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlower_20_bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장 및 로드 코드.\n",
        "path = '/content/model/'\n",
        "torch.save(model.state_dict(), path+\"CoLA.pt\")\n",
        "model.load_state_dict(torch.load(path + \"CoLA.pt\", map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6f3ddQs0x7V-",
        "outputId": "fcf8bd39-919f-468d-918c-5bcdf78d3e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST-2"
      ],
      "metadata": {
        "id": "wT4suA2WBNIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "SpQOdhi1DbYn",
        "outputId": "ef35ef09-5498-485f-9b47-38c4e96c4065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "2JY--dvwDgyY",
        "outputId": "230dc92f-2485-4395-ce3e-1f150e71d97e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install wget\n",
        "!pip install datasets\n",
        "!pip install scikit-learn\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "OFsfCKWNDhY4",
        "outputId": "8ca4a69d-6653-4258-d88e-6dfba7e1405e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import time, datetime\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "id": "1NvOu43oDwo5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Downloading SST-2 dataset...')\n",
        "\n",
        "# SST-2 데이터셋 ZIP 파일 URL\n",
        "url = 'https://dl.fbaipublicfiles.com/glue/data/SST-2.zip'\n",
        "\n",
        "# 아직 다운로드되지 않았다면 저장\n",
        "if not os.path.exists('./SST-2.zip'):\n",
        "    wget.download(url, './SST-2.zip')"
      ],
      "metadata": {
        "id": "CbV5qPoxFfwm",
        "outputId": "d0e05d8e-1c38-443a-dbaa-7b98a426650d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading SST-2 dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the SST-2 dataset (if we haven't already)\n",
        "if not os.path.exists('./SST-2/'):\n",
        "    !unzip SST-2.zip"
      ],
      "metadata": {
        "id": "nWhLDGo6FzEK",
        "outputId": "93a5d242-a534-4a98-e52a-8292dcb8bc0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the SST-2 training set into a pandas DataFrame.\n",
        "# The SST-2 zip unpacks to a folder “SST-2” containing “train.tsv”, which has a header.\n",
        "df = pd.read_csv(\"./SST-2/train.tsv\", sep='\\t')\n",
        "\n",
        "# Report the number of training sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "Z_CIPSWDGnM9",
        "outputId": "4d34229a-b99a-4bd7-deb8-0cdc01de7f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 67,349\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                sentence  label\n",
              "34482           why anyone should bother remembering it       0\n",
              "58894                      the self-serious equilibrium       0\n",
              "11951  the kind of parent who enjoys intentionally in...      0\n",
              "14827  suffers from too much norma rae and not enough...      0\n",
              "34422                                    the ` laughing       1\n",
              "13203  the movie is concocted and carried out by folk...      0\n",
              "40321                            a properly spooky film       1\n",
              "18071  poses for itself that one can forgive the film...      1\n",
              "4174                     more enjoyable than i expected       1\n",
              "31314                                moving and weighty       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99f90245-758d-4d1b-a017-d4ab8116d56a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34482</th>\n",
              "      <td>why anyone should bother remembering it</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58894</th>\n",
              "      <td>the self-serious equilibrium</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>the kind of parent who enjoys intentionally in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14827</th>\n",
              "      <td>suffers from too much norma rae and not enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34422</th>\n",
              "      <td>the ` laughing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13203</th>\n",
              "      <td>the movie is concocted and carried out by folk...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40321</th>\n",
              "      <td>a properly spooky film</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18071</th>\n",
              "      <td>poses for itself that one can forgive the film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>more enjoyable than i expected</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31314</th>\n",
              "      <td>moving and weighty</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99f90245-758d-4d1b-a017-d4ab8116d56a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99f90245-758d-4d1b-a017-d4ab8116d56a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99f90245-758d-4d1b-a017-d4ab8116d56a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86afecd1-2a1c-4a5f-9d98-5d360b40480a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86afecd1-2a1c-4a5f-9d98-5d360b40480a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86afecd1-2a1c-4a5f-9d98-5d360b40480a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"more enjoyable than i expected \",\n          \"the self-serious equilibrium \",\n          \"the movie is concocted and carried out by folks worthy of scorn , and \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예: 레이블 샘플 5개 보기\n",
        "df.loc[df.label == 1].sample(5)[['sentence', 'label']]"
      ],
      "metadata": {
        "id": "l1q4zLamGqVW",
        "outputId": "5b26f8a8-8801-457f-ff20-946986206e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       sentence  label\n",
              "41113                  heart-pounding suspense       1\n",
              "53006               an oddly winning portrayal       1\n",
              "20291  that is presented with universal appeal       1\n",
              "30150        more than their unique residences       1\n",
              "13014                rich and intelligent film       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6469074-37d4-4ade-b55a-3685ea419cbd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41113</th>\n",
              "      <td>heart-pounding suspense</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53006</th>\n",
              "      <td>an oddly winning portrayal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20291</th>\n",
              "      <td>that is presented with universal appeal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30150</th>\n",
              "      <td>more than their unique residences</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13014</th>\n",
              "      <td>rich and intelligent film</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6469074-37d4-4ade-b55a-3685ea419cbd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6469074-37d4-4ade-b55a-3685ea419cbd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6469074-37d4-4ade-b55a-3685ea419cbd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0c77cf03-5c7e-446b-b229-4afe39b39cea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c77cf03-5c7e-446b-b229-4afe39b39cea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0c77cf03-5c7e-446b-b229-4afe39b39cea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"an oddly winning portrayal \",\n          \"rich and intelligent film \",\n          \"that is presented with universal appeal \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels    = df.label.values"
      ],
      "metadata": {
        "id": "kT4z61RMG0q3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "u4bhqC5EHshE",
        "outputId": "d41eb599-1224-43cd-d3c7-5f7588257598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "db021d937c514dabaf2daede273b247c",
            "865d6210566a4efb83203585d12f3816",
            "3f71cc4a0bb44b4e95c31ff3a2bbd227",
            "06dc2e48fc394c94ace9299835e37642",
            "2e88994e249048a6b20be16828491201",
            "4832a2a48fbc4a9ba030b68ecdc3c1f8",
            "1e1dadb5518448359b4feb3254c39a39",
            "18b8dcd67aaf457493b008554489d4e7",
            "22f345b309944bbe82e6b1028b79c9ae",
            "437571621f7b4c3688a746c801eb5225",
            "c97f03d542fb476897322ece560c79d2",
            "0cb7c130287f43958c479930d7a71801",
            "7fed72dc0b8744c681bc1631646ffebf",
            "3a78229810704aa2ab59f0fb6db9edee",
            "707224129a724fe0a52bca2603bdd18a",
            "ae5bb9fac9344b2b8904d2fd435abe29",
            "bc0a11d9fffb472cb309044744b86130",
            "e46194ee37a84452b0268c61589c740d",
            "804f6624d6ff4ee4ab370c446714e7f0",
            "89fa207ed5574863a3ba26d48fe5539b",
            "216b3f9768c247cdb896001a58373473",
            "7fa3b5abbbc54073922c3bd23fc9d14b",
            "1d9b3bb7b55d4f43982f5479843a0e04",
            "363817c3578043fc962cece775f34dd1",
            "561e41f7d4184524be1244890f618506",
            "171adea36b7c488fb59ede737ee75b24",
            "3a917229e9854c66bfaa2bff4265f219",
            "bab7047752874943b5ac4d1b89a06647",
            "f9ca552323734ceabef0666b95f8bdec",
            "835572a66ddc4f729bb9d696c8118955",
            "5bc9ab062bd74ed79ff861e303ec1677",
            "f8261622693e4b9f8b55f85944b5421c",
            "556768f9f5734b1e9aaa6743344bd6ab",
            "80a65373e47c421bb3a0050251089278",
            "443f0a71356648c8b9a79415c0f1a3bf",
            "4c54365bd6e24486a841770ab9ab93df",
            "f98a539f0e2448bca778740a52669c04",
            "78f78ead30d34016936329073bfcfff3",
            "41443af6da3346dcb5f53e0e426b70ca",
            "a84b8d83e8c34cfca3271b96ce90fb25",
            "ad4795324fae4e71a1e3d50e878c8b12",
            "f2c8a0615004423db97131065abfb8c7",
            "111839d773924095a897cf17ff1463d9",
            "b76f4b90a9524408be7c5cedac4934bb"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db021d937c514dabaf2daede273b247c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cb7c130287f43958c479930d7a71801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d9b3bb7b55d4f43982f5479843a0e04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a65373e47c421bb3a0050251089278"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original SST-2 sentence.\n",
        "print('Original SST-2 sentence:', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized:', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token IDs.\n",
        "print('Token IDs:', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "id": "q2ZKSndRID6r",
        "outputId": "a25fb4ae-d584-4b72-816a-9d5d8d8e9407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SST-2 sentence: hide new secretions from the parental units \n",
            "Tokenized: ['hide', 'new', 'secret', '##ions', 'from', 'the', 'parental', 'units']\n",
            "Token IDs: [5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SST-2 문장들을 토크나이징하고 각 토큰을 ID로 매핑합니다.\n",
        "input_ids = []\n",
        "\n",
        "# 모든 문장에 대해…\n",
        "for sent in sentences:\n",
        "    # `encode`는 다음을 수행합니다:\n",
        "    #   (1) 문장 토크나이징\n",
        "    #   (2) 맨 앞에 `[CLS]` 토큰 추가\n",
        "    #   (3) 문장 끝에 `[SEP]` 토큰 추가\n",
        "    #   (4) 토큰을 ID로 변환\n",
        "    encoded_sent = tokenizer.encode(\n",
        "        sent,                      # 인코딩할 SST-2 문장\n",
        "        add_special_tokens=True,   # '[CLS]'와 '[SEP]' 추가\n",
        "        # (padding/truncation은 이후 단계에서 처리합니다)\n",
        "    )\n",
        "\n",
        "    # 인코딩된 문장을 리스트에 추가\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# 문장 0과 그에 대응하는 토큰 ID를 출력\n",
        "print('Original SST-2 sentence:', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ],
      "metadata": {
        "id": "i-rZnnGIIIrN",
        "outputId": "26f5bf14-162e-4106-db99-a0b7c6cae39b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original SST-2 sentence: hide new secretions from the parental units \n",
            "Token IDs: [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max sentence length:', max(len(sen) for sen in input_ids))"
      ],
      "metadata": {
        "id": "XaCjedW6IRyC",
        "outputId": "a714e90a-34b1-4f2a-a427-9f394e3e9b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# typical SST-2 sentence length...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence.\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=MAX_LEN,\n",
        "    dtype=\"long\",\n",
        "    value=0,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "id": "OqLIqsOUInIx",
        "outputId": "eb0f5228-39cf-45fe-d22d-7a87cba555af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks for SST-2\n",
        "attention_masks = []\n",
        "\n",
        "# For each tokenized sentence...\n",
        "for sent in input_ids:\n",
        "    #  - If token ID == 0, it's padding → mask 0\n",
        "    #  - If token ID >  0, it's a real token → mask 1\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "7XuRLEimIouw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1) SST-2 데이터 불러오기 (train / validation / test 분할 포함)\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# 2) pandas DataFrame으로 변환\n",
        "df_train = pd.DataFrame(raw_datasets[\"train\"])\n",
        "df_val   = pd.DataFrame(raw_datasets[\"validation\"])\n",
        "\n",
        "# 3) 문장과 레이블 리스트 생성\n",
        "sentences_train = df_train[\"sentence\"].values\n",
        "labels_train    = df_train[\"label\"].values\n",
        "\n",
        "sentences_val = df_val[\"sentence\"].values\n",
        "labels_val    = df_val[\"label\"].values\n",
        "\n",
        "# 4) 토크나이저 로드(변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "# 5) 토큰화 & 인코딩 (train/val 각각)\n",
        "def encode_sentences(sentences, tokenizer):\n",
        "    input_ids = []\n",
        "    for sent in sentences:\n",
        "        encoded = tokenizer.encode(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "        )\n",
        "        input_ids.append(encoded)\n",
        "    return input_ids\n",
        "\n",
        "train_ids = encode_sentences(sentences_train, tokenizer)\n",
        "val_ids   = encode_sentences(sentences_val, tokenizer)\n",
        "\n",
        "# 6) MAX_LEN을 SST-2 특성에 맞춰 늘리기 (예: 64)\n",
        "MAX_LEN = 10\n",
        "\n",
        "# 7) 패딩/트렁케이트\n",
        "train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=tokenizer.pad_token_id,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "val_ids   = pad_sequences(val_ids,   maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=tokenizer.pad_token_id,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# 8) 어텐션 마스크 생성\n",
        "def make_masks(input_ids):\n",
        "    return [[int(tok_id != tokenizer.pad_token_id) for tok_id in seq]\n",
        "            for seq in input_ids]\n",
        "\n",
        "train_masks = make_masks(train_ids)\n",
        "val_masks   = make_masks(val_ids)\n",
        "\n",
        "# 9) 텐서로 변환\n",
        "train_inputs      = torch.tensor(train_ids)\n",
        "train_labels      = torch.tensor(labels_train)\n",
        "train_attention  = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(val_ids)\n",
        "validation_labels = torch.tensor(labels_val)\n",
        "validation_attention = torch.tensor(val_masks)\n",
        "\n",
        "# 10) DataLoader 준비 (batch_size 등은 SST-2에 맞춰 조정)\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_attention, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(validation_inputs, validation_attention, validation_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "validation_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "EkzyM2DAJGPf",
        "outputId": "b3afea96-083d-489e-f16a-3691ead23feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "1a5840e2df6348eca02447bfedea0649",
            "99ca06b117eb4c6dad415965568cdcf6",
            "83220f19b635412eab682cab5bc720ae",
            "c5497ed0fcf04257a2726a9ee2bc3733",
            "cd356a7de7574d358e12140ed24c13a3",
            "dbf342b938a64f85b1961a0ee38d5ff3",
            "9bed66be81a94fe6a3e54ad07ae0d230",
            "b849200754c542c4a07cc2aa9541684d",
            "a604f1a88da04b7f89e81ec650474b4d",
            "d92986ddb08b45cd8111e737e8c2e8f2",
            "5ab4c768da444e47b9f0cd3870c61482",
            "ab6aa31d2b4f4443b0a2fcb95bef0638",
            "417f83983a7f4e8686b219014ba681d8",
            "9e234e3a448140b38652178278fe6dd9",
            "9f0605d2083e443791e57a9019f186c9",
            "f3ff5873e76e42cabf94e3e85a75da0a",
            "160e87ba3479427385ce87c98afc1110",
            "00bf30774c98423a857639c2b0a6b014",
            "e218a9050ca94de2ad05f7c148a09871",
            "444d93f64e8845dab6e1c6608dc7eb22",
            "42ef029a158c479f9467151d18fdc3d0",
            "41bc09022acb46cc801934cbb561c703",
            "4ab664ecc8ab483fa07277c82e74eec4",
            "ca81668fb22f4a43b821d002e5753e08",
            "410a8c52d526421cb0afe57c6bd4a41a",
            "fe12f25534a74dd8856378f0fb0fb71b",
            "6f20a96100a64a578f7cac3da14a7775",
            "b59ec14eac0b4865a6cb934978072678",
            "8655ce3293e741f9af9400606c57d17f",
            "59a001929b6d4df18177de6d952c5767",
            "394f8096276d4284a8ff5521914c3c63",
            "7f1f79a6cc8542ceb7a3f3e3fbef1fac",
            "d4c52edee3fe4be38dad81272fccb104",
            "7ba04a175c8445f2add4a3b647dcb456",
            "fc0ec4ff5d5940fbb338b3c3d8ed8cad",
            "c270d57d1072451aa00f5e03e919ee2f",
            "d74f555fa02f4acbbaf93001d362f20e",
            "3d22d4036e6c45d68ece655dd2f4a0cc",
            "873f43914a2249799d3ef2f8f828ddbd",
            "baaae265e0d84a3791ae0632493d0ccc",
            "b75243ba07134a36bc0e0d267274883f",
            "18dfe4d7248547e8aeb06e6103f35b78",
            "bdfc38648dd842f88fa85fa6ecd4a6a5",
            "7611fdc79c004561bc29703777425ccf",
            "1896fd4e05f64530a0bf21ac5a0af439",
            "86d94d3d8dd04669ad535230d7083622",
            "5b214fb6c29444bf97a9b97d98a158ab",
            "56fdb426dff842b9aba18c38c0af5757",
            "f237a42965904188b958f800e226c880",
            "567e56ed9b704ef8b393822650aaf62c",
            "3e23b89404a640a09bc68e3633153243",
            "a9d3b89111384c64ab2130e89eb2c232",
            "f2d1b27dd45f469397963e4e4bb935f7",
            "27ff6e3eebca429c852e837550e94990",
            "80a3d74e93dd491ca1b3e500edeb36b6",
            "621a4f42fdad49da9eddd152c029785b",
            "db82352ec4564c42add70792f0744cdb",
            "5ac05e34cfdb4e7fb03c849a1c61101e",
            "20fce077f1d04fd39e249b542fd77e26",
            "61034abc604242b79202771b40f0b9fe",
            "31f15f9616234ff785c1312c1d2a0ac7",
            "f7093cc42f7a4b7c83e9da99a20d3583",
            "813c55fd435b4082af3a077f88231993",
            "c15de209f4554309ab2bb96b276778e3",
            "7e79dd427c324d19b588753e97caf007",
            "e0df0ff0599a4f588e08e074730cb5f4",
            "992775a8a69b4130abff8878b3129939",
            "7a2be34b7f934b37adc623da7d63fd53",
            "2b8984e98113473bb8c7477d65a7b354",
            "44e0b63cb46147c7a9e8a2e142a870d6",
            "206caa5ed7d3432d93f63c9e79088f19",
            "326b8cf85bfc47dab93e0f4ba888086d",
            "5e305fd542f341519f6dfdb8bf2ea794",
            "086a59d4ec5a4db6a67f10ed4afc2305",
            "30b0379d35ca45d6ba0b298fc26a7bbe",
            "209ff1d8406249b7bc8aebdd153c1c13",
            "1124b19f1de64c6a9250f0a7bee3f93d"
          ]
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a5840e2df6348eca02447bfedea0649"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab6aa31d2b4f4443b0a2fcb95bef0638"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ab664ecc8ab483fa07277c82e74eec4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ba04a175c8445f2add4a3b647dcb456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1896fd4e05f64530a0bf21ac5a0af439"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "621a4f42fdad49da9eddd152c029785b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "992775a8a69b4130abff8878b3129939"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",   # 12-layer BERT, uncased vocab\n",
        "    num_labels=2,          # SST-2 is binary (positive / negative)\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "# Move the model to GPU for training/inference\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "XvdsETdaKLrY",
        "outputId": "8031bce0-cc67-4d10-974b-12542b1a03b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969,
          "referenced_widgets": [
            "92c21638f71d4165a022b6fd0f697a00",
            "78e4746f75cc44f2b4e27122fe2bada8",
            "1f794bc9fc5c41d3901c2da6ed59dccf",
            "03455df901b446f4bf7e34932b94fd4e",
            "72d3be86354a4d40a945eb952633375a",
            "c4a582c5a07247de8d485d81f9bc81ac",
            "9946ba66145f4262a2bea29205a80bbb",
            "cc919824bea944b280b44a5605174542",
            "29cbdc77708d415598827c4f78009cc8",
            "bd0e47cd84ce4cd6a5292fbf16d54264",
            "b0203731c3b6412785569019b5f53371"
          ]
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92c21638f71d4165a022b6fd0f697a00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-fetch params to be sure\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print(f\"The SST-2 fine-tuned BERT model has {len(params)} named parameters.\\n\")\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for name, tensor in params[0:5]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")\n",
        "\n",
        "print('\\n==== First Transformer Layer ====\\n')\n",
        "for name, tensor in params[5:21]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for name, tensor in params[-4:]:\n",
        "    shape = tuple(tensor.size())\n",
        "    print(f\"{name:<55} {str(shape):>12}\")"
      ],
      "metadata": {
        "id": "CwHACT1RKb5z",
        "outputId": "824bcea8-41b5-40f4-954d-2c2f38df1d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The SST-2 fine-tuned BERT model has 201 named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer Layer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for fine-tuning on SST-2.\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,   # learning rate commonly used for SST-2 fine-tuning\n",
        "    eps=1e-8   # Adam epsilon\n",
        ")"
      ],
      "metadata": {
        "id": "dTbHb8NeKhfo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs for SST-2 (authors recommend ~3)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,         # run_glue.py 기본값\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "-0__rGtHLJ9I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our SST-2 predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "UZdM1oxQLxMW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    \"\"\"\n",
        "    소요 시간을 초 단위로 받아서 'hh:mm:ss' 형식의 문자열로 반환합니다.\n",
        "    SST-2 GLUE 미세조정(training/evaluation) 로그 출력에 사용하세요.\n",
        "    \"\"\"\n",
        "    # 초 단위로 반올림\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    # 'hh:mm:ss' 포맷으로 변환\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "ABNueEAPL-25"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 재현 가능성을 위해 시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 에폭별 평균 손실 기록용\n",
        "loss_values = []\n",
        "\n",
        "# 에폭 수는 앞서 설정한 epochs 변수 사용\n",
        "for epoch_i in range(epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training (SST-2)\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(f'======== SST-2 Epoch {epoch_i+1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and step != 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'  Batch {step:>5,} of {len(train_dataloader):>5,}. Elapsed: {elapsed}')\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass (SST-2는 binary label)\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(f\"  Training epoch took: {format_time(time.time() - t0)}\")\n",
        "\n",
        "    # ========================================\n",
        "    #             Validation (SST-2)\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "            logits = outputs[0].detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            preds = np.argmax(logits, axis=1)\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(label_ids)\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"  Validation took: {format_time(time.time() - t0)}\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"SST-2 fine-tuning complete!\")\n"
      ],
      "metadata": {
        "id": "nPBQtpWdMa-T",
        "outputId": "3ab14f8d-c14b-4f1f-ffe6-4a1ea04cf1b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== SST-2 Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:04\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:07\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:10\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:13\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:16\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:19\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:22\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:25\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:28\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:31\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:34\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:37\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:40\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:43\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:46\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:49\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:52\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:55\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:58\n",
            "  Batch   800 of 2,105. Elapsed: 0:01:01\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:04\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:07\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:10\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:13\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:16\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:19\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:23\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:26\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:29\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:32\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:35\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:38\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:41\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:44\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:47\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:50\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:53\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:56\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:59\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:02:02\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:02:05\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:08\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:11\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:14\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:17\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:20\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:23\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:26\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:29\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:32\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:35\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:38\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epoch took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7993\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== SST-2 Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:03\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:06\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:09\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:12\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:15\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:18\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:21\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:24\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:27\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:30\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:33\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:36\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:39\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:42\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:45\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:48\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:51\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:54\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:57\n",
            "  Batch   800 of 2,105. Elapsed: 0:01:00\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:03\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:06\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:09\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:12\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:15\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:18\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:21\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:24\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:27\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:30\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:33\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:37\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:40\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:42\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:45\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:48\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:51\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:54\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:57\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:02:00\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:02:03\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:06\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:09\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:12\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:15\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:19\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:21\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:24\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:27\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:30\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:33\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:36\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epoch took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7913\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== SST-2 Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40 of 2,105. Elapsed: 0:00:03\n",
            "  Batch    80 of 2,105. Elapsed: 0:00:06\n",
            "  Batch   120 of 2,105. Elapsed: 0:00:09\n",
            "  Batch   160 of 2,105. Elapsed: 0:00:12\n",
            "  Batch   200 of 2,105. Elapsed: 0:00:15\n",
            "  Batch   240 of 2,105. Elapsed: 0:00:18\n",
            "  Batch   280 of 2,105. Elapsed: 0:00:21\n",
            "  Batch   320 of 2,105. Elapsed: 0:00:24\n",
            "  Batch   360 of 2,105. Elapsed: 0:00:27\n",
            "  Batch   400 of 2,105. Elapsed: 0:00:30\n",
            "  Batch   440 of 2,105. Elapsed: 0:00:33\n",
            "  Batch   480 of 2,105. Elapsed: 0:00:36\n",
            "  Batch   520 of 2,105. Elapsed: 0:00:39\n",
            "  Batch   560 of 2,105. Elapsed: 0:00:42\n",
            "  Batch   600 of 2,105. Elapsed: 0:00:45\n",
            "  Batch   640 of 2,105. Elapsed: 0:00:48\n",
            "  Batch   680 of 2,105. Elapsed: 0:00:51\n",
            "  Batch   720 of 2,105. Elapsed: 0:00:54\n",
            "  Batch   760 of 2,105. Elapsed: 0:00:57\n",
            "  Batch   800 of 2,105. Elapsed: 0:01:00\n",
            "  Batch   840 of 2,105. Elapsed: 0:01:03\n",
            "  Batch   880 of 2,105. Elapsed: 0:01:06\n",
            "  Batch   920 of 2,105. Elapsed: 0:01:09\n",
            "  Batch   960 of 2,105. Elapsed: 0:01:12\n",
            "  Batch 1,000 of 2,105. Elapsed: 0:01:15\n",
            "  Batch 1,040 of 2,105. Elapsed: 0:01:18\n",
            "  Batch 1,080 of 2,105. Elapsed: 0:01:21\n",
            "  Batch 1,120 of 2,105. Elapsed: 0:01:24\n",
            "  Batch 1,160 of 2,105. Elapsed: 0:01:27\n",
            "  Batch 1,200 of 2,105. Elapsed: 0:01:30\n",
            "  Batch 1,240 of 2,105. Elapsed: 0:01:33\n",
            "  Batch 1,280 of 2,105. Elapsed: 0:01:36\n",
            "  Batch 1,320 of 2,105. Elapsed: 0:01:39\n",
            "  Batch 1,360 of 2,105. Elapsed: 0:01:42\n",
            "  Batch 1,400 of 2,105. Elapsed: 0:01:45\n",
            "  Batch 1,440 of 2,105. Elapsed: 0:01:48\n",
            "  Batch 1,480 of 2,105. Elapsed: 0:01:51\n",
            "  Batch 1,520 of 2,105. Elapsed: 0:01:54\n",
            "  Batch 1,560 of 2,105. Elapsed: 0:01:57\n",
            "  Batch 1,600 of 2,105. Elapsed: 0:02:00\n",
            "  Batch 1,640 of 2,105. Elapsed: 0:02:03\n",
            "  Batch 1,680 of 2,105. Elapsed: 0:02:06\n",
            "  Batch 1,720 of 2,105. Elapsed: 0:02:09\n",
            "  Batch 1,760 of 2,105. Elapsed: 0:02:12\n",
            "  Batch 1,800 of 2,105. Elapsed: 0:02:15\n",
            "  Batch 1,840 of 2,105. Elapsed: 0:02:18\n",
            "  Batch 1,880 of 2,105. Elapsed: 0:02:21\n",
            "  Batch 1,920 of 2,105. Elapsed: 0:02:24\n",
            "  Batch 1,960 of 2,105. Elapsed: 0:02:27\n",
            "  Batch 2,000 of 2,105. Elapsed: 0:02:30\n",
            "  Batch 2,040 of 2,105. Elapsed: 0:02:33\n",
            "  Batch 2,080 of 2,105. Elapsed: 0:02:36\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 0:02:38\n",
            "\n",
            "Running Validation...\n",
            "  Validation Accuracy: 0.7901\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "SST-2 fine-tuning complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 스타일 설정 (Seaborn)\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# SST-2 학습 손실 곡선 그리기\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# 축 레이블 및 제목\n",
        "plt.title(\"SST-2 Fine-tuning Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Epoch 번호 표시\n",
        "plt.xticks(range(1, len(loss_values) + 1))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "awFGag7vOW9s",
        "outputId": "c4b3553b-da32-4a48-e7a3-74250a07e4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, SequentialSampler, DataLoader\n",
        "\n",
        "# SST-2 validation split을 pandas DataFrame으로 변환\n",
        "df = pd.DataFrame(raw_datasets['validation'])\n",
        "\n",
        "# 문장 수 출력\n",
        "print('Number of validation sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# 문장과 레이블 리스트 생성\n",
        "sentences = df['sentence'].values\n",
        "labels    = df['label'].values\n",
        "\n",
        "# 토크나이징 및 ID 매핑\n",
        "input_ids = []\n",
        "for sent in sentences:\n",
        "    encoded = tokenizer.encode(\n",
        "        sent,\n",
        "        add_special_tokens=True  # [CLS], [SEP] 추가\n",
        "    )\n",
        "    input_ids.append(encoded)\n",
        "\n",
        "# 패딩/트렁케이팅\n",
        "input_ids = pad_sequences(\n",
        "    input_ids, maxlen=MAX_LEN,\n",
        "    dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        ")\n",
        "\n",
        "# Attention mask 생성 (0=패딩, 1=실제 토큰)\n",
        "attention_masks = [\n",
        "    [float(i > 0) for i in seq]\n",
        "    for seq in input_ids\n",
        "]\n",
        "\n",
        "# 텐서로 변환\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks  = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# DataLoader 구성\n",
        "batch_size = 32\n",
        "prediction_data    = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, sampler=prediction_sampler, batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "wPGXVkwrOzeu",
        "outputId": "499718d1-a53f-46f5-9074-1c13fae30b1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation sentences: 872\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SST-2 검증(validation) 셋에 대한 예측 수행\n",
        "print('Predicting labels for {:,} validation sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# 모델을 평가 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 예측값과 실젯값 저장용\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "# 배치 단위로 예측 수행\n",
        "for batch in prediction_dataloader:\n",
        "    # GPU로 배치 옮기기\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # 그래디언트 계산 하지 않음\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            token_type_ids=None,\n",
        "            attention_mask=b_input_mask\n",
        "        )\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 옮기고 numpy로 변환\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 저장\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "metadata": {
        "id": "z7G8bwDMO17R",
        "outputId": "81f03860-78bc-4008-bc4c-3c20faf17775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 872 validation sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = df.label.sum()\n",
        "total = len(df)\n",
        "pct = pos / total * 100.0\n",
        "\n",
        "print('Positive samples: %d of %d (%.2f%%)' % (pos, total, pct))\n"
      ],
      "metadata": {
        "id": "OtKW1ZX9O4Sm",
        "outputId": "01426eed-b48b-4fd1-beaa-9fce61e7269d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 444 of 872 (50.92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "import numpy as np\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# SST-2 테스트 배치별 Matthews 상관계수 계산\n",
        "print('Calculating Matthews Corr. Coef. for each SST-2 test batch...')\n",
        "\n",
        "# predictions: 리스트 of ndarray [batch_size, 2], true_labels: 리스트 of ndarray [batch_size]\n",
        "for i in range(len(true_labels)):\n",
        "    # logits에서 가장 큰 클래스를 예측 레이블로 선택\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    # 해당 배치의 MCC 계산\n",
        "    mcc = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "    matthews_set.append(mcc)\n",
        "\n",
        "# 결과 출력\n",
        "print('Batch-wise MCCs:', ['{:.4f}'.format(m) for m in matthews_set])\n",
        "print('Average MCC       : {:.4f}'.format(np.mean(matthews_set)))\n"
      ],
      "metadata": {
        "id": "zuh9uwiyO7hr",
        "outputId": "cf2874dc-6a80-4254-b5e3-94f5f52f1773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each SST-2 test batch...\n",
            "Batch-wise MCCs: ['0.6190', '0.8126', '0.3333', '0.5000', '0.5040', '0.3830', '0.6256', '0.6113', '0.4454', '0.7006', '0.6455', '0.4980', '0.5220', '0.7454', '0.7460', '0.7229', '0.5636', '0.5922', '0.4732', '0.6864', '0.7559', '0.5164', '0.4228', '0.3522', '0.6386', '0.7705', '0.5040', '0.7746']\n",
            "Average MCC       : 0.5880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# … (위에서 matthews_set을 계산한 뒤)\n",
        "\n",
        "# SST-2 배치별 MCC 출력\n",
        "print(\"배치별 Matthews CorrCoef:\", [\"{:.4f}\".format(m) for m in matthews_set])\n",
        "\n",
        "# 평균 MCC 계산 및 출력\n",
        "avg_mcc = np.mean(matthews_set)\n",
        "print(\"평균 Matthews CorrCoef : {:.4f}\".format(avg_mcc))\n"
      ],
      "metadata": {
        "id": "q1u4UaBaO9si",
        "outputId": "959326cc-f7da-4555-9474-da61c3449ce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "배치별 Matthews CorrCoef: ['0.6190', '0.8126', '0.3333', '0.5000', '0.5040', '0.3830', '0.6256', '0.6113', '0.4454', '0.7006', '0.6455', '0.4980', '0.5220', '0.7454', '0.7460', '0.7229', '0.5636', '0.5922', '0.4732', '0.6864', '0.7559', '0.5164', '0.4228', '0.3522', '0.6386', '0.7705', '0.5040', '0.7746']\n",
            "평균 Matthews CorrCoef : 0.5880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# 1) 모든 배치의 logits를 하나의 배열로 합치고, 각 샘플의 예측 라벨(0 또는 1) 생성\n",
        "all_logits = np.vstack(predictions)               # shape = [num_batches*batch_size, 2]\n",
        "flat_predictions = np.argmax(all_logits, axis=1)  # [num_samples]\n",
        "\n",
        "# 2) 모든 배치의 실제 레이블을 하나의 배열로 합치기\n",
        "flat_true_labels = np.concatenate(true_labels)    # [num_samples]\n",
        "\n",
        "# 3) SST-2 테스트 세트에 대한 MCC 계산 및 출력\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "print(f\"SST-2 Test MCC: {mcc:.3f}\")\n"
      ],
      "metadata": {
        "id": "B3ZE1-FqO_1A",
        "outputId": "c2a3c100-9da6-4c24-ce55-852bf8f077a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST-2 Test MCC: 0.582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SST - 2  적용"
      ],
      "metadata": {
        "id": "YvtIdiYRP9QG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "# 1) CORDIC-Softmax이 적용된 SelfAttention 정의\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. [B,12,L,L]\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            # row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n",
        "\n",
        "# 2) SST-2용 BERT 모델 로드 (이미 fine-tuned 체크포인트가 있다면 그걸로)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",  # 또는 ./sst2_output 같은 로컬 경로\n",
        "    num_labels=2\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 3) 각 레이어의 self-attention을 패치\n",
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    mod  = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 그대로 복사\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n",
        "\n",
        "print(\"Self-Attention modules after patch:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    print(f\" Layer {i:2d}: {layer.attention.self.__class__.__name__}\")\n"
      ],
      "metadata": {
        "id": "DpUxcH-AP8LF",
        "outputId": "8830d5c9-e408-4942-ca52-b32b0a6f0d34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-Attention modules after patch:\n",
            " Layer  0: BertSelfAttentionModified\n",
            " Layer  1: BertSelfAttentionModified\n",
            " Layer  2: BertSelfAttentionModified\n",
            " Layer  3: BertSelfAttentionModified\n",
            " Layer  4: BertSelfAttentionModified\n",
            " Layer  5: BertSelfAttentionModified\n",
            " Layer  6: BertSelfAttentionModified\n",
            " Layer  7: BertSelfAttentionModified\n",
            " Layer  8: BertSelfAttentionModified\n",
            " Layer  9: BertSelfAttentionModified\n",
            " Layer 10: BertSelfAttentionModified\n",
            " Layer 11: BertSelfAttentionModified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "# 1) 각 레이어의 Self-Attention 모듈 클래스 확인\n",
        "print(\"== Self-Attention Modules ==\")\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "print(\"=============================\\n\")\n",
        "\n",
        "# 2) 모델 클래스 이름 확인 (Cordic 패치된 SST-2용 버전이어야 함)\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "#    → 예: BertForSequenceClassificationCordic\n",
        "\n",
        "# 3) forward 메서드가 서브클래스에서 오버라이드된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "#    → 예: BertForSequenceClassificationCordic.forward\n",
        "\n",
        "# 4) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)\n"
      ],
      "metadata": {
        "id": "wH1ZcdEZQUO8",
        "outputId": "09888f37-5206-4803-cb11-0bd88629188c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "=============================\n",
            "\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass: 마지막 레이어 어텐션 가중치까지 출력하도록 설정\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,                # SST-2 validation batch의 input_ids\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True      # 모든 레이어의 attention_probs를 리턴\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 12번째(=마지막) 레이어의 attention_probs만 꺼내기\n",
        "all_attentions = outputs.attentions    # 길이 12인 tuple, each is [B, H, L, L]\n",
        "last_layer_probs = all_attentions[-1]  # [B, H, L, L]\n",
        "\n",
        "# 3) “키” 차원(L)에 대해 합이 1인지 검사\n",
        "#    sums.shape == [B, H, L]\n",
        "sums = last_layer_probs.sum(dim=-1)\n",
        "print(\"마지막 레이어 어텐션 확률 합 (shape={}):\\n{}\".format(sums.shape, sums))\n"
      ],
      "metadata": {
        "id": "6lQtyK9YQWtY",
        "outputId": "7496b17a-712c-4444-e177-5e53788b2d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마지막 레이어 어텐션 확률 합 (shape=torch.Size([8, 12, 10])):\n",
            "tensor([[[0.9878, 0.9907, 0.9844, 0.9895, 0.9912, 0.9929, 0.9895, 0.9883,\n",
            "          0.9846, 0.9810],\n",
            "         [0.9905, 0.9944, 0.9785, 0.9797, 0.9927, 0.9919, 0.9800, 0.9885,\n",
            "          0.9917, 0.9705],\n",
            "         [0.9939, 0.9888, 0.9978, 0.9817, 0.9893, 0.9980, 0.9937, 0.9912,\n",
            "          0.9880, 0.9739],\n",
            "         [0.9963, 0.9910, 0.9824, 0.9968, 0.9854, 0.9917, 0.9832, 0.9866,\n",
            "          0.9873, 0.9832],\n",
            "         [0.9966, 1.0010, 0.9956, 0.9961, 0.9951, 0.9966, 0.9915, 0.9941,\n",
            "          0.9980, 0.9968],\n",
            "         [0.9963, 0.9929, 0.9929, 0.9878, 0.9812, 0.9939, 0.9941, 0.9951,\n",
            "          0.9929, 0.9985],\n",
            "         [0.9934, 0.9810, 0.9915, 0.9841, 0.9932, 0.9941, 0.9834, 0.9749,\n",
            "          0.9709, 0.9927],\n",
            "         [0.9839, 0.9919, 0.9861, 0.9851, 0.9912, 0.9785, 0.9951, 0.9697,\n",
            "          0.9749, 0.9890],\n",
            "         [0.9968, 0.9949, 0.9788, 0.9983, 0.9775, 0.9956, 0.9961, 0.9929,\n",
            "          0.9976, 0.9978],\n",
            "         [0.9871, 0.9932, 0.9954, 0.9961, 0.9871, 0.9790, 0.9883, 0.9751,\n",
            "          0.9866, 0.9924],\n",
            "         [0.9985, 0.9958, 0.9890, 0.9888, 0.9893, 0.9844, 0.9795, 0.9922,\n",
            "          0.9978, 0.9888],\n",
            "         [0.9954, 0.9988, 0.9888, 0.9893, 0.9910, 0.9810, 0.9829, 0.9846,\n",
            "          0.9915, 0.9897]],\n",
            "\n",
            "        [[0.9927, 0.9968, 0.9788, 0.9861, 0.9951, 0.9973, 0.9944, 0.9993,\n",
            "          0.9929, 0.9993],\n",
            "         [0.9927, 0.9937, 0.9968, 0.9968, 0.9944, 0.9849, 0.9946, 0.9949,\n",
            "          0.9934, 0.9919],\n",
            "         [0.9978, 0.9990, 0.9924, 0.9995, 1.0015, 0.9966, 0.9968, 0.9937,\n",
            "          0.9995, 0.9954],\n",
            "         [0.9790, 0.9951, 0.9944, 0.9963, 0.9937, 0.9980, 0.9963, 0.9880,\n",
            "          0.9927, 0.9966],\n",
            "         [0.9919, 0.9961, 0.9941, 0.9961, 0.9929, 0.9961, 0.9954, 0.9995,\n",
            "          0.9941, 0.9961],\n",
            "         [0.9971, 0.9958, 0.9956, 0.9980, 0.9990, 0.9976, 0.9993, 0.9980,\n",
            "          0.9973, 0.9990],\n",
            "         [0.9951, 0.9897, 0.9998, 0.9980, 0.9971, 0.9854, 0.9956, 0.9966,\n",
            "          0.9971, 0.9968],\n",
            "         [0.9958, 0.9976, 0.9983, 0.9988, 0.9980, 0.9976, 0.9985, 0.9978,\n",
            "          0.9973, 0.9985],\n",
            "         [0.9883, 0.9993, 1.0005, 1.0005, 0.9980, 0.9990, 0.9980, 0.9932,\n",
            "          0.9963, 0.9910],\n",
            "         [0.9963, 0.9946, 0.9954, 0.9985, 0.9915, 0.9919, 0.9966, 0.9941,\n",
            "          0.9958, 0.9932],\n",
            "         [1.0039, 0.9990, 0.9954, 0.9988, 0.9993, 0.9941, 0.9963, 0.9968,\n",
            "          1.0000, 0.9954],\n",
            "         [0.9915, 0.9990, 0.9973, 0.9961, 0.9978, 0.9973, 0.9998, 0.9993,\n",
            "          0.9985, 0.9985]],\n",
            "\n",
            "        [[0.9919, 0.9956, 0.9966, 0.9985, 0.9985, 0.9978, 0.9966, 0.9963,\n",
            "          0.9998, 0.9958],\n",
            "         [0.9966, 0.9988, 0.9968, 0.9985, 0.9988, 0.9998, 1.0000, 0.9993,\n",
            "          0.9958, 0.9988],\n",
            "         [0.9990, 0.9971, 0.9961, 0.9963, 0.9968, 0.9963, 0.9971, 1.0000,\n",
            "          0.9963, 0.9961],\n",
            "         [0.9966, 0.9976, 0.9998, 0.9973, 0.9978, 0.9966, 0.9971, 0.9993,\n",
            "          0.9983, 0.9993],\n",
            "         [0.9941, 0.9976, 0.9978, 0.9990, 0.9968, 0.9990, 1.0000, 0.9968,\n",
            "          0.9998, 0.9985],\n",
            "         [0.9990, 0.9976, 0.9954, 1.0002, 0.9995, 0.9995, 0.9937, 0.9946,\n",
            "          0.9944, 0.9993],\n",
            "         [0.9873, 0.9968, 0.9995, 0.9985, 0.9966, 1.0005, 0.9998, 1.0002,\n",
            "          0.9961, 0.9990],\n",
            "         [1.0010, 0.9980, 0.9961, 0.9988, 0.9976, 0.9985, 0.9897, 1.0012,\n",
            "          0.9990, 0.9985],\n",
            "         [0.9988, 0.9956, 0.9976, 0.9978, 0.9958, 0.9895, 0.9949, 0.9915,\n",
            "          0.9893, 0.9963],\n",
            "         [0.9976, 0.9966, 0.9907, 0.9963, 0.9998, 0.9949, 0.9980, 1.0034,\n",
            "          0.9966, 0.9963],\n",
            "         [0.9958, 1.0000, 0.9993, 0.9985, 0.9961, 0.9946, 0.9993, 0.9983,\n",
            "          0.9985, 0.9985],\n",
            "         [0.9988, 0.9963, 0.9993, 0.9978, 0.9980, 0.9993, 0.9968, 0.9978,\n",
            "          0.9963, 0.9971]],\n",
            "\n",
            "        [[0.9978, 0.9966, 0.9993, 0.9988, 0.9990, 0.9973, 0.9961, 0.9971,\n",
            "          0.9966, 1.0000],\n",
            "         [0.9980, 0.9980, 1.0015, 0.9973, 0.9954, 0.9958, 0.9954, 0.9963,\n",
            "          0.9912, 0.9949],\n",
            "         [0.9976, 0.9983, 0.9963, 0.9976, 0.9971, 1.0007, 0.9971, 1.0000,\n",
            "          0.9976, 0.9973],\n",
            "         [0.9844, 0.9932, 0.9949, 0.9961, 0.9956, 0.9956, 0.9941, 0.9937,\n",
            "          0.9968, 0.9824],\n",
            "         [0.9912, 0.9951, 0.9971, 0.9980, 0.9956, 0.9978, 0.9993, 0.9985,\n",
            "          0.9993, 0.9976],\n",
            "         [0.9980, 0.9976, 1.0012, 0.9985, 0.9963, 0.9993, 0.9961, 0.9958,\n",
            "          0.9978, 0.9983],\n",
            "         [0.9951, 0.9983, 0.9912, 0.9966, 0.9973, 0.9968, 0.9961, 0.9946,\n",
            "          0.9968, 0.9963],\n",
            "         [0.9934, 1.0005, 0.9985, 1.0005, 0.9973, 1.0005, 1.0002, 0.9983,\n",
            "          0.9963, 0.9985],\n",
            "         [0.9956, 0.9939, 0.9985, 0.9963, 0.9907, 0.9846, 0.9888, 0.9990,\n",
            "          0.9846, 0.9949],\n",
            "         [0.9912, 0.9983, 0.9849, 0.9915, 0.9846, 0.9866, 0.9978, 0.9990,\n",
            "          0.9946, 0.9897],\n",
            "         [0.9973, 0.9932, 0.9988, 0.9968, 0.9944, 0.9995, 0.9963, 0.9973,\n",
            "          1.0000, 0.9929],\n",
            "         [0.9954, 0.9990, 0.9971, 0.9968, 0.9941, 1.0005, 0.9978, 0.9978,\n",
            "          0.9968, 0.9939]],\n",
            "\n",
            "        [[0.9934, 0.9934, 0.9976, 0.9985, 0.9968, 0.9907, 0.9912, 0.9971,\n",
            "          0.9924, 0.9944],\n",
            "         [0.9941, 0.9895, 0.9907, 0.9966, 0.9958, 0.9893, 0.9958, 0.9983,\n",
            "          0.9968, 0.9983],\n",
            "         [0.9976, 0.9973, 0.9949, 0.9993, 0.9988, 0.9971, 0.9988, 0.9971,\n",
            "          0.9978, 0.9985],\n",
            "         [0.9927, 0.9900, 0.9849, 0.9956, 0.9946, 0.9954, 0.9971, 0.9968,\n",
            "          0.9941, 0.9954],\n",
            "         [0.9895, 0.9937, 0.9897, 0.9968, 0.9971, 0.9980, 0.9966, 0.9961,\n",
            "          0.9990, 0.9919],\n",
            "         [0.9944, 0.9973, 0.9966, 0.9963, 0.9998, 0.9985, 0.9973, 0.9958,\n",
            "          0.9973, 0.9968],\n",
            "         [0.9961, 0.9902, 0.9978, 0.9956, 0.9963, 0.9961, 0.9978, 0.9978,\n",
            "          1.0000, 0.9968],\n",
            "         [0.9946, 0.9932, 0.9980, 0.9990, 0.9966, 0.9971, 0.9961, 1.0007,\n",
            "          0.9915, 0.9968],\n",
            "         [0.9934, 0.9932, 0.9978, 0.9963, 1.0002, 1.0000, 0.9912, 0.9946,\n",
            "          0.9910, 0.9880],\n",
            "         [0.9963, 0.9966, 0.9980, 0.9980, 0.9971, 0.9978, 0.9937, 0.9968,\n",
            "          0.9944, 0.9949],\n",
            "         [0.9941, 0.9958, 0.9976, 0.9980, 0.9990, 0.9912, 0.9983, 0.9980,\n",
            "          0.9973, 0.9980],\n",
            "         [0.9990, 0.9966, 0.9978, 0.9995, 0.9937, 0.9993, 0.9988, 0.9963,\n",
            "          1.0012, 0.9932]],\n",
            "\n",
            "        [[0.9871, 0.9971, 0.9990, 1.0005, 0.9978, 0.9937, 0.9988, 0.9958,\n",
            "          0.9927, 0.9944],\n",
            "         [0.9939, 0.9998, 0.9995, 0.9954, 0.9941, 0.9976, 0.9919, 0.9875,\n",
            "          0.9941, 0.9988],\n",
            "         [0.9988, 0.9937, 0.9949, 0.9976, 0.9993, 0.9995, 0.9985, 0.9963,\n",
            "          0.9966, 0.9973],\n",
            "         [0.9924, 0.9941, 0.9966, 0.9966, 0.9988, 0.9954, 0.9980, 0.9958,\n",
            "          0.9968, 0.9905],\n",
            "         [0.9946, 0.9961, 0.9983, 0.9983, 1.0010, 0.9968, 1.0010, 0.9990,\n",
            "          0.9907, 0.9976],\n",
            "         [0.9961, 1.0010, 0.9971, 0.9944, 0.9951, 0.9988, 0.9907, 0.9924,\n",
            "          0.9941, 0.9980],\n",
            "         [0.9910, 0.9988, 0.9934, 0.9883, 0.9971, 0.9932, 0.9937, 0.9954,\n",
            "          0.9978, 0.9961],\n",
            "         [0.9951, 0.9939, 0.9980, 0.9988, 0.9971, 0.9973, 0.9939, 0.9946,\n",
            "          0.9978, 0.9946],\n",
            "         [0.9990, 0.9883, 0.9995, 0.9902, 0.9971, 0.9968, 0.9788, 0.9885,\n",
            "          0.9844, 0.9934],\n",
            "         [0.9976, 0.9990, 0.9951, 0.9978, 0.9956, 0.9968, 0.9976, 0.9924,\n",
            "          0.9971, 0.9993],\n",
            "         [0.9958, 0.9971, 0.9958, 0.9990, 0.9983, 0.9998, 0.9988, 0.9971,\n",
            "          0.9998, 0.9983],\n",
            "         [0.9971, 0.9949, 0.9988, 0.9978, 0.9922, 0.9956, 0.9946, 0.9902,\n",
            "          0.9993, 0.9961]],\n",
            "\n",
            "        [[0.9993, 0.9983, 1.0010, 0.9995, 0.9978, 1.0000, 1.0000, 0.9983,\n",
            "          0.9995, 0.9976],\n",
            "         [0.9985, 0.9998, 0.9998, 0.9978, 0.9958, 0.9985, 1.0005, 0.9961,\n",
            "          0.9988, 1.0007],\n",
            "         [0.9980, 0.9990, 0.9946, 0.9998, 0.9976, 0.9963, 0.9980, 0.9983,\n",
            "          0.9980, 0.9963],\n",
            "         [0.9993, 0.9976, 0.9980, 0.9978, 0.9980, 0.9983, 0.9963, 0.9993,\n",
            "          0.9971, 0.9988],\n",
            "         [0.9998, 0.9976, 0.9980, 0.9971, 0.9973, 0.9985, 0.9985, 0.9985,\n",
            "          0.9973, 0.9995],\n",
            "         [0.9985, 0.9971, 0.9990, 1.0002, 0.9990, 0.9990, 0.9951, 0.9968,\n",
            "          0.9983, 0.9939],\n",
            "         [0.9990, 0.9990, 1.0000, 0.9988, 0.9993, 0.9978, 0.9966, 0.9963,\n",
            "          0.9966, 0.9978],\n",
            "         [0.9934, 0.9978, 0.9983, 0.9973, 0.9988, 0.9985, 0.9985, 1.0002,\n",
            "          0.9978, 0.9946],\n",
            "         [0.9983, 0.9978, 0.9976, 0.9956, 0.9983, 0.9993, 0.9976, 0.9995,\n",
            "          1.0002, 0.9993],\n",
            "         [0.9963, 0.9963, 0.9995, 0.9995, 0.9990, 0.9961, 0.9978, 0.9983,\n",
            "          0.9983, 0.9963],\n",
            "         [0.9978, 0.9980, 0.9998, 0.9988, 0.9985, 0.9993, 0.9998, 0.9990,\n",
            "          0.9985, 0.9978],\n",
            "         [0.9978, 0.9971, 0.9980, 0.9971, 0.9993, 0.9993, 0.9985, 0.9983,\n",
            "          0.9998, 0.9944]],\n",
            "\n",
            "        [[0.9961, 0.9941, 0.9929, 0.9998, 0.9958, 0.9897, 0.9832, 0.9949,\n",
            "          0.9944, 0.9966],\n",
            "         [0.9961, 0.9905, 0.9976, 0.9927, 0.9866, 0.9971, 0.9954, 0.9954,\n",
            "          0.9954, 0.9922],\n",
            "         [0.9966, 0.9983, 1.0002, 0.9971, 0.9949, 0.9983, 0.9956, 0.9990,\n",
            "          0.9985, 0.9978],\n",
            "         [0.9973, 0.9973, 0.9968, 0.9961, 0.9963, 0.9983, 0.9995, 0.9995,\n",
            "          0.9966, 0.9988],\n",
            "         [0.9988, 0.9961, 0.9976, 0.9941, 0.9998, 0.9980, 0.9993, 0.9958,\n",
            "          0.9978, 0.9966],\n",
            "         [0.9980, 0.9971, 0.9998, 1.0000, 0.9949, 0.9980, 0.9968, 0.9922,\n",
            "          0.9946, 0.9905],\n",
            "         [0.9968, 0.9990, 0.9946, 0.9966, 0.9966, 0.9954, 0.9902, 0.9951,\n",
            "          0.9927, 0.9971],\n",
            "         [0.9973, 0.9968, 0.9907, 0.9983, 0.9968, 0.9968, 0.9988, 0.9993,\n",
            "          0.9990, 0.9990],\n",
            "         [0.9949, 0.9861, 0.9954, 0.9949, 0.9958, 0.9863, 0.9958, 0.9875,\n",
            "          0.9961, 0.9907],\n",
            "         [0.9951, 0.9956, 0.9976, 0.9980, 1.0002, 0.9963, 0.9966, 0.9978,\n",
            "          0.9978, 0.9990],\n",
            "         [0.9966, 0.9973, 0.9988, 0.9990, 0.9998, 0.9983, 0.9968, 0.9988,\n",
            "          0.9968, 0.9963],\n",
            "         [0.9978, 0.9968, 0.9937, 0.9985, 0.9983, 0.9990, 0.9941, 0.9990,\n",
            "          0.9902, 0.9961]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation_sst2(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "    # tqdm으로 진행 상황 표시\n",
        "    for batch in tqdm(validation_dataloader, desc=\"Validating\"):\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "        # forward\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "        logits = outputs[0]            # [B, 2]\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(logits, b_labels)\n",
        "        eval_loss += loss.item()\n",
        "\n",
        "        # preds & labels\n",
        "        preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "        labels = b_labels.detach().cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # 평균 지표\n",
        "    avg_loss    = eval_loss / nb_eval_steps\n",
        "    avg_acc     = np.mean(np.array(all_preds) == np.array(all_labels))  # 0~1\n",
        "    mcc         = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # positive 비율\n",
        "    pos_pred_ratio = 100.0 * np.sum(all_preds) / len(all_preds)\n",
        "    pos_true_ratio = 100.0 * np.sum(all_labels) / len(all_labels)\n",
        "\n",
        "    # 출력\n",
        "    print(f\"\\nValidation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision          : {precision*100:.2f}%\")\n",
        "    print(f\"Recall             : {recall*100:.2f}%\")\n",
        "    print(f\"F1-score           : {f1*100:.2f}%\")\n",
        "    print(f\"Predicted Positive 비율: {pos_pred_ratio:.2f}%\")\n",
        "    print(f\"Actual   Positive 비율: {pos_true_ratio:.2f}%\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"accuracy\": avg_acc,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"pred_pos_ratio\": pos_pred_ratio,\n",
        "        \"true_pos_ratio\": pos_true_ratio,\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation_sst2(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "id": "ucbY_j5UQnGi",
        "outputId": "b33eabc7-87eb-4452-f067-9d3ad2bc0b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644,
          "referenced_widgets": [
            "6ba9397e1dcb4824b6e25f1cfb336086",
            "bdc389897586466ea9359812a7952ab2",
            "eb93787249a247d5bd5c1c67fe2849bb",
            "c53688db978247b585d9894d5b4299f2",
            "3ed05f10e62a482d87fc60cf7f82d900",
            "47856a92429c4dd28e5427f7d3878d09",
            "2e202efe0ad744bc851c208c089e127d",
            "0ec1269f4edc4776ad4ffb30af60bb9b",
            "76fbd476b354463a8ef5b16a087a59e8",
            "ef0865ab9f3e4c28883c2ddcb61671ab",
            "236d869cd8394948b76d197566d54783"
          ]
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba9397e1dcb4824b6e25f1cfb336086"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f3faa474590f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# 사용 예시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation_sst2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-f3faa474590f>\u001b[0m in \u001b[0;36mrun_validation_sst2\u001b[0;34m(model, validation_dataloader, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             outputs = model(\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-2980de5a32bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# row = row - row.max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m63.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m63.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;31m# (3) Python float 리스트로 변환 → top()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}