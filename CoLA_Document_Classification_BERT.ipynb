{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification BERT [CoLA]\n",
        "\n",
        "*   항목 추가\n",
        "*   항목 추가\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SGcOaw5P769d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg-qog2IyzCc",
        "outputId": "fb2dd1b7-65ae-4e78-e2d5-e542fe71ec29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic"
      ],
      "metadata": {
        "id": "x6iTkvfbQ6Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores, dim=-1):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    \"\"\"\n",
        "    chunk_size = len(attention_scores) // dim\n",
        "    data_list = [attention_scores[i * chunk_size:(i + 1) * chunk_size] for i in range(120)]\n",
        "\n",
        "    # 120개의 결과 리스트 생성\n",
        "    result_arrays = []\n",
        "\n",
        "    # 각 10개씩 top 함수에 전달\n",
        "    for i in range(120):\n",
        "        result = top(*data_list[i])  # 리스트를 개별 인자로 풀어서 전달\n",
        "        result_arrays.append(result)  # 결과 저장\n",
        "\n",
        "    return result_arrays\n",
        "\n",
        "\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    fixed_binary_int = int(fixed_binary, 2)\n",
        "    lower_20_bits = fixed_binary_int & 0xFFFFF\n",
        "    return lower_20_bits\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "        #print(int_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "   #return int_values\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    # 이진수의 길이\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 방법으로 음수 변환\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수는 그냥 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "        #print(hex(exp_fraction[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "'''\n",
        "top(\n",
        "    0b00000011000110001110,  # 첫 번째 data_in 값\n",
        "    0b00000100010011110000,  # 두 번째 data_in 값\n",
        "    0b00000000010011111010,  # 세 번째 data_in 값\n",
        "    0b00000010101101111100,  # 네 번째 data_in 값\n",
        "    0b00000111000110011000,  # 다섯 번째 data_in 값\n",
        "    0b00000100010100001101,  # 여섯 번째 data_in 값\n",
        "    0b11111100110100100011,  # 일곱 번째 data_in 값\n",
        "    0b11111111100000001011,  # 여덟 번째 data_in 값\n",
        "    0b00000011010101100100,  # 아홉 번째 data_in 값\n",
        "    0b11111010100111110111   # 열 번째 data_in 값\n",
        ")\n",
        "'''\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ✅ 기존 Softmax -> Sigmoid Normalization 적용\n",
        "        attention_probs = top(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "HM1AXhHcQ04X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구조 적용,, 재시작"
      ],
      "metadata": {
        "id": "eA7KlC3ftQ-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) Query/Key/Value 계산 (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) Attention score 계산 & scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ---------------------------------------------------\n",
        "        # 3) CORDIC-Softmax: top()을 120번 자동 호출\n",
        "        #    attention_scores.shape == [B, H, L, L] with L=10\n",
        "        # ---------------------------------------------------\n",
        "        B, H, L, _ = attention_scores.size()             # B=1, H=12, L=10\n",
        "        flat = attention_scores.view(-1, L)              # shape = [B*H, 10]\n",
        "        rows = []\n",
        "        for row in flat:                                 # 자동으로 1*12 = 12 행 × 10 쿼리 = 120 호출\n",
        "            # row.tolist() → Python float 리스트 길이 10\n",
        "            top_out = top(*row.tolist())                 # 여러분의 top(data1…data10)\n",
        "            # 다시 tensor 로 만들 때, dtype/device 일치시키기\n",
        "            rows.append(torch.tensor(\n",
        "                top_out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows)              # shape = [B*H, 10]\n",
        "        attention_probs = attention_probs.view(B, H, L, L)\n",
        "        # ---------------------------------------------------\n",
        "\n",
        "        # 4) Dropout & Context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "zfSHmJVQtUqh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. 1,12,10,10\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "        # ─────────────────────────────────────────────\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "JxoOuCl6wyU6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    # Modified 모듈 생성\n",
        "    mod = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 로드\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n"
      ],
      "metadata": {
        "id": "peAPhZdDvZzN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "# → BertForSequenceClassificationCordic 이어야 함\n",
        "\n",
        "# 2) forward 메서드가 서브클래스에서 정의된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "# → BertForSequenceClassificationCordic.forward 여야 함\n",
        "\n",
        "# 3) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)"
      ],
      "metadata": {
        "id": "huL4Du0TtzwD",
        "outputId": "df92579b-a669-4ca1-c1ce-3ddb3b0a77d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 마지막 레이어 확률만 꺼내기\n",
        "all_attentions = outputs.attentions    # tuple of length 12, each is [B, H, L, L]\n",
        "attention_probs = all_attentions[-1]   # 마지막 레이어의 [B, H, L, L] 텐서\n",
        "\n",
        "# 3) 마지막 축(키 방향)으로 합이 1인지 확인\n",
        "sums = attention_probs.sum(dim=-1)     # shape = [B, H, L]\n",
        "print(\"어텐션 확률 합:\", sums)\n"
      ],
      "metadata": {
        "id": "m2Fs1SMmxKoy",
        "outputId": "b602bff1-524c-4db8-90bb-8fa5cf7df73a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어텐션 확률 합: tensor([[[0.9946, 0.9958, 0.9958, 0.9941, 0.9922, 0.9954, 0.9941, 0.9961,\n",
            "          0.9978, 0.9983],\n",
            "         [0.9995, 0.9968, 0.9932, 0.9983, 0.9985, 1.0005, 0.9978, 0.9941,\n",
            "          0.9973, 0.9998],\n",
            "         [0.9995, 0.9946, 0.9949, 0.9966, 0.9951, 0.9998, 0.9990, 0.9944,\n",
            "          0.9929, 0.9944],\n",
            "         [0.9988, 0.9980, 0.9973, 0.9958, 0.9937, 0.9995, 1.0002, 0.9915,\n",
            "          0.9878, 0.9946],\n",
            "         [0.9976, 0.9963, 0.9976, 0.9954, 0.9944, 0.9958, 0.9917, 0.9980,\n",
            "          0.9976, 0.9919],\n",
            "         [0.9954, 1.0005, 0.9932, 0.9929, 0.9961, 0.9954, 0.9927, 0.9919,\n",
            "          0.9968, 0.9915],\n",
            "         [0.9954, 0.9951, 0.9995, 0.9980, 0.9980, 0.9939, 0.9968, 0.9929,\n",
            "          0.9971, 0.9929],\n",
            "         [0.9932, 0.9973, 0.9983, 0.9934, 1.0029, 0.9990, 1.0000, 0.9939,\n",
            "          0.9973, 0.9990],\n",
            "         [0.9927, 0.9958, 0.9749, 0.9995, 0.9846, 0.9956, 0.9995, 1.0005,\n",
            "          0.9980, 1.0007],\n",
            "         [0.9988, 0.9919, 0.9946, 0.9966, 0.9924, 0.9988, 0.9963, 0.9990,\n",
            "          0.9973, 0.9961],\n",
            "         [0.9973, 0.9944, 0.9978, 0.9919, 0.9978, 0.9985, 0.9973, 0.9971,\n",
            "          0.9961, 0.9993],\n",
            "         [0.9927, 0.9951, 0.9968, 0.9958, 0.9893, 0.9929, 0.9971, 0.9917,\n",
            "          0.9932, 1.0007]],\n",
            "\n",
            "        [[0.9934, 0.9885, 0.9983, 0.9905, 0.9939, 1.0015, 0.9922, 0.9937,\n",
            "          0.9924, 0.9895],\n",
            "         [0.9958, 0.9875, 0.9956, 0.9976, 0.9941, 0.9988, 0.9968, 0.9951,\n",
            "          0.9956, 0.9968],\n",
            "         [0.9919, 0.9929, 0.9932, 0.9971, 0.9958, 0.9939, 0.9949, 0.9976,\n",
            "          0.9949, 0.9934],\n",
            "         [0.9885, 1.0000, 0.9907, 0.9971, 0.9895, 0.9956, 0.9954, 0.9971,\n",
            "          0.9949, 0.9946],\n",
            "         [1.0000, 0.9871, 0.9978, 0.9951, 0.9963, 0.9961, 0.9946, 0.9958,\n",
            "          0.9995, 0.9998],\n",
            "         [0.9973, 0.9746, 0.9937, 0.9946, 0.9980, 0.9905, 0.9934, 1.0010,\n",
            "          0.9983, 0.9976],\n",
            "         [0.9985, 0.9929, 0.9961, 0.9976, 0.9924, 0.9961, 0.9980, 0.9980,\n",
            "          0.9983, 0.9927],\n",
            "         [0.9956, 0.9993, 0.9961, 0.9976, 0.9971, 0.9963, 0.9944, 0.9963,\n",
            "          0.9983, 0.9966],\n",
            "         [0.9966, 0.9961, 0.9934, 0.9990, 0.9937, 0.9900, 0.9963, 0.9797,\n",
            "          0.9951, 0.9954],\n",
            "         [0.9988, 0.9995, 0.9954, 0.9949, 0.9912, 0.9983, 0.9980, 0.9980,\n",
            "          0.9949, 0.9937],\n",
            "         [0.9915, 0.9978, 0.9924, 0.9980, 0.9956, 0.9956, 0.9976, 0.9983,\n",
            "          0.9954, 0.9963],\n",
            "         [0.9963, 0.9917, 0.9944, 0.9985, 0.9956, 0.9990, 0.9937, 0.9946,\n",
            "          0.9961, 0.9966]],\n",
            "\n",
            "        [[0.9951, 0.9966, 0.9995, 0.9956, 0.9932, 1.0005, 0.9924, 0.9976,\n",
            "          0.9966, 0.9980],\n",
            "         [0.9985, 0.9922, 0.9980, 0.9990, 0.9973, 0.9958, 0.9980, 0.9985,\n",
            "          0.9980, 0.9993],\n",
            "         [0.9971, 1.0010, 0.9976, 0.9980, 0.9968, 0.9973, 0.9985, 0.9985,\n",
            "          0.9968, 0.9961],\n",
            "         [1.0005, 0.9966, 1.0002, 0.9939, 0.9961, 0.9966, 0.9961, 0.9958,\n",
            "          0.9939, 0.9951],\n",
            "         [0.9971, 0.9927, 0.9956, 0.9937, 0.9890, 0.9929, 0.9910, 0.9934,\n",
            "          0.9968, 0.9954],\n",
            "         [0.9995, 0.9963, 0.9932, 0.9941, 0.9968, 0.9966, 0.9968, 0.9963,\n",
            "          0.9961, 0.9961],\n",
            "         [0.9976, 0.9985, 0.9990, 0.9976, 0.9978, 0.9971, 0.9944, 0.9990,\n",
            "          0.9980, 0.9995],\n",
            "         [0.9946, 0.9985, 0.9985, 1.0002, 0.9983, 1.0002, 1.0005, 0.9976,\n",
            "          0.9968, 1.0002],\n",
            "         [0.9958, 0.9951, 0.9937, 0.9902, 0.9944, 0.9890, 0.9880, 0.9871,\n",
            "          0.9963, 0.9900],\n",
            "         [0.9954, 0.9978, 0.9988, 0.9976, 0.9978, 0.9985, 0.9958, 0.9985,\n",
            "          0.9968, 0.9934],\n",
            "         [0.9968, 0.9956, 0.9990, 0.9990, 0.9990, 0.9990, 0.9956, 0.9966,\n",
            "          0.9958, 0.9993],\n",
            "         [0.9988, 0.9973, 0.9985, 0.9951, 0.9934, 0.9966, 0.9971, 0.9958,\n",
            "          0.9958, 0.9963]],\n",
            "\n",
            "        [[1.0000, 0.9966, 0.9944, 0.9954, 0.9976, 0.9961, 0.9941, 0.9988,\n",
            "          0.9968, 0.9917],\n",
            "         [0.9941, 0.9954, 0.9949, 0.9993, 0.9983, 0.9937, 0.9978, 0.9915,\n",
            "          0.9985, 1.0000],\n",
            "         [0.9949, 0.9958, 0.9963, 0.9968, 1.0005, 0.9958, 0.9968, 0.9993,\n",
            "          0.9980, 0.9983],\n",
            "         [0.9915, 0.9934, 0.9954, 0.9973, 0.9941, 1.0000, 0.9995, 1.0027,\n",
            "          0.9988, 0.9990],\n",
            "         [0.9956, 0.9993, 0.9993, 1.0000, 0.9980, 0.9968, 0.9934, 0.9968,\n",
            "          0.9985, 0.9937],\n",
            "         [0.9971, 0.9988, 0.9978, 0.9988, 0.9958, 0.9905, 0.9954, 0.9905,\n",
            "          0.9956, 0.9951],\n",
            "         [0.9976, 0.9927, 0.9890, 0.9961, 1.0005, 0.9939, 0.9998, 0.9966,\n",
            "          1.0027, 0.9966],\n",
            "         [0.9878, 0.9956, 0.9958, 0.9966, 1.0000, 1.0002, 0.9985, 0.9954,\n",
            "          0.9946, 0.9946],\n",
            "         [0.9998, 0.9917, 0.9912, 0.9929, 0.9956, 0.9814, 0.9968, 0.9915,\n",
            "          0.9980, 0.9932],\n",
            "         [1.0007, 0.9988, 0.9993, 0.9976, 0.9980, 0.9963, 0.9971, 0.9951,\n",
            "          0.9978, 0.9941],\n",
            "         [1.0010, 0.9963, 0.9980, 0.9971, 0.9971, 0.9927, 0.9958, 0.9983,\n",
            "          0.9966, 0.9978],\n",
            "         [0.9902, 0.9890, 0.9956, 0.9956, 0.9968, 0.9951, 0.9846, 0.9932,\n",
            "          0.9963, 0.9963]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "    model.eval()\n",
        "    eval_accuracy = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            # 배치를 GPU로\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            #logits만 얻기\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # CPU로 내리고 numpy 변환\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            # 배치별 정확도 계산\n",
        "            batch_acc = flat_accuracy(logits, label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.2f}\")\n",
        "    print(f\"Validation Time   : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return avg_accuracy\n",
        "\n",
        "avg_acc = run_validation(model, validation_dataloader, device)"
      ],
      "metadata": {
        "id": "r3GHXPFAyqKm",
        "outputId": "1123cb16-a3db-4862-a2b3-d9ba434eb141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n",
            "Validation Accuracy: 0.80\n",
            "Validation Time   : 0:07:24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    # 2) 준비\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_accuracy = 0.0\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            # Forward pass (logits 얻기)\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]              # [B, 2]\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = criterion(logits, b_labels)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            #probs_tensor = torch.softmax(logits, dim=1)               # [B,2]\n",
        "            #pos_probs = probs_tensor[:, 1].detach().cpu().numpy()     # positive 클래스 확률\n",
        "            #threshold = 0.6                                           # 원하는 임계치\n",
        "            #preds = (pos_probs > threshold).astype(int)               # 0.6 초과면 1, 아니면 0\n",
        "            label_ids = b_labels.detach().cpu().numpy()\n",
        "            batch_acc = np.sum(preds == label_ids) / len(label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "\n",
        "            # 저장\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(label_ids.tolist())\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    # 3) 평균 지표 계산\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_loss     = eval_loss / nb_eval_steps\n",
        "    mcc          = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # 4) 결과 출력\n",
        "    print(f\"Validation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision / Recall / F1: {precision:.4f} / {recall:.4f} / {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": avg_accuracy,\n",
        "        \"loss\": avg_loss,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5cgFqujvRRb",
        "outputId": "e5d700e4-d09e-4471-ec7b-b7dee7c313e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSdpaSelfAttention\n",
            "  Layer  1: BertSdpaSelfAttention\n",
            "  Layer  2: BertSdpaSelfAttention\n",
            "  Layer  3: BertSdpaSelfAttention\n",
            "  Layer  4: BertSdpaSelfAttention\n",
            "  Layer  5: BertSdpaSelfAttention\n",
            "  Layer  6: BertSdpaSelfAttention\n",
            "  Layer  7: BertSdpaSelfAttention\n",
            "  Layer  8: BertSdpaSelfAttention\n",
            "  Layer  9: BertSdpaSelfAttention\n",
            "  Layer 10: BertSdpaSelfAttention\n",
            "  Layer 11: BertSdpaSelfAttention\n",
            "=============================\n",
            "\n",
            "Validation Loss    : 0.6102\n",
            "Validation Accuracy: 0.8287\n",
            "Matthews CorrCoef  : 0.5779\n",
            "Precision / Recall / F1: 0.8356 / 0.9358 / 0.8829\n",
            "Confusion Matrix:\n",
            " [[155 109]\n",
            " [ 38 554]]\n",
            "Validation Time    : 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ."
      ],
      "metadata": {
        "id": "cSd2dA-wQ94T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3425a0e2-31a5-4322-e6e8-64a457eae668"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa3486f-3ef7-4c94-b4fb-6bf868f38faa"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f86334-fa27-4728-d08f-9f5e559bf426"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac95e9cd-d6e3-436a-973d-7b2c481782b1"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cd51ac-28ef-4095-fcb8-d0bdad207abc"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "2558b3a2-af45-4de6-a7e7-223749de7e52"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "660             bc01      1         NaN   \n",
              "4428            ks08      1         NaN   \n",
              "8532            ad03      1         NaN   \n",
              "2902            l-93      1         NaN   \n",
              "7618           sks13      1         NaN   \n",
              "7048          sgww85      1         NaN   \n",
              "1782            r-67      0           *   \n",
              "4127            ks08      1         NaN   \n",
              "3554            ks08      1         NaN   \n",
              "2205            l-93      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "660                 We have someone in the living room.  \n",
              "4428                               Was the child found?  \n",
              "8532                 How did Julie say that Jenny left?  \n",
              "2902                             I detached the handle.  \n",
              "7618                           There were seven people.  \n",
              "7048               She's gone and ruined her dress now.  \n",
              "1782  Willy is taller than Bill by as much as I know...  \n",
              "4127  The King of Rock and Roll's records led to dan...  \n",
              "3554                     He walked right into the wall.  \n",
              "2205                                 Tessa cut herself.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e59a905-4ff0-491b-aad2-6de7d3770dbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We have someone in the living room.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4428</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Was the child found?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8532</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>How did Julie say that Jenny left?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2902</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I detached the handle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7618</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There were seven people.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7048</th>\n",
              "      <td>sgww85</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>She's gone and ruined her dress now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Willy is taller than Bill by as much as I know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4127</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The King of Rock and Roll's records led to dan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3554</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He walked right into the wall.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2205</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tessa cut herself.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e59a905-4ff0-491b-aad2-6de7d3770dbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e59a905-4ff0-491b-aad2-6de7d3770dbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e59a905-4ff0-491b-aad2-6de7d3770dbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e246a843-d440-4fab-a026-8eac31da272f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e246a843-d440-4fab-a026-8eac31da272f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e246a843-d440-4fab-a026-8eac31da272f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence_source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"bc01\",\n          \"ks08\",\n          \"sgww85\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_notes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"He walked right into the wall.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "810a89ed-e996-45cb-c02d-7cdaa92f62eb"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "1158  The doctor brought to the passengers who had p...      0\n",
              "8459         Anson believed Jenny to have hurt himself.      0\n",
              "7464                        Will not John go to school?      0\n",
              "8158                   I inquired could we leave early.      0\n",
              "989   The ship's sinking to collect the insurance wa...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f25b97d-bf62-4ac4-948b-7fd029ff955f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>The doctor brought to the passengers who had p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8459</th>\n",
              "      <td>Anson believed Jenny to have hurt himself.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7464</th>\n",
              "      <td>Will not John go to school?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8158</th>\n",
              "      <td>I inquired could we leave early.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>The ship's sinking to collect the insurance wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f25b97d-bf62-4ac4-948b-7fd029ff955f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f25b97d-bf62-4ac4-948b-7fd029ff955f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f25b97d-bf62-4ac4-948b-7fd029ff955f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-047489d7-45bf-433a-81e5-7c6725edcdd9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-047489d7-45bf-433a-81e5-7c6725edcdd9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-047489d7-45bf-433a-81e5-7c6725edcdd9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Anson believed Jenny to have hurt himself.\",\n          \"The ship's sinking to collect the insurance was very devious.\",\n          \"Will not John go to school?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac6b1a8-f230-4a77-de9a-4cf10fa684c8"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e5ac72-8a25-479a-ac65-656aa62d72b5"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f47eda2-84f8-421d-dac6-cf479155d199"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b345b7-a842-45de-efc1-83df0e544823"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d5751a-4d84-4547-f873-6f62202f6ae5"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204907aa-ee84-49b4-96cb-0f02de5433e5"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4d2302-0904-4ee8-8c8f-b0395eaf558b"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3"
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3cca43-25fd-40d6-f5fa-744d7ac8b3d3"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:26.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:33.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:34.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:00:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:33.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:07.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:13.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:33.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:00:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "d235e60e-58ee-432c-b86c-1706df19d5aa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3da284-7f97-4357-b076-43b6c542418d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62369874-9fc0-43cd-eb4d-ddf88fa78724"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78d0f5e-64ae-44d4-f905-3a8e3753f959"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a269d544-4163-4268-96a9-825a8d31c187"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dda0a03-c1b0-4bce-eab5-0b9276da1c26"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.049286405809014416),\n",
              " np.float64(-0.2548235957188128),\n",
              " np.float64(0.4040950971038548),\n",
              " np.float64(0.23372319715296222),\n",
              " np.float64(0.44440090347500916),\n",
              " np.float64(0.7410010097502685),\n",
              " np.float64(0.4879500364742666),\n",
              " np.float64(-0.06788442333021306),\n",
              " np.float64(0.8320502943378436),\n",
              " np.float64(0.8246211251235321),\n",
              " np.float64(0.8459051693633014),\n",
              " np.float64(0.647150228929434),\n",
              " np.float64(0.8150678894028793),\n",
              " np.float64(0.647150228929434),\n",
              " np.float64(0.1794871794871795),\n",
              " np.float64(0.6625413488689132),\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20542275-298f-4270-9edc-b8dac9f31a41"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 코드"
      ],
      "metadata": {
        "id": "xd5BzXwU8HM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MAX_LEN = 10\n",
        "\n",
        "def predict_with_cordic(model, tokenizer, sentence, device):\n",
        "    \"\"\"\n",
        "    CORDIC-Softmax 패치된 model + tokenizer를 이용해\n",
        "    단일 문장(sentence)에 대해 CoLA 예측을 수행합니다.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 토크나이징 + 패딩\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # GPU/CPU 동일하게 맞추기\n",
        "    inputs = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "    # 순전파만 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs.get(\"token_type_ids\", None)\n",
        "        )\n",
        "        # HuggingFace 버전 따라 .logits 또는 [0]\n",
        "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
        "\n",
        "    # CORDIC-Softmax로 이미 변환된 attention을 쓰므로\n",
        "    # classification head 출력만 softmax\n",
        "    probs = torch.softmax(logits, dim=-1)    # [1, 2]\n",
        "    pred  = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    return pred, probs.cpu().numpy().flatten()\n",
        "\n",
        "\n",
        "# — 사용 예시 —\n",
        "sentence = \"Here is a sample sentence to test CORDIC inference.\"\n",
        "pred, probs = predict_with_cordic(model, tokenizer, sentence, device)\n",
        "\n",
        "label_name = \"acceptable\" if pred == 1 else \"unacceptable\"\n",
        "print(f\"Sentence        : {sentence}\")\n",
        "print(f\"Predicted label : {pred} ({label_name})\")\n",
        "print(f\"Probabilities   : [0]={probs[0]:.4f}, [1]={probs[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "ddIcD3HipFSO",
        "outputId": "f0bead73-a2f3-40b3-8781-7ebb1136d030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cordic_softmax_2way' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# — 사용 예시 —\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Here is a sample sentence to test CORDIC inference.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_cordic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"acceptable\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"unacceptable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36mpredict_with_cordic\u001b[0;34m(model, tokenizer, sentence, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 순전파만 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-cfef15f4be3a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 2) CORDIC-Softmax으로 대체 (num_labels=2라면 top_2 입력 함수 필요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 여기서는 예시로 두 값에 대한 지수→분모→나눗셈을 직접 호출한다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcordic_softmax_2way\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# logits.shape == [B,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cordic_softmax_2way' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d731a4d-adf9-475b-a709-34946ac56710"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# 1. 모델 및 토크나이저 로드 (예: 'bert-base-uncased' 사용)\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()               # GPU로 이동\n",
        "model.eval()               # 평가 모드로 전환\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# 2. 추론할 영어 문장 예시\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "\n",
        "# 3. 문장 토큰화 및 인코딩\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,      # [CLS]와 [SEP] 토큰 추가\n",
        "    max_length=10,                # 최대 길이 설정\n",
        "    padding=\"max_length\",         # 최대 길이에 맞춰 패딩\n",
        "    truncation=True,              # 길면 잘라냄\n",
        "    return_tensors=\"pt\"           # 파이토치 텐서 반환\n",
        ")\n",
        "\n",
        "# 4. 텐서를 GPU로 이동\n",
        "inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "\n",
        "# 5. 추론 (forward pass)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs[0]  # 모델의 출력은 튜플이며, 첫 번째 요소가 로짓입니다.\n",
        "\n",
        "# 6. Softmax 적용 (선택 사항) 및 예측 클래스 결정\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "# 7. 결과 출력\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", predicted_class.item())\n",
        "print(\"예측 확률:\", probs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: tensor([[0.7347, 0.2653]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    입력된 문장에 대해 학습된 모델을 사용하여 예측을 수행합니다.\n",
        "    Returns:\n",
        "        predicted_class: 예측된 클래스 (예: 0 또는 1)\n",
        "        probs: 각 클래스의 확률 (numpy 배열)\n",
        "    \"\"\"\n",
        "    # 문장을 토큰화하고 encode_plus를 통해 [CLS], [SEP] 토큰을 추가하며, 패딩/자르기 적용\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,      # [CLS]와 [SEP] 추가\n",
        "        max_length=max_length,        # 최대 길이\n",
        "        padding=\"max_length\",         # 최대 길이에 맞게 패딩\n",
        "        truncation=True,              # 길면 자르기\n",
        "        return_tensors=\"pt\"           # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # GPU로 텐서를 전송\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # 모델을 평가 모드로 전환하고, 추론 시에는 기울기를 계산하지 않도록 설정\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # 모델의 출력은 튜플 형태로, 첫 번째 요소가 logits입니다.\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 사용\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PITHYJKhPHD",
        "outputId": "c1e48647-320b-42aa-d562-a50a05b01a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.73471546 0.26528448]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic 코드"
      ],
      "metadata": {
        "id": "oK0EdSFZjeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    결과는 원본 형태 (1, 12, 10, 10)로 반환\n",
        "    \"\"\"\n",
        "    if isinstance(attention_scores, torch.Tensor):\n",
        "        attention_scores = attention_scores.detach().cpu().numpy()  # ✅ detach() 추가\n",
        "\n",
        "    batch_size, num_heads, seq_length, _ = attention_scores.shape\n",
        "    result_arrays = np.zeros((batch_size, num_heads, seq_length, seq_length))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        for row in range(seq_length):\n",
        "            for col in range(seq_length // 10):\n",
        "                input_values = attention_scores[0, head, row, col * 10:(col + 1) * 10]\n",
        "                result = top(*input_values)\n",
        "                result_arrays[0, head, row, col * 10:(col + 1) * 10] = result\n",
        "\n",
        "    # ✅ numpy -> torch 변환할 때 `.to(device)` 추가\n",
        "    return torch.tensor(result_arrays, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 정수부는 7비트 (Signed, 2의 보수)\n",
        "    - 소수부는 13비트 (항상 양수)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ PyTorch Tensor 처리\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        value = value.detach().cpu().numpy()\n",
        "\n",
        "    # ✅ NaN 또는 Inf 값 체크 후 예외 처리\n",
        "    if np.isnan(value) or np.isinf(value):\n",
        "        raise ValueError(f\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\")\n",
        "\n",
        "    # ✅ **최대/최소 값 제한 (7비트 표현 범위)**\n",
        "    value = max(min(value, 63), -64)\n",
        "\n",
        "    # ✅ 정수부와 소수부 분리\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수 부분\n",
        "\n",
        "    # ✅ 2의 보수 변환 (음수 처리)\n",
        "    if int_part < 0:\n",
        "        int_part = (1 << int_bits) + int_part\n",
        "\n",
        "    int_binary = format(int_part, f'0{int_bits}b')\n",
        "\n",
        "    # ✅ 12비트 0 추가 (BERT 출력 형식 유지)\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트)\n",
        "    frac_binary = \"\"\n",
        "    for _ in range(frac_bits):\n",
        "        frac_part *= 2\n",
        "        if frac_part >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_part -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 문자열 생성\n",
        "    binary_string = int_binary + frac_binary\n",
        "\n",
        "    # ✅ `binary_string`이 음수 값을 포함하는지 확인 후 처리\n",
        "    if \"-\" in binary_string:\n",
        "        raise ValueError(f\"[ERROR] 잘못된 바이너리 문자열 변환 감지: {binary_string}\")\n",
        "\n",
        "    # ✅ 20비트 정수 변환 (부호 처리)\n",
        "    fixed_binary = int(binary_string, 2)\n",
        "    if value < 0:\n",
        "        fixed_binary = (1 << 20) - fixed_binary  # 2의 보수 변환\n",
        "\n",
        "    lower_20_bits = fixed_binary & 0xFFFFF  # 20비트 마스킹\n",
        "\n",
        "    return lower_20_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    \"\"\"\n",
        "    2의 보수 표현된 이진수를 정수로 변환하는 함수.\n",
        "    \"\"\"\n",
        "    # ✅ \"0b\" 제거\n",
        "    binary_str = binary_str.replace(\"0b\", \"\")\n",
        "\n",
        "    # ✅ 이진수 길이 확인\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # ✅ 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 변환 (음수)\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JuXVpD_Fjj7q",
        "outputId": "92b4e0a7-8f92-4fb4-e9da-9a1ba0f0b8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0528564453125,\n",
              " 0.0977783203125,\n",
              " 0.0128173828125,\n",
              " 0.0438232421875,\n",
              " 0.3963623046875,\n",
              " 0.0980224609375,\n",
              " 0.0552978515625,\n",
              " 0.0140380859375,\n",
              " 0.0599365234375,\n",
              " 0.1666259765625)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 수정 및 적용 코드"
      ],
      "metadata": {
        "id": "o19OXrVjjoaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# … (BertSelfAttentionModified / BertEncoderModified / BertWithModifiedAttentionForClassification 정의부는 그대로) …\n",
        "\n",
        "# 4. 모델 생성\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "\n",
        "# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\n",
        "checkpoint = torch.load(\"./model/CoLA.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "# 이후 GPU 이동·평가 모드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 예시 추론 함수 (변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=device):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred  = torch.argmax(probs, dim=1).item()\n",
        "    return pred, probs.cpu().numpy()\n",
        "\n",
        "# 테스트\n",
        "sentence = \"This is a grammatically acceptable sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sXS8S2bXX17u",
        "outputId": "8e8a0084-48e7-458f-db5a-5450af90ce01"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e186ff2ff0d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/CoLA.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                     warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "scMdkDy7tAqU",
        "outputId": "8e4b9b79-2fec-49f1-addb-5207366623b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassificationModified(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Softmax 대신 CORDIC을 적용\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "XySJ0nStsisx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # 여기서 원래 softmax를 적용하는 대신 CORDIC 기반 함수를 사용합니다.\n",
        "        # 예를 들어, top_1200_input(attention_scores)를 사용하여 softmax 결과를 근사합니다.\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        # 만약 반환된 결과가 numpy 형태라면, torch.tensor로 변환해주어야 합니다.\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 원래 출력은 (context_layer, attention_probs) 또는 (context_layer,)인데,\n",
        "        # 필요에 따라 raw attention scores도 반환하도록 할 수 있습니다.\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "# 만약 학습된 가중치를 로드해야 한다면 로드합니다.\n",
        "# model.load_state_dict(torch.load(\"your_checkpoint.pt\"), strict=False)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# 이제 이 모델은 CoLA나 다른 영어 문장 분류 작업에 사용할 수 있습니다.\n",
        "# 예시 추론 함수:\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 문장으로 테스트\n",
        "sentence = \"This is a grammatically acceptable for sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "itlqawMcjmJ3",
        "outputId": "11d60001-ac23-433a-cb2d-a279facb7a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is a grammatically acceptable for sentence.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.5131679  0.48683208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 encoder 내 각 레이어의 self-attention 모듈 타입을 출력하여\n",
        "# 수정된 BertSelfAttentionModified가 적용되었는지 확인합니다.\n",
        "print(\"수정된 Attention Layers 확인:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn_layer = layer.attention.self\n",
        "    print(f\"Layer {i} self-attention layer type: {type(attn_layer)}\")\n"
      ],
      "metadata": {
        "id": "8WUtGKLuoW2z",
        "outputId": "fa8009ef-7082-49b3-ea5a-13e2553196a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정된 Attention Layers 확인:\n",
            "Layer 0 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 1 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 2 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 3 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 4 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 5 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 6 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 7 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 8 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 9 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 10 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 11 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디버깅용 잡동사니코드"
      ],
      "metadata": {
        "id": "H5iP5hhyJuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print(f\"[TOP] exp_fraction_output[{i}] = {exp_fraction_output[i]}\")\n",
        "    print(f\"[TOP] exp_int_output[{i}] = {exp_int_output[i]}\")\n",
        "    print(f\"[TOP] exp_whole[{i}] = {exp_whole[i]}\")\n",
        "    print(f\"[TOP] exp_trunc[{i}] = {exp_trunc[i]}\")\n",
        "    print(f\"[TOP] exp_accum_input[{i}] = {exp_accum_input[i]}\")\n",
        "    print(f\"[TOP] x_divider = {x_divider[0]}\")\n",
        "    print(f\"[TOP] y_dividend = {y_dividend[i]}\")\n",
        "    print(f\"[TOP] data_out[{i}] = {data_out[i]}\")"
      ],
      "metadata": {
        "id": "rAamcoXWSjnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # ✅ 디버깅용 Q, K 체크\n",
        "        with torch.no_grad():\n",
        "            h = hidden_states.detach().cpu().numpy()\n",
        "            print(\"=== Hidden States 디버깅 ===\")\n",
        "            print(\"min:\", np.min(h), \"max:\", np.max(h))\n",
        "            print(\"NaN 수:\", np.isnan(h).sum(), \"Inf 수:\", np.isinf(h).sum())\n",
        "            q = query_layer.detach().cpu().numpy()\n",
        "            k = key_layer.detach().cpu().numpy()\n",
        "            print(\"=== Q, K 디버깅 ===\")\n",
        "            print(\"Q min/max:\", np.min(q), np.max(q))\n",
        "            print(\"K min/max:\", np.min(k), np.max(k))\n",
        "            print(\"Q NaN 수:\", np.isnan(q).sum(), \"K NaN 수:\", np.isnan(k).sum())\n",
        "            print(\"Q Inf 수:\", np.isinf(q).sum(), \"K Inf 수:\", np.isinf(k).sum())\n",
        "\n",
        "        # attention score 계산 후 clamp\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 계산 직후 ===\")\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item(), \"Inf 수:\", torch.isinf(attention_scores).sum().item())\n",
        "        attention_scores = torch.clamp(attention_scores, min=-10.0, max=10.0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 예시 ===\")\n",
        "            print(attention_scores[0, 0, 0, :10])\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item())\n",
        "        # CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "\n",
        "# 2. BertLayerWithNaNCheck: layer 0 내부 모듈 NaN 추적\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n",
        "\n",
        "\n",
        "# 3. BertEncoderModified\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "        self.layer[0] = BertLayerWithNaNCheck(self.layer[0])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_values=None, use_cache=False, output_attentions=False,\n",
        "                output_hidden_states=False, return_dict=True):\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            with torch.no_grad():\n",
        "                hs = hidden_states.detach().cpu().numpy()\n",
        "                if np.isnan(hs).sum() > 0:\n",
        "                    print(f\"[NaN DETECTED] ❌ in hidden_states BEFORE layer {i}\")\n",
        "                else:\n",
        "                    print(f\"[OK] ✅ hidden_states BEFORE layer {i}\")\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask[i] if head_mask is not None else None,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_values[i] if past_key_values is not None else None,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "        return (hidden_states,)\n",
        "\n",
        "\n",
        "# 4. BertWithModifiedAttentionForClassification\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 5. Load config and model\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dTD-BGlHKAh5",
        "outputId": "383af56c-e173-4f09-db40-610c833f616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayerWithNaNCheck(\n",
              "          (layer): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttentionModified(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_class = np.argmax(probs)\n",
        "\n",
        "    return pred_class, probs\n"
      ],
      "metadata": {
        "id": "sgc6czs9DqMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_nan(module, input, output):\n",
        "    if isinstance(output, torch.Tensor):\n",
        "        if torch.isnan(output).any():\n",
        "            print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "    elif isinstance(output, (tuple, list)):\n",
        "        for o in output:\n",
        "            if torch.is_tensor(o) and torch.isnan(o).any():\n",
        "                print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    module.register_forward_hook(check_for_nan)\n"
      ],
      "metadata": {
        "id": "2QHFLakIFV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        # Attention\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        # Intermediate\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        # Output\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n"
      ],
      "metadata": {
        "id": "gAA7SyorIaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sentence = \"The cat is sitting on the mat.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "\n",
        "print(\"문장:\", sentence)\n",
        "print(\"예측 클래스:\", pred_class)\n",
        "print(\"클래스별 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "yv0VeRUlDpLp",
        "outputId": "1cd74ea5-ca18-4524-d57c-bed12d1b5f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ✅ hidden_states BEFORE layer 0\n",
            "=== [Layer 0] BEFORE ===\n",
            "min: -4.571415901184082 max: 3.8990025520324707\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Hidden States 디버깅 ===\n",
            "min: -4.571416 max: 3.8990026\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: -2.1867194 2.275151\n",
            "K min/max: -2.4105966 2.2897592\n",
            "Q NaN 수: 0 K NaN 수: 0\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([ 0.4173, -0.1602, -0.0771,  0.3595,  0.1112, -0.1229, -0.2256, -0.0283,\n",
            "        -0.1147, -0.0984], device='cuda:0')\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0\n",
            "[NaN DETECTED] ❌ after Attention in Layer 0\n",
            "[NaN DETECTED] ❌ after Intermediate in Layer 0\n",
            "[NaN DETECTED] ❌ after Output in Layer 0\n",
            "=== [Layer 0] AFTER ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "[NaN DETECTED] ❌ in hidden_states BEFORE layer 1\n",
            "=== Hidden States 디버깅 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: nan nan\n",
            "K min/max: nan nan\n",
            "Q NaN 수: 49152 K NaN 수: 49152\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
            "min: nan max: nan\n",
            "NaN 수: 49152\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8b7cffed0231>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The cat is sitting on the mat.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-c78350183b4c>\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(model, tokenizer, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[OK] ✅ hidden_states BEFORE layer {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN 수:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        batch_size, num_heads, seq_len, _ = attention_scores.shape\n",
        "        for b in range(batch_size):\n",
        "          for h in range(num_heads):\n",
        "            for row in range(seq_len):\n",
        "              float_row = attention_scores[b, h, row, :10].detach().cpu().numpy().tolist()\n",
        "\n",
        "              if any(np.isnan(f) for f in float_row):\n",
        "                print(f\"[NaN] b={b}, head={h}, row={row} - 입력에 NaN 있음! ❌\")\n",
        "                continue  # 이건 skip하고 다음으로\n",
        "              try:\n",
        "                cordic_attention = top(*float_row)\n",
        "              except Exception as e:\n",
        "                print(f\"[ERROR] top() 실패: {e}\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "          sample_row = attention_scores[0, 0, 0, :10]  # [10개 float]\n",
        "          float_row = sample_row.detach().cpu().numpy().tolist()\n",
        "          print(\"[DEBUG] top 입력값:\", float_row)\n",
        "\n",
        "          try:\n",
        "            top_result = top(*float_row)\n",
        "            print(\"[DEBUG] top 출력값:\", top_result)\n",
        "          except Exception as e:\n",
        "            print(\"[ERROR] top에서 예외 발생:\", e)\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top(*float_row)\n",
        "\n",
        "        if any(np.isnan(c) for c in cordic_attention):\n",
        "          print(f\"[NaN DETECTED] ❌ top() 결과에 NaN 존재! input: {float_row}\")\n",
        "\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # ⚠️ 먼저 너의 원본 문장 리스트가 있어야 해!\n",
        "# 예: dataset_sentences = [\"문장1\", \"문장2\", ..., \"문장N\"]\n",
        "        # 🧪 validation_dataloader에서 원문 문장 추출 (예시)\n",
        "        dataset_sentences = []\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "          input_ids = batch[0]\n",
        "          for ids in input_ids:\n",
        "            text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "            dataset_sentences.append(text)\n",
        "\n",
        "        for i, sentence in enumerate(dataset_sentences):\n",
        "          try:\n",
        "            pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "          except Exception as e:\n",
        "            print(f\"[❌ NaN 발생] 문장 index = {i}\")\n",
        "            print(\"문장 내용:\", sentence)\n",
        "            print(\"에러 메시지:\", e)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "_dPquKTIGbOE",
        "outputId": "54615d57-7130-49f1-b469-d5b229ca4e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적용 모델 validation"
      ],
      "metadata": {
        "id": "JSRL23_d7voR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "h4m08g6HohMF",
        "outputId": "214cd12b-e10a-47d1-a737-bad6e12eb38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b8146705381d>:34: RuntimeWarning: invalid value encountered in cast\n",
            "  int_part = np.floor(value).astype(int)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e22c35b96d8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The documentation for this `model` function is here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-50e5032ce9fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# (2) CORDIC-Softmax 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# (3) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             rows.append(torch.tensor(\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdata_66\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mdata_77\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata_88\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdata_99\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdata_1010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ✅ 5. 최종 32비트 바이너리 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mfixed_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_binary\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrac_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlower_20_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFFFFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlower_20_bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장 및 로드 코드.\n",
        "path = '/content/model/'\n",
        "torch.save(model.state_dict(), path+\"CoLA.pt\")\n",
        "model.load_state_dict(torch.load(path + \"CoLA.pt\", map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6f3ddQs0x7V-",
        "outputId": "fcf8bd39-919f-468d-918c-5bcdf78d3e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}