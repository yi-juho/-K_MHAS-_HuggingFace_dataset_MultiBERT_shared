{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification BERT [CoLA]\n"
      ],
      "metadata": {
        "id": "SGcOaw5P769d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfafdcf-fa36-478e-edca-19f89bcc696f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b7d4cb-e5fe-4958-f8b5-144ee4533239"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c9d221-ed4f-4928-bce5-03fdd7fe7d97"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf33265-dc6e-4f8e-d870-265034aa3b23"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3a0648-d9d0-4798-bedd-582cc4c83825"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "88eef868-5764-4999-a1b9-00e466a51995"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "2303            l-93      1         NaN   \n",
              "5912            c_13      1         NaN   \n",
              "7287           sks13      1         NaN   \n",
              "6210            c_13      1         NaN   \n",
              "1359            r-67      1         NaN   \n",
              "5675            c_13      1         NaN   \n",
              "5835            c_13      1         NaN   \n",
              "5474            b_73      1         NaN   \n",
              "4615            ks08      1         NaN   \n",
              "1124            r-67      0           *   \n",
              "\n",
              "                                               sentence  \n",
              "2303                I separated the yolk and the white.  \n",
              "5912         Yuko rubbed the pizza with a garlic clove.  \n",
              "7287                 John can go to the market quickly.  \n",
              "6210       John was bitten by an advertising executive.  \n",
              "1359  The boy whose guardian's employee we elected p...  \n",
              "5675                               I gave Leah the box.  \n",
              "5835                   I want Mary to sign my yearbook.  \n",
              "5474  What his father wants him to be is a better po...  \n",
              "4615                John has been taken to the library.  \n",
              "1124                Did that John showed up please you?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08b71223-573a-461e-8155-cc4f43633738\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2303</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I separated the yolk and the white.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5912</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yuko rubbed the pizza with a garlic clove.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7287</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John can go to the market quickly.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6210</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John was bitten by an advertising executive.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The boy whose guardian's employee we elected p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5675</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I gave Leah the box.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5835</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I want Mary to sign my yearbook.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5474</th>\n",
              "      <td>b_73</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What his father wants him to be is a better po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4615</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John has been taken to the library.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1124</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Did that John showed up please you?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b71223-573a-461e-8155-cc4f43633738')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08b71223-573a-461e-8155-cc4f43633738 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08b71223-573a-461e-8155-cc4f43633738');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-faa90c98-47a6-4715-a579-14b4dc368fdd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-faa90c98-47a6-4715-a579-14b4dc368fdd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-faa90c98-47a6-4715-a579-14b4dc368fdd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence_source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"l-93\",\n          \"c_13\",\n          \"ks08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_notes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"John has been taken to the library.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1c8d33da-3bfe-45b3-c9bb-9c521f6b2852"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "361   Which problem do you wonder whether John said ...      0\n",
              "2419       The new tax Jaws will gain the middle class.      0\n",
              "3154                          The fear shivered Sharon.      0\n",
              "6529                    Who do you regret that saw you?      0\n",
              "8039                                   We kicked myself      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f618a98-bec5-4770-98ef-bb268767dee4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Which problem do you wonder whether John said ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2419</th>\n",
              "      <td>The new tax Jaws will gain the middle class.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3154</th>\n",
              "      <td>The fear shivered Sharon.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6529</th>\n",
              "      <td>Who do you regret that saw you?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8039</th>\n",
              "      <td>We kicked myself</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f618a98-bec5-4770-98ef-bb268767dee4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f618a98-bec5-4770-98ef-bb268767dee4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f618a98-bec5-4770-98ef-bb268767dee4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62bafc7c-04fb-4668-a1a7-4d3c693bd179\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62bafc7c-04fb-4668-a1a7-4d3c693bd179')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62bafc7c-04fb-4668-a1a7-4d3c693bd179 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The new tax Jaws will gain the middle class.\",\n          \"We kicked myself\",\n          \"The fear shivered Sharon.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5eeb5fa-6ddd-4103-8692-7259c6ccac56"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a20dba-0887-425f-be17-d56f31db27cc"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ec300b-c0eb-4c9e-c4cc-26d99421268a"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c125709-5744-4405-bc7c-4e90e2934615"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecda3f1-2274-466e-d6be-9af5e78e6312"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061b7083-175c-496b-a5e1-66dfe21a2f99"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38836336-8ffb-46fe-c841-b8b39db43b78"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fbd477-7534-47cc-aaa6-cc818ed99644"
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413e433d-ac78-426c-cff5-92639ebe0306"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:06.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:10.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:14.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:19.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:23.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:29.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:00:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:04.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:08.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:11.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:18.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:22.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:04.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:07.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:11.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:14.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:18.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:00:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:04.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:07.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:11.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:14.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:18.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:22.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:00:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "ab58e4ad-17e5-48a1-9d67-d93388b556d0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBMAAAI/CAYAAAAleJEqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAophJREFUeJzs3Xd8leX9//H3OdmbhOxABhBCGAESNojKUBQUV0HFQcVJtbX++m3VFlScrXXVr9o6AKGiYF0IsgVFIAFCIIxACGSQhOxAJlnn/P6g5GskQA4knJzk9Xw8eFju+7rv+3P00xDeue7rMpjNZrMAAAAAAABayGjtAgAAAAAAgG0hTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAAAAAABYhTAAAABctISFBUVFRioqKavV7f/nll4qKitK4ceNa/d5t7cknn1RUVJSefPJJa5cCAECbsLd2AQAA4Pwu5S/qL7/8sm655ZZWrAYAAIAwAQCAds/X17fZ41VVVaqqqjrvGGdn5zarS5JcXFwUERHRJvf28PBQRESEAgIC2uT+AADg4hEmAADQzm3ZsqXZ42+//bb+93//97xj2lpMTIxWr17dJveeOHGiJk6c2Cb3BgAAl4Y1EwAAAAAAgEWYmQAAQAd1Zq2FRYsWqVevXnr//fe1adMm5eXl6dSpUzp06JAkqbq6Whs2bNCPP/6oQ4cOKT8/XxUVFerSpYtiYmI0ffp0XXnllc0+IyEhQffcc48kNd7vjC+//FJPPfWUQkJC9P3332vfvn364IMPlJiYqBMnTiggIEATJkzQ7Nmz5eXldda9f3n9z52ZlTFs2DAtXrxY27Zt04IFC5ScnKzKykp169ZNkydP1gMPPCAnJ6dz/jtav369Fi1apAMHDqihoUHdu3fXDTfcoJkzZ+qf//xnk2e0toSEBH3yySdKSkpSaWmp3Nzc1KdPH91444266aabZGdn1+x1e/bs0aJFi5SUlKTCwkLZ2dnJ29tbISEhGjlypG699VYFBgY2uebIkSNauHChtm/frry8PJlMJvn4+CggIEAjRozQ1KlT1bNnz1b/jACAjoswAQCADi4rK0tPPPGEioqK5OTkJHv7pn/8r1q1Sk899ZQkyWAwyN3dXfb29iosLNSGDRu0YcMG3XffffrTn/500TV8++23euqpp1RXVycPDw81NDQoOztbCxcu1JYtW7R06VK5ubld1L0//PBD/f3vf5d0ep2Furo6HT16VG+//ba2b9+uBQsWNPsX87/+9a+aP39+4+89PT115MgR/f3vf9cPP/yguLi4i/uwLfDyyy9r4cKFkk7/O/fw8FB5ebni4+MVHx+v5cuX65133pG7u3uT67766is99dRTMpvNkiRHR0fZ2dkpNzdXubm52rFjh4KCgposurllyxY9/PDDqq2tlSQ5ODjIxcVFeXl5ysvL0549e+Tg4KDHHnuszT4vAKDj4TUHAAA6uJdeekkeHh5auHChdu/erV27djVZ58DT01P33XeflixZoqSkJO3cuVO7d+/W5s2b9dhjj8nBwUHz58/Xhg0bLur5JSUlevrpp3XTTTdp06ZN2rlzp3bt2qW5c+fKwcFBhw8f1ocffnhR9z548KBee+01Pfjgg9q6dat27NihnTt36je/+Y2k0z/9/+qrr866buXKlY1BwpQpU/Tjjz9qx44d2rVrl55//nklJyfr008/vaiaLuTf//53Y5Awffp0bd68ubHup556Svb29oqPj9ecOXOaXFddXa3nn39eZrNZN954o9atW6e9e/cqMTFRSUlJ+uKLLzRr1ix17dq1yXXPPvusamtrNWbMGH377bfat2+fduzYoeTkZK1YsUKPPfaYQkJC2uSzAgA6LmYmAADQwRmNRi1cuLDJ1Pef78AwYcIETZgw4azr/P399eijj8rFxUV/+9vftHjxYo0fP97i51dXV+vmm2/WCy+80HjMxcVFM2bM0LFjx7RgwQKtXLlSv/vd7yy+d1lZmR599NEmP1V3d3fXb3/7Wx0+fFhr167VypUrddtttzWeN5vNeuuttyRJo0eP1t///ncZDAZJkpOTk6ZNmyZ7e/vG2Rqt6dSpU3r77bclnQ4x5s2b13jO1dVVM2fOlJ2dnV544QV99913mjVrlvr37y9JOnz4sCorK+Xq6qqXX365yQwTV1dX9e/fv3HsGcXFxcrKypJ0ejaEv79/4zknJydFRkYqMjKy1T8nAKDjY2YCAAAd3NSpU896h94SV111lSRp9+7damhouKh7PPLII80ePxNOZGZmqrq62uL7Ojo66r777jvvvX+5lkNKSooyMzMlSQ899FBjkPBzN998s4KDgy2u50K2bNmiEydOSJIeffTRZsfceeed8vPzkyStWLGi8biHh4ckqa6urvEeF+Lm5iaj8fS3e4WFhRdZNQAAZyNMAACgg4uNjb3gmKKiIv3jH//Q9OnTNXz4cPXt21dRUVGKiorS9ddfL+n0DIOTJ09a/PwuXbooLCys2XM//0l5WVmZxfeOjIw851oLZ+79y5r3798v6fTaAYMHD272WoPBoKFDh1pcz4Xs27dPkhQUFNRkdsjP2dnZacSIEU3GS1JoaKh69Oihuro6TZs2Te+//75SUlLOG/A4Oztr5MiRkqT7779fb731lvbs2dO4fgIAABeLMAEAgA7ul+/Q/1JSUpKuu+46vfPOO9q9e7dOnDghJycnde3aVb6+vvL29m4cezGzB863sOLPF0asq6trk3vX19c3OV5aWirpdMjh6Oh4zusDAgIsrudCiouLW3TvMzNJzoyXTn+eN954Q926dVNOTo5ee+013XTTTYqLi9Ovf/1rLVmypNn/Pi+88IL69OmjkpISvfvuu5o2bZpiY2N1xx136MMPP2zxLAcAAH6ONRMAAOjgzkxzb059fb3+3//7fyorK1N0dLR+//vfKy4urskuAllZWZo4caIkNe4iAOvo06ePVq1apU2bNumnn35SUlKSDh8+rK1bt2rr1q16//339a9//atxW1BJCg4O1ldffaUtW7bohx9+0K5du3To0CHt2rVLu3bt0vvvv6+33nqrcQYDAAAtQZgAAEAntnv3buXk5MjOzk7/+te/mv2JeUd71/7MTIsTJ06otrb2nLMT8vPzW/3ZZ2aJ5OXlnXfcmfPNzSpxdHTUNddco2uuuUbS6ZkWa9as0RtvvKHjx4/rySefPGsHC6PRqCuuuEJXXHGFJKmiokIbN27U66+/rtzcXP3hD3/Qxo0bzztTAwCAn+M1BwAAOrHjx49Lknx8fM459X7btm2Xs6Q2169fP0mnX6tISkpqdozZbNbOnTtb/dlndlvIy8tTenp6s2MaGhqUkJAgSRowYMAF7+nt7a3bb79df/jDHyRJBw4caHyV41zc3d11ww036MUXX5R0es2M1NTUFn8OAAAIEwAA6MTO7BBQVFSkoqKis87n5eVp8eLFl7usNhUdHd24IOT777/f7Ksb33zzjXJyclr92aNHj1aXLl0kSf/7v//b7JjPPvtMBQUFkqTJkyc3Hr/QoolOTk6N//vMqy0Xcw0AAC3BnxoAAHRicXFxcnV1ldls1uOPP9740/KGhgZt3rxZd999t5UrbH0Gg0GPPfaYJOmnn37Sn/70p8ZXGmpqavT555/rmWeekZeXV6s/29nZufHZK1as0Ny5cxtDnOrqai1atEgvv/yyJOn6669vnMkgSStXrtTtt9+uzz77TMeOHWs8fua/1WuvvSZJGjx4cGPtSUlJuuGGG7Rw4UIdOXJEJpNJ0umZF7t27dKzzz4r6fSCjz9fZwEAgAthzQQAADoxDw8P/fGPf9Szzz6rHTt2aNKkSXJ1dVVDQ4Nqamrk7e2tl19+WY888oi1S21VN9xwg/bu3auPP/5Y33zzjZYvXy5PT09VVVWprq5OI0aM0MCBA/Wvf/2r1dcRuOuuu3Ts2DEtXLhQS5cu1bJly+Tp6anKysrGnSeGDx+u559/vsl1ZrNZSUlJja9mODo6ytXVVWVlZY0hgb+/f+OrC2ekpqbq5Zdf1ssvvywHBwe5ubmpoqKi8Vnu7u567bXXmuysAQDAhRAmAADQyd1xxx0KDg7Whx9+qH379qmhoUEBAQG68sor9cADD1zUlo224Omnn9bQoUO1aNEiHThwQLW1terRo4emTp2qe++9V6+88ookydPTs9Wf/dRTT+nqq6/WkiVLtGvXLp04cUJubm7q06ePpk6dqptuuumsv9yPGzdOf/3rX5WQkKADBw6osLBQJ0+elJubmyIiInT11VfrrrvualLvgAED9OabbyohIUHJyckqKCjQiRMn5OjoqMjISI0ePVr33HNPm2yDCQDo2Axm9ngCAAA4y+23366kpCT99re/1W9+8xtrlwMAQLvCmgkAAAC/sH379sbXCc5spwgAAP4PYQIAAOiUnnvuOX355ZcqLCxs3NGhrKxMn332mWbPni1JGjFihGJiYqxZJgAA7RKvOQAAgE5p6tSpOnjwoKTTixm6uLiorKysMVjo1auX5s+fz3oCAAA0gzABAAB0Shs2bND69euVnJysoqIiVVRUyN3dXb169dLEiRM1ffp0ubi4WLtMAADaJcIEAAAAAABgEdZMAAAAAAAAFiFMAAAAAAAAFrG3dgE4P7PZLJOp/b+JYjQabKJOtB/0DCxFz8BS9AwsRc/AUvQMLGEr/WI0GmQwGC44jjChnTOZzCopqbR2Gedlb2+Ut7ebysqqVF9vsnY5sAH0DCxFz8BS9AwsRc/AUvQMLGFL/eLj4yY7uwuHCbzmAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALEKYAAAAAAAALGJv7QJg20wms1IySlSXXioHg1k9g71kNBqsXRYAAAAAoA0RJuCiJR4q0JL1h1VaXtN4zNvDSXdOiFRclL8VKwMAAAAAtCVec8BFSTxUoHe+2tckSJCk0vIavfPVPiUeKrBSZQAAAACAtkaYAIuZTGYtWX/4vGM+XX9YJpP5MlUEAAAAALicCBNgsdRjJ86akfBLJeU1Sj124vIUBAAAAAC4rAgTYLETlecPEiwdBwAAAACwLYQJsFgXN6dWHQcAAAAAsC2ECbBY7+5d5O1x/qDAaJDMZtZMAAAAAICOiDABFjMaDbpzQuR5x5jM0t8/261l36eprr7hMlUGAAAAALgcCBNwUeKi/PWbm/ufNUPBx8NJD0zpq7EDg2SWtHp7luZ9vFNZ+eXWKRQAAAAA0OrsrV0AbFdclL8GR/rpSO5J1ZkNcjCY1TPYS0ajQSP7B2pQLz8tXJWinMJKPf/xTt10RYSuGx4mo9Fg7dIBAAAAAJeAmQm4JEajQdHhProytpuiw32aBAWDIn017/7hiu3tpwaTWV/8cFSvfLJL+aVVVqwYAAAAAHCpCBPQpjxdHfWbm/tr1uRouTjZKS3npJ6dv0ObknJYoBEAAAAAbBRhAtqcwWDQ6AFBeu6+YeoT2kU1dQ1atOaQ3vpPsk5U1Fi7PAAAAACAhQgTcNn4ernoD3cM1u3jI2VvZ1TykWLN/Wi7dh4ssHZpAAAAAAALECbgsjIaDLpmaHc98+uhCgvwUEV1nd79ep/e/3a/qk7VWbs8AAAAAEALECbAKkJ83fTne+I0ZVS4DAYpfn++5ny0XfszSqxdGgAAAADgAggTYDX2dkbdMraHnr4rTgHeLiotr9Frn+3WJ+tSVVPXYO3yAAAAAADnQJgAq+sZ4qVnfz1MV8eGSJI2JGbruQU7lH68zMqVAQAAAACaQ5iAdsHJ0U53XxOlJ6YNVBd3R+WVVOnFRYn6evNR1TeYrF0eAAAAAOBnCBPQrvTv0VXzZg3XsGh/mcxmLd+SoZf/najjxZXWLg0AAAAA8F+ECWh33F0c9PDU/nroxn5yc7ZX+vFyPbtgh9bvPCaT2Wzt8gAAAACg0yNMQLs1vG+A5s0arn4RPqqrN2nJ+sN6felulZSdsnZpAAAAANCpESagXfP2cNIT0wbqrmt6y9HeqAMZpZrz0XZt258nM7MUAAAAAMAqCBPQ7hkMBo2L7aZn7xumHsGeqq6p1wffHtB7X+9TRXWdtcsDAAAAgE6HMAE2I9DHVU/dFaubr4iQndGgnYcKNefDBCUfKbZ2aQAAAADQqRAmwKbYGY26YXSE/nxPnIK6uupkZa3e/HyPFq0+qFO19dYuDwAAAAA6BcIE2KTwQE89M3OorhnaXZK0aXeunp2/Q2nZJ61cGQAAAAB0fIQJsFmODna6fXyk/ueOwfLxdFLBiWq9/EmivvjhiOobTNYuDwAAAAA6LMIE2LzoMG/Nu2+4RvUPlNksrdyWqec/3qnswgprlwYAAAAAHRJhAjoEV2d73T+lr35zc3+5uzjoWEGF5i3codUJWTKZ2EISAAAAAFoTYQI6lLgofz0/a5gG9uyq+gazlm1M098+TVLRiWprlwYAAAAAHQZhAjocL3cn/fa2GM28ro+cHO2UeuyE5s7frs3JuTKbmaUAAAAAAJeKMAEdksFg0NiBwXruvmGK7OalU7UNWvDdQf3vl3tVVllr7fIAAAAAwKYRJqBD8+/ioj/dGatfXdVT9nYGJR0u0pyPEpSUWmjt0gAAAADAZhEmoMMzGg26bkSY5tw7VN383FVeVae3v9yrj1YeUHVNvbXLAwAAAACbY2/tAiwVHx+vBQsWaM+ePaqqqlJwcLAmTZqkBx98UK6urhbd68knn9RXX3113jEffPCBxo4d2+y5yspKvf/++1qzZo1yc3Pl6uqqgQMH6r777tPw4cMtqgVtr7u/u+bcO0Rf/3RUq+OztGVvng5mntCsydHqE+Zt7fIAAAAAwGbYVJiwePFivfjiizKbzQoMDFRQUJDS0tL03nvvae3atVqyZIm6dOli8X2DgoIUFBTU7DkvL69mj5eUlOjOO+9Uenq6HB0d1atXL5WUlGjTpk364YcfNGfOHM2YMcPiWtC2HOyN+tVVvTSwp68+WnlAhSdO6dVPkzRxaHfdemUPOdjbWbtEAAAAAGj3bCZM2Ldvn1566SVJ0rx58zRt2jQZDAbl5+frkUce0f79+zVnzhy9/fbbFt/71ltv1WOPPWbRNX/+85+Vnp6ufv366b333lNAQIDMZrOWLVumuXPn6sUXX1RsbKyio6Mtrgdtr3f3Lnr218O09Ps0/bgnV2t3HNP+9BLdP6WvwgI9rF0eAAAAALRrNrNmwrvvviuTyaSpU6dq+vTpMhgMkqSAgAC9/vrrMhqNWrt2rQ4ePNjmtRw4cEDff/+9jEaj3njjDQUEBEg6vYPA9OnTNXXqVDU0NOjdd99t81pw8Vyc7DXzuj767W0x8nRzVE5RpV5YtFMrtmaowWSydnkAAAAA0G7ZRJhQWVmpzZs3S5KmTZt21vnw8HCNGDFCkrR69eo2r2fNmjWSpBEjRigsLOys89OnT5ck/fDDD6qqqmrzenBpBvXy1bxZwxTX208NJrO+/PGoXvlkl/JL+W8HAAAAAM2xidccUlJSVFtbK0dHR8XExDQ7Ji4uTlu3btWePXssvn9CQoIOHz6sEydOyNPTU/369dONN96okJCQZsfv3r1bkjRkyJBmz8fExMjR0VE1NTVKSUlRXFycxTXh8vJ0ddTsm/tr2/48fbIuVUdyyvTM/O2aPi5SVw0KbpwJAwAAAACwkZkJ6enpkqTg4GA5ODg0OyY0NLTJWEvs2LFDa9asUUJCgtatW6c333xT1157rT744INmx2dkZDR55i85ODg0Luh4MfXAOgwGg0b1D9K8+4YrOsxbtXUmLV5zSG98vkel5TXWLg8AAAAA2g2bmJlw8uRJSefeWeHn586MbYmwsDA9+eSTGjFihEJCQuTo6KhDhw5p/vz5Wr16tf7+97/L1dX1rF0ZLKmnrKysxfWci719+8587OyMTf5p6wK6uupPd8Vq3Y5jWvZ9mvYdLdHc+ds187o+Gt43wNrldQgdrWfQ9ugZWIqegaXoGViKnoElOmK/2ESYUFNz+qfC55qVIEmOjo5NxrbEI488ctaxgQMH6q233tJzzz2nJUuW6M0339RNN90kNze3i6rn1KlTLa6nOUajQd7ebhce2A54erpYu4RWdfu10Ro9qJteX5KotOyTeufLvdqXXqqHbxkgd1dHa5fXIXS0nkHbo2dgKXoGlqJnYCl6BpboSP1iE2GCk5OTJKmuru6cY2pra5uMvVRPPPGEPv/8c5WVlSk+Pl7jx49vUk91dXWL6nF2dr6kOkwms8rK2vdCgHZ2Rnl6uqisrFoNDR1rFwR3R6OevjtOy39K1/KfMvRDUraS0wr1wA191b9HV2uXZ7M6cs+gbdAzsBQ9A0vRM7AUPQNL2FK/eHq6tGgGhU2ECS15haElrx5YwsPDQ5GRkTpw4IAyMzObnPP09FR1dXWL6vH09LzkWurr23ezndHQYLKZWi114+gI9Yvw0YcrUpRfUqW/LUnS+Nhuuu3qnnJysLN2eTarI/cM2gY9A0vRM7AUPQNL0TOwREfqF5t4YSM8PFySlJube87ZAFlZWU3GtoYzrzHU19c3W88vQ4Yz6urqlJub2+r1wLp6Bnvp2V8P1fjYbpKkDbuy9eyCHTqae+nrYgAAAACALbGJMCE6OloODg6qra1VcnJys2MSExMlSYMGDWqVZ9bX1+vo0aOSpMDAwCbnzjzjzDN/KTk5WXV1dXJyclJ0dHSr1IP2wcnBTjOu6a0npg+Ut4eT8kuq9NLiRH29+ajq2/l0JQAAAABoLTYRJri7u2vMmDGSpGXLlp11PiMjQ/Hx8ZKkSZMmtcozly5dqvLyctnb22vEiBFNzl177bWSpISEhGZnJyxdulSSNHbs2CYLN6Lj6B/RVfNmDdOIvgEymc1aviVDLy1O1PHiSmuXBgAAAABtzibCBEmaPXu2DAaDvvnmGy1dulRms1mSVFBQoCeeeEImk0kTJkxQnz59mlw3btw4jRs3TqtXr25yfMuWLXr11VeVkZHR5Hhtba0WL16sl19+WZJ0++23y9/fv8mYfv366eqrr1ZDQ4N+//vfq6CgQJJkNpu1dOlSffPNNzIajc3uFoGOw83ZQQ/e2E8PT+0nN2d7ZeSV69kFO7RuxzGZ/tufAAAAANARGcxm2/lbz8KFC/XKK6/IbDYrKChI3t7eSktLU21trSIiIrRkyRL5+Pg0uSYqKkqS9PLLL+uWW25pPL5+/Xr95je/kST5+voqICBAkpSenq6qqtO7J1x77bX6+9//3rjN48+VlJTojjvuUEZGhhwdHdWrVy+Vlpbq+PHjMhgM+vOf/6y77777kj9zQ4NJJSXt+6fd9vZGeXu7qbS0ssMsJmKp0vIaLfguRfvSSyRJ0WHemjU5Wj6el7abR0dFz8BS9AwsRc/AUvQMLEXPwBK21C8+Pm4dZzeHM2bOnKmoqCjNnz9fycnJKi4uVnBwsCZNmqQHH3zQolcK+vXrp9mzZ2v37t3KzMxUenq66urq5OPjozFjxujmm2/WuHHjznm9j4+PvvjiC33wwQdavXq10tLS5OrqqrFjx2rWrFlnvRqBjs3bw0m/nzZQm5JytHRjmlIySzXno+2aMTFSI/sFymAwWLtEAAAAAGg1NjUzoTNiZoLtyS+p0ocrDujIf3d5iIvy0z3XRsnD9ewZLp0VPQNL0TOwFD0DS9EzsBQ9A0vYUr+0dGaCzayZANiKAB9XPXlXrG4e20N2RoMSDxVqzkfbtSetyNqlAQAAAECrIEwA2oCd0agbRoXrL/cMUbCvm8oqa/XWf5L18eqDOlVbb+3yAAAAAOCSECYAbSgs0EPPzByia4Z2l0HSD7tz9cz87TqcfcLapQEAAADARSNMANqYg72dbh8fqf+5Y7C6ejqp8MQpvfLJLv1n0xHVtfP3pQAAAACgOYQJwGXSJ8xbz903XKMHBMpslr6Lz9TzH+9UdkGFtUsDAAAAAIsQJgCXkauzvWZN7qvf3DxA7i4Oyi6s0LyPd2hVQqZMJjZWAQAAAGAbCBMAK4iL8tPz9w/XoF6+qm8w6/ONR/S3JbtUeKLa2qUBAAAAwAURJgBW4uXmqMduHaBfX9dHTo52Ss0+qbnzt+vHPbkym5mlAAAAAKD9IkwArMhgMOiKgcGad98w9e7mpZraBi1cdVBvf7FXJytrrV0eAAAAADSLMAFoB/y6uOiPd8Zq2tW9ZG9n0O60Is35MEGJhwqtXRoAAAAAnIUwAWgnjEaDJg0P1dx7h6q7v7sqquv0zld79dGKA6o6VW/t8gAAAACgEWEC0M5083fXX+4Zoskjw2QwSFv25emZ+QlKySy1dmkAAAAAIIkwAWiXHOyNuvXKnnpyRqz8ujiruKxGr36apM82HFZdfYO1ywMAAADQyREmAO1YZLcueu6+YbpqULAkae2OY3pu4U5l5pVbuTIAAAAAnRlhAtDOOTva655JffT4r2Lk5eao3KJKvbBop77dkq4Gk8na5QEAAADohAgTABsR09NX82YN05AoPzWYzPpqc7pe+fcu5ZdUWbs0AAAAAJ0MYQJgQzxcHfXITf31wJS+cnGy15HcMj2zYLu+35Uts9ls7fIAAAAAdBKECYCNMRgMGtk/UM/PGqboMG/V1pn077WpemPZHpWW11i7PAAAAACdAGECYKN8PJ31/24fpDsmRMrB3qh96SWa+1GCtqfkW7s0AAAAAB0cYQJgw4wGgyYO6a5nfz1U4YEeqjxVr39+s1//Wr5fFdV11i4PAAAAQAdFmAB0AEFd3fT03XG6cXS4jAaDEg7ka+5HCdqXXmzt0gAAAAB0QIQJQAdhb2fUTVf00NN3xynAx1UnKmr1+tI9+vfaQ6qpbbB2eQAAAAA6EMIEoIPpEeypZ389VOPjukmSvt+Vo2cXbNeR3JNWrgwAAABAR0GYAHRATg52mjGxt/7f9EHy9nBSfmm1Xl68S1/9eFT1DSZrlwcAAADAxhEmAB1YvwgfzZs1TCP6BchkNuvbrRl6cVGicooqrV0aAAAAABtGmAB0cG7ODnrwhn565Kb+cnO2V2Z+uZ5bsENrdxyTyWy2dnkAAAAAbBBhAtBJDO3jr+fvH64BPbqqvsGkzzYc1t8/TVLxyVPWLg0AAACAjSFMADqRLu5OevxXMbrn2ig5Ohh1MOuE5s5P0Ja9x2VmlgIAAACAFiJMADoZg8GgqwaH6Ln7hqlniKeqaxr00coUvfvVPpVV1Vq7PAAAAAA2gDAB6KQCvF315IxY3XplD9kZDUpMLdTcj7Zrd1qRtUsDAAAA0M4RJgCdmJ3RqMkjwzXn3iEK8XVTWWWt/vGfZC1claLqmnprlwcAAACgnSJMAKDQAA/NnTlE1w7rLoOkH/cc1zPztyv12AlrlwYAAACgHSJMACBJcrC30/RxkfrjnYPV1dNZRSdP6a+f7NLnG9NUV2+ydnkAAAAA2hHCBABNRIV6a96sYRozIEhmSasSsvT8xzt1rKDC2qUBAAAAaCcIEwCcxcXJXvdNjtZjtwyQh6uDsgsrNG/hDn0XnymTiS0kAQAAgM6OMAHAOQ3u7afnZw3X4EhfNZjM+s+mI/rrkl0qOFFt7dIAAAAAWBFhAoDz8nRz1KO3DNB910fL2dFOh7NP6pn52/XjnlyZzcxSAAAAADojwgQAF2QwGDQmJkjz7hum3t27qKa2QQtXHdQ//pOskxU11i4PAAAAwGVGmACgxXy7uOiPdw7WtKt7yd7OoD1HijXno+1KPFRg7dIAAAAAXEaECQAsYjQYNGl4qObOHKpQf3dVVNfpna/26YNvD6jqVL21ywMAAABwGRAmALgo3fzc9Zd7h2jyyDAZDNK2/XmaOz9BKRkl1i4NAAAAQBsjTABw0eztjLr1yp56akac/Lu4qKSsRq9+tlufrj+s2roGa5cHAAAAoI0QJgC4ZL26eenZ+4bqqsEhkqR1O4/puYU7lJFXZuXKAAAAALQFwgQArcLZ0V73XBulx381UF5ujjpeXKUXFyVq+ZZ0NZhM1i4PAAAAQCsiTADQqmJ6dtXz9w/XkD7+ajCZ9fXmdL20eJfySqqsXRoAAACAVmJv7QIsFR8frwULFmjPnj2qqqpScHCwJk2apAcffFCurq6XfP9PPvlE8+bNkyQNGzZMixcvPmtMdna2xo8ff977DBw4UMuWLbvkegBb5O7ioEem9lNCpK/+vTZV6cfL9Oz87frV1b00LjbE2uUBAAAAuEQ2FSYsXrxYL774osxmswIDAxUUFKS0tDS99957Wrt2rZYsWaIuXbpc9P3z8/P1+uuvW3RNbGxss8cjIyMvug6gIzAYDBrRL1C9u3fR/O9SdCCjVJ+sS9Xuw4V64MZ+8vZ2s3aJAAAAAC6SzYQJ+/bt00svvSRJmjdvnqZNmyaDwaD8/Hw98sgj2r9/v+bMmaO33377op/x7LPPqrq6WldffbU2btzYoms+/fTTi34e0Bn4eDrriemDtHFXjj7fmKb9GaV6+v14zb51oGIivK1dHgAAAICLYDNrJrz77rsymUyaOnWqpk+fLoPBIEkKCAjQ66+/LqPRqLVr1+rgwYMXdf/vvvtO33//vWbMmKF+/fq1ZulAp2c0GDQ+rpue+fVQRQR5qOpUvf7+SaLe+XKvKqrrrF0eAAAAAAvZRJhQWVmpzZs3S5KmTZt21vnw8HCNGDFCkrR69WqL73/y5Em9+OKLCgwM1OOPP35JtQI4t6CubnrqrjjdPLaHjEaDEg7ka85HCdp7tNjapQEAAACwgE285pCSkqLa2lo5OjoqJiam2TFxcXHaunWr9uzZY/H9X3nlFRUVFemdd96Rm5tl73G/8MILOnr0qAwGg0JCQjRmzBhNmDBBRqNN5DTAZWdvZ9TNY3voithuenXxTh0vrtIby/bo6sEhmnZ1Lzk52lm7RAAAAAAXYBNhQnp6uiQpODhYDg4OzY4JDQ1tMraltm3bpi+//FLjxo3ThAkTLK7tl7s9LF26VNHR0Xr77bfVvXt3i+8HdBaR3b31/P3D9dn6w1qfmK2NSTnan1GiB6b0Vc8QL2uXBwAAAOA8bCJMOHnypCTJy+vcf8E4c+7M2JY4deqU5s6dK1dXV82dO7fF19nb2+vGG2/U5MmT1atXL/n7+6u0tFQ//PCD3nzzTaWkpGjWrFn68ssv5e7u3uL7nvt57XuWg52dsck/gQs50ysuzg6657o+iuvjrw+W71dBabVe+neibhgVrpvG9pA9PYX/4usMLEXPwFL0DCxFz8ASHbFfbCJMqKmpkaRzzkqQJEdHxyZjW+If//iHsrKy9NRTTykoKKjF1wUGBurVV19tciwgIEDTpk3T8OHDdcsttygzM1OLFi3S7NmzW3zf5hiNBpvZQs/T08XaJcDGnOmZMd5uGhQdqH99laxNidlaviVD+zJK9f/ujFVooKeVq0R7wtcZWIqegaXoGViKnoElOlK/2ESY4OTkJEmqqzv3qu+1tbVNxl7IgQMH9PHHH6tv3766++67L73I/woLC9Mdd9yhDz74QOvWrbvkMMFkMqusrKqVqmsbdnZGeXq6qKysWg0NJmuXAxtwrp6577o+6h/urYXfHdTRnJN6/PUf9KtxPXXNsFAZ/7uDCzonvs7AUvQMLEXPwFL0DCxhS/3i6enSohkUNhEmtOQVhpa8CvFzf/7zn2UymTRv3jzZ2bXugm+DBw+WJGVkZLTK/err23ezndHQYLKZWtE+NNczsZF+6jHLUwtXHVTykWItWXdYuw4V6r7J0fL16jhJLi4OX2dgKXoGlqJnYCl6BpboSP1iE2FCeHi4JCk3N1d1dXXNvu6QlZXVZOyFHDhwQHZ2dnr44YfPOldVdXomQFJSkkaPHi1J+s9//tPiVyHO1NfQ0NCi8QCa6uLupN/dFqMf9uRq6YY0Hcw6oWfmb9edE3prVP9AGZilAAAAAFiVTYQJ0dHRcnBwUG1trZKTkxUXF3fWmMTEREnSoEGDWnzfhoYGFRUVnfN8XV1d43lLgoHDhw9LOr22AoCLYzAYdNWgEPUN89aHK1KUlnNSH61MUdLhIt0zKUqero7WLhEAAADotGxiKUl3d3eNGTNGkrRs2bKzzmdkZCg+Pl6SNGnSpBbd89ChQ+f89eijj0qShg0b1nisW7duLbpvZWWllixZIkmNsxoAXDx/b1c9OSNWt17ZQ3ZGg3alFmruhwnaffjcQSAAAACAtmUTYYIkzZ49WwaDQd98842WLl0qs9ksSSooKNATTzwhk8mkCRMmqE+fPk2uGzdunMaNG6fVq1e3Wi1z5szR2rVrGxd9POPIkSO6//77lZ2dLVdXV82aNavVngl0ZkajQZNHhmvOvUMU4uemsqo6/eOLZC34LkXVNfXWLg8AAADodGziNQdJiomJ0ZNPPqlXXnlFc+fO1XvvvSdvb2+lpaWptrZWERERev7558+6LicnR9L/rYPQGpKTk7Vs2TI5ODgoNDRU7u7uKi0tbVy3wcvLS2+++WaLZzMAaJnQAA/NvXeovtp8VGsSsrQ5+bhSMkt1/5S+6t29i7XLAwAAADoNmwkTJGnmzJmKiorS/PnzlZycrOLiYgUHB2vSpEl68MEH5ebmdlnqeOihh7R582bt27dPRUVFyszMlLOzs/r166exY8dqxowZ8vPzuyy1AJ2Ng71R067upYE9u+qjlSkqOnlKf/1kl64dHqqbr+ghB3ubmXAFAAAA2CyD+cz7AmiXGhpMKimptHYZ52Vvb5S3t5tKSys7zDYnaFut1TPVNfX6bMNhbU4+LkkK8XPTA1P6KjTAo7VKRTvB1xlYip6BpegZWIqegSVsqV98fNxkZ3fhH9DxIzwANsvFyV6/vj5aj906QJ6uDsoprNTzH+/Uym0ZMpnISQEAAIC2QpgAwOYNjvTTvPuHa3CkrxpMZn3xw1G98skuFZS23lopAAAAAP4PYQKADsHT1VGP3jJAsyZHy9nRTmk5J/XM/B3atDtHvM0FAAAAtC7CBAAdhsFg0OgBQZo3a5j6hHZRTV2DFq0+pLf+k6yTFTXWLg8AAADoMAgTAHQ4vl4u+sMdgzV9XC/Z2xmVfKRYcz7arp0HC6xdGgAAANAhECYA6JCMBoOuHRaqZ2YOUWiAuyqq6/Tu1/v0wbf7VXWqztrlAQAAADaNMAFAhxbi566/3DNEU0aFyWCQtu3P15yPtutARom1SwMAAABsFmECgA7P3s6oW8b21NN3xcnf20Wl5TX6+2e7tWRdqmrrGqxdHgAAAGBzCBMAdBo9Q7z03K+H6erBIZKk9YnZem7hDqUfL7NyZQAAAIBtIUwA0Kk4Odrp7muj9PtpA+Xl7qjjxVV6aXGilv+UrvoGk7XLAwAAAGwCYQKATmlAj656ftZwDe3jrwaTWV//lK6X/52o48WV1i4NAAAAaPcIEwB0Wu4uDnrkpv568Ma+cnWyV/rxcj23YIc2JGbLZDZbuzwAAACg3SJMANDpjegbqOfvH65+ET6qrTfpk3Wpen3pbpWUnbJ2aQAAAEC7RJgAAJK8PZz0xLSBmjGxtxztjTqQUaq5H21X/P48mZmlAAAAADRBmAAA/2UwGDQ+rpuevW+YIoI8VVVTr/e/PaB/frNfFdV11i4PAAAAaDcIEwDgFwJ9XPX03bG66YoI2RkN2nGwQHM+SlDykWJrlwYAAAC0C4QJANAMO6NRN46O0NN3xymoq6tOVtTqzc/3aNGaQzpVW2/t8gAAAACrIkwAgPOICPLUMzOHauKQ7pKkTUk5enb+DqXlnLRyZQAAAID1ECYAwAU4OtjpjgmR+p/bB8nH00kFJ6r18r8T9cUPR1TfYLJ2eQAAAMBlR5gAAC0UHe6jefcN06j+gTKbpZXbMvXCxzuVXVhh7dIAAACAy4owAQAs4OrsoPun9NXsm/rL3cVBWQUVmrdwp1YnZMnEFpIAAADoJAgTAOAiDOnjr+dnDVNMz66qbzBp2cY0vbokSUUnqq1dGgAAANDmCBMA4CJ5uTvpd7fF6N5JUXJysNOhYyc0d/52bU7OlZlZCgAAAOjACBMA4BIYDAZdOShEz80apl7dvHSqtkELvjuo//1yr8oqa61dHgAAANAmCBMAoBX4d3HRk3fG6raresrOaFDS4SLN+ShBSamF1i4NAAAAaHWECQDQSoxGg64fEaa5M4eqm5+byqvq9PaXezV/ZYqqa+qtXR4AAADQaggTAKCVdfd315x7h+q64aEySPpp73E9M3+7DmWVWrs0AAAAoFUQJgBAG3CwN+pXV/fSn2bEytfLWUUnT+lvS5K09PvDqqtvsHZ5AAAAwCUhTACANtS7exc9d98wjR0YJLOkNduPad7HO5WVX27t0gAAAICLRpgAAG3MxcleM6+L1m9vjZGnq4NyCiv1/Mc7tWJrhhpMJmuXBwAAAFiMMAEALpNBkb6ad/9wxfX2U4PJrC9/PKpXPtml/NIqa5cGAAAAWIQwAQAuI09XR82+ub9mTY6Wi5OdjuSU6dn5O7QpKUdms9na5QEAAAAtQpgAAJeZwWDQ6AFBmnffcPUJ7aKaugYtWnNIb36erBMVNdYuDwAAALggwgQAsJKuXs76wx2Ddfv4SNnbGbX3aLHmfJigHQcLrF0aAAAAcF6ECQBgRUaDQdcM7a5nfj1UYQEeqjxVr/e+3qf3v92vylN11i4PAAAAaBZhAgC0AyG+bvrzPXG6YVS4jAaD4vfna+5H27U/o8TapQEAAABnIUwAgHbC3s6om8f20FN3xyrA20Wl5TV67bPd+mRdqmrqGqxdHgAAANCIMAEA2pmewV569tfDNC42RJK0ITFbzy3YofTjZVauDAAAADiNMAEA2iEnRzvddU2Unpg+UF3cHZVXUqUXFyXq681HVd9gsnZ5AAAA6OQIEwCgHesf0VXzZg3XsGh/mcxmLd+SoZcWJ+p4caW1SwMAAEAnRpgAAO2cu4uDHp7aXw/d2E9uzvbKyCvXswt2aN3OYzKZzdYuDwAAAJ0QYQIA2IjhfQM0b9Zw9Y/wUV29SZ+uP6zXPtutkrJT1i4NAAAAnQxhAgDYEG8PJ/1+2kDdfU1vOToYlZJZqjkfbde2fXkyM0sBAAAAlwlhAgDYGIPBoKtju+m5Xw9Tj2BPVdfU64MVB/Te1/tUUV1n7fIAAADQCRAmAICNCvBx1VN3xermKyJkZzRo56FCzfkwQclHiqxdGgAAADo4mwsT4uPj9dBDD2nEiBGKiYnRpEmT9Oabb6qqqqpV7v/JJ58oKipKUVFRuvvuu887tri4WC+88ILGjx+vAQMGaPTo0Xr88ceVkpLSKrUAwIXYGY26YXSE/nxPnIK6uupkZa3e/DxZH68+qFO19dYuDwAAAB2UTYUJixcv1syZM7Vp0yY5OTmpZ8+eysnJ0XvvvafbbrtNJ06cuKT75+fn6/XXX2/R2MzMTN14441avHixSkpKFBkZKbPZrFWrVulXv/qVNmzYcEm1AIAlwgM99czMobpmaHdJ0g+7c/Xs/B1Kyz5p5coAAADQEdlMmLBv3z699NJLkqR58+Zp06ZN+uqrr7R+/Xr169dPR44c0Zw5cy7pGc8++6yqq6t19dVXn3ec2WzW7373OxUVFemKK67Qjz/+qC+//FI//vijZs+erbq6Ov3hD39QQUHBJdUDAJZwdLDT7eMj9T93DFZXTycVnKjWy58k6j+bjqi+wWTt8gAAANCB2EyY8O6778pkMmnq1KmaPn26DAaDJCkgIECvv/66jEaj1q5dq4MHD17U/b/77jt9//33mjFjhvr163fesRs2bFBKSoo8PDz02muvycPDQ5Jkb2+v3/3udxo6dKiqqqo0f/78i6oFAC5FdJi3nrtvuEb3D5TZLH0Xn6nnP96p7MIKa5cGAACADsImwoTKykpt3rxZkjRt2rSzzoeHh2vEiBGSpNWrV1t8/5MnT+rFF19UYGCgHn/88QuOX7VqlSRp0qRJ8vLyOuv8mRrPjAOAy83V2V6zpvTVb24eIHcXBx0rqNC8hTu0OiFLJhNbSAIAAODS2ESYkJKSotraWjk6OiomJqbZMXFxcZKkPXv2WHz/V155RUVFRZozZ47c3NwuOP7MM4YMGdLs+TPH8/LylJ+fb3E9ANBa4qL89PysYRrYs6vqG8xatjFNf/s0SYUnqq1dGgAAAGyYTYQJ6enpkqTg4GA5ODg0OyY0NLTJ2Jbatm2bvvzyS40bN04TJky44Pja2lrl5OQ0eeYvBQUFNdZ59OhRi+oBgNbm5e6k394Wo5nX9ZGTo51Sj53Q3PnbtXlPrsxmZikAAADAcvbWLqAlTp48vRp5c68UnHHm3JmxLXHq1CnNnTtXrq6umjt3bouuqaiokMlkOm89BoNBnp6eKi4uVllZWYvrORd7+/ad+djZGZv8E7gQesY6xsV1U/8ePnp/+QGlHjuhBasOaveRIt13fbS83J2sXd550TOwFD0DS9EzsBQ9A0t0xH6xiTChpqZGks45K0GSHB0dm4xtiX/84x/KysrSU089paCgIItq+fkzz1fPqVOnWlxPc4xGg7y9L/zqRXvg6eli7RJgY+iZy8/b201/++1YffNDmhavOqik1CL9JTdBv7ltkEYOaNnXQWuiZ2ApegaWomdgKXoGluhI/WITYYKT0+mfmNXV1Z1zTG1tbZOxF3LgwAF9/PHH6tu3r+6++26La/n5M89Xj7Ozc4vv3RyTyayysqpLukdbs7MzytPTRWVl1Wpg+zm0AD1jfVcPClbPIA/965v9OlZQoZcWbtcVMUG669oouTi1vz8a6BlYip6BpegZWIqegSVsqV88PV1aNIOi/X3H2IyWvMLQklchfu7Pf/6zTCaT5s2bJzs7uxbX4u7uLqPRKJPJdM56zGZz4+sNnp6eLb73udTXt+9mO6OhwWQztaJ9oGesK7irm/5yzxB9/dNRrY7P0ubk4zqQUapZk6PVJ8zb2uU1i56BpegZWIqegaXoGViiI/WLTYQJ4eHhkqTc3FzV1dU1+7pDVlZWk7EXcuDAAdnZ2enhhx8+61xV1emZAElJSRo9erQk6T//+Y+CgoLk6Oio4OBgZWdnKysrS7GxsWddf/z48cZZFBERES2qBwCswcHeqF9d1UsDe/rqo5UHVHjilF79NEkTh3bXrVf2kIN9y8NWAAAAdB42sfpDdHS0HBwcVFtbq+Tk5GbHJCYmSpIGDRrU4vs2NDSoqKjorF9nwoS6urrGYw0NDY3XnXnGzp07m73vmeOBgYEKDAxscT0AYC29u3fRs78eprEDg2WWtHbHMT23cKcy88qtXRoAAADaIZsIE9zd3TVmzBhJ0rJly846n5GRofj4eEnSpEmTWnTPQ4cOnfPXo48+KkkaNmxY47Fu3bo1XnvttddKklavXt3sqw5namxpLQDQHrg42WvmdX30u9ti5OnmqNyiSr2waKe+3ZqhBlPHmI4HAACA1mETYYIkzZ49WwaDQd98842WLl3auDd6QUGBnnjiCZlMJk2YMEF9+vRpct24ceM0btw4rV69utVqmTBhgqKiolReXq4//OEPKi8//ZO7hoYGvfXWW9qxY4dcXFx03333tdozAeByGdjLV8/PGqa4KD81mMz66sejeuXfu5Rf2r4XgwUAAMDlYxNrJkhSTEyMnnzySb3yyiuaO3eu3nvvPXl7eystLU21tbWKiIjQ888/f9Z1OTk5kv5vHYTWYDQa9dZbb2nGjBn68ccfNXbsWEVERCgvL0/FxcVycHDQq6++qoCAgFZ7JgBcTh6ujpp9U3/F78/Xv9el6khumZ6Zv13Tx0XqqkHBMhgM1i4RAAAAVmQzMxMkaebMmVqwYIHGjh2r6upqpaWlKTg4WA8//LC++OIL+fj4XLZaIiIitHz5ct11113y9vZWamqqpNOvQCxbtkwTJ068bLUAQFswGAwa2T9Qz88apugwb9XWmbR4zSG98fkelZbXWLs8AAAAWJHBfOZ9AbRLDQ0mlZRUWruM87K3N8rb202lpZUdZpsTtC16xvaYzGZt2Jmt//xwRHX1Jrk52+vua6M0LPryzMCiZ2ApegaWomdgKXoGlrClfvHxcZOd3YXnHdjUzAQAgHUYDQZNHNpdz8wcqrBAD1Weqtc/v9mvfy3fr8pTddYuDwAAAJcZYQIAoMWCfd3057vjdOPocBkNBiUcyNfcj7Zrf3qJtUsDAADAZUSYAACwiL2dUTdd0UNP3x2nAB9XlZbX6LWlu/XvtYdUU9dg7fIAAABwGRAmAAAuSo9gTz3766EaH9tNkvT9rhw9u2CHjuaWWbkyAAAAtDXCBADARXNysNOMa3rriekD5e3hpPySKr20OFFfbz6q+ob2vbgQAAAALh5hAgDgkvWP6Kp5s4ZpRN8AmcxmLd+SoRcXJyq3qH3vRgMAAICLQ5gAAGgVbs4OevDGfnp4aj+5OdsrM69czy3coXU7jsnELsQAAAAdCmECAKBVDYsO0LxZw9W/h4/q6k36dMNhvfbZbhWfPGXt0gAAANBKCBMAAK3O28NJv//VQN19bZQcHYxKySzV3PkJ2rrvuMzMUgAAALB5hAkAgDZhMBh09eAQPffrYeoZ7KnqmgZ9uCJF7369T+VVtdYuDwAAAJeAMAEA0KYCfFz15F2xunlsD9kZDUo8VKg5H23XnrQia5cGAACAi0SYAABoc3ZGo24YFa6/3DNEwb5uKqus1Vv/SdbCVQd1qrbe2uUBAADAQoQJAIDLJizQQ8/MHKJrhnaXQdKPe3L1zPztSj12wtqlAQAAwAL2bf2AhoYGffrpp9qyZYuMRqOuuuoq/epXv2rrxwIA2ikHezvdPj5Sg3r56qOVKSo8cUp//WSXJo0I1U1jesjBnpwbAACgvWuV79j+85//KDo6Wo8//vhZ55544gm9+OKL2rRpkzZs2KC5c+fq97//fWs8FgBgw/qEeWverGEaPSBQZkmr4rP0/Mc7lV1QYe3SAAAAcAGtEiZs2bJFkjRlypQmxxMSErRmzRqZzWYNHjxYo0aNkiStXr1a69evb41HAwBsmIuTvWZN7qtHbxkgdxcHZRdWaN7HO7QqIVMm0+ktJE0ms1IySvTDrmylZJQ0HgcAAID1tMprDikpKZKk2NjYJse//vprSdK0adM0b948SdK7776rf/zjH/rqq680YcKE1ng8AMDGxfb2U88QL3286qB2pxXp841HtOdwkYb3DdCKbZkqLa9pHOvt4aQ7J0QqLsrfihUDAAB0bq0yM6G0tFSOjo7y8fFpcnzbtm0yGAy6++67G4/NmDFDkrRv377WeDQAoIPwcnPUY7cO0K+v6yMnRzulZp/U4rWpTYIESSotr9E7X+1T4qECK1UKAACAVgkTKisr5eTk1ORYQUGB8vLy1LVrV0VGRjYe9/Lykru7u0pKSlrj0QCADsRgMOiKgcF6duZQ2dsZzjv20/WHeeUBAADASlolTHB3d1d5ebmqq6sbj+3YsUOSNHjw4Gav+WX4AADAGaXlNapvOH9QUFJew5aSAAAAVtIqYcKZmQerVq1qPPb111/LYDBo6NChTcaWl5eroqJCvr6+rfFoAEAHdKKy5sKDLBgHAACA1tUqCzBOmTJFO3bs0Lx587Rnzx4VFRVp8+bNcnR01HXXXddkbFJSkiQpPDy8NR4NAOiAuri1bPba1n15igjyVIC3axtXBAAAgJ9rlZkJt912m0aNGqVTp05p2bJl2rBhgwwGgx5//HH5+fk1Gbt69epmZywAAHBG7+5d5O1x4UBh39ESPf1+vN7/dr9yiiovQ2UAAACQWmlmgp2dnT788EOtWLFCSUlJ8vT01NixYxUXF9dkXG1trQoLCzVkyBCNHTu2NR4NAOiAjEaD7pwQqXe+OvfOP7dc2UNp2SeVfKRY8fvzFb8/X3FRfpoyMlxhgR6XsVoAAIDOx2A2m1kKux1raDCppKR9/7TN3t4ob283lZZWqr7eZO1yYAPoGbRU4qECLVl/uMn2kD4eTrpjQqTiovwlSZl55VqxLUOJhwobx8T07Kopo8LVK8TrsteM9oGvM7AUPQNL0TOwhC31i4+Pm+zsLvwSQ6vMTAAAoC3ERflrcKSfjuSeVJ3ZIAeDWT2DvWQ0/t+2kWGBHvrNzQOUU1ihlfGZSjiQr+QjxUo+UqzoMG/dMCpcUaFdZDCcf6tJAAAAtNxlCRM2btyoLVu2yGg06sorr9To0aMvx2MBAB2A0WhQdLjPBdP8ED93PXhDP00dHaGV8Znati9PKZmlSsksVa9uXrphVLj6R/gQKgAAALSCVnnNYe3atfrrX/+q0aNHa968eU3Ovfzyy1q0aFGTYzNnztSf/vSnS31sp8BrDuiI6BlY6mJ6puhktVYlZGnznuOqbzh9TVigh24YFa5Bkb4yEip0aHydgaXoGViKnoElbKlfWvqaQ6vs5vD9998rNzdXQ4YMaXJ8//79+vjjj2U2mxUUFKTQ0FCZzWYtXLhQCQkJrfFoAACa5evloruvidJfHx6pa4Z2l6ODUZl55frfL/fqmfnblXAgXyYTywYBAABcjFYJE/bu3StJGjlyZJPjX3zxhSRp4sSJWr9+vdasWaMZM2bIbDZr2bJlrfFoAADOy9vDSbePj9TfHhmlySPD5Oxop5zCSv1r+X79+cME/ZT8fzMXAAAA0DKtEiaUlJTIzs5Ofn5+TY5v2bJFBoNBDzzwgIzG04966KGHJEm7d+9ujUcDANAinq6OuvXKnnp19ijddEWE3JztlV9Spfnfpejp9+O1KSlHde182iEAAEB70SoLMJaXl8vNza3JsdLSUmVmZsrLy0sxMTGNx/39/eXi4qLCwsJf3gYAgDbn5uygG0dHaOKQ7tq0O0drErJUdPKUFq05pOVb0nXd8DCNHRQsJwc7a5cKAADQbrVKmODq6qry8nLV1dXJwcFBkpSYmChJGjRo0Fnjz4wBAMBaXJzsdd3wMI2P7aYf9+RqVUKWSstr9OmGw1qxLUPXDgvV1YND5OLELsoAAAC/1CqvOfTo0UNms1k//PBD47FVq1bJYDAoLi6uydjq6mqVl5ef9UoEAADW4OhgpwlDuuuVh0bq3klR8vVyVnlVnf6z6Yj++N5WffNTuipP1Vm7TAAAgHalVX7cMnHiRO3evVt/+ctfdPToURUWFuq7776T0WjUdddd12Ts3r17ZTab1a1bt9Z4NAAArcLB3qgrB4Vo9IAgJRzI18ptmcorqdI3P6VrzfYsjYvtpmuGdpenm6O1SwUAALC6VgkT7rrrLi1fvlyHDh3SG2+8IbPZ3Hi8e/fuTcauXbtWBoPhrG0kAQBoD+ztjBo9IEgj+wVq56ECrdiaqezCCn0Xn6n1O4/pykEhmjQ8VN4eTtYuFQAAwGpaJUxwcnLSkiVL9PHHH2v37t3y8PDQ1VdfrSlTpjQZV1tbqx07digoKEhjxoxpjUcDANAmjEaDhkUHaEgff+1JK9KKrRlKP16udTuPaWNStsbEBOv64aHy7eJi7VIBAAAuO4P5zDQCtEsNDSaVlFRau4zzsrc3ytvbTaWllapnWzW0AD0DS7WHnjGbzdqfUaJvt2TocPZJSZKd0aAR/QI0eWS4An1crVIXmtceega2hZ6BpegZWMKW+sXHx012dhdeXpElqgEAaAGDwaD+EV3VP6KrDmWVasXWDO3PKNWWvXnaui9Pw6IDNHlkmLr5uVu7VAAAgDbXJmFCRUWFDhw4oOLiYklS165d1bdvX7m78w0WAMD2RYV6KyrUW0dyT2rl1kztTitSwoF8JRzIV2xvP00ZFabwQE9rlwkAANBmWjVMOLMA4+bNm2UyNZ26YTQadeWVV+p3v/udoqKiWvOxAABYRc9gL/32thhl5ZdrxbZMJR4s0K7UQu1KLdSAHl11w6hw9ermZe0yAQAAWl2rhQlr167V//zP/6i2tlbNLcPQ0NCgjRs3asuWLfr73/+uiRMnttajAQCwqtAAD82+qb9yiyq1clumEg7ka+/RYu09Wqw+oV10w6hw9QnzlsFgsHapAAAAraJVFmA8duyYJk+erNraWoWEhOj+++/X6NGjFRgYKEnKy8vTli1b9NFHHyk7O1tOTk5asWLFWdtG4mwswIiOiJ6BpWytZwpKq/RdfKa27M1Tg+n0H7M9Qzx1w6hwDejRlVDhMrC1noH10TOwFD0DS9hSv7R0AcYLj2iBjz76SLW1tRo0aJCWL1+uO+64Q6GhoXJ0dJSjo6NCQ0N1xx13aPny5Ro0aJBqa2u1YMGC1ng0AADtjr+3q2ZeF61XHhqp8bHdZG9n1JGcMr35ebKeW7hDiYcKZGIzJQAAYMNa5TWHbdu2yWAw6LnnnpObm9s5x7m6uuq5557T1KlTtWXLlot6Vnx8vBYsWKA9e/aoqqpKwcHBmjRpkh588EG5ulq2LdfSpUuVlJSkAwcOqKioSCdPnpSLi4t69OihiRMn6q677pKLy9n7h2dnZ2v8+PHnvffAgQO1bNkyi+oBAHQsXb2cNeOa3poyKkxrth/TxqQcZeVX6J2v9inE102TR4ZpaLS/7Iytku0DAABcNq3ymsPAgQPl4OCgnTt3tmj8kCFDVFdXpz179lj0nMWLF+vFF1+U2WxWYGCgfHx8lJaWptraWvXs2VNLlixRly5dWny/IUOGqLy8XM7OzgoICJCHh4fy8/NVWFgoSQoPD9fChQsVFBTU5LqfhwmxsbHN3jsyMlLz5s2z6PM1h9cc0BHRM7BUR+mZ8qparduZrQ2Jx1Rd0yBJ8vd20eQRYRrZP1D2LZhSiJbpKD2Dy4eegaXoGVjClvqlpa85tMrMBHt7e9XX17dorNlsVl1dneztLXv0vn379NJLL0mS5s2bp2nTpslgMCg/P1+PPPKI9u/frzlz5ujtt99u8T0fffRRxcbGqn///jL+7KdCiYmJevzxx5WRkaFnnnlG77///jnv8emnn1r0OQAAnZeHq6NuGdtDk4Z114ZdOVq345gKSqu1YNVBLd+SrutHhGlMTJAc7O2sXSoAAMB5tcqPQMLCwlRTU6PNmzdfcOzmzZtVU1OjsLAwi57x7rvvymQyaerUqZo+fXrj4lUBAQF6/fXXZTQatXbtWh08eLDF95w5c6ZiYmKaBAmSFBcXp6eeeqqx3qqqKotqBQDgfFydHXTDqHD97ZGRmnZ1L3m6Oaq4rEaL16bqj//cprXbs1RT22DtMgEAAM6pVcKEcePGyWw2a86cOTpy5Mg5x6WlpWnu3LkyGAwXXHPg5yorKxuDimnTpp11Pjw8XCNGjJAkrV692sLqm9ezZ09JkslkUk1NTavcEwCAn3N2tNek4aH628MjNWNib/l4OulkRa0++z5N//PeVq3clqHqmpbN/AMAALicWuU1h5kzZ+rzzz9XXl6ebrrpJk2aNEkjR45UQECApNNbQ27btk1r1qxRXV2dAgMDde+997b4/ikpKaqtrZWjo6NiYmKaHRMXF6etW7davA7DuSQmJkqSQkJC5O3tfc5xL7zwgo4ePSqDwaCQkBCNGTNGEyZMOGu2AwAA5+LoYKfxcd105aBgbd2Xp5XbMlR44pS++OGoVsVnacKQbpowpLvcXRysXSoAAICkVgoT3N3d9eGHH+rhhx9WTk6OVqxYoRUrVpw1zmw2q1u3bnrvvffk7u7e4vunp6dLkoKDg+Xg0Pw3UqGhoU3GXoz6+noVFBRo/fr1euONN+Tg4KCnn376vNcsXry4ye+XLl2q6Ohovf322+revftF1wIA6Hzs7YwaOzBYowcEavuBAq3YlqHjxVVaviVDa3Yc07jBIbpmWKi83BytXSoAAOjkWiVMkE7vXrB8+XJ98sknWr16tQ4dOqSGhtPve9rZ2SkqKkrXX3+97rjjjvNuH9mckydPSpK8vLzOOebMuTNjLfHiiy9q0aJFTY6NGTNGjz32mAYNGnTWeHt7e914442aPHmyevXqJX9/f5WWluqHH37Qm2++qZSUFM2aNUtffvmlRaHJudjbt+9ZDmdW+mzJip+ARM/Acp2tZ+xl1BWDgjV6YJASDxbom5/SlZVfoVUJWVqfmK2rB4fo+pFh8vF0tnap7VZn6xlcOnoGlqJnYImO2C+tsjVkc+rq6pqEAGdmFJSXl+uee+6RwWDQl19+2aJ7vfPOO/rHP/6hIUOG6JNPPml2zLZt2zRz5kzZ2dnpwIEDFtW6aNEirVq1SrW1tcrNzVVJSYlcXV11880368knn5SjY8t/ApSZmalbbrlFFRUV+t3vfqfZs2dbVMsvmc3mxsUmAQCdk9ls1o6UfC1bl6pDWaWSJHs7g8YPDdVt4yIV2NWykB4AAOBStdrMhF9ycHCQr6/vWcfr6+uVkpJi0V+QnZycJJ0OKM6ltra2yVhL3HPPPbrnnnsaf79z504999xz+uSTT5Sbm6t//vOfLb5XWFiY7rjjDn3wwQdat27dJYcJJpNZZWXtezcJOzujPD1dVFZWrYaG9r1nKtoHegaWomekyCAPPX13rPanl2j5T+k6mHVCa+IztS4hSyP7B+rGMeEKIlRoRM/AUvQMLEXPwBK21C+eni4tmkHRZmFCa2rJKwwteRWipYYMGaL3339fEydO1MaNG5WYmKi4uLgWXz948GBJUkZGxiXXIkn19e272c5oaDDZTK1oH+gZWIqekfqEeqvPnd5KPXZCK7ZmaF96ibbsPa6te49raLS/Jo8MV3f/S3/FrqOgZ2ApegaWomdgiY7ULzbxwkZ4eLgkKTc395yzE7KyspqMvVRBQUHq3bu3JGn//v0WXXvmlY4za0YAANDaenfvoiemD9Kce4docKSvzJK2pxTomfnb9fYXyUo/XmbtEgEAQAdmEzMToqOj5eDgoNraWiUnJzc7S+DMVo7NLZh4sc6EAZaGAocPH5YkBQYGtlotAAA0JyLIU4/dGqNjBRVauS1DO1IKlHS4SEmHi9Q/wkdTRoWrd/cu1i4TAAB0MDYxM8Hd3V1jxoyRJC1btuys8xkZGYqPj5ckTZo0qVWemZGRodTUVEmnw4yWqqys1JIlSyRJo0ePbpVaAAC4kO7+7np4an+98MBwjeofKKPBoH3pJXrlk1366ye7tD+jRG205jIAAOiEbCJMkKTZs2fLYDDom2++0dKlSxu/ISooKNATTzwhk8mkCRMmqE+fPk2uGzdunMaNG6fVq1c3Ob5q1SotWrRIhYWFZz0rPj5eDzzwgEwmk/r27athw4Y1OT9nzhytXbu2cdHHM44cOaL7779f2dnZcnV11axZs1rjowMA0GJBXd10/5S+eumhEbpqULDsjAYdOnZCr322Wy8uTtTutCJCBQAAcMls4jUHSYqJidGTTz6pV155RXPnztV7770nb29vpaWlqba2VhEREXr++efPui4nJ0eSVFXVdEeE/Px8vfzyy3rxxRcVFBQkX19fmc1m5eTkqLT09LZbvXr10jvvvCOjsWnmkpycrGXLlsnBwUGhoaFyd3dXaWlp47oNXl5eevPNN9WtW7e2+FcBAMAF+Xdx0T2T+mjKqHCtTsjSD3tydTS3TP/4T7JC/d01ZVS4YqP8ZGT7YQAAcBFsJkyQpJkzZyoqKkrz589XcnKyiouLFRwcrEmTJunBBx+Um1vLt8SaMGGCampqtH37dqWnpystLU319fXy9vbW2LFjdc0112jq1KlydHQ869qHHnpImzdv1r59+1RUVKTMzEw5OzurX79+Gjt2rGbMmCE/P7/W/OgAAFwUH09n3TmxtyaPCtfa7Vn6PilHWQUVevfrfQrq6qopI8M1rK+/7Iw2M1kRAAC0AwbzRcx1tGQNgeaYzWYZDAalpKRc0n06g4YGk0pKKq1dxnnZ2xvl7e2m0tLKDrPNCdoWPQNL0TOtp6K6Tut3HtO6ndmqrqmXdHoWw/UjwzSqf6DsW7CvtC2gZ2ApegaWomdgCVvqFx8fN9m14PuBi5qZwLuWAADYJncXB910RQ9dMzRUG5OytWb7MRWcqNbCVQe1fEu6rhsepitiguToYGftUgEAQDt2UWHCo48+2tp1AACAy8jV2V6TR4ZrQlx3/bA7R6u2Z6mkrEafrEvViq0ZunZYqK4aHCxnR5t6IxIAAFwmF/WaAy4fXnNAR0TPwFL0TNurq2/QT8nH9V18porLaiSdnsUwcWh3jY/tJldn2woV6BlYip6BpegZWMKW+qVNX3MAAAAdi4O9na6O7aYrBgZr2/48rdyWqYLSan3141GtTsjS+Lhumjikmzxcz16YGAAAdD6ECQAAoJG9nVFXxARrVP9A7ThYoJVbM5VTVKkVWzO0bscxXT04RNcO6y4vdydrlwoAAKyIMAEAAJzFzmjUiL6BGhYdoKTUQn27NUNZ+RVavT1LG3Zla2xMsK4bESofT2drlwoAAKyAMAEAAJyT0WBQXJS/Ynv7ae/RYn27JUNHcsu0YVe2Nu3O0egBgbp+RJj8vV2tXSoAALiMCBMAAMAFGQwGxfT01YAeXXUws1Tfbs3QwawT+nHPcf2UnKfhfQM0eWSYgn3drF0qAAC4DAgTAABAixkMBkWH+yg63EeHs09oxdZM7T1arG378xS/P09xffw1ZWSYQgM8rF0qAABoQ4QJAADgokR266LfT+uijLwyrdiaqV2phdp5sEA7DxZoUC9fTR4Vpp7BXtYuEwAAtAHCBAAAcEnCAz316C0DlF1YoZXbMrU9JV+704q0O61I/cK9NWVUuKJCva1dJgAAaEWECQAAoFV083PXQzf209QxEfpuW6a27c/T/oxS7c8oVe9uXpoyOlz9wn1kMBisXSoAALhEhAkAAKBVBfq46r7J0bpxdLhWJWRpc3KuUrNP6vWlexQR5KEpo8I1qJcvoQIAADaMMAEAALQJ3y4uuvvaKE0ZFa7VCVn6YXeO0o+X6+0v9qqbn7umjArTkCh/GY2ECgAA2BrCBAAA0Ka8PZx0x4RITR4ZprU7jmnDrmxlF1bon9/sV6BPuiaPDNOIfgGyMxqtXSoAAGgh/tQGAACXhaebo267qqdefWSUpo6JkJuzvfJKqvTRyhQ99a94/bA7R3X1JmuXCQAAWoCZCQAA4LJyd3HQ1DERumZod21MytGa7VkqOnlKH68+pOVbMnTd8FCNHRgsRwc7a5cKAADOgTABAABYhYuTva4fEabxcd304+5crUrIVGl5jZasP6wV2zJ17bDuumpQiFyc+HYFAID2hj+dAQCAVTk52Gni0O66anCItuw9ru/iM1V08pQ+33hE323L1MSh3TUhrptcnR2sXSoAAPgvwgQAANAuONgbddXgEI2JCVLCgXyt2Jap/JIqfb05XWu2Z2lcbDdNHNpdnq6O1i4VAIBOjzABAAC0K/Z2Ro0eEKSR/QK181CBvt2aoZzCSq3clql1O4/pqkEhmjQ8VF3cnaxdKgAAnRZhAgAAaJeMRoOGRQdoSB9/7T5cpG+3Zigzr1xrdxzT97tydMXAIF03PFS+Xi7WLhUAgE6HMAEAALRrRoNBsb39NDjSV/vSS/Tt1gylZZ/Uxl05+nF3rkb2D9TkkWEK8Ha1dqkAAHQahAkAAMAmGAwGDejRVf0jfHQo64S+3ZqhlMxS/ZR8XFv2HtfwvgGaPDJcIb5u1i4VAIAOjzABAADYFIPBoD5h3uoT5q20nJNasTVDyUeKFb8/X/H78xUX5aepV0TI25tQAQCAtkKYAAAAbFavEC89/quByswr14ptGUo8VNj4a0h0gK4b3l0RgZ7WLhMAgA6HMAEAANi8sEAP/ebmAcoprNDK+EwlHMjXzpTTv6LDvHXDqHBFhXaRwWCwdqkAAHQIhAkAAKDDCPFz14M39NOtV/bU2p3Z+n7nMaVkliols1S9unnphlHh6h/hQ6gAAMAlIkwAAAAdToCPq347fbCuG9ZdK7Zm6Mc9x5WWfVJvLNujsEAP3TAqXIMifWUkVAAA4KIQJgAAgA7Lt4uL7romSpNHhmvN9ixt2p2jzLxy/e+XexXi56YpI8M1tI+/jEZCBQAALGG0dgEAAABtzdvDSbePj9TfHhmlySPD5OJkp5zCSv1r+X79+cME/ZR8XPUNJmuXCQCAzSBMAAAAnYanq6NuvbKnXn1klG66IkJuzvbKL6nS/O9S9PT78dqUlKO6ekIFAAAuhNccAABAp+Pq7KAbR0do4pDu2rQ7R2sSslR08pQWrTmk5VvSdd3wMI0dFCwnBztrlwoAQLtEmAAAADotFyd7XTc8TONju+nHPblalZCl0vIafbrhsFZsy9C1w0J19eAQuTjxLRMAAD/Hn4wAAKDTc3Sw04Qh3XXloBBt3XdcK7dlqujkKf1n0xGtis/UhCHdNWFIN7k5O1i7VAAA2gXCBAAAgP9ysDfqykEhGhMTpIQD+VqxNVN5JVX65qd0rdmepXGx3XTN0O7ydHO0dqkAAFgVYQIAAMAv2BmNGtU/SCP6BioxtVDfbslQdmGFvovP1Pqdx3TloBBNGh4qbw8na5cKAIBVECYAAACcg9Fo0NA+/oqL8tOetCKt2Jqh9OPlWrfzmDYmZWtMTLCuHx4q3y4u1i4VAIDLijABAADgAowGgwZH+mlQL1/tzyjRii0ZSs0+qU1JOdq8J1cj+gVo8shwBfq4WrtUAAAuC8IEAACAFjIYDOof0VX9I7rqUFapVmzN0P6MUm3Zm6et+/I0LDpAk0eGqZufu7VLBQCgTREmAAAAXISoUG9FhXrrSO5Jrdyaqd1pRUo4kK+EA/mK7e2nKaPCFB7oae0yAQBoE4QJAAAAl6BnsJd+e1uMsvLLtWJbphIPFmhXaqF2pRZqQI+uumFUuHp187J2mQAAtCrCBAAAgFYQGuCh2Tf1V25RpVZuy1TCgXztPVqsvUeL1Se0i24YFa4+Yd4yGAzWLhUAgEtGmAAAANCKgn3d9MANfTV1TLi+i8/Slr3HdTDrhA5m7VbPEE/dMCpcA3p0JVQAANg0wgQAAIA24O/tqpnX9dGNo8O1KiFLP+7J1ZGcMr35ebJCA9x1w6hwDe7tJyOhAgDABtlcmBAfH68FCxZoz549qqqqUnBwsCZNmqQHH3xQrq6Wbce0dOlSJSUl6cCBAyoqKtLJkyfl4uKiHj16aOLEibrrrrvk4nLufaOLi4v13nvvaePGjSooKJCnp6eGDh2qhx56SNHR0Zf6UQEAQAfg4+msGRN7a8rIMK3ZcUwbd+UoK79C73y1T8G+bpoyMkxDo/1lZzRau1QAAFrMYDabzdYuoqUWL16sF198UWazWYGBgfLx8VFaWppqa2vVs2dPLVmyRF26dGnx/YYMGaLy8nI5OzsrICBAHh4eys/PV2FhoSQpPDxcCxcuVFBQ0FnXZmZm6s4771RRUZFcXV0VERGhvLw8FRcXy8HBQW+99ZbGjx9/yZ+5ocGkkpLKS75PW7K3N8rb202lpZWqrzdZuxzYAHoGlqJnYKn23DMV1XVat+OY1idmq7qmXpLk7+2iySPCNLJ/oOztCBWsoT33DNonegaWsKV+8fFxk10L/iyymTBh3759+tWvfiWz2aznnntO06ZNk8FgUH5+vh555BHt379f11xzjd5+++0W33PhwoWKjY1V//79ZfzZTwMSExP1+OOPq6CgQFdeeaXef//9JteZzWbdfPPNSklJ0RVXXKE33nhDHh4eqq+v1zvvvKN3331Xrq6uWrNmjfz9/S/pcxMmoCOiZ2ApegaWsoWeqTpVpw27crRuxzFVVNdJkrp6Oun6EWEaExMkB3s7K1fYudhCz6B9oWdgCVvql5aGCTYTfb/77rsymUyaOnWqpk+f3rhoUUBAgF5//XUZjUatXbtWBw8ebPE9Z86cqZiYmCZBgiTFxcXpqaeekiRt3rxZVVVVTc5v2LBBKSkp8vDw0GuvvSYPDw9Jkr29vX73u99p6NChqqqq0vz58y/lIwMAgA7M1dlBN4wK198eGalpV/eSp5ujistqtHhtqv74z21auz1LNbUN1i4TAIBm2USYUFlZqc2bN0uSpk2bdtb58PBwjRgxQpK0evXqVnlmz549JUkmk0k1NTVNzq1atUqSNGnSJHl5nb1v9Jkaz4wDAAA4F2dHe00aHqq/PTxSMyb2lo+nk05W1Oqz79P0P+9t1cptGY2vQwAA0F7YRJiQkpKi2tpaOTo6KiYmptkxcXFxkqQ9e/a0yjMTExMlSSEhIfL29m5y7swzhgwZ0uy1Z47n5eUpPz+/VeoBAAAdm6ODncbHddMrD43UzOv6yL+Liyqq6/TFD0f1P+9u1debjza+DgEAgLXZxG4O6enpkqTg4GA5ODg0OyY0NLTJ2ItRX1+vgoICrV+/Xm+88YYcHBz09NNPNxlTW1urnJycJs/8paCgIDk4OKiurk5Hjx5VQEDARdcEAAA6F3s7o8YODNboAYHanlKgFVszdLy4Ssu3ZGjNjmMaNzhE1wwLlZebo7VLBQB0YjYRJpw8eVKSmn2l4Iwz586MtcSLL76oRYsWNTk2ZswYPfbYYxo0aFCT4xUVFTKZTOetx2AwyNPTU8XFxSorK7O4nl+yt2/fE0jOLM7RkkU6AImegeXoGViqI/SMvYy6YmCwRscEKfFggb75KV1Z+RValZCl9YnZunpwiK4fGSYfT2drl9ohdISeweVFz8ASHbFfbCJMOLNmwblmJUiSo6Njk7GW6N69u2JjY1VbW6vc3FyVlJRo165dWr58ufr27dt471/e/+fHz1XPqVOnLK7n54xGg7y93S7pHpeLp6eLtUuAjaFnYCl6BpbqKD1zzSh3TRwZoR0p+Vq2LlWHskq1dscxfb8rW+OHhuq2cZEK7Gob3y+0dx2lZ3D50DOwREfqF5sIE5ycnCRJdXXnfk+wtra2yVhL3HPPPbrnnnsaf79z504999xz+uSTT5Sbm6t//vOfZ9Xy82eerx5n50v7aYHJZFZZWdWFB1qRnZ1Rnp4uKiurVkND+97mBO0DPQNL0TOwVEftmcggDz19d6wOZJTqm81HdTDrhNbEZ2pdQpZG9g/UjWPCFUSocFE6as+g7dAzsIQt9Yunp0uLZlDYRJjQklcYWvIqREsNGTJE77//viZOnKiNGzcqMTGxcYFHd3d3GY1GmUymc9ZjNpsbX2/w9PS85Hra+z6kZzQ0mGymVrQP9AwsRc/AUh21Z6K6d9Ef74xV6rETWrE1Q/vSS7Rl73Ft3XtcQ6P9NXlkuLr7u1u7TJvUUXsGbYeegSU6Ur/YxAsb4eHhkqTc3Nxzzk7IyspqMvZSBQUFqXfv3pKk/fv3Nx53dHRUcHBwk2f+0vHjxxvrjIiIaJV6AAAAfql39y56Yvogzbl3iAZH+sosaXtKgZ6Zv11vf5Gs9OOXvnYTAADNsYkwITo6Wg4ODqqtrVVycnKzY85s5fjLBRMvRUNDQ5N/nnHmGTt37mz2ujPHAwMDFRgY2Gr1AAAANCciyFOP3Rqj5+4bpmHR/jJISjpcpOc/3qnXl+5W6rET1i4RANDB2ESY4O7urjFjxkiSli1bdtb5jIwMxcfHS5ImTZrUKs/MyMhQamqqpNNhxs9de+21kqTVq1c3+6rDmRpbqxYAAICW6O7vroen9tcLDwzX6P6BMhoM2pdeolc+2aW/frJL+zNKZDabrV0mAKADsIkwQZJmz54tg8Ggb775RkuXLm38g7CgoEBPPPGETCaTJkyYoD59+jS5bty4cRo3bpxWr17d5PiqVau0aNEiFRYWnvWs+Ph4PfDAAzKZTOrbt6+GDRvW5PyECRMUFRWl8vJy/eEPf1B5ebmk0zMY3nrrLe3YsUMuLi667777WvNfAQAAQIsEdXXTrCl99fJDI3TVoGDZGQ06dOyEXvtst15cnKjdaUWECgCAS2Iw29CfJAsXLtQrr7wis9msoKAgeXt7Ky0tTbW1tYqIiNCSJUvk4+PT5JqoqChJ0ssvv6xbbrmlyb1efvllSafXR/D19ZXZbFZOTo5KS0slSb169dIHH3zQuEbCz6Wnp2vGjBkqLi6Wq6urIiIilJeXp+LiYjk4OOiNN97QxIkTL/kzNzSYVFJSecn3aUv29kZ5e7uptLSywywmgrZFz8BS9AwsRc80VVJ2SqsTsvTDnlzV/fffR6i/u6aMCldslJ+MBoOVK7Q+egaWomdgCVvqFx8ft46zm8MZM2fOVFRUlObPn6/k5GQVFxcrODhYkyZN0oMPPig3t5ZvhTRhwgTV1NRo+/btSk9PV1pamurr6+Xt7a2xY8fqmmuu0dSpU+Xo6Njs9REREVq+fLnee+89bdy4UampqfL09NS1116rhx9+WH379m2tjw0AAHBJfDyddefE3po8Klxrt2fp+6QcZRVU6N2v9ymoq6umjAzXsL7+sjPazKRVAICV2dTMhM6ImQnoiOgZWIqegaXomfOrqK7T+p3HtH5ntqpq6iVJ/l1cdP3IMI3qHyj7FvxEqqOhZ2ApegaWsKV+6ZAzEwAAAHDp3F0cdNMVPXTN0FBtTMrWmu3HVHCiWgtXHdTyLem6bniYrogJkqODnbVLBQC0U4QJAAAAnZSrs70mjwzXhLju+mF3jlZtz1JJWY0+WZeqFVszdO2wUF01OFjOjnzLCABoij8ZAAAAOjknRztdMyxUV8eG6Kfk4/ouPlPFZTVatjFN38VnauLQ7hof202uznzrCAA4jT8RAAAAIElysLfT1bHddMXAYG3bn6eV2zJVUFqtr348qtUJWRof100Th3STh2vzC1QDADoPwgQAAAA0YW9n1BUxwRrVP1A7DhZo5dZM5RRVasXWDK3bcUxXDw7RtcO6y8vdydqlAgCshDABAAAAzbIzGjWib6CGRQcoKbVIK7ZmKDO/XKu3Z2nDrmyNjQnWdSNC5ePpbO1SAQCXGWECAAAAzstoMCguyk+xvX2192iJvt2ariM5ZdqwK1ubdudo9IBAXT8iTP7ertYuFQBwmRAmAAAAoEUMBoNienbVgB4+OphZqm+3Zuhg1gn9uOe4fkrO0/C+AZo8MkzBvm7WLhUA0MYIEwAAAGARg8Gg6HAfRYf76HD2Ca3Ymqm9R4u1bX+e4vfnKa6Pv6aMDFNogIe1SwUAtBHCBAAAAFy0yG5d9PtpXZSRV6YVWzO1K7VQOw8WaOfBAg3q5avJo8LUM9jL2mUCAFoZYQIAAAAuWXigpx69ZYCyCyu0clumtqfka3dakXanFalfuLemjApXVKi3tcsEALQSwgQAAAC0mm5+7nroxn6aOiZC323L1Lb9edqfUar9GaXq3c1LU0aHq1+4jwwGg7VLBQBcAsIEAAAAtLpAH1fdNzlaN44O16qELG1OzlVq9km9vnSPIoI8NGVUuAb18iVUAAAbRZgAAACANuPbxUV3XxulKaPCtWZ7ljYl5Sj9eLne/mKvuvm5a8qoMA2J8pfRSKgAALaEMAEAAABtztvDSbePj9T1I8K0bucxbUjMVnZhhf75zX4F+qRr8sgwjegXIDuj0dqlAgBagK/WAAAAuGw83Rx165U99ersUZo6JkJuzvbKK6nSRytT9NS/4vXD7hzV1ZusXSYA4AKYmQAAAIDLzs3ZQVPHROiaod21MSlHa7ZnqejkKX28+pCWb8nQdcNDNXZgsBwd7KxdKgCgGYQJAAAAsBoXJ3tdPyJM4+O66cfduVqVkKnS8hotWX9YK7Zm6NrhobpqUIhcnPi2FQDaE74qAwAAwOqcHOw0cWh3XTU4RFv2Htd38ZkqOnlKn288ou+2ZWri0O6aENdNrs4O1i4VACDCBAAAALQjDvZGXTU4RGNigpRwIF8rtmUqv6RKX29O15rtWRoX200Th3aXp6ujtUsFgE6NMAEAAADtjr2dUaMHBGlkv0DtPFSgb7dmKKewUiu3ZWrdzmO6alCIJg0PVRd3J2uXCgCdEmECAAAA2i2j0aBh0QEa0sdfew4X6dutGcrIK9faHcf0/a4cXTEwSNcND5Wvl4u1SwWAToUwAQAAAO2e0WDQ4N5+GhTpq/3pJVq+NUNp2Se1cVeOftydq5H9AzV5ZJgCvF2tXSoAdAqECQAAALAZBoNB/Xt0Vb8IHx3KOqFvt2YoJbNUPyUf15a9xzW8b4AmjwxXiK+btUsFgA6NMAEAAAA2x2AwqE+Yt/qEeSst56RWbM1Q8pFixe/PV/z+fMVF+WnKyHCFBXpYu1QA6JAIEwAAAGDTeoV46fFfDVRmXrlWbMtQ4qHCxl8xPbtqyqhw9QrxsnaZANChECYAAACgQwgL9NBvbh6gnMIKrYzPVMKBfCUfKVbykWJFh3nrhlHhigrtIoPB0OQ6k8mslIwS1aWXysFgVs9gLxmNhnM8BQAgESYAAACggwnxc9eDN/TT1DER+m5bprbuy1NKZqlSMkvVq5uXbhgVrv4RPjIYDEo8VKAl6w+rtLym8XpvDyfdOSFScVH+VvwUANC+Gcxms9naReDcGhpMKimptHYZ52Vvb5S3t5tKSytVX2+ydjmwAfQMLEXPwFL0DH6u6GS1Vidk6cc9x1XfcLofwgI91DfMW6sSss553W9u7k+ggHPi6wwsYUv94uPjJjs74wXHXXgEAAAAYMN8vVx01zVR+tsjI3XtsO5ydDAqM6/8vEGCJH26/rBMJn7uBgDNIUwAAABAp9DF3UnTx0Xq1UdGaUS/gAuOLymvUeqxE21fGADYIMIEAAAAdCoero6K6dm1RWNPVNRceBAAdEIswAgAAIBOp4ubU4vGffb9YaUfL1dsb19FduvCLg8A8F+ECQAAAOh0enfvIm8Ppya7ODSnrLJO63Ye07qdx+Tu4qBBkb6KjfRTvwhvOdjbXaZqAaD9IUwAAABAp2M0GnTnhEi989W+c4558Ma+crS3U1JqoXanFamiuk4/JR/XT8nH5eRgpwE9fBTb208xPbvK1dnhMlYPANZHmAAAAIBOKS7KX7+5ub+WrD/cZIaCj4eT7pgQ2bgtZGxvPzWYTErNOqFdqUXadbhQpeU12nmoUDsPFcrOaFCfMG/F9vbT4EhfdXFv2SsUAGDLDGazmf1u2rGGBpNKSiqtXcZ52dKeqWgf6BlYip6BpegZWMJkMutI7knVmQ1yMJjVM9jrvGsjmM1mZeSVa1dqoXalFup4cVWT8z2DPRXb20+xvf0U4OPa1uXDSvg6A0vYUr/4+LjJzu7CezUwMwEAAACdmtFoUHS4T4u/0TcYDIoI8lREkKduvbKnjhdXKulwkXalFupobpmO/PfX55uOKMTXTYN7+yq2t5/CAjxkMLCAI4COgTABAAAAuARBXd0U1NVN148IU2l5jXYfPj1j4WDWCeUUVSqnqFIrtmbKx9NJgyNPz1jo3d1LdkZ2aQdguwgTAAAAgFbi7eGkq2O76erYbqo8VafkI8XalVqovUeLVVJWow2J2dqQmC13FwcN7NX1vztD+MjRgZ0hANgWwgQAAACgDbg5O2hkv0CN7Beo2roG7c8oUVJqUePOEFv25mnL3jw5Ohg1IKLr6Z0henWVGztDALABhAkAAABAG3N0sNPgSD8Njjy9M8ThYye1K7VQSYcLVVxWo8TUQiWmnt4ZIiq0y393hvCTtwc7QwBonwgTAAAAgMvIzmhUnzBv9Qnz1h0TIpWVX6HE/wYLOYWVOpBRqgMZpfr32lRFBHkq9r8LOAZ1dbN26QDQiDABAAAAsBKDwaCwQA+FBXrolrE9lF9SpV3/XcDxaE6Z0o+f/vXFD0cV1NW1ccvJ8EB2hgBgXYQJAAAAQDsR4OOq64aH6brhYTpRUaPd/91yMiWzVMeLq7RyW6ZWbsuUt4eTYiP9NLi3r3p37yL7FuwJDwCtyebChPj4eC1YsEB79uxRVVWVgoODNWnSJD344INydXVt8X0aGhoUHx+vTZs2KSkpSRkZGTp16pS6dOmiAQMGaPr06brqqquavTY7O1vjx48/7/0HDhyoZcuWWfLRAAAAgEZd3J101eAQXTU4RFWn6pV8tEi7Uou090ixSstrtGFXtjbsypabs70G9vLV4Eg/9e/hIyd2hgBwGdhUmLB48WK9+OKLMpvNCgwMVFBQkNLS0vTee+9p7dq1WrJkibp06dKie3355Zf6y1/+IkkyGo0KDQ2Vm5ubMjMz9f333+v777/X9OnT9dxzz513CllsbGyzxyMjIy3+fAAAAEBzXJ3tNaJvoEb0DVRdfYP2Z5QqKbVQu9OKVF5Vp6378rR1X54c7Y3qF+Gj2N5+GtjLV+4u7AwBoG3YTJiwb98+vfTSS5KkefPmadq0aTIYDMrPz9cjjzyi/fv3a86cOXr77bdbfM+oqCjdfffdmjRpkjw8PCRJ9fX1+vjjj/Xqq69q6dKl6tOnj+68885z3uPTTz+9tA8GAAAAWMDB3k6DevlqUC9fmUxmHc4+oaT/vg5RdPKUkg4XKelwkYyGn+8M4SsfT2drlw6gAzGYzWaztYtoidmzZ2vDhg266aab9Ne//rXJuYyMDF133XUymUz65ptv1KdPnwve78SJE/Ly8jrnrIM5c+Zo2bJl6tOnj7755psm537+msOhQ4cu8hO1TEODSSUllW36jEtlb2+Ut7ebSksrVV9vsnY5sAH0DCxFz8BS9Aws1RF6xmw261hBhXalFmpXapGyCyuanA8P9GhcwDHYl50hLlVH6BlcPrbULz4+brJrwTosNjEzobKyUps3b5YkTZs27azz4eHhGjFihLZu3arVq1e3KEy40OsQY8eO1bJly5Senn5RNQMAAACXk8FgUGiAh0IDPHTTFT1UUFqlXalFSjpcqLTsk8rIK1dGXrm+/PGoAn1cNfi/W05GBHnKyM4QACxkE2FCSkqKamtr5ejoqJiYmGbHxMXFaevWrdqzZ0+rPPPUqVOSJBcXl/OOe+GFF3T06FEZDAaFhIRozJgxmjBhgoxGVtQFAACA9fh7u2rS8FBNGh6qk5W12n349IyFlMwS5ZVUaVV8llbFZ6mLu6MGR56esRAVys4QAFrGJsKEM7MDgoOD5eDQ/CIyoaGhTcZeqpUrV0o6HVKcz+LFi5v8funSpYqOjtbbb7+t7t27t0otAAAAwKXwcnPUlYNCdOWgEFXX1Gvv0WLtSi1U8pFinaio1cakHG1MypGrk71ienVVbKSfBvToKidHdoYA0DybCBNOnjwpSfLy8jrnmDPnzoy9FOvXr9fGjRtlMBh0//33n3Xe3t5eN954oyZPnqxevXrJ399fpaWl+uGHH/Tmm28qJSVFs2bN0pdffil3d/dLrsfevn2nw2fep2nJezWARM/AcvQMLEXPwFKdqWc87B01akCQRg0IUl29SQcySpR4qFC7UgtVVlmr+P35it+fLwd7o/r38FFcb38N7u0rD1dHa5fernSmnsGl64j9YhNhQk1NjSSdc1aCJDk6OjYZe7GOHDmiJ598UpJ07733Nrv1Y2BgoF599dUmxwICAjRt2jQNHz5ct9xyizIzM7Vo0SLNnj37kuoxGg3y9raNBXI8Pc//SgjwS/QMLEXPwFL0DCzVGXvG389DVw0NU4PJrEOZJdq297ji9x1XXnGVklKLlJRaJKNB6tfDVyMGBGpE/yD5e7tau+x2ozP2DC5eR+oXmwgTnJycJEl1dXXnHFNbW9tk7MU4fvy47r//fpWXl+vKK6/UH/7wB4vvERYWpjvuuEMffPCB1q1bd8lhgslkVllZ1SXdo63Z2Rnl6emisrJqNTS075VJ0T7QM7AUPQNL0TOwFD1zWlAXZ91yRYRuHhN+emeIQ4XaeahAWfkV2nukSHuPFOmDr/cpPNBDcVF+iuvjrxBft3PukNaR0TOwhC31i6enS8fZzaElrzC05FWI8yksLNTMmTOVm5urYcOG6e233z7vTIjzGTx4sKTTW1a2hva+dcgZDQ0mm6kV7QM9A0vRM7AUPQNL0TP/J7irm4JHuWnKqHAVnqhWUmqhdh0u0uHsE407Q3zxw1H5e7s0bjnZI7jz7QxBz8ASHalfbCJMCA8PlyTl5uaqrq6u2b/kZ2VlNRlrieLiYt17773KyMjQ4MGD9c9//vOSZjicqa+hoeGi7wEAAAC0F35dXHTNsFBdMyxUZZW12p1WpF2phTqQUaqC0mqtTsjS6oQsebk5anDk6S0n+4R5szME0IHZRJgQHR0tBwcH1dbWKjk5udkdFhITEyVJgwYNsujeJ06c0K9//WsdOXJE/fr10wcffCA3t0tbo+Dw4cOSTq+tAAAAAHQknm6OGjswWGMHBqu6pl770kv+uzNEkU5W1mrT7lxt2p0rFyd7DezZVYN7+2lADx85O9rEXz0AtJBN/D/a3d1dY8aM0caNG7Vs2bKzwoSMjAzFx8dLkiZNmtTi+1ZUVOi+++7ToUOH1Lt3b3300Ufy8PC4pForKyu1ZMkSSdLo0aMv6V4AAABAe+biZK+hffw1tI+/6htMOphZql2phUo6fDpYiD+Qr/gD+bK3M6pfuLcG9/bToEhfebIzBGDzbCJMkKTZs2dr06ZN+uabbxQbG6tp06bJYDCooKBATzzxhEwmkyZMmKA+ffo0uW7cuHGSpD/+8Y9Ngobq6mo9+OCD2r9/v3r06KGFCxfK29u7RbXMmTNHV1xxha666qrGXSSk0ztB/OUvf1F2drZcXV01a9asVvjkAAAAQPtnb2dU/x5d1b9HV911rVlHc8u0K/X0lpMFpdXac6RYe44Uy7BaiuzW5fQ6C5G+8u3ScVa3BzoTmwkTYmJi9OSTT+qVV17R3Llz9d5778nb21tpaWmqra1VRESEnn/++bOuy8nJkSRVVTXdEWHRokWNr0ZI0qOPPnrOZ//jH/+Qn59f4++Tk5O1bNkyOTg4KDQ0VO7u7iotLW1ct8HLy0tvvvmmunXrdkmfGQAAALBFRoNBvUK81CvES7+6qqdyiipPL+CYWqTM/HKlHjuh1GMn9NmGwwr1d1dsbz8N7u2nbn6dc2cIwBbZTJggSTNnzlRUVJTmz5+v5ORkFRcXKzg4WJMmTdKDDz5o0VoHZ7aSlKSjR4+ed2xNTU2T3z/00EPavHmz9u3bp6KiImVmZsrZ2Vn9+vXT2LFjNWPGjCbhAwAAANBZGQwGdfNzVzc/d90wOkJFJ6uVlFqkpMOFOnTshLIKKpRVUKGvf0qXXxfnxp0hegZ7yWgkWADaK4PZbDZbuwicW0ODSSUlldYu47zs7Y3y9nZTaWllh9nmBG2LnoGl6BlYip6BpegZ6yivOr0zRFJqkfZnlKjuZ//uPd0cNajX6Z0hosO85WDfvnaGoGdgCVvqFx8fN9m1YCcWm5qZAAAAAKDj8HB11BUxwboiJlinauu172iJkg4Xak9ascoqa/Xjnlz9uCdXzo52iunZVbG9/TSgR1e5OPHXGMDa+H8hAAAAAKtzdrTXkD7+GvLfnSEOZZ04vYDj4UKdrKjV9pQCbU8pkL2dQdFhPort7atBkX7ycmNnCMAaCBMAAAAAtCv2dkb1i/BRvwgfzbimt9KPn9kZokj5JVXae7RYe48Wa9HqQ+rVzUuDI/0UG+Unf3aGAC4bwgQAAAAA7ZbRYFDPYC/1DPbSbVf21PHiqsYtJzPyynU4+6QOZ5/Uso1p6ubnrtjep9dZ6O7vzs4QQBsiTAAAAABgEwwGg4J93RTs66Ypo8JVUnZKSYeLtCu1UIeyTii7sELZhRVaviVDvl7/tzNErxB2hgBaG2ECAAAAAJvk4+ms8XHdND6umyqq67Qn7XSwsD+9REUnT2ntjmNau+OYPFwdGneG6BvuLQd7O2uXDtg8wgQAAAAANs/dxUGjBwRp9IAg1dQ1aN/REu1KLVTykf/f3r1HR1Wf+x//zCSTkPs9gQRCQswkXAwkUcCK2EYUOFpLLUKVHkRUPCLqWcrvSM8BT1uPhVZPj4oVratcSkVBf0vpT2ug3FqKcovhnkASkkAukBshN8jkMr8/QqbkhEsmJExm8n6txVqZ2Xt/59nJ43bnyXd/nwrVNjRp56FS7TxUKk8PN906LEQp5lAlDQuV9wB+JQK6g/9yAAAAALgUT5ObUhPClJoQpuaWVp043dYZIjOnQudqG7U/u0z7s8vkZjRo+NAgpZjDlBwfqgBfT0eHDjgNigkAAAAAXJa7m1EjYoI1IiZYs+41q+BMrW0Bx9LKBh3Jr9KR/Cqt3XRccVEBSr60gGNEkLejQwf6NIoJAAAAAPoFg8Gg2EH+ih3krx/dHafSynpby8n80hrlFp9XbvF5fbI9T1FhPkqJb1vAMTqCzhDA/0YxAQAAAEC/NCjER/ff4aP774jRudpGZeaU2zpDFJfXq7i8Xv/v6wKF+A9om7EQH6b4IQFyMxodHTrgcBQTAAAAAPR7QX6eSksZrLSUwaq/2KRDuZX69kS5DudXqrLmorbsL9KW/UXy9WrrDHH78HDdmTLA0WEDDkMxAQAAAAAu4zPApDtGDdQdowaqsalFx/Kr9G1OuQ7kVKjuQpP+frhUfz9cqhWfH9Gtw0I0Jj5Uo+NC5D3A5OjQgZuGYgIAAAAAXIWnyU3J5jAlm8PU0tqqE6fPX+oMUa6qmkbtyy7TvkudIRKjA5ViDtOY+DAF+dEZAq6NYgIAAAAAdIGb0ajhQ4M0fGiQZk9JUFV9s7bvK1TG8XIVV9TraME5HS04p7WbTygu0l/J5rYFHAcG0xkCrodiAgAAAADYyWAw6JYhgQrxNWnaXcN0tqqhrTNETrnyimuUV9L279MdeYoM9VFyfFvLyZiBfnSGgEugmAAAAAAANygi2FtTxw/V1PFDVV3XqMycCn17olzZhedUUlGvkop6fflNoYL9PZV8qeWkmc4QcGIUEwAAAACgBwX6eup7yVH6XnKUGi426VDepc4QJ6tUVdOorRlF2ppRJJ8B7hpzS9uMhRGxwfI0uTk6dKDLKCYAAAAAQC/xHmDS+JEDNX7kQFmaWnSs8Jy+PfGPzhC7jpzRriNn5GEyalRsiFLMoUqKC5WvF50h0LdRTAAAAACAm8DD5KYxt4RqzC2hamltVW7ReX17ou1xiMqai21rLpwol9FgUMKlzhApZjpDoG+imAAAAAAAN5mb0aiE6CAlRAfpx/fcolNn65SZ01ZMKCqvV1bhOWUVntOHfzmh2EF+tsLCoBAfR4cOSKKYAAAAAAAOZTAYNHSgn4YO9GvrDHGuQZmXZizkFZ9Xfmmt8ktr9X//elKDQrxtCzjGDPKTkc4QcBCKCQAAAADQh0QEeWvKuGhNGRet83WNysxtKyxkFZxTaWWDSisL9efdhQry81RyfKiSzWFKGBIodzc6Q+DmoZgAAAAAAH1UgK+nvjsmSt8dE6ULjc22zhCHTlbqXG2jtn1brG3fFstngLuS4kKVYg7VqNgQeXrQGQK9i2ICAAAAADgBL093jRsRoXEjItTU3KKsS50hMnMqVNvQpG+OntE3R8/Iw92okbHBSjGHafQtdIZA76CYAAAAAABOxuTupqS4tjaSsydblVt83tYNouL8RWXmVCgzp0JGg0HmIQG2BRyD/Qc4OnS4CIoJAAAAAODEjEaDzEMCZR4SqJlpt+h0WZ1txsLpsjpln6pW9qlqrduSo6ED/9EZIjLEWwYWcEQ3UUwAAAAAABdhMBgUHeGn6Ii2zhBl1ReUeaJcmSfKlVN0XoVnalV4plaf/e2kIoK9lRIfqhRzmGIj/ekMAbtQTAAAAAAAFxUe6KXJY6M1eWy0auotOnCpM8SxgiqdrWrQV3tO6as9pxTg63Gp5WSoEqOD6AyB66KYAAAAAAD9gL+PhyaOjtTE0ZG60NiswycvdYbIq9T5Oot2ZBZrR2axvDzdNfqWEKXEh2nUsGAN8ODXRnRGVgAAAABAP+Pl6a6xwyM0dniEmppblX3qH50hauot2n30rHYfPSuTu1EjY4KVbA7VmFtC5eft4ejQ0UdQTAAAAACAfszkbtStw0J067AQ/fN9Vp0sqbF1hiirvqADuRU6kFshg0EyDw5UijlMyeZQhQZ4OTp0OBDFBAAAAACApLbOELcMDtAtgwP08PfiVFxer29z2goLp87W6fjpah0/Xa2PtuYoOsLX1hkiKtSHzhD9DMUEAAAAAEAnBoNBg8N9NTjcVw/eGauK6gvKzGlbwPFEUbVOna3TqbN1+nxnvsIDvWyFhWFRdIboDygmAAAAAACuKzTQS/fePkT33j5ENQ0WHcypUGZOhY7kV6ms+oLS955S+t5TCvDxUHJ8qJLNYRo+lM4QropiAgAAAADALv7eHrprdKTuGh2pi5ZmHTlZpW9PlOtgXqXO11u040CJdhwokZenm5LiQpUcH6pbh4XIy5NfQV0FP0kAAAAAQLcN8HDXbYnhui0xXM0t7Z0hKpSZU67zdRbtOXZWe46dlbubUSNigpRiDtOYW0Ll70NnCGdGMQEAAAAA0CPc3YwaFRuiUbEh+sl9ZuVf1hni7LkLOpRXqUN5lTIYpPiogEudIcIUFkhnCGdDMQEAAAAA0OOMBoPiogIUFxWg6d+NU0llg62wUHimVieKzutE0Xl9vC1XQ8L/0RlicBidIZwBxQQAAAAAQK8yGAyKCvVRVKiPvv+dGFWev6jMSy0nT5w+r9NldTpdVqeNf89XWOAAJce3FRZuiQqQ0UhhoS+imAAAAAAAuKlCAgZo0m1DNOm2Iaq70KQDOW1rLBzJr1J59UVt3ndam/edlr+3SWPiQ5ViDtPwocEyudMZoq+gmAAAAAAAcBhfL5MmJA3ShKRBarS06Eh+ZVtniNxK1TQ06W8HS/W3g6Xy9HBT0rAQpZjDlBRHZwhH47sPAAAAAOgTPD3clJoQrtSEts4Qx09X69sT5co8Ua7qOov2ZZdpX3aZ3N0MGj40WCnmUI2JD1MAnSFuOooJAAAAAIA+x93NqJExwRoZE6xZ95pVUFprW8DxTFWDDp+s1OGTlfpD+nHFDQ5QSnyYUsyhCg/ydnTo/YLTFRN2796tVatW6eDBg2poaFBkZKSmTJmiefPmydu760nT0tKi3bt3a8eOHcrMzFRBQYEuXryowMBA3XrrrZo5c6a++93vXnOMyspKrVixQtu3b1dZWZn8/f11++236+mnn9bw4cNv8EwBAAAAAFJbZ4hhkf4aFumv6d+NU2llva2wkF9aq9yi88otOq8N23M1OMzH1hliSLgvnSF6icFqtVodHURXrV27Vq+99pqsVqsGDhyo4OBg5ebmymKxKC4uTuvWrVNgYGCXxvrkk0+0ePFiSZLRaFR0dLR8fHxUWFiouro6SdLMmTP185///IrJV1hYqEcffVQVFRXy9vZWbGyszpw5o8rKSplMJr311lu65557bvicW1paVVVVf8Pj9CZ3d6OCgnx07ly9mptbHR0OnAA5A3uRM7AXOQN7kTOwFznTd1TVXFRmToW+PVGu46eq1XrZr7ihAe2dIUIVPzjQYZ0hnClfgoN95OZ2/YUunWZmwpEjR/TLX/5SkvSLX/xCM2bMkMFg0NmzZ/XMM8/o6NGjWrJkiZYvX97lMRMSEvTP//zPmjJlivz8/CRJzc3NWrNmjV5//XWtX79eiYmJevTRRzscZ7Va9cILL6iiokJ33XWX/ud//kd+fn5qbm7Wb3/7W7377rtauHChNm3apPDw8J77JgAAAAAAOgj2H6B7UgfrntTBqrvQpEN5Ffr2RIWOnKxUxfmL+sv+0/rL/tPy9fpHZ4iRMUEyubs5OnSn5jQzE+bPn6+tW7dq2rRp+tWvftVhW0FBgaZOnarW1lZt3LhRiYmJ1x2vurpaAQEBV53ysmTJEm3YsEGJiYnauHFjh21btmzRs88+Kz8/P23dulUBAQEdtv/kJz/Rvn379Pjjj2vRokV2nmlHzEyAKyJnYC9yBvYiZ2Avcgb2Imf6vsamFh3Nr1LmiXIdyK1Q/cVm2zZPDzfdOixEKfGhSooLlfeA3v07uzPlS1dnJjhFk876+nrt3LlTkjRjxoxO22NiYjR+/HhJUnp6epfGDAwMvOazMxMnTpQk5efnd9r21VdfSZKmTJnSqZBweYzt+wEAAAAAbi5Pk5tSzGF64oERevP5Cfo/Px6je1IHK8jPU42WFu3PLtPv/t8xvfD2Tv1m/QFtzyxWdV2jo8N2Gk7xmENWVpYsFos8PDyUlJR0xX1SU1P19ddf6+DBgz3ymRcvXpQkeXl5ddrW/hm33XbbFY9tf//MmTM6e/asIiIieiQmAAAAAID93IxGDY8J1vCYYD06KV4FZ9o6Q2TmVKikol5H8qt0JL9Kf9x0XMOi/C91hghTRDCdIa7GKYoJ7bMDIiMjZTKZrrhPdHR0h31v1JdffimprUhxOYvFouLi4g6f+b8NGjRIJpNJTU1NOnnyJMUEAAAAAOgjDAaDYgf5K3aQv350d5zOVDXYOkOcLKlRXnHbv0925Ckq1EfJ5jClmsMUHUFniMs5RTHh/PnzknTFRwratW9r3/dGbNmyRdu3b5fBYNCTTz7ZYVtdXZ1aW1uvGY/BYJC/v78qKytVU1Nzw/G4u/ftp1Han6fpynM1gETOwH7kDOxFzsBe5AzsRc64jsHhvhoc7qsHJ8TqXG2jvj1RrozsMmUVnlNxRb2KK+r1xdcFCvEfoNSEMKUmhMkcHSg3Y9d/9q6YL05RTGhsbHtu5WqzEiTJw8Ojw77dlZeXZ1s08bHHHlNKSsoVY7n8M68VT/vjEt1lNBoUFORzQ2PcLP7+nR8JAa6FnIG9yBnYi5yBvcgZ2IuccS1BQT4aFh2s6ZMSVNdg0f6ss/rmSKkysstUWXNRm/ed1uZ9p+Xn7aGxIyN0x6hBGpMQLk/T1TtDtLRadexkpapyKxXsP0AjhoXIzUEtKnuSUxQTPD09JUlNTU1X3cdisXTYtztKS0v15JNPqra2VnfffbcWLlx41Vgu/8xrxTNgwIBuxyNJra1W1dQ03NAYvc3NzSh/fy/V1FxQS0vfXpkUfQM5A3uRM7AXOQN7kTOwFznTP4weFqzRw4JlmZqoo/lV2n+8TJknKlTbYNHWfae1dd9peZiMSooLUWpCuMbcEiofr3/8EXxfdpk+3HRcVbX/+KN0sJ+nZk1O0O2J4Y44pevy9/fq0gwKpygmdOURhq48CnEt5eXlmjNnjkpKSjR27FgtX778ijMhfH19ZTQa1draetV4rFar7fEGf3//bsVzub7eOqRdS0ur08SKvoGcgb3IGdiLnIG9yBnYi5zpH4wGg24dFqJbh4Vo9uRW5Zw+r29zypV5olyVNY3an12u/dnlcjMalBAdqBRzmNyMRq1Jz+40VlVto5Z/ekjP/nCUUhP6ZkGhK5yimBATEyNJKikpUVNT0xV/yT916lSHfe1RWVmpxx57TAUFBUpOTtZ777131RkOHh4eioyMVFFRkU6dOtXpMQipbYZD+yyK2NhYu+MBAAAAAPRNbkajEocGKXFokB65J16nztYp40S5MnPKVVxer2MF53Ss4Nx1x/loS46S48NkdNJHHpxi9Yfhw4fLZDLJYrHo0KFDV9wnIyNDkjRmzBi7xq6urtbjjz+uvLw8jRw5Uh988IF8fK69RkH7Z+zfv/+K29vfHzhwoAYOHGhXPAAAAAAA52AwGDR0oJ8emjhMrz4xTkvnjdfD34tTZOj1W0pW1TbqxOnq3g+ylzhFMcHX11cTJkyQJG3YsKHT9oKCAu3evVuSNGXKlC6PW1dXp7lz5+r48eMym836/e9/Lz8/v+seN3nyZElSenr6FR91aI/RnlgAAAAAAM4tIthbU8cN1QPfienS/tX1N9ZAwJGcopggSfPnz5fBYNDGjRu1fv16Wa1WSVJZWZlefPFFtba2atKkSUpMTOxwXFpamtLS0pSent7h/QsXLmjevHk6evSohg0bptWrVysoKKhLsUyaNEkJCQmqra3VwoULVVtbK0lqaWnRW2+9pX379snLy0tz587tgTMHAAAAADiTQJ+uNQbo6n59kVOsmSBJSUlJWrRokZYtW6ZXXnlFK1asUFBQkHJzc2WxWBQbG6tXX32103HFxcWSpIaGjh0R/vCHP9gejZCkBQsWXPWz3377bYWFhdleG41GvfXWW5o1a5b+9re/aeLEiYqNjdWZM2dUWVkpk8mk119/XRERETd62gAAAAAAJ2MeEqggP0+dq736zINgP0+ZhwTevKB6mNMUEyRpzpw5SkhI0MqVK3Xo0CFVVlYqMjJSU6ZM0bx586671sHlLm/rePLkyWvu29jYOQFiY2P1pz/9SStWrND27dt14sQJ+fv7a/LkyfqXf/kXjRgxousnBgAAAABwGUajQY9OitdvPzty1X0emRTvtIsvSpLB2v68APqklpZWVVXVOzqMa3J3NyooyEfnztXTFgddQs7AXuQM7EXOwF7kDOxFzqArMo6Xad2WnA4zFIL9PPXIpPg+2xYyONhHbm7XXxHBqWYmAAAAAADgLFITwpUcH6a8kvNqshpkMlgVFxng1DMS2lFMAAAAAACglxiNBg2PCXa5mSxO080BAAAAAAD0DRQTAAAAAACAXSgmAAAAAAAAu1BMAAAAAAAAdqGYAAAAAAAA7EIxAQAAAAAA2IViAgAAAAAAsAvFBAAAAAAAYBeKCQAAAAAAwC4UEwAAAAAAgF0oJgAAAAAAALtQTAAAAAAAAHahmAAAAAAAAOxisFqtVkcHgauzWq1qbe37PyI3N6NaWlodHQacCDkDe5EzsBc5A3uRM7AXOQN7OEu+GI0GGQyG6+5HMQEAAAAAANiFxxwAAAAAAIBdKCYAAAAAAAC7UEwAAAAAAAB2oZgAAAAAAADsQjEBAAAAAADYhWICAAAAAACwC8UEAAAAAABgF4oJAAAAAADALhQTAAAAAACAXSgmAAAAAAAAu1BMAAAAAAAAdqGYAAAAAAAA7EIxAQAAAAAA2IViAgAAAAAAsIu7owNA37J7926tWrVKBw8eVENDgyIjIzVlyhTNmzdP3t7e3Rpz06ZN+uMf/6js7Gw1NTVp6NChevDBBzV79myZTKYePgPcbD2ZM4sWLdJnn312zX0++OADTZw48UZChoOUl5dr165dOnLkiA4fPqysrCw1NjZq7NixWrt27Q2N3RvXLjheb+TM8uXL9c4771xzn5/97Gd65JFHujU+HMdqtSozM1Pbtm1TRkaGTp48qbq6Ovn5+WnEiBGaNm2avv/978tgMHRrfO5nXE9v5Qz3M67tq6++0tdff62jR4+qrKxM1dXVMplMiomJ0d13363HHntMQUFB3Rrb2a4zFBNgs3btWr322muyWq0aOHCgBg0apNzcXK1YsUKbN2/WunXrFBgYaNeYv/rVr7Ry5UpJUnR0tLy8vJSTk6Nf//rX2r59u1auXCkPD49eOBvcDL2RM5I0aNAgDRo06IrbAgICbjBqOMqXX36ppUuX9vi4vZWHcLzeyhlJCgkJ0dChQ6+4LSwsrFc+E71r9+7dmjNnju31kCFDFBUVpeLiYu3atUu7du3Sl19+qeXLl9t978H9jGvqzZyRuJ9xVe+9956ys7Pl4eGhsLAwJSQkqKqqSseOHdOxY8e0YcMGrVy5UomJiXaN65TXGStgtVoPHz5sTUxMtCYkJFg//vhja2trq9VqtVrPnDlj/eEPf2g1m83WBQsW2DXm5s2brWaz2Tpq1Cjrli1bbO/n5uZa09LSrGaz2bp06dIePQ/cPL2RMy+//LLVbDZb33777d4IGQ72ySefWOfMmWP97//+b+vmzZutb775ptVsNlt/8pOfdHvM3shD9B29kTNvv/221Ww2W19++eUejBR9wa5du6xpaWnWNWvWWCsqKjps++yzz6yjRo2yms1m669//Wu7xuV+xnX1Vs5wP+Pa1q9fb927d6/VYrF0eD87O9v6wAMPWM1ms/Wf/umf7BrTWa8zrJkASdK7776r1tZW/eAHP9DMmTNt07kiIiL0m9/8RkajUZs3b1Z2dnaXx2yfRvrUU0/pnnvusb0fFxen//qv/5Ikffjhh6qqqurBM8HN0hs5A9c2ffp0rVq1Si+++KLuvfdehYSE3PCY5KFr642cgetKSkpSenq6Zs+e3SlXpk2bpmeffVaS9Omnn6q1tbXL43I/47p6K2fg2mbMmKHbb7+902MHCQkJeu211yRJubm5ysvL6/KYznqdoZgA1dfXa+fOnZLa/uP432JiYjR+/HhJUnp6epfGLCgosN28z5w5s9P2O+64Q0OHDpXFYtHWrVu7GzocpDdyBrAXeQjgcr6+vtd8prj9+fTq6uou35BzP+PaeiNn0L8NGzbM9vWFCxe6dIwzX2dYMwHKysqSxWKRh4eHkpKSrrhPamqqvv76ax08eLBLYx44cEBS27NnERERVx2zsLBQBw8e1MMPP9yt2OEYvZEzl9uzZ49ycnJUXV0tf39/jRw5Ug8++KCioqJuNHS4kN7OQ7i27OxsvfTSSyovL5ePj48SEhJ0//33Kz4+3tGhoZdcvHjR9vWAAQO6dAz3M/1bd3LmctzP9D8ZGRmSJG9vb8XGxnbpGGe+zlBMgPLz8yVJkZGRV63ORkdHd9j3egoKCjoc1xNjou/ojZy53L59+zq8/stf/qLf/va3euGFF/TUU0/ZPR5cU2/nIVxbVlaWsrKybK+3bdum9957T7Nnz9bLL78sNzc3B0aH3vDll19KkhITE+Xr69ulY7if6d+6kzOX436mf2htbbV1H3rjjTckSQsXLpSPj0+Xjnfm6wzFBOj8+fOSrr2qbPu29n17csyampoujYm+ozdyRpKGDh2qRYsWafz48YqKipKHh4eOHz+ulStXKj09XW+88Ya8vb01a9asGzsBuITeykO4tvDwcD3//PO66667NHjwYPn6+io/P1/r1q3Txx9/rDVr1sjd3V3/9m//5uhQ0YOOHDmijz/+WJI0b968Lh/H/Uz/1d2ckbif6S9Wr17dqeNQUlKSli1bZlfbT2e+zrBmAtTY2ChJ13xmrL0NSfu+PTnm5VPI4Bx6I2ck6ZlnntHjjz+u4cOHy9/fXwMGDNDo0aP11ltv6dFHH5Ukvfnmm6qvr7+B6OEqeisP4dpmzpypZ599VklJSQoODpaHh4cSEhL085//XAsXLpQkrVmzRkVFRQ6OFD2loqJCzz33nJqbm3Xvvffq/vvv7/Kx3M/0TzeSMxL3M/1FRESEUlJSNHr0aIWFhclgMCgrK0sbN26065d+Z77OUEyAPD09JUlNTU1X3cdisXTYtyfH7M4zaHCs3siZ63nxxRdlMplUU1Oj3bt398iYcG6OyEO4trlz5yo8PFzNzc3atm2bo8NBD6itrdVTTz2lkpISjRw5UsuWLbPreO5n+p8bzZnr4X7GdUydOlUfffSRNmzYoL///e/6/PPPNXr0aH3xxReaPXu2WlpaujSOM19nKCagS9OAuzL95nL+/v5dHrN9XziP3siZ6/Hz87MtjFZYWNgjY8K5OSIP4drc3Nw0evRoSVxnXEF9fb2efPJJHTt2TPHx8fr9739v93Pv3M/0Lz2RM9fD/YzrSkxM1Pvvv6+goCBlZWXZ1ty4Hme+zlBMgGJiYiRJJSUlV62InTp1qsO+19O+eum1LpL2jom+ozdypivap381Nzf32JhwXo7KQ7g2rjOu4cKFC3r66ad14MABxcTEaNWqVQoKCrJ7HO5n+o+eypmu4Drjunx9fTV27FhJ0tGjR7t0jDNfZygmQMOHD5fJZJLFYtGhQ4euuE97m5MxY8Z0acz2v+wUFRXp7NmzPTIm+o7eyJnraW5u1smTJyVJAwcO7JEx4dwckYdwfTk5OZK4zjizxsZGPfPMM9q3b5+ioqK0evVqhYWFdWss7mf6h57Mmevhfsb1tReJuvqYgzNfZygmQL6+vpowYYIkacOGDZ22FxQU2J7pmjJlSpfGjI2NldlsliStX7++0/ZvvvlGhYWFMplMuueee7obOhykN3LmetavX6/a2lq5u7tr/PjxPTImnJsj8hCubceOHbZiwp133ungaNAdTU1Neu655/TNN98oIiJCa9as0aBBg7o9Hvczrq+nc+Z6uJ9xbdXV1dq7d6+ktj96dIUzX2coJkCSNH/+fBkMBm3cuFHr16+X1WqVJJWVlenFF19Ua2urJk2apMTExA7HpaWlKS0tTenp6Z3GXLBggSTpgw8+6LCQ1cmTJ7V48WJJ0qOPPqrg4ODeOi30op7OmV27dun111+39dptZ7FYtHbtWlvrnR//+McKDw/vvRNDn/PII48oLS1Nq1ev7rStu3kI13a1nMnJydErr7yi7OzsDu+3trbqiy++0EsvvSRJ+t73vqekpKSbFS56SEtLi1566SX99a9/VVhYmNasWaMhQ4Z06VjuZ/qn3sgZ7mdc2969e/Xuu+9esePP0aNH9cQTT6i2tlYRERGd/pDhitcZg7X9zgv93urVq7Vs2TJZrVYNGjRIQUFBys3NlcViUWxsrNatW9cpgRMSEiRJS5cu1UMPPdRpzF/+8pdas2aNJCk6Olre3t7KyclRS0uLUlNTtWrVKlZZd2I9mTNbtmzRs88+K0kKDQ1VRESEJCk/P18NDQ2SpMmTJ+uNN96wtceBcyktLdW0adNsry0WixoaGuTu7t5hgasnn3xSTz31lO11WlqaiouLtWDBAj333HOdxu1OHsI59HTOZGVl2cYLDAxUZGSk3NzcdOrUKdviVrfddptWrFjR5xa5wvVdXhCKioqy/X/kSpYsWaIRI0bYXnM/0z/1Rs5wP+PaLv/5hoWFKTw8XG5ubiotLVV5ebmktpaR77//fqeZCa54nXF3dADoO+bMmaOEhAStXLlShw4dUmVlpSIjIzVlyhTNmzdPPj4+do/57//+70pOTta6deuUlZWlsrIyxcXF6cEHH9ScOXOu2U8VfV9P5szIkSM1f/58HThwQIWFhcrPz1dTU5OCg4M1YcIE/fCHP1RaWlovng16W0tLi6qrqzu939zc3OF9e3so98a1C31DT+dMVFSU/vVf/1UHDhxQXl6eCgsLZbFYFBAQoIkTJ+qBBx7QAw88IDc3tx46A9xM7a3TJKm4uFjFxcVX3be2ttausbmfcU29kTPcz7i25ORk/fSnP9WePXuUm5urgoICWSwW+fv7a9y4cUpLS9P06dO71QXEGa8zzEwAAAAAAAB2Yc0EAAAAAABgF4oJAAAAAADALhQTAAAAAACAXSgmAAAAAAAAu1BMAAAAAAAAdqGYAAAAAAAA7EIxAQAAAAAA2IViAgAAAAAAsAvFBAAAAAAAYBeKCQAAAN2QkJCghIQE7dmzx9GhAABw07k7OgAAAOAali9frnfeeafL+x8/frwXowEAAL2JYgIAAOhxoaGhjg4BAAD0IooJAACgx+3atcvRIQAAgF7EmgkAAAAAAMAuzEwAAAAOl5aWpuLiYi1dulT33Xef3n//fW3evFmlpaXy8vJSamqqnn76aY0ePfqqY7S0tOizzz7Tn/70Jx0/flz19fUKCgpScnKyZs2apXHjxl0zhtLSUq1du1a7du1SUVGRmpqaFB4ervj4eE2ePFlTp06Vp6fnFY+tq6vTBx98oE2bNqmkpEReXl4aM2aM5s+ff82YAQBwVhQTAABAn1FTU6Pp06crPz9fJpNJnp6eqq6u1tatW7V9+3a9+uqrmj59eqfjamtrNX/+fO3du1eS5ObmJh8fH5WXl2vTpk3atGmT5s6dq5dffvmKn/v555/rlVdeUWNjoyTJZDLJx8dHpaWlOn36tLZt26aEhAQNHz6807Hl5eV66KGHVFhYKE9PTxmNRlVXV2vHjh3atWuX3nvvPU2YMKEHv0sAADgejzkAAIA+45133lFVVZXefPNNHThwQBkZGfrzn/+ssWPHqrW1Vf/5n/+po0ePdjruP/7jP7R3716ZTCYtXrxYGRkZ2rdvn3bu3Kkf/ehHkqSVK1fqo48+6nTsjh07tGjRIjU2NiolJUUffvihDh06pD179igzM1MffvihZsyYIZPJdMWYf/GLX8hkMmnNmjU6cOCAMjMz9cknnyg2NlZNTU165ZVX1Nra2rPfKAAAHMxgtVqtjg4CAAA4v8tbQ16vm8PUqVO1ePFi2+v2xxwkafXq1brjjjs67H/x4kX94Ac/UEFBge6++2797ne/s207ePCgZsyYIantF/uZM2d2+rznn39emzZtUlBQkP7617/aHldobm7W5MmTVVRUpNTUVK1evVoeHh5dOt+EhARJUnBwsL744guFhIR02H78+HE9+OCDkqR169YpNTW1S+MCAOAMmJkAAAB6XEVFxTX/1dXVXfG4lJSUToUESRowYICeeOIJSdLOnTtVW1tr2/bnP/9ZkjRw4EA9/PDDVxz3hRdekCSdO3euQ6eJPXv2qKioSJL005/+tMuFhMvNmDGjUyFBais2DB48WFJbYQEAAFfCmgkAAKDHdfeX5/Hjx193W2trq44ePWp7feTIEUnSuHHjZDRe+e8kcXFxioiI0NmzZ3XkyBGlpaVJkjIzMyVJYWFhuvXWW7sV87UWWAwPD1dRUZHOnz/frbEBAOirmJkAAAD6jIiIiC5tq6qqsn1dWVl53WOltpkLl+8vtS2eKEmRkZH2B3uJj4/PVbe5u7f93aa5ubnb4wMA0BdRTAAAAP2WwWBwdAgAADgligkAAKDPOHv2bJe2BQcH275uX6/gzJkz1xy7ffvl6xu0LxRZUlJif7AAAPRjFBMAAECfsWfPnutuMxqNGjFihO39UaNG2bZfrQVjXl6erRhx+doIKSkpktoedzh8+PCNBQ8AQD9CMQEAAPQZGRkZVywoNDY2auXKlZKkCRMmyN/f37bt/vvvl9Q2c+GTTz654rhvv/22JCkoKEjf+c53bO+PGzdOQ4YMkSQtXbpUFoulZ04EAAAXRzEBAAD0GX5+fnr++eeVnp5uW7QwLy9P8+bN08mTJ+Xm5qbnn3++wzFJSUmaPHmyJOnVV1/VH//4R124cEFS24yDxYsXKz09XVJbi0hPT0/bsW5ublqyZIkMBoMyMjI0Z84c7d+/3zbDwWKxaM+ePVq4cKFyc3N7/fwBAHAWtIYEAAA97s4777zuPsuXL7c9ZtBuwYIF+vjjj/XCCy/Iw8NDnp6eqq2tldS2WOLPfvazK7ZwfO2113Tu3Dnt3btXr776qpYuXSofHx/V1NTIarVKkubOnatHHnmk07F33323li1bpiVLligjI0OzZs2Sh4eHvL29VVdXZytqPPHEE3Z/HwAAcFUUEwAAQI+rqKi47j5NTU2d3vP399enn36q999/X5s3b1ZpaakCAwOVnJysp59+WsnJyVccy8/PT6tXr9Znn32mjRs36vjx42poaFBoaKhSUlI0a9YsjRs37qqxTJs2Tbfddpv+8Ic/aNeuXSopKVFjY6MiIyNlNpt13333KS4uruvfAAAAXJzB2l6uBwAAcJC0tDQVFxdr6dKleuihhxwdDgAAuA7WTAAAAAAAAHahmAAAAAAAAOxCMQEAAAAAANiFYgIAAAAAALALCzACAAAAAAC7MDMBAAAAAADYhWICAAAAAACwC8UEAAAAAABgF4oJAAAAAADALhQTAAAAAACAXSgmAAAAAAAAu1BMAAAAAAAAdqGYAAAAAAAA7EIxAQAAAAAA2OX/A5jd29kKCdXSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1ee69c-b284-4176-bb22-5e3a0c889547"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f559e16-06e9-4089-b581-585bbad1b00d"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dc9fcc-4d4f-4f19-e320-048cd42d1e41"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2f2922-718d-4d58-b8a5-d4abfb2e409b"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4814027d-9229-442e-bbe6-1fb4a2fda6f3"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.21713222235566895),\n",
              " 0.0,\n",
              " np.float64(0.4857959309463206),\n",
              " np.float64(0.4127594582445936),\n",
              " np.float64(0.21867346044008387),\n",
              " np.float64(0.7562449037944323),\n",
              " np.float64(0.29277002188455997),\n",
              " 0.0,\n",
              " np.float64(0.9165151389911681),\n",
              " np.float64(0.6659416347320276),\n",
              " np.float64(0.8459051693633014),\n",
              " np.float64(0.647150228929434),\n",
              " np.float64(0.7562449037944323),\n",
              " np.float64(0.6753002216523571),\n",
              " np.float64(0.30261376633440124),\n",
              " np.float64(0.41281272698065485),\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cb4a9c-9438-4193-8f2d-b1959e191b7a"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 코드"
      ],
      "metadata": {
        "id": "xd5BzXwU8HM1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef71888e-2981-4b2d-eed5-3b9ba92a6a01"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# 1. 모델 및 토크나이저 로드 (예: 'bert-base-uncased' 사용)\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()               # GPU로 이동\n",
        "model.eval()               # 평가 모드로 전환\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# 2. 추론할 영어 문장 예시\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "\n",
        "# 3. 문장 토큰화 및 인코딩\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,      # [CLS]와 [SEP] 토큰 추가\n",
        "    max_length=10,                # 최대 길이 설정\n",
        "    padding=\"max_length\",         # 최대 길이에 맞춰 패딩\n",
        "    truncation=True,              # 길면 잘라냄\n",
        "    return_tensors=\"pt\"           # 파이토치 텐서 반환\n",
        ")\n",
        "\n",
        "# 4. 텐서를 GPU로 이동\n",
        "inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "\n",
        "# 5. 추론 (forward pass)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs[0]  # 모델의 출력은 튜플이며, 첫 번째 요소가 로짓입니다.\n",
        "\n",
        "# 6. Softmax 적용 (선택 사항) 및 예측 클래스 결정\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "# 7. 결과 출력\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", predicted_class.item())\n",
        "print(\"예측 확률:\", probs)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 1\n",
            "예측 확률: tensor([[0.3839, 0.6161]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    입력된 문장에 대해 학습된 모델을 사용하여 예측을 수행합니다.\n",
        "    Returns:\n",
        "        predicted_class: 예측된 클래스 (예: 0 또는 1)\n",
        "        probs: 각 클래스의 확률 (numpy 배열)\n",
        "    \"\"\"\n",
        "    # 문장을 토큰화하고 encode_plus를 통해 [CLS], [SEP] 토큰을 추가하며, 패딩/자르기 적용\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,      # [CLS]와 [SEP] 추가\n",
        "        max_length=max_length,        # 최대 길이\n",
        "        padding=\"max_length\",         # 최대 길이에 맞게 패딩\n",
        "        truncation=True,              # 길면 자르기\n",
        "        return_tensors=\"pt\"           # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # GPU로 텐서를 전송\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # 모델을 평가 모드로 전환하고, 추론 시에는 기울기를 계산하지 않도록 설정\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # 모델의 출력은 튜플 형태로, 첫 번째 요소가 logits입니다.\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 사용\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PITHYJKhPHD",
        "outputId": "e4be73f8-1241-4124-f9f7-a4b1838a8781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 1\n",
            "예측 확률: [[0.49480566 0.50519437]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic 코드"
      ],
      "metadata": {
        "id": "oK0EdSFZjeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    결과는 원본 형태 (1, 12, 10, 10)로 반환\n",
        "    \"\"\"\n",
        "    if isinstance(attention_scores, torch.Tensor):\n",
        "        attention_scores = attention_scores.detach().cpu().numpy()  # ✅ detach() 추가\n",
        "\n",
        "    batch_size, num_heads, seq_length, _ = attention_scores.shape\n",
        "    result_arrays = np.zeros((batch_size, num_heads, seq_length, seq_length))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        for row in range(seq_length):\n",
        "            for col in range(seq_length // 10):\n",
        "                input_values = attention_scores[0, head, row, col * 10:(col + 1) * 10]\n",
        "                result = top(*input_values)\n",
        "                result_arrays[0, head, row, col * 10:(col + 1) * 10] = result\n",
        "\n",
        "    # ✅ numpy -> torch 변환할 때 `.to(device)` 추가\n",
        "    return torch.tensor(result_arrays, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 정수부는 7비트 (Signed, 2의 보수)\n",
        "    - 소수부는 13비트 (항상 양수)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ PyTorch Tensor 처리\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        value = value.detach().cpu().numpy()\n",
        "\n",
        "    # ✅ NaN 또는 Inf 값 체크 후 예외 처리\n",
        "    if np.isnan(value) or np.isinf(value):\n",
        "        raise ValueError(f\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\")\n",
        "\n",
        "    # ✅ **최대/최소 값 제한 (7비트 표현 범위)**\n",
        "    value = max(min(value, 63), -64)\n",
        "\n",
        "    # ✅ 정수부와 소수부 분리\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수 부분\n",
        "\n",
        "    # ✅ 2의 보수 변환 (음수 처리)\n",
        "    if int_part < 0:\n",
        "        int_part = (1 << int_bits) + int_part\n",
        "\n",
        "    int_binary = format(int_part, f'0{int_bits}b')\n",
        "\n",
        "    # ✅ 12비트 0 추가 (BERT 출력 형식 유지)\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트)\n",
        "    frac_binary = \"\"\n",
        "    for _ in range(frac_bits):\n",
        "        frac_part *= 2\n",
        "        if frac_part >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_part -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 문자열 생성\n",
        "    binary_string = int_binary + frac_binary\n",
        "\n",
        "    # ✅ `binary_string`이 음수 값을 포함하는지 확인 후 처리\n",
        "    if \"-\" in binary_string:\n",
        "        raise ValueError(f\"[ERROR] 잘못된 바이너리 문자열 변환 감지: {binary_string}\")\n",
        "\n",
        "    # ✅ 20비트 정수 변환 (부호 처리)\n",
        "    fixed_binary = int(binary_string, 2)\n",
        "    if value < 0:\n",
        "        fixed_binary = (1 << 20) - fixed_binary  # 2의 보수 변환\n",
        "\n",
        "    lower_20_bits = fixed_binary & 0xFFFFF  # 20비트 마스킹\n",
        "\n",
        "    return lower_20_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    \"\"\"\n",
        "    2의 보수 표현된 이진수를 정수로 변환하는 함수.\n",
        "    \"\"\"\n",
        "    # ✅ \"0b\" 제거\n",
        "    binary_str = binary_str.replace(\"0b\", \"\")\n",
        "\n",
        "    # ✅ 이진수 길이 확인\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # ✅ 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 변환 (음수)\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JuXVpD_Fjj7q",
        "outputId": "66db6f5b-007b-4f4d-dc20-8826b8f1ac41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0528564453125,\n",
              " 0.0977783203125,\n",
              " 0.0128173828125,\n",
              " 0.0438232421875,\n",
              " 0.3963623046875,\n",
              " 0.0980224609375,\n",
              " 0.0552978515625,\n",
              " 0.0140380859375,\n",
              " 0.0599365234375,\n",
              " 0.1666259765625)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 수정 및 적용 코드"
      ],
      "metadata": {
        "id": "o19OXrVjjoaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "scMdkDy7tAqU",
        "outputId": "4412745e-fa12-4532-e28a-94361b424f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassificationModified(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Softmax 대신 CORDIC을 적용\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "XySJ0nStsisx"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # 여기서 원래 softmax를 적용하는 대신 CORDIC 기반 함수를 사용합니다.\n",
        "        # 예를 들어, top_1200_input(attention_scores)를 사용하여 softmax 결과를 근사합니다.\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        # 만약 반환된 결과가 numpy 형태라면, torch.tensor로 변환해주어야 합니다.\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 원래 출력은 (context_layer, attention_probs) 또는 (context_layer,)인데,\n",
        "        # 필요에 따라 raw attention scores도 반환하도록 할 수 있습니다.\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "# 만약 학습된 가중치를 로드해야 한다면 로드합니다.\n",
        "# model.load_state_dict(torch.load(\"your_checkpoint.pt\"), strict=False)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# 이제 이 모델은 CoLA나 다른 영어 문장 분류 작업에 사용할 수 있습니다.\n",
        "# 예시 추론 함수:\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 문장으로 테스트\n",
        "sentence = \"This is a grammatically acceptable for sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "itlqawMcjmJ3",
        "outputId": "cf03d6cb-9b2e-4b3a-afd2-56c513147bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is a grammatically acceptable for sentence.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.51398903 0.48601103]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 encoder 내 각 레이어의 self-attention 모듈 타입을 출력하여\n",
        "# 수정된 BertSelfAttentionModified가 적용되었는지 확인합니다.\n",
        "print(\"수정된 Attention Layers 확인:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn_layer = layer.attention.self\n",
        "    print(f\"Layer {i} self-attention layer type: {type(attn_layer)}\")\n"
      ],
      "metadata": {
        "id": "8WUtGKLuoW2z",
        "outputId": "e36c3321-4bd7-4371-f983-d799fd05c5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정된 Attention Layers 확인:\n",
            "Layer 0 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 1 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 2 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 3 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 4 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 5 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 6 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 7 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 8 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 9 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 10 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 11 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디버깅용 잡동사니코드"
      ],
      "metadata": {
        "id": "H5iP5hhyJuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # ✅ 디버깅용 Q, K 체크\n",
        "        with torch.no_grad():\n",
        "            h = hidden_states.detach().cpu().numpy()\n",
        "            print(\"=== Hidden States 디버깅 ===\")\n",
        "            print(\"min:\", np.min(h), \"max:\", np.max(h))\n",
        "            print(\"NaN 수:\", np.isnan(h).sum(), \"Inf 수:\", np.isinf(h).sum())\n",
        "            q = query_layer.detach().cpu().numpy()\n",
        "            k = key_layer.detach().cpu().numpy()\n",
        "            print(\"=== Q, K 디버깅 ===\")\n",
        "            print(\"Q min/max:\", np.min(q), np.max(q))\n",
        "            print(\"K min/max:\", np.min(k), np.max(k))\n",
        "            print(\"Q NaN 수:\", np.isnan(q).sum(), \"K NaN 수:\", np.isnan(k).sum())\n",
        "            print(\"Q Inf 수:\", np.isinf(q).sum(), \"K Inf 수:\", np.isinf(k).sum())\n",
        "\n",
        "        # attention score 계산 후 clamp\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 계산 직후 ===\")\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item(), \"Inf 수:\", torch.isinf(attention_scores).sum().item())\n",
        "        attention_scores = torch.clamp(attention_scores, min=-10.0, max=10.0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 예시 ===\")\n",
        "            print(attention_scores[0, 0, 0, :10])\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item())\n",
        "        # CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "\n",
        "# 2. BertLayerWithNaNCheck: layer 0 내부 모듈 NaN 추적\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n",
        "\n",
        "\n",
        "# 3. BertEncoderModified\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "        self.layer[0] = BertLayerWithNaNCheck(self.layer[0])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_values=None, use_cache=False, output_attentions=False,\n",
        "                output_hidden_states=False, return_dict=True):\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            with torch.no_grad():\n",
        "                hs = hidden_states.detach().cpu().numpy()\n",
        "                if np.isnan(hs).sum() > 0:\n",
        "                    print(f\"[NaN DETECTED] ❌ in hidden_states BEFORE layer {i}\")\n",
        "                else:\n",
        "                    print(f\"[OK] ✅ hidden_states BEFORE layer {i}\")\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask[i] if head_mask is not None else None,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_values[i] if past_key_values is not None else None,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "        return (hidden_states,)\n",
        "\n",
        "\n",
        "# 4. BertWithModifiedAttentionForClassification\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 5. Load config and model\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dTD-BGlHKAh5",
        "outputId": "383af56c-e173-4f09-db40-610c833f616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayerWithNaNCheck(\n",
              "          (layer): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttentionModified(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_class = np.argmax(probs)\n",
        "\n",
        "    return pred_class, probs\n"
      ],
      "metadata": {
        "id": "sgc6czs9DqMM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_nan(module, input, output):\n",
        "    if isinstance(output, torch.Tensor):\n",
        "        if torch.isnan(output).any():\n",
        "            print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "    elif isinstance(output, (tuple, list)):\n",
        "        for o in output:\n",
        "            if torch.is_tensor(o) and torch.isnan(o).any():\n",
        "                print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    module.register_forward_hook(check_for_nan)\n"
      ],
      "metadata": {
        "id": "2QHFLakIFV8P"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        # Attention\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        # Intermediate\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        # Output\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n"
      ],
      "metadata": {
        "id": "gAA7SyorIaZv"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sentence = \"The cat is sitting on the mat.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "\n",
        "print(\"문장:\", sentence)\n",
        "print(\"예측 클래스:\", pred_class)\n",
        "print(\"클래스별 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "yv0VeRUlDpLp",
        "outputId": "1cd74ea5-ca18-4524-d57c-bed12d1b5f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ✅ hidden_states BEFORE layer 0\n",
            "=== [Layer 0] BEFORE ===\n",
            "min: -4.571415901184082 max: 3.8990025520324707\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Hidden States 디버깅 ===\n",
            "min: -4.571416 max: 3.8990026\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: -2.1867194 2.275151\n",
            "K min/max: -2.4105966 2.2897592\n",
            "Q NaN 수: 0 K NaN 수: 0\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([ 0.4173, -0.1602, -0.0771,  0.3595,  0.1112, -0.1229, -0.2256, -0.0283,\n",
            "        -0.1147, -0.0984], device='cuda:0')\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0\n",
            "[NaN DETECTED] ❌ after Attention in Layer 0\n",
            "[NaN DETECTED] ❌ after Intermediate in Layer 0\n",
            "[NaN DETECTED] ❌ after Output in Layer 0\n",
            "=== [Layer 0] AFTER ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "[NaN DETECTED] ❌ in hidden_states BEFORE layer 1\n",
            "=== Hidden States 디버깅 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: nan nan\n",
            "K min/max: nan nan\n",
            "Q NaN 수: 49152 K NaN 수: 49152\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
            "min: nan max: nan\n",
            "NaN 수: 49152\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8b7cffed0231>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The cat is sitting on the mat.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-c78350183b4c>\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(model, tokenizer, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[OK] ✅ hidden_states BEFORE layer {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN 수:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적용 모델 validation"
      ],
      "metadata": {
        "id": "JSRL23_d7voR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "h4m08g6HohMF",
        "outputId": "f747f4b3-303a-4ba6-bc0d-053e10605c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-e22c35b96d8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The documentation for this `model` function is here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-6e3b41572d66>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcordic_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg-qog2IyzCc",
        "outputId": "84868b88-7f46-4258-8f8c-8f39d188821e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장 및 로드 코드.\n",
        "path = '/content/model/'\n",
        "torch.save(model.state_dict(), path+\"CoLA.pt\")\n",
        "model.load_state_dict(torch.load(path+\"CoLA.pt\"))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6f3ddQs0x7V-",
        "outputId": "917276df-e585-497f-b9f8-9b06944ce3af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}