{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yi-juho/-K_MHAS-_HuggingFace_dataset_MultiBERT_shared/blob/main/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification BERT [CoLA]\n",
        "\n",
        "*   항목 추가\n",
        "*   항목 추가\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SGcOaw5P769d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg-qog2IyzCc",
        "outputId": "a5577caa-baea-4fb0-9f03-7b1caae01b21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic"
      ],
      "metadata": {
        "id": "x6iTkvfbQ6Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores, dim=-1):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    \"\"\"\n",
        "    chunk_size = len(attention_scores) // dim\n",
        "    data_list = [attention_scores[i * chunk_size:(i + 1) * chunk_size] for i in range(120)]\n",
        "\n",
        "    # 120개의 결과 리스트 생성\n",
        "    result_arrays = []\n",
        "\n",
        "    # 각 10개씩 top 함수에 전달\n",
        "    for i in range(120):\n",
        "        result = top(*data_list[i])  # 리스트를 개별 인자로 풀어서 전달\n",
        "        result_arrays.append(result)  # 결과 저장\n",
        "\n",
        "    return result_arrays\n",
        "\n",
        "\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 31~20 비트: 항상 0 (상위 12비트)\n",
        "    - 19~13 비트: 정수부 (7비트, Signed, 2의 보수)\n",
        "    - 12~0 비트: 소수부 (13비트, 항상 양수)\n",
        "\n",
        "    정수부는 내림하여 변환하고, 소수부를 정확한 2진 변환 방식으로 변환.\n",
        "    \"\"\"\n",
        "    max_frac_value = 2**frac_bits  # 13비트 소수부 정밀도 (8192)\n",
        "\n",
        "    # ✅ 1. 정수부와 소수부 정확하게 분리 (내림 적용)\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수부 절댓값 유지\n",
        "\n",
        "    # ✅ 2. 정수부(7비트) 변환 (2의 보수 변환)\n",
        "    if int_part < 0:\n",
        "        int_binary = format((1 << int_bits) + int_part, f'0{int_bits}b')  # 7비트 2의 보수 변환\n",
        "    else:\n",
        "        int_binary = format(int_part, f'0{int_bits}b')  # 7비트 양수 표현\n",
        "\n",
        "    # ✅ 3. 앞 12비트는 항상 0으로 유지\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 4. 소수부 변환 (부동소수점 오차 최소화)\n",
        "    frac_binary = \"\"\n",
        "    frac_value = frac_part  # 소수부 값 유지\n",
        "    for _ in range(frac_bits):  # 13비트 반복\n",
        "        frac_value *= 2\n",
        "        if frac_value >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_value -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 5. 최종 32비트 바이너리 생성\n",
        "    fixed_binary = int_binary + frac_binary\n",
        "    fixed_binary_int = int(fixed_binary, 2)\n",
        "    lower_20_bits = fixed_binary_int & 0xFFFFF\n",
        "    return lower_20_bits\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "        #print(int_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "   #return int_values\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    # 이진수의 길이\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 방법으로 음수 변환\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수는 그냥 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "        #print(hex(exp_fraction[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "'''\n",
        "top(\n",
        "    0b00000011000110001110,  # 첫 번째 data_in 값\n",
        "    0b00000100010011110000,  # 두 번째 data_in 값\n",
        "    0b00000000010011111010,  # 세 번째 data_in 값\n",
        "    0b00000010101101111100,  # 네 번째 data_in 값\n",
        "    0b00000111000110011000,  # 다섯 번째 data_in 값\n",
        "    0b00000100010100001101,  # 여섯 번째 data_in 값\n",
        "    0b11111100110100100011,  # 일곱 번째 data_in 값\n",
        "    0b11111111100000001011,  # 여덟 번째 data_in 값\n",
        "    0b00000011010101100100,  # 아홉 번째 data_in 값\n",
        "    0b11111010100111110111   # 열 번째 data_in 값\n",
        ")\n",
        "'''\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ✅ 기존 Softmax -> Sigmoid Normalization 적용\n",
        "        attention_probs = top(attention_scores)\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "HM1AXhHcQ04X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구조 적용,, 재시작"
      ],
      "metadata": {
        "id": "eA7KlC3ftQ-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) Query/Key/Value 계산 (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) Attention score 계산 & scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # ---------------------------------------------------\n",
        "        # 3) CORDIC-Softmax: top()을 120번 자동 호출\n",
        "        #    attention_scores.shape == [B, H, L, L] with L=10\n",
        "        # ---------------------------------------------------\n",
        "        B, H, L, _ = attention_scores.size()             # B=1, H=12, L=10\n",
        "        flat = attention_scores.view(-1, L)              # shape = [B*H, 10]\n",
        "        rows = []\n",
        "        for row in flat:                                 # 자동으로 1*12 = 12 행 × 10 쿼리 = 120 호출\n",
        "            # row.tolist() → Python float 리스트 길이 10\n",
        "            top_out = top(*row.tolist())                 # 여러분의 top(data1…data10)\n",
        "            # 다시 tensor 로 만들 때, dtype/device 일치시키기\n",
        "            rows.append(torch.tensor(\n",
        "                top_out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "        attention_probs = torch.stack(rows)              # shape = [B*H, 10]\n",
        "        attention_probs = attention_probs.view(B, H, L, L)\n",
        "        # ---------------------------------------------------\n",
        "\n",
        "        # 4) Dropout & Context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "zfSHmJVQtUqh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention\n",
        "\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self,\n",
        "                hidden_states,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_attention_mask=None,\n",
        "                past_key_value=None,\n",
        "                output_attentions=False):\n",
        "\n",
        "        # 1) query/key/value (원본과 동일)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        key_layer   = self.transpose_for_scores(\n",
        "                          self.key(encoder_hidden_states\n",
        "                                   if encoder_hidden_states is not None\n",
        "                                   else hidden_states)\n",
        "                      )\n",
        "        value_layer = self.transpose_for_scores(\n",
        "                          self.value(encoder_hidden_states\n",
        "                                     if encoder_hidden_states is not None\n",
        "                                     else hidden_states)\n",
        "                      )\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # 2) 스코어 계산 및 scaling\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2)\n",
        "        ) / (self.attention_head_size ** 0.5)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # 3) CORDIC-Softmax 교체\n",
        "\n",
        "        B, H, L, _ = attention_scores.size()           # e.g. 1,12,10,10\n",
        "        flat = attention_scores.view(-1, L)            # [B*H, L]\n",
        "        rows = []\n",
        "\n",
        "        for row in flat:\n",
        "            # (1) 안정화: max 빼기\n",
        "            row = row - row.max()\n",
        "            # (2) 정수부 범위 클램핑 (–63.999 ~ +63.999)\n",
        "            row = row.clamp(min=-63.999, max=63.999)\n",
        "            # (3) Python float 리스트로 변환 → top()\n",
        "            out = top(*row.tolist())\n",
        "            # (4) 다시 tensor 생성\n",
        "            rows.append(torch.tensor(\n",
        "                out,\n",
        "                dtype=attention_scores.dtype,\n",
        "                device=attention_scores.device\n",
        "            ))\n",
        "\n",
        "        attention_probs = torch.stack(rows).view(B, H, L, L)\n",
        "        # ─────────────────────────────────────────────\n",
        "\n",
        "        # 4) dropout & context 계산 (원본과 동일)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) \\\n",
        "                  if output_attentions else (context_layer,)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "JxoOuCl6wyU6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = model.config\n",
        "for layer in model.bert.encoder.layer:\n",
        "    orig = layer.attention.self\n",
        "    # Modified 모듈 생성\n",
        "    mod = BertSelfAttentionModified(config)\n",
        "    # 기존 가중치 로드\n",
        "    mod.load_state_dict(orig.state_dict(), strict=False)\n",
        "\n",
        "    mod.to(device)\n",
        "    # 교체\n",
        "    layer.attention.self = mod\n"
      ],
      "metadata": {
        "id": "peAPhZdDvZzN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn = layer.attention.self\n",
        "    print(f\"Layer {idx:2d}: {attn.__class__.__name__:<30} (module: {attn.__class__.__module__})\")\n",
        "\n",
        "print(\"모델 클래스:\", model.__class__.__name__)\n",
        "# → BertForSequenceClassificationCordic 이어야 함\n",
        "\n",
        "# 2) forward 메서드가 서브클래스에서 정의된 것인지 확인\n",
        "print(\"forward 메서드 qualname:\", model.forward.__qualname__)\n",
        "# → BertForSequenceClassificationCordic.forward 여야 함\n",
        "\n",
        "# 3) 실제 forward 소스 코드 출력\n",
        "source = inspect.getsource(model.__class__.forward)\n",
        "print(\"\\n----- forward 소스 -----\\n\", source)"
      ],
      "metadata": {
        "id": "huL4Du0TtzwD",
        "outputId": "df92579b-a669-4ca1-c1ce-3ddb3b0a77d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer  0: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  1: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  2: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  3: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  4: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  5: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  6: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  7: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  8: BertSelfAttentionModified      (module: __main__)\n",
            "Layer  9: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 10: BertSelfAttentionModified      (module: __main__)\n",
            "Layer 11: BertSelfAttentionModified      (module: __main__)\n",
            "모델 클래스: BertForSequenceClassification\n",
            "forward 메서드 qualname: BertForSequenceClassification.forward\n",
            "\n",
            "----- forward 소스 -----\n",
            "     @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
            "    @add_code_sample_docstrings(\n",
            "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
            "        output_type=SequenceClassifierOutput,\n",
            "        config_class=_CONFIG_FOR_DOC,\n",
            "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
            "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
            "    )\n",
            "    def forward(\n",
            "        self,\n",
            "        input_ids: Optional[torch.Tensor] = None,\n",
            "        attention_mask: Optional[torch.Tensor] = None,\n",
            "        token_type_ids: Optional[torch.Tensor] = None,\n",
            "        position_ids: Optional[torch.Tensor] = None,\n",
            "        head_mask: Optional[torch.Tensor] = None,\n",
            "        inputs_embeds: Optional[torch.Tensor] = None,\n",
            "        labels: Optional[torch.Tensor] = None,\n",
            "        output_attentions: Optional[bool] = None,\n",
            "        output_hidden_states: Optional[bool] = None,\n",
            "        return_dict: Optional[bool] = None,\n",
            "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
            "        r\"\"\"\n",
            "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
            "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
            "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
            "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
            "        \"\"\"\n",
            "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
            "\n",
            "        outputs = self.bert(\n",
            "            input_ids,\n",
            "            attention_mask=attention_mask,\n",
            "            token_type_ids=token_type_ids,\n",
            "            position_ids=position_ids,\n",
            "            head_mask=head_mask,\n",
            "            inputs_embeds=inputs_embeds,\n",
            "            output_attentions=output_attentions,\n",
            "            output_hidden_states=output_hidden_states,\n",
            "            return_dict=return_dict,\n",
            "        )\n",
            "\n",
            "        pooled_output = outputs[1]\n",
            "\n",
            "        pooled_output = self.dropout(pooled_output)\n",
            "        logits = self.classifier(pooled_output)\n",
            "\n",
            "        loss = None\n",
            "        if labels is not None:\n",
            "            if self.config.problem_type is None:\n",
            "                if self.num_labels == 1:\n",
            "                    self.config.problem_type = \"regression\"\n",
            "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
            "                    self.config.problem_type = \"single_label_classification\"\n",
            "                else:\n",
            "                    self.config.problem_type = \"multi_label_classification\"\n",
            "\n",
            "            if self.config.problem_type == \"regression\":\n",
            "                loss_fct = MSELoss()\n",
            "                if self.num_labels == 1:\n",
            "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
            "                else:\n",
            "                    loss = loss_fct(logits, labels)\n",
            "            elif self.config.problem_type == \"single_label_classification\":\n",
            "                loss_fct = CrossEntropyLoss()\n",
            "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
            "            elif self.config.problem_type == \"multi_label_classification\":\n",
            "                loss_fct = BCEWithLogitsLoss()\n",
            "                loss = loss_fct(logits, labels)\n",
            "        if not return_dict:\n",
            "            output = (logits,) + outputs[2:]\n",
            "            return ((loss,) + output) if loss is not None else output\n",
            "\n",
            "        return SequenceClassifierOutput(\n",
            "            loss=loss,\n",
            "            logits=logits,\n",
            "            hidden_states=outputs.hidden_states,\n",
            "            attentions=outputs.attentions,\n",
            "        )\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        b_input_ids,\n",
        "        attention_mask=b_input_mask,\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "# 2) 튜플에서 마지막 레이어 확률만 꺼내기\n",
        "all_attentions = outputs.attentions    # tuple of length 12, each is [B, H, L, L]\n",
        "attention_probs = all_attentions[-1]   # 마지막 레이어의 [B, H, L, L] 텐서\n",
        "\n",
        "# 3) 마지막 축(키 방향)으로 합이 1인지 확인\n",
        "sums = attention_probs.sum(dim=-1)     # shape = [B, H, L]\n",
        "print(\"어텐션 확률 합:\", sums)\n"
      ],
      "metadata": {
        "id": "m2Fs1SMmxKoy",
        "outputId": "b602bff1-524c-4db8-90bb-8fa5cf7df73a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어텐션 확률 합: tensor([[[0.9946, 0.9958, 0.9958, 0.9941, 0.9922, 0.9954, 0.9941, 0.9961,\n",
            "          0.9978, 0.9983],\n",
            "         [0.9995, 0.9968, 0.9932, 0.9983, 0.9985, 1.0005, 0.9978, 0.9941,\n",
            "          0.9973, 0.9998],\n",
            "         [0.9995, 0.9946, 0.9949, 0.9966, 0.9951, 0.9998, 0.9990, 0.9944,\n",
            "          0.9929, 0.9944],\n",
            "         [0.9988, 0.9980, 0.9973, 0.9958, 0.9937, 0.9995, 1.0002, 0.9915,\n",
            "          0.9878, 0.9946],\n",
            "         [0.9976, 0.9963, 0.9976, 0.9954, 0.9944, 0.9958, 0.9917, 0.9980,\n",
            "          0.9976, 0.9919],\n",
            "         [0.9954, 1.0005, 0.9932, 0.9929, 0.9961, 0.9954, 0.9927, 0.9919,\n",
            "          0.9968, 0.9915],\n",
            "         [0.9954, 0.9951, 0.9995, 0.9980, 0.9980, 0.9939, 0.9968, 0.9929,\n",
            "          0.9971, 0.9929],\n",
            "         [0.9932, 0.9973, 0.9983, 0.9934, 1.0029, 0.9990, 1.0000, 0.9939,\n",
            "          0.9973, 0.9990],\n",
            "         [0.9927, 0.9958, 0.9749, 0.9995, 0.9846, 0.9956, 0.9995, 1.0005,\n",
            "          0.9980, 1.0007],\n",
            "         [0.9988, 0.9919, 0.9946, 0.9966, 0.9924, 0.9988, 0.9963, 0.9990,\n",
            "          0.9973, 0.9961],\n",
            "         [0.9973, 0.9944, 0.9978, 0.9919, 0.9978, 0.9985, 0.9973, 0.9971,\n",
            "          0.9961, 0.9993],\n",
            "         [0.9927, 0.9951, 0.9968, 0.9958, 0.9893, 0.9929, 0.9971, 0.9917,\n",
            "          0.9932, 1.0007]],\n",
            "\n",
            "        [[0.9934, 0.9885, 0.9983, 0.9905, 0.9939, 1.0015, 0.9922, 0.9937,\n",
            "          0.9924, 0.9895],\n",
            "         [0.9958, 0.9875, 0.9956, 0.9976, 0.9941, 0.9988, 0.9968, 0.9951,\n",
            "          0.9956, 0.9968],\n",
            "         [0.9919, 0.9929, 0.9932, 0.9971, 0.9958, 0.9939, 0.9949, 0.9976,\n",
            "          0.9949, 0.9934],\n",
            "         [0.9885, 1.0000, 0.9907, 0.9971, 0.9895, 0.9956, 0.9954, 0.9971,\n",
            "          0.9949, 0.9946],\n",
            "         [1.0000, 0.9871, 0.9978, 0.9951, 0.9963, 0.9961, 0.9946, 0.9958,\n",
            "          0.9995, 0.9998],\n",
            "         [0.9973, 0.9746, 0.9937, 0.9946, 0.9980, 0.9905, 0.9934, 1.0010,\n",
            "          0.9983, 0.9976],\n",
            "         [0.9985, 0.9929, 0.9961, 0.9976, 0.9924, 0.9961, 0.9980, 0.9980,\n",
            "          0.9983, 0.9927],\n",
            "         [0.9956, 0.9993, 0.9961, 0.9976, 0.9971, 0.9963, 0.9944, 0.9963,\n",
            "          0.9983, 0.9966],\n",
            "         [0.9966, 0.9961, 0.9934, 0.9990, 0.9937, 0.9900, 0.9963, 0.9797,\n",
            "          0.9951, 0.9954],\n",
            "         [0.9988, 0.9995, 0.9954, 0.9949, 0.9912, 0.9983, 0.9980, 0.9980,\n",
            "          0.9949, 0.9937],\n",
            "         [0.9915, 0.9978, 0.9924, 0.9980, 0.9956, 0.9956, 0.9976, 0.9983,\n",
            "          0.9954, 0.9963],\n",
            "         [0.9963, 0.9917, 0.9944, 0.9985, 0.9956, 0.9990, 0.9937, 0.9946,\n",
            "          0.9961, 0.9966]],\n",
            "\n",
            "        [[0.9951, 0.9966, 0.9995, 0.9956, 0.9932, 1.0005, 0.9924, 0.9976,\n",
            "          0.9966, 0.9980],\n",
            "         [0.9985, 0.9922, 0.9980, 0.9990, 0.9973, 0.9958, 0.9980, 0.9985,\n",
            "          0.9980, 0.9993],\n",
            "         [0.9971, 1.0010, 0.9976, 0.9980, 0.9968, 0.9973, 0.9985, 0.9985,\n",
            "          0.9968, 0.9961],\n",
            "         [1.0005, 0.9966, 1.0002, 0.9939, 0.9961, 0.9966, 0.9961, 0.9958,\n",
            "          0.9939, 0.9951],\n",
            "         [0.9971, 0.9927, 0.9956, 0.9937, 0.9890, 0.9929, 0.9910, 0.9934,\n",
            "          0.9968, 0.9954],\n",
            "         [0.9995, 0.9963, 0.9932, 0.9941, 0.9968, 0.9966, 0.9968, 0.9963,\n",
            "          0.9961, 0.9961],\n",
            "         [0.9976, 0.9985, 0.9990, 0.9976, 0.9978, 0.9971, 0.9944, 0.9990,\n",
            "          0.9980, 0.9995],\n",
            "         [0.9946, 0.9985, 0.9985, 1.0002, 0.9983, 1.0002, 1.0005, 0.9976,\n",
            "          0.9968, 1.0002],\n",
            "         [0.9958, 0.9951, 0.9937, 0.9902, 0.9944, 0.9890, 0.9880, 0.9871,\n",
            "          0.9963, 0.9900],\n",
            "         [0.9954, 0.9978, 0.9988, 0.9976, 0.9978, 0.9985, 0.9958, 0.9985,\n",
            "          0.9968, 0.9934],\n",
            "         [0.9968, 0.9956, 0.9990, 0.9990, 0.9990, 0.9990, 0.9956, 0.9966,\n",
            "          0.9958, 0.9993],\n",
            "         [0.9988, 0.9973, 0.9985, 0.9951, 0.9934, 0.9966, 0.9971, 0.9958,\n",
            "          0.9958, 0.9963]],\n",
            "\n",
            "        [[1.0000, 0.9966, 0.9944, 0.9954, 0.9976, 0.9961, 0.9941, 0.9988,\n",
            "          0.9968, 0.9917],\n",
            "         [0.9941, 0.9954, 0.9949, 0.9993, 0.9983, 0.9937, 0.9978, 0.9915,\n",
            "          0.9985, 1.0000],\n",
            "         [0.9949, 0.9958, 0.9963, 0.9968, 1.0005, 0.9958, 0.9968, 0.9993,\n",
            "          0.9980, 0.9983],\n",
            "         [0.9915, 0.9934, 0.9954, 0.9973, 0.9941, 1.0000, 0.9995, 1.0027,\n",
            "          0.9988, 0.9990],\n",
            "         [0.9956, 0.9993, 0.9993, 1.0000, 0.9980, 0.9968, 0.9934, 0.9968,\n",
            "          0.9985, 0.9937],\n",
            "         [0.9971, 0.9988, 0.9978, 0.9988, 0.9958, 0.9905, 0.9954, 0.9905,\n",
            "          0.9956, 0.9951],\n",
            "         [0.9976, 0.9927, 0.9890, 0.9961, 1.0005, 0.9939, 0.9998, 0.9966,\n",
            "          1.0027, 0.9966],\n",
            "         [0.9878, 0.9956, 0.9958, 0.9966, 1.0000, 1.0002, 0.9985, 0.9954,\n",
            "          0.9946, 0.9946],\n",
            "         [0.9998, 0.9917, 0.9912, 0.9929, 0.9956, 0.9814, 0.9968, 0.9915,\n",
            "          0.9980, 0.9932],\n",
            "         [1.0007, 0.9988, 0.9993, 0.9976, 0.9980, 0.9963, 0.9971, 0.9951,\n",
            "          0.9978, 0.9941],\n",
            "         [1.0010, 0.9963, 0.9980, 0.9971, 0.9971, 0.9927, 0.9958, 0.9983,\n",
            "          0.9966, 0.9978],\n",
            "         [0.9902, 0.9890, 0.9956, 0.9956, 0.9968, 0.9951, 0.9846, 0.9932,\n",
            "          0.9963, 0.9963]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "    model.eval()\n",
        "    eval_accuracy = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            # 배치를 GPU로\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            #logits만 얻기\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]\n",
        "\n",
        "            # CPU로 내리고 numpy 변환\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "            # 배치별 정확도 계산\n",
        "            batch_acc = flat_accuracy(logits, label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.2f}\")\n",
        "    print(f\"Validation Time   : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return avg_accuracy\n",
        "\n",
        "avg_acc = run_validation(model, validation_dataloader, device)"
      ],
      "metadata": {
        "id": "r3GHXPFAyqKm",
        "outputId": "1123cb16-a3db-4862-a2b3-d9ba434eb141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n",
            "Validation Accuracy: 0.80\n",
            "Validation Time   : 0:07:24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "def run_validation(model, validation_dataloader, device):\n",
        "    # 1) Self-Attention 모듈 확인\n",
        "    print(\"== Self-Attention Modules ==\")\n",
        "    for idx, layer in enumerate(model.bert.encoder.layer):\n",
        "        cls_name = layer.attention.self.__class__.__name__\n",
        "        print(f\"  Layer {idx:2d}: {cls_name}\")\n",
        "    print(\"=============================\\n\")\n",
        "\n",
        "    # 2) 준비\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    eval_accuracy = 0.0\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            # Forward pass (logits 얻기)\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            )\n",
        "            logits = outputs[0]              # [B, 2]\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = criterion(logits, b_labels)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n",
        "            #probs_tensor = torch.softmax(logits, dim=1)               # [B,2]\n",
        "            #pos_probs = probs_tensor[:, 1].detach().cpu().numpy()     # positive 클래스 확률\n",
        "            #threshold = 0.6                                           # 원하는 임계치\n",
        "            #preds = (pos_probs > threshold).astype(int)               # 0.6 초과면 1, 아니면 0\n",
        "            label_ids = b_labels.detach().cpu().numpy()\n",
        "            batch_acc = np.sum(preds == label_ids) / len(label_ids)\n",
        "            eval_accuracy += batch_acc\n",
        "\n",
        "            # 저장\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(label_ids.tolist())\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "    # 3) 평균 지표 계산\n",
        "    avg_accuracy = eval_accuracy / nb_eval_steps\n",
        "    avg_loss     = eval_loss / nb_eval_steps\n",
        "    mcc          = matthews_corrcoef(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='binary'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # 4) 결과 출력\n",
        "    print(f\"Validation Loss    : {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Matthews CorrCoef  : {mcc:.4f}\")\n",
        "    print(f\"Precision / Recall / F1: {precision:.4f} / {recall:.4f} / {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "    print(f\"Validation Time    : {format_time(time.time() - t0)}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": avg_accuracy,\n",
        "        \"loss\": avg_loss,\n",
        "        \"mcc\": mcc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "# 사용 예시\n",
        "metrics = run_validation(model, validation_dataloader, device)\n"
      ],
      "metadata": {
        "id": "Y5cgFqujvRRb",
        "outputId": "3a136fb8-c49f-4305-fdc2-dab5ee266c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Self-Attention Modules ==\n",
            "  Layer  0: BertSelfAttentionModified\n",
            "  Layer  1: BertSelfAttentionModified\n",
            "  Layer  2: BertSelfAttentionModified\n",
            "  Layer  3: BertSelfAttentionModified\n",
            "  Layer  4: BertSelfAttentionModified\n",
            "  Layer  5: BertSelfAttentionModified\n",
            "  Layer  6: BertSelfAttentionModified\n",
            "  Layer  7: BertSelfAttentionModified\n",
            "  Layer  8: BertSelfAttentionModified\n",
            "  Layer  9: BertSelfAttentionModified\n",
            "  Layer 10: BertSelfAttentionModified\n",
            "  Layer 11: BertSelfAttentionModified\n",
            "=============================\n",
            "\n",
            "Validation Loss    : 0.6492\n",
            "Validation Accuracy: 0.7882\n",
            "Matthews CorrCoef  : 0.4643\n",
            "Precision / Recall / F1: 0.7831 / 0.9578 / 0.8617\n",
            "Confusion Matrix:\n",
            " [[107 157]\n",
            " [ 25 567]]\n",
            "Validation Time    : 0:07:28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ."
      ],
      "metadata": {
        "id": "cSd2dA-wQ94T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7176e681-76a1-472a-e50b-772d342280ec"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eae585c-7e42-428a-f2a7-c8215fc98644"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5886cbb-9730-47b0-eb5c-3e2c9e9e01e4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b55477-29de-4009-85e6-5ab180148d5b"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b6cfee-0d42-41c4-f264-e9bb798400aa"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "c72f1f6f-0b35-4213-a662-86a1f9a599a2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "4700            ks08      1         NaN   \n",
              "6660            m_02      1         NaN   \n",
              "672             bc01      1         NaN   \n",
              "4400            ks08      1         NaN   \n",
              "6673            m_02      1         NaN   \n",
              "4664            ks08      1         NaN   \n",
              "2257            l-93      1         NaN   \n",
              "4737            ks08      0           *   \n",
              "1680            r-67      1         NaN   \n",
              "4190            ks08      1         NaN   \n",
              "\n",
              "                                               sentence  \n",
              "4700  Whether this is feasible hasn't yet been deter...  \n",
              "6660            The mouse jumped out of the cheese box.  \n",
              "672   Sue moved, and Mary also transferred, her busi...  \n",
              "4400  Fred must have been both singing songs and dri...  \n",
              "6673  The wealthy young man bought his secret fiancé...  \n",
              "4664                             He was kicked by John.  \n",
              "2257                            They skated the canals.  \n",
              "4737              Mary got heard to insult her parents.  \n",
              "1680  It is this hat that it is certain that he was ...  \n",
              "4190                             He is afraid of foxes.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ba598ce-2de9-49d5-8f65-14fdee9c9b61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4700</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Whether this is feasible hasn't yet been deter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6660</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The mouse jumped out of the cheese box.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sue moved, and Mary also transferred, her busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4400</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fred must have been both singing songs and dri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6673</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The wealthy young man bought his secret fiancé...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4664</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He was kicked by John.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2257</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They skated the canals.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4737</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Mary got heard to insult her parents.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is this hat that it is certain that he was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4190</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He is afraid of foxes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ba598ce-2de9-49d5-8f65-14fdee9c9b61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ba598ce-2de9-49d5-8f65-14fdee9c9b61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ba598ce-2de9-49d5-8f65-14fdee9c9b61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-751cb0e9-05d6-494c-99a0-240134ad405c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-751cb0e9-05d6-494c-99a0-240134ad405c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-751cb0e9-05d6-494c-99a0-240134ad405c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence_source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"m_02\",\n          \"r-67\",\n          \"bc01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_notes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"It is this hat that it is certain that he was wearing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2449b4cb-5358-4921-ef31-9351348ea3ca"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  label\n",
              "7892  Bill's reading Shakespeare and Maureen's singi...      0\n",
              "4510  The president could not approve the bill, coul...      0\n",
              "4828   Fred knows which politician for her to vote for.      0\n",
              "4592  As a statesman, scarcely he could do anything ...      0\n",
              "7638                        Susan hopes Susan to sleep.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6960d3eb-d05c-413f-8ab0-2f5dcfff52a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>Bill's reading Shakespeare and Maureen's singi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4510</th>\n",
              "      <td>The president could not approve the bill, coul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4828</th>\n",
              "      <td>Fred knows which politician for her to vote for.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4592</th>\n",
              "      <td>As a statesman, scarcely he could do anything ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7638</th>\n",
              "      <td>Susan hopes Susan to sleep.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6960d3eb-d05c-413f-8ab0-2f5dcfff52a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6960d3eb-d05c-413f-8ab0-2f5dcfff52a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6960d3eb-d05c-413f-8ab0-2f5dcfff52a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-41411899-5e14-4257-92c4-0b6f81f37e19\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41411899-5e14-4257-92c4-0b6f81f37e19')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-41411899-5e14-4257-92c4-0b6f81f37e19 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The president could not approve the bill, could he?\",\n          \"Susan hopes Susan to sleep.\",\n          \"Fred knows which politician for her to vote for.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191cf748-c7a2-4b07-ba26-e0d1433656ed"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55b69ba-2003-494e-b1d4-21d4f65eca6d"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e341edff-f2bc-4875-cb51-2383228f98d8"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92295bf0-bc25-4b89-c46e-fa2d693fdc30"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a07af9-76c1-425c-e8d4-55c761dd182a"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 10\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 10 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbff14a9-9e48-4141-b4cc-115010bbe2bf"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    hidden_dropout_prob=0.2,\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.2, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dacaf6-82ab-4833-fd71-d2ea128d8638"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3"
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8,\n",
        "                  weight_decay=0.01 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = warmup_steps, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944fa595-b456-4cfb-9a67-05df0b9f2c00"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:14.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:00:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:14.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:00:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:06.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:09.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    241.    Elapsed: 0:00:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:00:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "5d392f44-d42c-4ffc-d550-3e6e6d449988"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f08bce-8811-4f2a-b5cd-1f2d975131d8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a78580-ad61-4c2c-cc2d-21ec0354c61a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f0699b-7d45-43f4-955f-55591918d79b"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a57b5e-356e-4f57-8613-b95290baba43"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eccbd9-75c9-4c56-ee3a-a043306c8ca2"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.21713222235566895),\n",
              " 0.0,\n",
              " np.float64(0.34500484066310094),\n",
              " np.float64(0.4127594582445936),\n",
              " np.float64(0.3567530340063379),\n",
              " np.float64(0.6397114734243627),\n",
              " np.float64(0.09759000729485333),\n",
              " 0.0,\n",
              " np.float64(0.8320502943378436),\n",
              " np.float64(0.5633234713140696),\n",
              " np.float64(0.7679476477883045),\n",
              " np.float64(0.6546536707079772),\n",
              " np.float64(0.6397114734243627),\n",
              " np.float64(0.5447047794019222),\n",
              " np.float64(0.394853422012197),\n",
              " np.float64(0.49382916465843113),\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125fd749-0172-4b25-96e8-b0975f796aea"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론 코드"
      ],
      "metadata": {
        "id": "xd5BzXwU8HM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MAX_LEN = 10\n",
        "\n",
        "def predict_with_cordic(model, tokenizer, sentence, device):\n",
        "    \"\"\"\n",
        "    CORDIC-Softmax 패치된 model + tokenizer를 이용해\n",
        "    단일 문장(sentence)에 대해 CoLA 예측을 수행합니다.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 토크나이징 + 패딩\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # GPU/CPU 동일하게 맞추기\n",
        "    inputs = {k: v.to(device) for k, v in encoded.items()}\n",
        "\n",
        "    # 순전파만 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs.get(\"token_type_ids\", None)\n",
        "        )\n",
        "        # HuggingFace 버전 따라 .logits 또는 [0]\n",
        "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
        "\n",
        "    # CORDIC-Softmax로 이미 변환된 attention을 쓰므로\n",
        "    # classification head 출력만 softmax\n",
        "    probs = torch.softmax(logits, dim=-1)    # [1, 2]\n",
        "    pred  = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    return pred, probs.cpu().numpy().flatten()\n",
        "\n",
        "\n",
        "# — 사용 예시 —\n",
        "sentence = \"Here is a sample sentence to test CORDIC inference.\"\n",
        "pred, probs = predict_with_cordic(model, tokenizer, sentence, device)\n",
        "\n",
        "label_name = \"acceptable\" if pred == 1 else \"unacceptable\"\n",
        "print(f\"Sentence        : {sentence}\")\n",
        "print(f\"Predicted label : {pred} ({label_name})\")\n",
        "print(f\"Probabilities   : [0]={probs[0]:.4f}, [1]={probs[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "ddIcD3HipFSO",
        "outputId": "f0bead73-a2f3-40b3-8781-7ebb1136d030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cordic_softmax_2way' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# — 사용 예시 —\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Here is a sample sentence to test CORDIC inference.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_cordic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"acceptable\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"unacceptable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ee95f68f343f>\u001b[0m in \u001b[0;36mpredict_with_cordic\u001b[0;34m(model, tokenizer, sentence, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 순전파만 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-cfef15f4be3a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 2) CORDIC-Softmax으로 대체 (num_labels=2라면 top_2 입력 함수 필요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 여기서는 예시로 두 값에 대한 지수→분모→나눗셈을 직접 호출한다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcordic_softmax_2way\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# logits.shape == [B,2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cordic_softmax_2way' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d731a4d-adf9-475b-a709-34946ac56710"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# 1. 모델 및 토크나이저 로드 (예: 'bert-base-uncased' 사용)\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.cuda()               # GPU로 이동\n",
        "model.eval()               # 평가 모드로 전환\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# 2. 추론할 영어 문장 예시\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "\n",
        "# 3. 문장 토큰화 및 인코딩\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sentence,\n",
        "    add_special_tokens=True,      # [CLS]와 [SEP] 토큰 추가\n",
        "    max_length=10,                # 최대 길이 설정\n",
        "    padding=\"max_length\",         # 최대 길이에 맞춰 패딩\n",
        "    truncation=True,              # 길면 잘라냄\n",
        "    return_tensors=\"pt\"           # 파이토치 텐서 반환\n",
        ")\n",
        "\n",
        "# 4. 텐서를 GPU로 이동\n",
        "inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "\n",
        "# 5. 추론 (forward pass)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs[0]  # 모델의 출력은 튜플이며, 첫 번째 요소가 로짓입니다.\n",
        "\n",
        "# 6. Softmax 적용 (선택 사항) 및 예측 클래스 결정\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "# 7. 결과 출력\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", predicted_class.item())\n",
        "print(\"예측 확률:\", probs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: tensor([[0.7347, 0.2653]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    입력된 문장에 대해 학습된 모델을 사용하여 예측을 수행합니다.\n",
        "    Returns:\n",
        "        predicted_class: 예측된 클래스 (예: 0 또는 1)\n",
        "        probs: 각 클래스의 확률 (numpy 배열)\n",
        "    \"\"\"\n",
        "    # 문장을 토큰화하고 encode_plus를 통해 [CLS], [SEP] 토큰을 추가하며, 패딩/자르기 적용\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,      # [CLS]와 [SEP] 추가\n",
        "        max_length=max_length,        # 최대 길이\n",
        "        padding=\"max_length\",         # 최대 길이에 맞게 패딩\n",
        "        truncation=True,              # 길면 자르기\n",
        "        return_tensors=\"pt\"           # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # GPU로 텐서를 전송\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # 모델을 평가 모드로 전환하고, 추론 시에는 기울기를 계산하지 않도록 설정\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # 모델의 출력은 튜플 형태로, 첫 번째 요소가 logits입니다.\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 사용\n",
        "sentence = \"This is an example sentence for inference.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PITHYJKhPHD",
        "outputId": "c1e48647-320b-42aa-d562-a50a05b01a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is an example sentence for inference.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.73471546 0.26528448]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cordic 코드"
      ],
      "metadata": {
        "id": "oK0EdSFZjeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def top_1200_input(attention_scores):\n",
        "    \"\"\"\n",
        "    1200개의 attention_scores를 120개의 리스트로 나누어 각 리스트를 top 함수에 전달\n",
        "    결과는 원본 형태 (1, 12, 10, 10)로 반환\n",
        "    \"\"\"\n",
        "    if isinstance(attention_scores, torch.Tensor):\n",
        "        attention_scores = attention_scores.detach().cpu().numpy()  # ✅ detach() 추가\n",
        "\n",
        "    batch_size, num_heads, seq_length, _ = attention_scores.shape\n",
        "    result_arrays = np.zeros((batch_size, num_heads, seq_length, seq_length))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        for row in range(seq_length):\n",
        "            for col in range(seq_length // 10):\n",
        "                input_values = attention_scores[0, head, row, col * 10:(col + 1) * 10]\n",
        "                result = top(*input_values)\n",
        "                result_arrays[0, head, row, col * 10:(col + 1) * 10] = result\n",
        "\n",
        "    # ✅ numpy -> torch 변환할 때 `.to(device)` 추가\n",
        "    return torch.tensor(result_arrays, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def float_to_fixed_point(value, int_bits=7, frac_bits=13):\n",
        "    \"\"\"\n",
        "    실수를 32비트 Fixed-Point 바이너리로 변환하는 함수.\n",
        "    - 정수부는 7비트 (Signed, 2의 보수)\n",
        "    - 소수부는 13비트 (항상 양수)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ PyTorch Tensor 처리\n",
        "    if isinstance(value, torch.Tensor):\n",
        "        value = value.detach().cpu().numpy()\n",
        "\n",
        "    # ✅ NaN 또는 Inf 값 체크 후 예외 처리\n",
        "    if np.isnan(value) or np.isinf(value):\n",
        "        raise ValueError(f\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\")\n",
        "\n",
        "    # ✅ **최대/최소 값 제한 (7비트 표현 범위)**\n",
        "    value = max(min(value, 63), -64)\n",
        "\n",
        "    # ✅ 정수부와 소수부 분리\n",
        "    int_part = np.floor(value).astype(int)\n",
        "    frac_part = abs(value - int_part)  # 소수 부분\n",
        "\n",
        "    # ✅ 2의 보수 변환 (음수 처리)\n",
        "    if int_part < 0:\n",
        "        int_part = (1 << int_bits) + int_part\n",
        "\n",
        "    int_binary = format(int_part, f'0{int_bits}b')\n",
        "\n",
        "    # ✅ 12비트 0 추가 (BERT 출력 형식 유지)\n",
        "    int_binary = \"0\" * 12 + int_binary\n",
        "\n",
        "    # ✅ 소수부 변환 (13비트)\n",
        "    frac_binary = \"\"\n",
        "    for _ in range(frac_bits):\n",
        "        frac_part *= 2\n",
        "        if frac_part >= 1:\n",
        "            frac_binary += \"1\"\n",
        "            frac_part -= 1\n",
        "        else:\n",
        "            frac_binary += \"0\"\n",
        "\n",
        "    # ✅ 최종 32비트 바이너리 문자열 생성\n",
        "    binary_string = int_binary + frac_binary\n",
        "\n",
        "    # ✅ `binary_string`이 음수 값을 포함하는지 확인 후 처리\n",
        "    if \"-\" in binary_string:\n",
        "        raise ValueError(f\"[ERROR] 잘못된 바이너리 문자열 변환 감지: {binary_string}\")\n",
        "\n",
        "    # ✅ 20비트 정수 변환 (부호 처리)\n",
        "    fixed_binary = int(binary_string, 2)\n",
        "    if value < 0:\n",
        "        fixed_binary = (1 << 20) - fixed_binary  # 2의 보수 변환\n",
        "\n",
        "    lower_20_bits = fixed_binary & 0xFFFFF  # 20비트 마스킹\n",
        "\n",
        "    return lower_20_bits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def binary_to_decimal(binary_str):\n",
        "    # 16비트 중 앞 3비트는 정수부, 뒤 13비트는 소수부\n",
        "    int_part = int(binary_str[:3], 2)  # 정수부\n",
        "    frac_part = int(binary_str[3:], 2) / (2 ** 13)  # 소수부를 2^13으로 나눔\n",
        "    return int_part + frac_part  # 정수부와 소수부 합산\n",
        "\n",
        "def hex_to_binary(hex_str):\n",
        "    \"\"\"\n",
        "    16비트 헥스 값을 16비트 바이너리 문자열로 변환하는 함수\n",
        "\n",
        "    :param hex_str: 변환할 16비트 헥스 값 (예: \"1A2F\" 또는 0x1A2F)\n",
        "    :return: 16비트 바이너리 문자열 (예: \"0001101000101111\")\n",
        "    \"\"\"\n",
        "    # hex_str가 정수형일 경우 문자열로 변환\n",
        "    if isinstance(hex_str, int):\n",
        "        hex_str = format(hex_str, 'X')  # 16진수 대문자로 변환\n",
        "\n",
        "    # 16진수를 10진수로 변환 후, 16비트 이진수로 변환\n",
        "    binary_str = bin(int(hex_str, 16))[2:].zfill(16)\n",
        "    return binary_str\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "# 테스트 예제\n",
        "\n",
        "\n",
        "def top(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10) : #20bit data\n",
        "\n",
        "    data_11 = float_to_fixed_point(data_1)\n",
        "    data_22 = float_to_fixed_point(data_2)\n",
        "    data_33 = float_to_fixed_point(data_3)\n",
        "    data_44 = float_to_fixed_point(data_4)\n",
        "    data_55 = float_to_fixed_point(data_5)\n",
        "    data_66 = float_to_fixed_point(data_6)\n",
        "    data_77 = float_to_fixed_point(data_7)\n",
        "    data_88 = float_to_fixed_point(data_8)\n",
        "    data_99 = float_to_fixed_point(data_9)\n",
        "    data_1010 = float_to_fixed_point(data_10)\n",
        "\n",
        "    data_list = [data_11, data_22, data_33, data_44, data_55, data_66, data_77, data_88, data_99, data_1010]\n",
        "    #data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    int_list = [0] * 10 #exp_int input\n",
        "    exp_int_output = [0]*10 #exp_int output\n",
        "    fraction_list=[0]*10 #cordic_exu input\n",
        "    exp_fraction_output = [0]*10 #cordic_exu output\n",
        "    exp_whole=[0]*10 #cordic_exu +cordic_int\n",
        "    exp_trunc=[0]*10\n",
        "    exp_accum_input=[0]*10 # accumulator input  (exponential)\n",
        "    exp_accum_output=[0]*1\n",
        "    x_divider = [0] * 10 #cordic diu input\n",
        "    y_dividend = [0] * 10 #cordic diu input\n",
        "    data_out = [0] * 10\n",
        "    binary_values = [0] * 10\n",
        "    int_values = [0.0] * 10\n",
        "    for i in range(10):  # int part\n",
        "        int_list[i] = data_list[i] >> 13\n",
        "    exp_int_output[0], exp_int_output[1], exp_int_output[2], exp_int_output[3], exp_int_output[4], exp_int_output[5], exp_int_output[6], exp_int_output[7], exp_int_output[8], exp_int_output[9]=exp_int(int_list[0], int_list[1], int_list[2], int_list[3], int_list[4], int_list[5], int_list[6], int_list[7], int_list[8], int_list[9])\n",
        "\n",
        "    for i in range(10):  # fraction part\n",
        "        fraction_list[i] = (data_list[i] & 0x1FFF) << 1  # 하위 13비트를 가져오고, 뒤에 0을 추가\n",
        "    exp_fraction_output[0], exp_fraction_output[1], exp_fraction_output[2], exp_fraction_output[3], exp_fraction_output[4], exp_fraction_output[5], exp_fraction_output[6], exp_fraction_output[7], exp_fraction_output[8], exp_fraction_output[9] = cordic_exu(fraction_list[0], fraction_list[1], fraction_list[2], fraction_list[3], fraction_list[4], fraction_list[5], fraction_list[6], fraction_list[7], fraction_list[8], fraction_list[9])\n",
        "\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_whole[i] = exp_int_output[i] * exp_fraction_output[i]\n",
        "\n",
        "    for i in range(10):\n",
        "       exp_trunc[i] = (exp_whole[i] >> 14) & 0xFFFFF  # 33~14 비트를 추출 (20비트)\n",
        "    for i in range(10):\n",
        "       exp_accum_input[i] = (exp_trunc[i] >> 4) & 0xFFFF\n",
        "\n",
        "    exp_accum_output[0] = cordic_accumulator(exp_accum_input[0],exp_accum_input[1],exp_accum_input[2],exp_accum_input[3],exp_accum_input[4],exp_accum_input[5],exp_accum_input[6],exp_accum_input[7],exp_accum_input[8],exp_accum_input[9])\n",
        "\n",
        "\n",
        "\n",
        "    # denominator_sf[i]에서 18~4 비트 추출 후, 앞에 0을 붙여서 x_divider에 할당\n",
        "    x_divider[0] = (exp_accum_output[0] >> 4) & 0x7FFF  # 18~4 비트를 추출 (15비트)\n",
        "\n",
        "    for i in range(10):\n",
        "    # numerator_sf[i]에서 15~4 비트 추출 후, 앞에 4개의 0을 붙여서 y_dividend에 할당\n",
        "        y_dividend[i] = (exp_accum_input[i] >> 4)  # 15~4 비트를 추출 (12비트)\n",
        "\n",
        "    data_out[0],data_out[1],data_out[2],data_out[3],data_out[4],data_out[5],data_out[6],data_out[7],data_out[8],data_out[9], = cordic_diu (x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],x_divider[0],y_dividend[0],y_dividend[1],y_dividend[2],y_dividend[3],y_dividend[4],y_dividend[5],y_dividend[6],y_dividend[7],y_dividend[8],y_dividend[9])\n",
        "\n",
        "    for i in range(10):\n",
        "        binary_values[i] = hex_to_binary(data_out[i])\n",
        "       # print(binary_values[i])\n",
        "\n",
        "    for i in range(10):\n",
        "        int_values[i] = binary_to_decimal(binary_values[i])\n",
        "\n",
        "    return int_values[0],int_values[1],int_values[2],int_values[3],int_values[4],int_values[5],int_values[6],int_values[7],int_values[8],int_values[9]\n",
        "\n",
        "def exp_int(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_to_int = [0]*10\n",
        "    int_output=[0]*10\n",
        "    for i in range(10):\n",
        "        # 이진수로 변환하여 signed_binary_to_int 함수에 전달\n",
        "        binary_str = bin(data_list[i])[2:].zfill(7)  # 20비트 이진수 문자열로 변환\n",
        "        data_to_int[i] = signed_binary_to_int(binary_str)\n",
        "\n",
        "    i_max = max(data_to_int)\n",
        "    offset=signed_binary_to_int(bin(0b0001011-i_max)[2:].zfill(7)) #offset\n",
        "\n",
        "    for i in range(10):\n",
        "        int_reg=data_to_int[i]+offset\n",
        "        #print(int_reg)\n",
        "        if int_reg==0 :\n",
        "            int_output[i]=0b0000_0000_0000_0001_00\n",
        "        elif int_reg==1 :\n",
        "            int_output[i]=0b0000_0000_0000_0010_11\n",
        "        elif int_reg==2 :\n",
        "            int_output[i]=0b0000_0000_0000_0111_10\n",
        "        elif int_reg==3 :\n",
        "            int_output[i]=0b0000_0000_0001_0100_00\n",
        "        elif int_reg==4 :\n",
        "            int_output[i]=0b0000_0000_0011_0110_10\n",
        "        elif int_reg==5 :\n",
        "            int_output[i]=0b0000_0000_1001_0100_10\n",
        "        elif int_reg==6 :\n",
        "            int_output[i]=0b0000_0001_1001_0011_10\n",
        "        elif int_reg==7 :\n",
        "            int_output[i]=0b0000_0100_0100_1000_11\n",
        "        elif int_reg==8 :\n",
        "            int_output[i]=0b0000_1011_1010_0101_00\n",
        "        elif int_reg==9 :\n",
        "            int_output[i]=0b0001_1111_1010_0111_00\n",
        "        elif int_reg==10 :\n",
        "            int_output[i]=0b0101_0110_0000_1010_10\n",
        "        elif int_reg==11 :\n",
        "            int_output[i]=0b1110_1001_1110_0010_01\n",
        "        else :\n",
        "            int_output[i]=0\n",
        "\n",
        "    return  int_output[0], int_output[1], int_output[2], int_output[3], int_output[4], int_output[5], int_output[6], int_output[7], int_output[8], int_output[9]\n",
        "\n",
        "\n",
        "def cordic_exu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_exu_pipe(data_list[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "def cordic_exu_pipe(z_in):\n",
        "    x_1, y_1, z_1=exp_unit(0b1001101010001111, 0, z_in, 0b0010001100100111,1)\n",
        "    x_2, y_2, z_2=exp_unit(x_1, y_1, z_1,0b0001000001011000,2)\n",
        "    x_3, y_3, z_3 = exp_unit(x_2, y_2, z_2, 0b0000100000001010, 3)\n",
        "    x_4, y_4, z_4 = exp_unit(x_3, y_3, z_3, 0b0000010000000001, 4)\n",
        "    x_5, y_5, z_5 = exp_unit(x_4, y_4, z_4, 0b0000001000000000, 5)\n",
        "    x_6, y_6, z_6 = exp_unit(x_5, y_5, z_5, 0b0000000100000000, 6)\n",
        "    x_7, y_7, z_7 = exp_unit(x_6, y_6, z_6, 0b0000000010000000, 7)\n",
        "    x_8, y_8, z_8 = exp_unit(x_7, y_7, z_7, 0b0000000001000000, 8)\n",
        "    x_9, y_9, z_9 = exp_unit(x_8, y_8, z_8, 0b0000000000100000, 9)\n",
        "    x_10, y_10, z_10 = exp_unit(x_9, y_9, z_9, 0b0000000000010000, 10)\n",
        "    x_11, y_11, z_11 = exp_unit(x_10, y_10, z_10, 0b0000000000001000, 11)\n",
        "    x_12, y_12, z_12 = exp_unit(x_11, y_11, z_11, 0b0000000000000100, 12)\n",
        "    x_13, y_13, z_13 = exp_unit(x_12, y_12, z_12, 0b0000000000000010, 13)\n",
        "    x_14, y_14, z_14 = exp_unit(x_13, y_13, z_13, 0b0000000000000010, 14)\n",
        "\n",
        "\n",
        "    exp_frac_reg=x_14+y_14\n",
        "    exp_frac = (exp_frac_reg >> 1) & 0xFFFF\n",
        "    #print(bin(exp_frac))\n",
        "    return exp_frac\n",
        "\n",
        "\n",
        "\n",
        "def exp_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "    x_cal = 0\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if z_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "        # 시계방향 (downward)\n",
        "        x_cal = x_in - (y_in >> pipe_num)\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "    else:\n",
        "        # 반시계방향 (upward)\n",
        "        x_cal = x_in + (y_in >> pipe_num)\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return x_cal, y_cal, z_cal\n",
        "\n",
        "\n",
        "def signed_binary_to_int(binary_str):\n",
        "    \"\"\"\n",
        "    2의 보수 표현된 이진수를 정수로 변환하는 함수.\n",
        "    \"\"\"\n",
        "    # ✅ \"0b\" 제거\n",
        "    binary_str = binary_str.replace(\"0b\", \"\")\n",
        "\n",
        "    # ✅ 이진수 길이 확인\n",
        "    n = len(binary_str)\n",
        "\n",
        "    # ✅ 부호 비트 확인 (최상위 비트가 1이면 음수)\n",
        "    if binary_str[0] == '1':\n",
        "        # 2의 보수 변환 (음수)\n",
        "        return int(binary_str, 2) - (1 << n)\n",
        "    else:\n",
        "        # 양수 변환\n",
        "        return int(binary_str, 2)\n",
        "\n",
        "\n",
        "def accumulator(sequence_in, exponential, state):\n",
        "    \"\"\"\n",
        "    입력값을 받아 sum1, sum2, denominator_sf 값을 업데이트하고 출력.\n",
        "    \"\"\"\n",
        "\n",
        "    # accumulator_SEL 토글\n",
        "    state[\"accumulator_SEL\"] = (state[\"accumulator_SEL\"] + sequence_in) & 1\n",
        "\n",
        "    # valid 시프트 레지스터 갱신\n",
        "    state[\"valid\"] = [sequence_in] + state[\"valid\"][:-1]\n",
        "\n",
        "    if state[\"accumulator_SEL\"]:  # accumulator 1 사용\n",
        "        state[\"sum1\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum2\"] = exponential  # sum2 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum1\"]  # denominator_sf 업데이트\n",
        "    else:  # accumulator 2 사용\n",
        "        state[\"sum2\"] += exponential\n",
        "        if sequence_in:\n",
        "            state[\"sum1\"] = exponential  # sum1 리셋\n",
        "        if state[\"valid\"][9]:\n",
        "            state[\"denominator_sf\"] = state[\"sum2\"]  # denominator_sf 업데이트\n",
        "\n",
        "    sequence_out = state[\"valid\"][0]\n",
        "\n",
        "    return  state[\"denominator_sf\"]\n",
        "\n",
        "\n",
        "def cordic_accumulator (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10):\n",
        "    data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    state_accumulator = {\n",
        "    \"denominator_sf\": 0,\n",
        "    \"accumulator_SEL\": 0,\n",
        "    \"valid\": [0] * 11,\n",
        "    \"sum1\": 0,\n",
        "    \"sum2\": 0\n",
        "}\n",
        "\n",
        "    exp_fraction[0]=  accumulator(1,data_list[0],state_accumulator)\n",
        "    exp_fraction[1]=  accumulator( 0 ,data_list[1],state_accumulator)\n",
        "    exp_fraction[2]=  accumulator( 0 ,data_list[2],state_accumulator)\n",
        "    exp_fraction[3]=  accumulator( 0 ,data_list[3],state_accumulator)\n",
        "    exp_fraction[4]=  accumulator( 0 ,data_list[4],state_accumulator)\n",
        "    exp_fraction[5]=  accumulator( 0 ,data_list[5],state_accumulator)\n",
        "    exp_fraction[6]=  accumulator( 0 ,data_list[6],state_accumulator)\n",
        "    exp_fraction[7]=  accumulator( 0 ,data_list[7],state_accumulator)\n",
        "    exp_fraction[8]=  accumulator( 0 ,data_list[8],state_accumulator)\n",
        "    exp_fraction[9]=  accumulator( 0 ,data_list[9],state_accumulator)\n",
        "    #print(hex(exp_fraction[9]))\n",
        "\n",
        "    return  exp_fraction[9]\n",
        "\n",
        "\n",
        "\n",
        "def fifo(exponential, state):\n",
        "\n",
        "\n",
        "        # FIFO 시프트 (FIFO_reg[i] = FIFO_reg[i-1])\n",
        "    state[\"FIFO_reg\"] = [exponential] + state[\"FIFO_reg\"][:-1]\n",
        "\n",
        "    numerator_sf = state[\"FIFO_reg\"][9]\n",
        "\n",
        "\n",
        "    return numerator_sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def div_unit(x_in, y_in, z_in, lut_val, pipe_num):\n",
        "    # 16-bit 입력 값\n",
        "\n",
        "    y_cal = 0\n",
        "    z_cal = 0\n",
        "\n",
        "    if y_in & (1 << 15):  # z_in[15] = MSB를 확인 (시계방향: z_in[15]가 1)\n",
        "\n",
        "\n",
        "        y_cal = y_in + (x_in >> pipe_num)\n",
        "        z_cal = z_in - lut_val\n",
        "    else:\n",
        "\n",
        "\n",
        "        y_cal = y_in - (x_in >> pipe_num)\n",
        "        z_cal = z_in + lut_val\n",
        "\n",
        "    if z_cal < 0:\n",
        "        # 음수일 경우 2의 보수를 구하고 16비트로 마스킹\n",
        "        z_cal = (z_cal + (1 << 16)) & 0xFFFF\n",
        "    else:\n",
        "        z_cal = z_cal & 0xFFFF\n",
        "    # 결과값 반환 (튜플로 출력)\n",
        "\n",
        "    return  y_cal, z_cal\n",
        "def cordic_diu_pipe(x_in, y_in):\n",
        "    y_1, z_1 = div_unit(x_in, y_in, 0, 0b0010000000000000, 0)\n",
        "    y_2, z_2 = div_unit(x_in, y_1, z_1, 0b0001000000000000, 1)\n",
        "    y_3, z_3 = div_unit(x_in, y_2, z_2, 0b0000100000000000, 2)\n",
        "    y_4, z_4 = div_unit(x_in, y_3, z_3, 0b0000010000000000, 3)\n",
        "    y_5, z_5 = div_unit(x_in, y_4, z_4, 0b0000001000000000, 4)\n",
        "    y_6, z_6 = div_unit(x_in, y_5, z_5, 0b0000000100000000, 5)\n",
        "    y_7, z_7 = div_unit(x_in, y_6, z_6, 0b0000000010000000, 6)\n",
        "    y_8, z_8 = div_unit(x_in, y_7, z_7, 0b0000000001000000, 7)\n",
        "    y_9, z_9 = div_unit(x_in, y_8, z_8, 0b0000000000100000, 8)\n",
        "    y_10, z_10 = div_unit(x_in, y_9, z_9, 0b0000000000010000, 9)\n",
        "    y_11, z_11 = div_unit(x_in, y_10, z_10, 0b0000000000001000, 10)\n",
        "    y_12, z_12 = div_unit(x_in, y_11, z_11, 0b0000000000000100, 11)\n",
        "    y_13, z_13 = div_unit(x_in, y_12, z_12, 0b0000000000000010, 12)\n",
        "    y_14, z_14 = div_unit(x_in, y_13, z_13, 0b0000000000000001, 13)\n",
        "    divided_val = z_14  # Final z value representing atan(y/x)\n",
        "    return divided_val\n",
        "\n",
        "def cordic_diu (data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10,data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20):\n",
        "    data_list_x = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10]\n",
        "    data_list_y = [data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20]\n",
        "    exp_fraction =[0]*10\n",
        "\n",
        "    for i in range(10):\n",
        "        exp_fraction[i]=  cordic_diu_pipe(data_list_x[i],data_list_y[i])\n",
        "        #print(bin(data_list[i]))\n",
        "\n",
        "    return exp_fraction[0], exp_fraction[1], exp_fraction[2], exp_fraction[3], exp_fraction[4], exp_fraction[5], exp_fraction[6], exp_fraction[7], exp_fraction[8], exp_fraction[9]\n",
        "\n",
        "\n",
        "top(1.548621,\n",
        "2.154268,\n",
        "0.15548,\n",
        "1.358942,\n",
        "3.54985,\n",
        "2.1578712,\n",
        "-1.58952,\n",
        "-0.248623,\n",
        "1.6685123,\n",
        "-2.68856\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "JuXVpD_Fjj7q",
        "outputId": "92b4e0a7-8f92-4fb4-e9da-9a1ba0f0b8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0528564453125,\n",
              " 0.0977783203125,\n",
              " 0.0128173828125,\n",
              " 0.0438232421875,\n",
              " 0.3963623046875,\n",
              " 0.0980224609375,\n",
              " 0.0552978515625,\n",
              " 0.0140380859375,\n",
              " 0.0599365234375,\n",
              " 0.1666259765625)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 수정 및 적용 코드"
      ],
      "metadata": {
        "id": "o19OXrVjjoaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# … (BertSelfAttentionModified / BertEncoderModified / BertWithModifiedAttentionForClassification 정의부는 그대로) …\n",
        "\n",
        "# 4. 모델 생성\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "\n",
        "# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\n",
        "checkpoint = torch.load(\"./model/CoLA.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "# 이후 GPU 이동·평가 모드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 예시 추론 함수 (변경 없음)\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=device):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        pred  = torch.argmax(probs, dim=1).item()\n",
        "    return pred, probs.cpu().numpy()\n",
        "\n",
        "# 테스트\n",
        "sentence = \"This is a grammatically acceptable sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "sXS8S2bXX17u",
        "outputId": "8e8a0084-48e7-458f-db5a-5450af90ce01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e186ff2ff0d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ★ 학습시킨 가중치만 불러오기 (절대 구조 정의부는 건드리지 마세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/CoLA.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m                     warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "scMdkDy7tAqU",
        "outputId": "8e4b9b79-2fec-49f1-addb-5207366623b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSequenceClassificationModified(BertForSequenceClassification):\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Softmax 대신 CORDIC을 적용\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "XySJ0nStsisx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "\n",
        "        # 여기서 원래 softmax를 적용하는 대신 CORDIC 기반 함수를 사용합니다.\n",
        "        # 예를 들어, top_1200_input(attention_scores)를 사용하여 softmax 결과를 근사합니다.\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        # 만약 반환된 결과가 numpy 형태라면, torch.tensor로 변환해주어야 합니다.\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # 원래 출력은 (context_layer, attention_probs) 또는 (context_layer,)인데,\n",
        "        # 필요에 따라 raw attention scores도 반환하도록 할 수 있습니다.\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "# 만약 학습된 가중치를 로드해야 한다면 로드합니다.\n",
        "# model.load_state_dict(torch.load(\"your_checkpoint.pt\"), strict=False)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# 이제 이 모델은 CoLA나 다른 영어 문장 분류 작업에 사용할 수 있습니다.\n",
        "# 예시 추론 함수:\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "def predict_sentence(model, tokenizer, sentence, max_length=10, device=\"cuda\"):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "    return predicted_class, probs.cpu().numpy()\n",
        "\n",
        "# 예시 문장으로 테스트\n",
        "sentence = \"This is a grammatically acceptable for sentence.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "print(\"입력 문장:\", sentence)\n",
        "print(\"예측된 클래스:\", pred_class)\n",
        "print(\"예측 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "itlqawMcjmJ3",
        "outputId": "11d60001-ac23-433a-cb2d-a279facb7a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: This is a grammatically acceptable for sentence.\n",
            "예측된 클래스: 0\n",
            "예측 확률: [[0.5131679  0.48683208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 encoder 내 각 레이어의 self-attention 모듈 타입을 출력하여\n",
        "# 수정된 BertSelfAttentionModified가 적용되었는지 확인합니다.\n",
        "print(\"수정된 Attention Layers 확인:\")\n",
        "for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    attn_layer = layer.attention.self\n",
        "    print(f\"Layer {i} self-attention layer type: {type(attn_layer)}\")\n"
      ],
      "metadata": {
        "id": "8WUtGKLuoW2z",
        "outputId": "fa8009ef-7082-49b3-ea5a-13e2553196a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정된 Attention Layers 확인:\n",
            "Layer 0 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 1 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 2 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 3 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 4 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 5 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 6 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 7 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 8 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 9 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 10 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n",
            "Layer 11 self-attention layer type: <class '__main__.BertSelfAttentionModified'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디버깅용 잡동사니코드"
      ],
      "metadata": {
        "id": "H5iP5hhyJuf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print(f\"[TOP] exp_fraction_output[{i}] = {exp_fraction_output[i]}\")\n",
        "    print(f\"[TOP] exp_int_output[{i}] = {exp_int_output[i]}\")\n",
        "    print(f\"[TOP] exp_whole[{i}] = {exp_whole[i]}\")\n",
        "    print(f\"[TOP] exp_trunc[{i}] = {exp_trunc[i]}\")\n",
        "    print(f\"[TOP] exp_accum_input[{i}] = {exp_accum_input[i]}\")\n",
        "    print(f\"[TOP] x_divider = {x_divider[0]}\")\n",
        "    print(f\"[TOP] y_dividend = {y_dividend[i]}\")\n",
        "    print(f\"[TOP] data_out[{i}] = {data_out[i]}\")"
      ],
      "metadata": {
        "id": "rAamcoXWSjnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # ✅ 디버깅용 Q, K 체크\n",
        "        with torch.no_grad():\n",
        "            h = hidden_states.detach().cpu().numpy()\n",
        "            print(\"=== Hidden States 디버깅 ===\")\n",
        "            print(\"min:\", np.min(h), \"max:\", np.max(h))\n",
        "            print(\"NaN 수:\", np.isnan(h).sum(), \"Inf 수:\", np.isinf(h).sum())\n",
        "            q = query_layer.detach().cpu().numpy()\n",
        "            k = key_layer.detach().cpu().numpy()\n",
        "            print(\"=== Q, K 디버깅 ===\")\n",
        "            print(\"Q min/max:\", np.min(q), np.max(q))\n",
        "            print(\"K min/max:\", np.min(k), np.max(k))\n",
        "            print(\"Q NaN 수:\", np.isnan(q).sum(), \"K NaN 수:\", np.isnan(k).sum())\n",
        "            print(\"Q Inf 수:\", np.isinf(q).sum(), \"K Inf 수:\", np.isinf(k).sum())\n",
        "\n",
        "        # attention score 계산 후 clamp\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 계산 직후 ===\")\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item(), \"Inf 수:\", torch.isinf(attention_scores).sum().item())\n",
        "        attention_scores = torch.clamp(attention_scores, min=-10.0, max=10.0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"=== [DEBUG] attention_scores 예시 ===\")\n",
        "            print(attention_scores[0, 0, 0, :10])\n",
        "            print(\"min:\", attention_scores.min().item(), \"max:\", attention_scores.max().item())\n",
        "            print(\"NaN 수:\", torch.isnan(attention_scores).sum().item())\n",
        "        # CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\n",
        "        cordic_attention = top_1200_input(attention_scores)\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "\n",
        "# 2. BertLayerWithNaNCheck: layer 0 내부 모듈 NaN 추적\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n",
        "\n",
        "\n",
        "# 3. BertEncoderModified\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "        self.layer[0] = BertLayerWithNaNCheck(self.layer[0])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_values=None, use_cache=False, output_attentions=False,\n",
        "                output_hidden_states=False, return_dict=True):\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            with torch.no_grad():\n",
        "                hs = hidden_states.detach().cpu().numpy()\n",
        "                if np.isnan(hs).sum() > 0:\n",
        "                    print(f\"[NaN DETECTED] ❌ in hidden_states BEFORE layer {i}\")\n",
        "                else:\n",
        "                    print(f\"[OK] ✅ hidden_states BEFORE layer {i}\")\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask,\n",
        "                head_mask[i] if head_mask is not None else None,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                past_key_values[i] if past_key_values is not None else None,\n",
        "                output_attentions,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "        return (hidden_states,)\n",
        "\n",
        "\n",
        "# 4. BertWithModifiedAttentionForClassification\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 5. Load config and model\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "dTD-BGlHKAh5",
        "outputId": "383af56c-e173-4f09-db40-610c833f616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayerWithNaNCheck(\n",
              "          (layer): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttentionModified(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def predict_sentence(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_class = np.argmax(probs)\n",
        "\n",
        "    return pred_class, probs\n"
      ],
      "metadata": {
        "id": "sgc6czs9DqMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_for_nan(module, input, output):\n",
        "    if isinstance(output, torch.Tensor):\n",
        "        if torch.isnan(output).any():\n",
        "            print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "    elif isinstance(output, (tuple, list)):\n",
        "        for o in output:\n",
        "            if torch.is_tensor(o) and torch.isnan(o).any():\n",
        "                print(f\"[NaN DETECTED] in {module.__class__.__name__}\")\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    module.register_forward_hook(check_for_nan)\n"
      ],
      "metadata": {
        "id": "2QHFLakIFV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BertLayerWithNaNCheck(nn.Module):\n",
        "    def __init__(self, layer):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def forward(self, hidden_states, *args, **kwargs):\n",
        "        print(\"=== [Layer 0] BEFORE ===\")\n",
        "        print(\"min:\", hidden_states.min().item(), \"max:\", hidden_states.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(hidden_states).sum().item(), \"Inf 수:\", torch.isinf(hidden_states).sum().item())\n",
        "\n",
        "        # Attention\n",
        "        hidden_states, *_ = self.layer.attention(hidden_states, *args, **kwargs)\n",
        "        if torch.isnan(hidden_states).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Attention in Layer 0\")\n",
        "\n",
        "        # Intermediate\n",
        "        intermediate_output = self.layer.intermediate(hidden_states)\n",
        "        if torch.isnan(intermediate_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Intermediate in Layer 0\")\n",
        "\n",
        "        # Output\n",
        "        layer_output = self.layer.output(intermediate_output, hidden_states)\n",
        "        if torch.isnan(layer_output).any():\n",
        "            print(\"[NaN DETECTED] ❌ after Output in Layer 0\")\n",
        "\n",
        "        print(\"=== [Layer 0] AFTER ===\")\n",
        "        print(\"min:\", layer_output.min().item(), \"max:\", layer_output.max().item())\n",
        "        print(\"NaN 수:\", torch.isnan(layer_output).sum().item(), \"Inf 수:\", torch.isinf(layer_output).sum().item())\n",
        "\n",
        "        return (layer_output,)\n"
      ],
      "metadata": {
        "id": "gAA7SyorIaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "sentence = \"The cat is sitting on the mat.\"\n",
        "pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "\n",
        "print(\"문장:\", sentence)\n",
        "print(\"예측 클래스:\", pred_class)\n",
        "print(\"클래스별 확률:\", pred_probs)\n"
      ],
      "metadata": {
        "id": "yv0VeRUlDpLp",
        "outputId": "1cd74ea5-ca18-4524-d57c-bed12d1b5f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] ✅ hidden_states BEFORE layer 0\n",
            "=== [Layer 0] BEFORE ===\n",
            "min: -4.571415901184082 max: 3.8990025520324707\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Hidden States 디버깅 ===\n",
            "min: -4.571416 max: 3.8990026\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: -2.1867194 2.275151\n",
            "K min/max: -2.4105966 2.2897592\n",
            "Q NaN 수: 0 K NaN 수: 0\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([ 0.4173, -0.1602, -0.0771,  0.3595,  0.1112, -0.1229, -0.2256, -0.0283,\n",
            "        -0.1147, -0.0984], device='cuda:0')\n",
            "min: -1.3686672449111938 max: 1.3171285390853882\n",
            "NaN 수: 0\n",
            "[NaN DETECTED] ❌ after Attention in Layer 0\n",
            "[NaN DETECTED] ❌ after Intermediate in Layer 0\n",
            "[NaN DETECTED] ❌ after Output in Layer 0\n",
            "=== [Layer 0] AFTER ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "[NaN DETECTED] ❌ in hidden_states BEFORE layer 1\n",
            "=== Hidden States 디버깅 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== Q, K 디버깅 ===\n",
            "Q min/max: nan nan\n",
            "K min/max: nan nan\n",
            "Q NaN 수: 49152 K NaN 수: 49152\n",
            "Q Inf 수: 0 K Inf 수: 0\n",
            "=== [DEBUG] attention_scores 계산 직후 ===\n",
            "min: nan max: nan\n",
            "NaN 수: 49152 Inf 수: 0\n",
            "=== [DEBUG] attention_scores 예시 ===\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
            "min: nan max: nan\n",
            "NaN 수: 49152\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "float_to_fixed_point() - NaN 또는 무한대 값 감지: nan",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-8b7cffed0231>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The cat is sitting on the mat.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-c78350183b4c>\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(model, tokenizer, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1674\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[OK] ✅ hidden_states BEFORE layer {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-79756fe349fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN 수:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# CORDIC 방식으로 softmax 대체 (임시로 softmax로 출력 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcordic_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_1200_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop_1200_input\u001b[0;34m(attention_scores)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_arrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#20bit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdata_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mdata_22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mdata_33\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-584fdc9bac46>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# ✅ NaN 또는 Inf 값 체크 후 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"float_to_fixed_point() - NaN 또는 무한대 값 감지: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# ✅ **최대/최소 값 제한 (7비트 표현 범위)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: float_to_fixed_point() - NaN 또는 무한대 값 감지: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertSelfAttention, BertEncoder, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# 1. BertSelfAttentionModified: 기존 softmax 대신 CORDIC 연산을 적용\n",
        "class BertSelfAttentionModified(BertSelfAttention):\n",
        "    def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
        "                encoder_hidden_states=None, encoder_attention_mask=None,\n",
        "                past_key_value=None, output_attentions=False):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / (self.attention_head_size ** 0.5)\n",
        "        batch_size, num_heads, seq_len, _ = attention_scores.shape\n",
        "        for b in range(batch_size):\n",
        "          for h in range(num_heads):\n",
        "            for row in range(seq_len):\n",
        "              float_row = attention_scores[b, h, row, :10].detach().cpu().numpy().tolist()\n",
        "\n",
        "              if any(np.isnan(f) for f in float_row):\n",
        "                print(f\"[NaN] b={b}, head={h}, row={row} - 입력에 NaN 있음! ❌\")\n",
        "                continue  # 이건 skip하고 다음으로\n",
        "              try:\n",
        "                cordic_attention = top(*float_row)\n",
        "              except Exception as e:\n",
        "                print(f\"[ERROR] top() 실패: {e}\")\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "          sample_row = attention_scores[0, 0, 0, :10]  # [10개 float]\n",
        "          float_row = sample_row.detach().cpu().numpy().tolist()\n",
        "          print(\"[DEBUG] top 입력값:\", float_row)\n",
        "\n",
        "          try:\n",
        "            top_result = top(*float_row)\n",
        "            print(\"[DEBUG] top 출력값:\", top_result)\n",
        "          except Exception as e:\n",
        "            print(\"[ERROR] top에서 예외 발생:\", e)\n",
        "        # CORDIC 방식으로 softmax 대체\n",
        "        cordic_attention = top(*float_row)\n",
        "\n",
        "        if any(np.isnan(c) for c in cordic_attention):\n",
        "          print(f\"[NaN DETECTED] ❌ top() 결과에 NaN 존재! input: {float_row}\")\n",
        "\n",
        "        attention_probs = torch.as_tensor(cordic_attention, dtype=torch.float32, device=hidden_states.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_probs = attention_probs + attention_mask\n",
        "\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        # ⚠️ 먼저 너의 원본 문장 리스트가 있어야 해!\n",
        "# 예: dataset_sentences = [\"문장1\", \"문장2\", ..., \"문장N\"]\n",
        "        # 🧪 validation_dataloader에서 원문 문장 추출 (예시)\n",
        "        dataset_sentences = []\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "          input_ids = batch[0]\n",
        "          for ids in input_ids:\n",
        "            text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "            dataset_sentences.append(text)\n",
        "\n",
        "        for i, sentence in enumerate(dataset_sentences):\n",
        "          try:\n",
        "            pred_class, pred_probs = predict_sentence(model, tokenizer, sentence)\n",
        "          except Exception as e:\n",
        "            print(f\"[❌ NaN 발생] 문장 index = {i}\")\n",
        "            print(\"문장 내용:\", sentence)\n",
        "            print(\"에러 메시지:\", e)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs, attention_scores)\n",
        "        else:\n",
        "            return (context_layer,)\n",
        "\n",
        "# 2. BertEncoderModified: 모든 레이어의 self-attention을 수정된 클래스로 교체\n",
        "class BertEncoderModified(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i in range(config.num_hidden_layers):\n",
        "            self.layer[i].attention.self = BertSelfAttentionModified(config)\n",
        "\n",
        "# 3. BertWithModifiedAttentionForClassification: 최종 모델에서 커스텀 encoder 사용\n",
        "class BertWithModifiedAttentionForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        config.num_labels = 2  # CoLA는 이진 분류 문제\n",
        "        super().__init__(config)\n",
        "        self.bert.encoder = BertEncoderModified(config)\n",
        "\n",
        "# 4. 모델 생성 및 학습/추론\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertWithModifiedAttentionForClassification(config)\n",
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "_dPquKTIGbOE",
        "outputId": "54615d57-7130-49f1-b469-d5b229ca4e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적용 모델 validation"
      ],
      "metadata": {
        "id": "JSRL23_d7voR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "id": "h4m08g6HohMF",
        "outputId": "214cd12b-e10a-47d1-a737-bad6e12eb38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b8146705381d>:34: RuntimeWarning: invalid value encountered in cast\n",
            "  int_part = np.floor(value).astype(int)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e22c35b96d8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The documentation for this `model` function is here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-50e5032ce9fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# (2) CORDIC-Softmax 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# (3) 다시 tensor 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             rows.append(torch.tensor(\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mtop\u001b[0;34m(data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mdata_66\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mdata_77\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata_88\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdata_99\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdata_1010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat_to_fixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b8146705381d>\u001b[0m in \u001b[0;36mfloat_to_fixed_point\u001b[0;34m(value, int_bits, frac_bits)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ✅ 5. 최종 32비트 바이너리 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mfixed_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_binary\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrac_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlower_20_bits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_binary_int\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFFFFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlower_20_bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 2: '000000000000-1111111111111111111111111111111111111111111111111111111100000001111111111111'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 저장 및 로드 코드.\n",
        "path = '/content/model/'\n",
        "torch.save(model.state_dict(), path+\"CoLA.pt\")\n",
        "model.load_state_dict(torch.load(path + \"CoLA.pt\", map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "6f3ddQs0x7V-",
        "outputId": "fcf8bd39-919f-468d-918c-5bcdf78d3e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithModifiedAttentionForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoderModified(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttentionModified(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}